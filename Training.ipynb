{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d32826f1-1369-4eb5-a21b-0e6e548cded3",
   "metadata": {},
   "source": [
    "### Download and make the dataset ready in Kaggle \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26c2ad5c-f43a-4b40-a647-ecc58c71ff16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T16:17:38.693282Z",
     "iopub.status.busy": "2025-07-13T16:17:38.692671Z",
     "iopub.status.idle": "2025-07-13T16:20:31.990912Z",
     "shell.execute_reply": "2025-07-13T16:20:31.990108Z",
     "shell.execute_reply.started": "2025-07-13T16:17:38.693248Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# ## uncomment if The zip file of the dataset isn't downloaded,extraced \n",
    "# !pip install gdown\n",
    "# Copy the link. The file ID is the long string of characters between d/ and /view.\n",
    "#For example, in the URL https://drive.google.com/file/d/1aBcDeFgHiJkLmNoPqRsTuVwXyZ/view?usp=sharing, \n",
    "#the file ID is 1aBcDeFgHiJkLmNoPqRsTuVwXyZ\n",
    "# !mkdir /kaggle/tmp\n",
    "# !gdown  1pzXpA5Cz0DJmjRsLxlqRNnJq-kOUvojb -O /kaggle/tmp/Labeled_CICMODBUS2023.zip\n",
    "# !unzip /kaggle/tmp/Labeled_CICMODBUS2023.zip -d /kaggle/working/\n",
    "\n",
    "# # ## uncomment if the python modules (modbus.py,utils.py ,...) not cloned  and added to the path \n",
    "\n",
    "# !git clone https://github.com/hamid-rd/FLBased-ICS-NIDS.git\n",
    "# import sys\n",
    "# # Add the repository folder to the Python path\n",
    "# repo_path = '/kaggle/working/FLBased-ICS-NIDS'\n",
    "# repo_input_path = '/kaggle/input/training/FLBased-ICS-NIDS'\n",
    "# dataset_path = '/kaggle/input/training/'\n",
    "\n",
    "# for path in {repo_path,repo_input_path,dataset_path}:\n",
    "#     if path not in sys.path:\n",
    "#         sys.path.append(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "601bb537-782e-4266-b619-48cdad4fe6a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T16:25:34.078617Z",
     "iopub.status.busy": "2025-07-13T16:25:34.077721Z",
     "iopub.status.idle": "2025-07-13T16:25:34.430103Z",
     "shell.execute_reply": "2025-07-13T16:25:34.429493Z",
     "shell.execute_reply.started": "2025-07-13T16:25:34.078584Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The CIC Modbus Dataset contains network (pcap) captures and attack logs from a simulated substation network.\n",
      "                The dataset is categorized into two groups: an attack dataset and a benign dataset\n",
      "                The attack dataset includes network traffic captures that simulate various types of Modbus protocol attacks in a substation environment.\n",
      "                The attacks are reconnaissance, query flooding, loading payloads, delay response, modify length parameters, false data injection, stacking Modbus frames, brute force write and baseline replay.\n",
      "                These attacks are based of some techniques in the MITRE ICS ATT&CK framework.\n",
      "                On the other hand, the benign dataset consists of normal network traffic captures representing legitimate Modbus communication within the substation network.\n",
      "                The purpose of this dataset is to facilitate research, analysis, and development of intrusion detection systems, anomaly detection algorithms and other security mechanisms for substation networks using the Modbus protocol.\n",
      "                https://www.unb.ca/cic/datasets/modbus-2023.html\n",
      "                In my custom PyTorch Dataset class,\n",
      "                I utilize the Enhanced CICflowMeter and the Attack logs correlation to extract and label sequential data flows,\n",
      "                preparing them for batch processing with the DataLoader, which is crucial for AI model training.\n",
      "                https://github.com/hamid-rd/FLBased-ICS-NIDS/tree/main\n",
      "\n",
      "                \n",
      "csv files  in the dataset directory founded with the filter:  ready\n",
      "{\n",
      "    \"total_dataset_num\": 170,\n",
      "    \"benign_dataset_num\": 62,\n",
      "    \"attack_dataset_num\": {\n",
      "        \"total_num\": 108,\n",
      "        \"external_num\": 8,\n",
      "        \"compromised-ied_num\": 43,\n",
      "        \"compromised-scada_num\": 57\n",
      "    },\n",
      "    \"attack_logs_num\": {\n",
      "        \"total_num\": 0,\n",
      "        \"external_num\": [],\n",
      "        \"compromised-ied_num\": 0,\n",
      "        \"compromised-scada_num\": 0\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# To test if every thing is okay (modbus.py class and correct number of founded csv files )\n",
    "from modbus import ModbusDataset,ModbusFlowStream\n",
    "\n",
    "# dataset_directory = \"/kaggle/working/ModbusDataset\" \n",
    "# dataset_directory = \"/kaggle/input/training/ModbusDataset\" \n",
    "dataset_directory = \"dataset\" \n",
    "\n",
    "modbus = ModbusDataset(dataset_directory,\"ready\")\n",
    "modbus.summary_print()\n",
    "\n",
    "# Don't forget to save version in kaggle (to save outputs written on the disk (/kaggle/working/))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d238262",
   "metadata": {},
   "source": [
    "### Unsupervised Autoencoder training  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2c01e06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T16:25:38.158958Z",
     "iopub.status.busy": "2025-07-13T16:25:38.158509Z",
     "iopub.status.idle": "2025-07-13T16:25:38.167563Z",
     "shell.execute_reply": "2025-07-13T16:25:38.166807Z",
     "shell.execute_reply.started": "2025-07-13T16:25:38.158938Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np # For standard deviation calculation\n",
    "from modbus import ModbusDataset,ModbusFlowStream\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix,recall_score\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "from utils import load_scalers\n",
    "import random\n",
    "from random import SystemRandom\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import torch.nn.init as init\n",
    "import flwr as fl\n",
    "import ray\n",
    "from collections import Counter\n",
    "from flwr.common import ndarrays_to_parameters\n",
    "\n",
    "def compute_threshold(mse_values,k=1):\n",
    "\n",
    "    \"\"\"\n",
    "    K-SIGMA\n",
    "    Computes the anomaly detection threshold (for marking sample as Intrusion if the IS was greater )\n",
    "    based on the mean and standard deviation of Mean Squared Error (MSE) values.\n",
    "    Formula: thr = mean(MSE) + std(MSE)\n",
    "    Args:\n",
    "    mse_values (torch.Tensor or list/np.array): A tensor or list of MSE values\n",
    "\n",
    "                            obtained from the validation set.\n",
    "    Returns:\n",
    "    float: The calculated threshold.\n",
    "    float: The calculated std.\n",
    "\n",
    "    \"\"\"\n",
    "    if not isinstance(mse_values, torch.Tensor):\n",
    "        mse_values = torch.tensor(mse_values, dtype=torch.float32)\n",
    "    if mse_values.numel() == 0:\n",
    "        return 0.0\n",
    "    mean_mse = torch.mean(mse_values)\n",
    "    std_mse = torch.std(mse_values)\n",
    "    print(\"-----------mse_loss mean : \",f\"{mean_mse.item():.4f}\",\"std:\",f\"{std_mse.item():.4f}\")\n",
    "    threshold = mean_mse + k*std_mse\n",
    "    return threshold.item(),std_mse.item()\n",
    "\n",
    "def vae_loss_function(recon_x, x, mu, logvar,beta =1):\n",
    "    \"\"\"\n",
    "    VAE loss function.\n",
    "    \"\"\"\n",
    "    MSE = nn.functional.mse_loss(recon_x, x, reduction='sum')\n",
    "    KLD = - 0.5 * torch.sum(1+ logvar - mu.pow(2) - logvar.exp())\n",
    "    return (MSE + beta*KLD)\n",
    "\n",
    "def _init_weights( module):\n",
    "    ## for one layer apply Xavier Initialization\n",
    "    if isinstance(module, nn.Linear):\n",
    "        init.xavier_normal_(module.weight)\n",
    "        if module.bias is not None:\n",
    "            init.zeros_(module.bias)\n",
    "    return module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9478520",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T16:25:42.807302Z",
     "iopub.status.busy": "2025-07-13T16:25:42.807033Z",
     "iopub.status.idle": "2025-07-13T16:25:42.941019Z",
     "shell.execute_reply": "2025-07-13T16:25:42.940221Z",
     "shell.execute_reply.started": "2025-07-13T16:25:42.807283Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The CIC Modbus Dataset contains network (pcap) captures and attack logs from a simulated substation network.\n",
      "                The dataset is categorized into two groups: an attack dataset and a benign dataset\n",
      "                The attack dataset includes network traffic captures that simulate various types of Modbus protocol attacks in a substation environment.\n",
      "                The attacks are reconnaissance, query flooding, loading payloads, delay response, modify length parameters, false data injection, stacking Modbus frames, brute force write and baseline replay.\n",
      "                These attacks are based of some techniques in the MITRE ICS ATT&CK framework.\n",
      "                On the other hand, the benign dataset consists of normal network traffic captures representing legitimate Modbus communication within the substation network.\n",
      "                The purpose of this dataset is to facilitate research, analysis, and development of intrusion detection systems, anomaly detection algorithms and other security mechanisms for substation networks using the Modbus protocol.\n",
      "                https://www.unb.ca/cic/datasets/modbus-2023.html\n",
      "                In my custom PyTorch Dataset class,\n",
      "                I utilize the Enhanced CICflowMeter and the Attack logs correlation to extract and label sequential data flows,\n",
      "                preparing them for batch processing with the DataLoader, which is crucial for AI model training.\n",
      "                https://github.com/hamid-rd/FLBased-ICS-NIDS/tree/main\n",
      "\n",
      "                \n",
      "csv files  in the dataset directory founded with the filter:  ready\n",
      "{\n",
      "    \"total_dataset_num\": 170,\n",
      "    \"benign_dataset_num\": 62,\n",
      "    \"attack_dataset_num\": {\n",
      "        \"total_num\": 108,\n",
      "        \"external_num\": 8,\n",
      "        \"compromised-ied_num\": 43,\n",
      "        \"compromised-scada_num\": 57\n",
      "    },\n",
      "    \"attack_logs_num\": {\n",
      "        \"total_num\": 0,\n",
      "        \"external_num\": [],\n",
      "        \"compromised-ied_num\": 0,\n",
      "        \"compromised-scada_num\": 0\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# dataset_directory = \"/kaggle/input/training/ModbusDataset\" # change this to the folder contain benign and attack subdirs\n",
    "dataset_directory = \"dataset\" \n",
    "modbus = ModbusDataset(dataset_directory,\"ready\")\n",
    "modbus.summary_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dede4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# AutoEncoder (AE)\n",
    "class AE(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder: (76-32-16-4-2)\n",
    "    Decoder: (2-4-16-32-76)\n",
    "    \"\"\"\n",
    "    def __init__(self,input_dim=76):\n",
    "        super(AE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        x_recon = self.decoder(z)\n",
    "        return x_recon\n",
    "\n",
    "\n",
    "# Variational AutoEncoder (VAE)\n",
    "class VAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder: (76-32-16-4-2 for mu and log_var)\n",
    "    Decoder: (2-4-16-32-76)\n",
    "    return x_recon, mu, logvar\n",
    "    \"\"\"\n",
    "    def __init__(self,input_dim=76):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 4),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(4, 2)\n",
    "        self.fc_logvar = nn.Linear(4, 2)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, input_dim),\n",
    "            nn.Sigmoid()\n",
    "                    )\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu = self.fc_mu(h)\n",
    "        logvar = self.fc_logvar(h)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_recon = self.decoder(z)\n",
    "        return x_recon, mu, logvar\n",
    "\n",
    "    \n",
    "class AAE_Encoder(nn.Module):\n",
    "    def __init__(self,input_dim=76):\n",
    "        \"\"\"\n",
    "        Encoder(Generator):(76-32-16-4-2)\n",
    "        \"\"\"\n",
    "        super(AAE_Encoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 16),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(16, 4),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(4, 2))\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "class AAE_Decoder(nn.Module):\n",
    "    def __init__(self,input_dim=76):\n",
    "        super(AAE_Decoder, self).__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2, 4),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(4, 16),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(16, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.decoder(x)\n",
    "class AAE_Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AAE_Discriminator, self).__init__()\n",
    "        # corrected to 2-16-4-1\n",
    "        self.discriminator = nn.Sequential(\n",
    "            nn.Linear(2, 16),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(16, 4),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(4, 1), \n",
    "            nn.Sigmoid()\n",
    "        )    \n",
    "    def forward(self, x):\n",
    "        return self.discriminator(x)\n",
    " \n",
    "class AdversarialAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AdversarialAutoencoder, self).__init__()\n",
    "        self.encoder = AAE_Encoder()\n",
    "        self.decoder = AAE_Decoder()\n",
    "        self.discriminator = AAE_Discriminator()\n",
    "    def forward(self, x):\n",
    "        fake_z = self.encoder(x)\n",
    "        x_recon = self.decoder(fake_z)\n",
    "        return fake_z,x_recon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436b79f1",
   "metadata": {},
   "source": [
    "### Part a: Centralized learning \n",
    "\n",
    "##### You can go from here right to the FL part\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d2e0ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T08:02:58.408647Z",
     "iopub.status.busy": "2025-07-13T08:02:58.407931Z",
     "iopub.status.idle": "2025-07-13T08:02:58.430831Z",
     "shell.execute_reply": "2025-07-13T08:02:58.430062Z",
     "shell.execute_reply.started": "2025-07-13T08:02:58.408625Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_eval(model,train_dataloader,val_dataloader,test_dataloader,learning_rates= [5e-6,1e-7,5e-5,1e-5,1e-6],\n",
    "               weight_decays=[1e-5,1e-4,1e-7],shuffle_files=True,num_epochs=20,eval_epoch=4,criterion_method=\"mse\", k_range=[1,3],train_model=True):\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model=model.to(device)\n",
    "    if criterion_method==\"bce\":\n",
    "        criterion = nn.BCELoss(reduction='sum').to(device)\n",
    "        eval_criterion = nn.BCELoss(reduction='none').to(device)\n",
    "    else: #mse\n",
    "        criterion = nn.MSELoss(reduction='sum').to(device)\n",
    "        eval_criterion = nn.MSELoss(reduction='none').to(device)\n",
    "    best_f1=0 #to save best version of the model during test\n",
    "    best_recall=0 #to save best version of the model during test\n",
    "\n",
    "    for lr, wd in itertools.product(learning_rates, weight_decays):\n",
    "        if model._get_name()==\"AdversarialAutoencoder\":\n",
    "            adversarial_criterion= nn.BCELoss(reduction=\"sum\")\n",
    "            optimizer_D = optim.SGD(model.discriminator.parameters(), lr=lr, weight_decay=wd)\n",
    "            optimizer_G =  optim.SGD(list(model.encoder.parameters()) + list(model.decoder.parameters()), lr=lr, weight_decay=wd)\n",
    "        else:\n",
    "            AE_optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "            ### new code\n",
    "            # AE_optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "        print(f\"\\n==================  lr={lr}, wd={wd} ==================\")\n",
    "        if train_model==True:\n",
    "            model.apply(_init_weights)\n",
    "        for epoch in range(num_epochs):\n",
    "            if train_model==True:\n",
    "                time_1 = time.time()\n",
    "                model.train()\n",
    "                train_loss = 0\n",
    "                ## for AAE\n",
    "                Discriminator_loss = 0\n",
    "                if shuffle_files:\n",
    "                    sys_rand = SystemRandom()\n",
    "                    sys_rand.shuffle(train_dataloader.dataset.csv_files)\n",
    "                for sequences, labels in train_dataloader:\n",
    "                    sequences=sequences.squeeze().to(device)\n",
    "                    if labels.sum()!=0:\n",
    "                        continue\n",
    "                    if model._get_name()==\"AdversarialAutoencoder\":\n",
    "                        target_ones= torch.ones(sequences.size(0), 1,device=device,dtype=torch.float)\n",
    "                        target_zeros= torch.zeros(sequences.size(0), 1,device=device,dtype=torch.float)\n",
    "                        random_latent = torch.randn(sequences.size(0), 2, device=device)\n",
    "                        optimizer_G.zero_grad()\n",
    "                        fake_z,decoded_seq = model(sequences)\n",
    "                        G_loss = 0.001*adversarial_criterion(model.discriminator(fake_z),target_ones ) + 0.999*criterion(decoded_seq, sequences)\n",
    "                        G_loss.backward()\n",
    "                        optimizer_G.step()\n",
    "                        # 2) discriminator loss\n",
    "                        optimizer_D.zero_grad()\n",
    "                        real_loss = adversarial_criterion(model.discriminator(random_latent), target_ones)\n",
    "                        fake_loss = adversarial_criterion(model.discriminator(fake_z.detach()),  target_zeros)\n",
    "                        D_loss = 0.5*(real_loss + fake_loss)\n",
    "                        D_loss.backward()\n",
    "                        optimizer_D.step()\n",
    "                        train_loss+=G_loss.item()\n",
    "                        Discriminator_loss+=D_loss.item()   \n",
    "                    else:\n",
    "                        AE_optimizer.zero_grad()\n",
    "                        if model._get_name()==\"AE\":\n",
    "                            recon = model(sequences)\n",
    "                            loss = criterion(recon, sequences) / sequences.size(0)\n",
    "                        elif model._get_name()==\"VAE\" :\n",
    "                            recon, mu, logvar = model(sequences)\n",
    "                            loss = vae_loss_function(recon, sequences, mu, logvar) /sequences.size(0)\n",
    "                        loss.backward()\n",
    "                        AE_optimizer.step()\n",
    "                        train_loss += loss.item()\n",
    "                print(f\"Train : time {(time.time()-time_1):.2f} s\",\n",
    "                f\"Epoch {epoch+1}\")\n",
    "                if model._get_name()==\"AdversarialAutoencoder\":\n",
    "                    print(f\"Generator Loss: {train_loss / len(train_dataloader):.4f}\",\n",
    "                        f\"Discriminator Loss: {Discriminator_loss / len(train_dataloader):.4f}\")\n",
    "                else:\n",
    "                    print(f\"Train Loss: {train_loss / len(train_dataloader):.4f}\")\n",
    "            # Evaluate part\n",
    "            if (epoch + 1) % eval_epoch == 0:\n",
    "                model.eval() \n",
    "                all_val_losses = []\n",
    "                all_val_labels = []\n",
    "                print(f\"--- Running Evaluation for Epoch {epoch+1} lr ={lr} wd {wd} ---\")\n",
    "                with torch.no_grad():\n",
    "                    for sequences, labels in val_dataloader:\n",
    "                        sequences = sequences.squeeze().to(device) \n",
    "                        if labels.sum()!=0:\n",
    "                            continue\n",
    "                        if criterion_method==\"bce\":\n",
    "                            ## may test features be greater than 1 after scaling \n",
    "                            sequences=torch.clamp(sequences, min=0.0, max=1.0)      \n",
    "                        if model._get_name()==\"AE\":\n",
    "                            recon = model(sequences)\n",
    "                        elif model._get_name()==\"VAE\" :\n",
    "                            recon, _, _ = model(sequences)\n",
    "                        elif model._get_name()==\"AdversarialAutoencoder\":\n",
    "                            _,recon= model(sequences)\n",
    "                        val_loss = eval_criterion(recon, sequences)\n",
    "                        if val_loss.dim() > 1:\n",
    "                            val_loss = val_loss\n",
    "                        else:\n",
    "                            val_loss = val_loss.unsqueeze(dim=0)\n",
    "                            labels = labels.unsqueeze(dim=0)\n",
    "                        if val_loss.dim()==3:\n",
    "                            ##GRU : mean of window\n",
    "                            val_loss = val_loss.mean(dim=1)\n",
    "                        val_loss = val_loss.sum(dim=1)\n",
    "                        all_val_losses.extend(val_loss.cpu().numpy())\n",
    "                        all_val_labels.extend(labels.flatten().cpu().numpy())     \n",
    "                threshold_1,std_mse = compute_threshold(all_val_losses,k=0)\n",
    "\n",
    "                all_val_losses = np.array(all_val_losses).squeeze()  \n",
    "                all_val_labels = np.array(all_val_labels).squeeze()  \n",
    "                # If intrusion score > threshold, predict 1 (intrusion), else 0 (benign)\n",
    "                # For FDR, get True Positives (TP) and False Positives (FP)\n",
    "                \n",
    "                predictions = (all_val_losses > threshold_1).astype(int)\n",
    "\n",
    "                accuracy = accuracy_score(all_val_labels, predictions)\n",
    "                print(f\"Val: Accuracy: {accuracy:.4f}  \")\n",
    "                model.eval() \n",
    "                all_test_losses = []\n",
    "                all_test_labels = []\n",
    "                with torch.no_grad():\n",
    "                    for sequences, labels in test_dataloader:\n",
    "                        sequences = sequences.squeeze().to(device)\n",
    "                        labels = labels.squeeze().to(device)\n",
    "                        if criterion_method==\"bce\":\n",
    "                            ## may test features be greater than 1 after scaling \n",
    "                            sequences=torch.clamp(sequences, min=0.0, max=1.0)\n",
    "                        if model._get_name()==\"AE\":\n",
    "                            recon = model(sequences)\n",
    "                        elif model._get_name()==\"VAE\"  :\n",
    "                            recon, mu, logvar = model(sequences)\n",
    "                        elif model._get_name()==\"AdversarialAutoencoder\":\n",
    "                            _,recon= model(sequences)\n",
    "\n",
    "                        intrusion_scores = eval_criterion(recon, sequences)\n",
    "                        if intrusion_scores.dim() > 1:\n",
    "                            intrusion_scores = intrusion_scores\n",
    "                        else:\n",
    "                            intrusion_scores = intrusion_scores.unsqueeze(dim=0)\n",
    "                            labels = labels.unsqueeze(dim=0)\n",
    "                        if intrusion_scores.dim()==3:\n",
    "                            ##GRU : mean of window\n",
    "                            intrusion_scores = intrusion_scores.mean(dim=1)\n",
    "                        intrusion_scores = intrusion_scores.sum(dim=1)\n",
    "                        all_test_losses.extend(intrusion_scores.cpu().numpy())\n",
    "                        all_test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "                all_test_losses = np.array(all_test_losses)\n",
    "                all_test_labels = np.array(all_test_labels)\n",
    "                temp_best_recall =best_recall\n",
    "                temp_best_f1 =best_f1\n",
    "\n",
    "                for k in k_range:\n",
    "                    threshold=threshold_1+k*std_mse\n",
    "                    print(f\" K: {k} K-SIGMA Threshold : ---thr {threshold:.4}\")\n",
    "                    predictions = (all_test_losses > threshold).astype(int)\n",
    "                    binary_test_labels = (all_test_labels != 0).astype(int)\n",
    "\n",
    "                    # Find the indices where the prediction was incorrect\n",
    "                    misclassified_indices = np.where(binary_test_labels != predictions)[0]\n",
    "\n",
    "                    # Get the original labels for those misclassified instances\n",
    "                    misclassified_original_labels = all_test_labels[misclassified_indices]\n",
    "\n",
    "                    # To get a summary count of which labels were misclassified\n",
    "                    print(\"Counts of : original binary labels\",Counter(binary_test_labels),\"predicted binary labels\",Counter(predictions))\n",
    "                    print(f\"Counts of  original  labels: {dict(sorted(Counter(all_test_labels).items()))}\")\n",
    "                    print(f\"Counts of misclassified original labels: {dict(sorted(Counter(misclassified_original_labels).items()))}\")\n",
    "                    accuracy = accuracy_score(binary_test_labels, predictions)\n",
    "                    f1 = f1_score(binary_test_labels, predictions, zero_division=0)\n",
    "                    recall = recall_score(binary_test_labels, predictions,zero_division=0)\n",
    "                    _, fp, _, tp = confusion_matrix(binary_test_labels, predictions, labels=[0, 1]).ravel()\n",
    "                    # FDR = FP / (FP + TP) \n",
    "                    if (fp + tp) == 0:\n",
    "                        fdr = 0.0 \n",
    "                    else:\n",
    "                        fdr = fp / (fp + tp)\n",
    "                    print(f\"Test : Accuracy: {accuracy:.4f} Recall : {recall:.4f} FDR: {fdr:.4f}  F1-score: {f1:.4f}  \")\n",
    "                    !mkdir best_models -p\n",
    "                    if f1>best_f1 :\n",
    "                        best_f1=f1\n",
    "                    if recall>best_recall:\n",
    "                        best_recall=recall\n",
    "                if (best_recall>temp_best_recall or best_f1 > temp_best_f1):\n",
    "                    if train_model==True:\n",
    "                        save_path =\"best_models/\"+model._get_name()+\"_f1_\"+f\"{best_f1:.2f}\" +\"_recall_\"+f\"{best_recall:.2f}\" +\"_.pth\"\n",
    "                        torch.save(model.state_dict(),save_path)\n",
    "                        print(\"model\",model._get_name(),\"is saved in\" ,save_path )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfeeeaf",
   "metadata": {},
   "source": [
    "#### Centralized : external scenario -> ied1a node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db440aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ied1b comp ied attack ->\n",
      " test:  1 ['dataset/ModbusDataset/attack/external/ied1a/ied1a-network-capture/ready/veth4edc015-0-labeled.csv']\n",
      "----------- Network-wide number of csv files -> \n",
      " ----------- train : 15 ['dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-16-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-31-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-18-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-23-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-19-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-27-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-20-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-24-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-29-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-14-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-21-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-30-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-32-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-26-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-15-labeled.csv'] \n",
      " -------- valid: 4 ['dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-28-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-22-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-25-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-17-labeled.csv']\n"
     ]
    }
   ],
   "source": [
    "# train_files=[col for col in modbus.dataset[\"benign_dataset_dir\"] if col.find(\"network-wide\")!=-1]\n",
    "train_files=[col for col in modbus.dataset[\"benign_dataset_dir\"] if col.find(\"network-wide\")!=-1][:]\n",
    "test_files=[col for col in modbus.dataset[\"attack_dataset_dir\"][\"external\"] if col.find(\"ied1a\")!=-1]\n",
    "random.seed(42)\n",
    "random.shuffle(train_files)\n",
    "random.shuffle(test_files)\n",
    "val_files = train_files[-4:]\n",
    "train_files = train_files[:-4]\n",
    "print(\"ied1b comp ied attack ->\\n test: \",len(test_files),test_files)\n",
    "print(\"----------- Network-wide number of csv files -> \\n ----------- train :\",len(train_files),train_files,\"\\n -------- valid:\",len(val_files),val_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb2505cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded scalers for 'network-wide'\n"
     ]
    }
   ],
   "source": [
    "### Try The Copy-on-Write (CoW) technique, share the same single copy of the dataset in memory with multiple forked workers from the main process\n",
    "# Ensure to have enough memory for saving large tensors in the ram \n",
    "###### else use chunk_size =1 and read the files iteratively\n",
    "\n",
    "use_cow=False\n",
    "window_size=1\n",
    "loaded_scalers=load_scalers('fitted_scalers')\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac4698b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T08:12:06.828444Z",
     "iopub.status.busy": "2025-07-13T08:12:06.827779Z",
     "iopub.status.idle": "2025-07-13T08:12:07.034947Z",
     "shell.execute_reply": "2025-07-13T08:12:07.034115Z",
     "shell.execute_reply.started": "2025-07-13T08:12:06.828415Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# This cell Initializes and returns train, validation, and test dataloaders.\n",
    "\n",
    "# This function supports two strategies for data loading:\n",
    "# 1. Copy-on-Write (use_cow=True): Loads the entire dataset into RAM. This is fast\n",
    "#     but memory-intensive. It allows multiple worker processes to share the same\n",
    "#     dataset copy in memory, which is efficient for multiprocessing.\n",
    "# 2. Iterative (use_cow=False): Reads data from files in small chunks. This is\n",
    "#     slower but uses significantly less memory, suitable for very large datasets\n",
    "#     that don't fit in RAM.\n",
    "\n",
    "#     train_files (list): List of file paths for the training dataset.\n",
    "#     val_files (list): List of file paths for the validation dataset.\n",
    "#     test_files (list): List of file paths for the test dataset.\n",
    "#     window_size (int): The size of the sliding window for sequence data.\n",
    "#     use_cow (bool, optional): If True, uses the Copy-on-Write strategy. \n",
    "#                                 Defaults to True.\n",
    "\n",
    "#      return        (train_dataloader, val_dataloader, test_dataloader)\n",
    "\n",
    "if use_cow==True:\n",
    "    large_chunk_size = modbus.dataset[\"metadata\"][\"founded_files_num\"][\"total_dataset_num\"]\n",
    "\n",
    "    dataset_configs = {\n",
    "        \"train\": {\"files\": train_files},\n",
    "        \"val\": {\"files\": val_files},\n",
    "        \"test\": {\"files\": test_files},\n",
    "    }\n",
    "    datasets = {}\n",
    "    ae_datasets = {}\n",
    "\n",
    "    print(\"Cow Processing datasets...\")\n",
    "\n",
    "    for name, config in dataset_configs.items():\n",
    "        print(f\"  - Creating '{name}' dataset...\")\n",
    "        \n",
    "        # 1. Create the primary ModbusFlowStream dataset\n",
    "        datasets[name] = ModbusFlowStream(\n",
    "            shuffle=False,\n",
    "            chunk_size=large_chunk_size,\n",
    "            batch_size=1,\n",
    "            csv_files=config[\"files\"],\n",
    "            scalers=loaded_scalers['network-wide']['min_max_scalers'],\n",
    "            window_size=window_size\n",
    "        )\n",
    "        \n",
    "        # 2. Call __getitem__(0) once to load the entire dataset chunk into memory\n",
    "        datasets[name].__getitem__(0)\n",
    "        \n",
    "        # used for specific AE training/evaluation without re-reading files.\n",
    "        ae_datasets[name] = ModbusFlowStream(\n",
    "            shuffle=False,  # AE data is typically processed in order\n",
    "            chunk_size=large_chunk_size,\n",
    "            batch_size=1,\n",
    "            csv_files=[],  # No CSV files needed as we copy the data directly\n",
    "            scalers=None,   # Data is already scaled from the original dataset\n",
    "            window_size=window_size\n",
    "        )\n",
    "        \n",
    "        # 4. Manually copy the loaded data and properties to the AE dataset\n",
    "\n",
    "        ae_datasets[name].current_chunk_data =  datasets[name].current_chunk_data\n",
    "        ae_datasets[name].current_len_chunk_data =  datasets[name].current_len_chunk_data\n",
    "        ae_datasets[name].current_chunk_labels =  datasets[name].current_chunk_labels\n",
    "        ae_datasets[name].total_batches =  datasets[name].total_batches\n",
    "        \n",
    "        print(f\"  - Finished '{name}' dataset.\")\n",
    "    train_dataloader=DataLoader(ae_datasets['train'],batch_size=64,shuffle=True,num_workers=1,persistent_workers=True,prefetch_factor=2,pin_memory=True)\n",
    "    val_dataloader=DataLoader(ae_datasets['val'],batch_size=64,shuffle=False,num_workers=1,persistent_workers=True,prefetch_factor=2,pin_memory=True)\n",
    "    test_dataloader=DataLoader(ae_datasets['test'],batch_size=64,shuffle=False,num_workers=1,persistent_workers=True,prefetch_factor=2,pin_memory=True)\n",
    "\n",
    "else :\n",
    "    train_dataloader=DataLoader(ModbusFlowStream( \n",
    "        shuffle=True,chunk_size=1,batch_size=64,csv_files=train_files,scalers=loaded_scalers['network-wide']['min_max_scalers'],window_size=window_size\n",
    "    ),  batch_size=1,shuffle=False)\n",
    "    val_dataloader=DataLoader(ModbusFlowStream( \n",
    "        shuffle=False,chunk_size=1,batch_size=64,csv_files=val_files,scalers=loaded_scalers['network-wide']['min_max_scalers'],window_size=window_size\n",
    "    ),batch_size=1,shuffle=False)\n",
    "    test_dataloader=DataLoader(ModbusFlowStream(shuffle=False,chunk_size=1,batch_size=64,csv_files=test_files,scalers=loaded_scalers['network-wide']['min_max_scalers'],window_size=window_size),\n",
    "                               batch_size=1,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69406aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34527 9584 1960\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataloader),len(val_dataloader),len(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e82123e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================  lr=0.001, wd=1e-06 ==================\n",
      "Train : time 140.57 s Epoch 1\n",
      "Train Loss: 0.1491\n",
      "--- Running Evaluation for Epoch 1 lr =0.001 wd 1e-06 ---\n",
      "-----------mse_loss mean :  0.0051 std: 0.1103\n",
      "Val: Accuracy: 0.9503  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.1154\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65618, 0: 59814})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29768, 1: 165}\n",
      "Test : Accuracy: 0.7614 Recall : 0.9954 FDR: 0.4537  F1-score: 0.7055  \n",
      " K: 1.25 K-SIGMA Threshold : ---thr 0.1429\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65591, 0: 59841})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29741, 1: 165}\n",
      "Test : Accuracy: 0.7616 Recall : 0.9954 FDR: 0.4534  F1-score: 0.7057  \n",
      " K: 1.5 K-SIGMA Threshold : ---thr 0.1705\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65571, 0: 59861})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29721, 1: 165}\n",
      "Test : Accuracy: 0.7617 Recall : 0.9954 FDR: 0.4533  F1-score: 0.7058  \n",
      " K: 1.75 K-SIGMA Threshold : ---thr 0.1981\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65556, 0: 59876})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29706, 1: 165}\n",
      "Test : Accuracy: 0.7619 Recall : 0.9954 FDR: 0.4531  F1-score: 0.7059  \n",
      " K: 2 K-SIGMA Threshold : ---thr 0.2257\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65555, 0: 59877})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29705, 1: 165}\n",
      "Test : Accuracy: 0.7619 Recall : 0.9954 FDR: 0.4531  F1-score: 0.7059  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.336\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 89437, 1: 35995})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 1973, 1: 1993}\n",
      "Test : Accuracy: 0.9684 Recall : 0.9447 FDR: 0.0548  F1-score: 0.9449  \n",
      "model AE is saved in best_models/AE_f1_0.94_recall_1.00_.pth\n",
      "Train : time 143.08 s Epoch 2\n",
      "Train Loss: 0.0039\n",
      "--- Running Evaluation for Epoch 2 lr =0.001 wd 1e-06 ---\n",
      "-----------mse_loss mean :  0.0034 std: 0.0738\n",
      "Val: Accuracy: 0.9520  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.07716\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65651, 0: 59781})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29791, 1: 155}\n",
      "Test : Accuracy: 0.7613 Recall : 0.9957 FDR: 0.4538  F1-score: 0.7054  \n",
      " K: 1.25 K-SIGMA Threshold : ---thr 0.09561\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65597, 0: 59835})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29747, 1: 165}\n",
      "Test : Accuracy: 0.7615 Recall : 0.9954 FDR: 0.4535  F1-score: 0.7056  \n",
      " K: 1.5 K-SIGMA Threshold : ---thr 0.1141\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65576, 0: 59856})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29726, 1: 165}\n",
      "Test : Accuracy: 0.7617 Recall : 0.9954 FDR: 0.4533  F1-score: 0.7058  \n",
      " K: 1.75 K-SIGMA Threshold : ---thr 0.1325\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65564, 0: 59868})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29714, 1: 165}\n",
      "Test : Accuracy: 0.7618 Recall : 0.9954 FDR: 0.4532  F1-score: 0.7059  \n",
      " K: 2 K-SIGMA Threshold : ---thr 0.151\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65552, 0: 59880})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29702, 1: 165}\n",
      "Test : Accuracy: 0.7619 Recall : 0.9954 FDR: 0.4531  F1-score: 0.7059  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.2248\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65526, 0: 59906})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29676, 1: 165}\n",
      "Test : Accuracy: 0.7621 Recall : 0.9954 FDR: 0.4529  F1-score: 0.7061  \n",
      "model AE is saved in best_models/AE_f1_0.94_recall_1.00_.pth\n",
      "Train : time 145.57 s Epoch 3\n",
      "Train Loss: 0.0029\n",
      "--- Running Evaluation for Epoch 3 lr =0.001 wd 1e-06 ---\n",
      "-----------mse_loss mean :  0.0040 std: 0.0732\n",
      "Val: Accuracy: 0.9163  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.07712\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65637, 0: 59795})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29780, 1: 158}\n",
      "Test : Accuracy: 0.7613 Recall : 0.9956 FDR: 0.4537  F1-score: 0.7055  \n",
      " K: 1.25 K-SIGMA Threshold : ---thr 0.09541\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65605, 0: 59827})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29755, 1: 165}\n",
      "Test : Accuracy: 0.7615 Recall : 0.9954 FDR: 0.4535  F1-score: 0.7056  \n",
      " K: 1.5 K-SIGMA Threshold : ---thr 0.1137\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65589, 0: 59843})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29739, 1: 165}\n",
      "Test : Accuracy: 0.7616 Recall : 0.9954 FDR: 0.4534  F1-score: 0.7057  \n",
      " K: 1.75 K-SIGMA Threshold : ---thr 0.132\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65576, 0: 59856})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29726, 1: 165}\n",
      "Test : Accuracy: 0.7617 Recall : 0.9954 FDR: 0.4533  F1-score: 0.7058  \n",
      " K: 2 K-SIGMA Threshold : ---thr 0.1503\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65567, 0: 59865})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29717, 1: 165}\n",
      "Test : Accuracy: 0.7618 Recall : 0.9954 FDR: 0.4532  F1-score: 0.7058  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.2234\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65524, 0: 59908})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29674, 1: 165}\n",
      "Test : Accuracy: 0.7621 Recall : 0.9954 FDR: 0.4529  F1-score: 0.7061  \n",
      "Train : time 145.03 s Epoch 4\n",
      "Train Loss: 0.0031\n",
      "--- Running Evaluation for Epoch 4 lr =0.001 wd 1e-06 ---\n",
      "-----------mse_loss mean :  0.0030 std: 0.0771\n",
      "Val: Accuracy: 0.9917  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.08008\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65599, 0: 59833})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29749, 1: 165}\n",
      "Test : Accuracy: 0.7615 Recall : 0.9954 FDR: 0.4535  F1-score: 0.7056  \n",
      " K: 1.25 K-SIGMA Threshold : ---thr 0.09936\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65572, 0: 59860})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29722, 1: 165}\n",
      "Test : Accuracy: 0.7617 Recall : 0.9954 FDR: 0.4533  F1-score: 0.7058  \n",
      " K: 1.5 K-SIGMA Threshold : ---thr 0.1186\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65558, 0: 59874})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29708, 1: 165}\n",
      "Test : Accuracy: 0.7618 Recall : 0.9954 FDR: 0.4532  F1-score: 0.7059  \n",
      " K: 1.75 K-SIGMA Threshold : ---thr 0.1379\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65548, 0: 59884})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29698, 1: 165}\n",
      "Test : Accuracy: 0.7619 Recall : 0.9954 FDR: 0.4531  F1-score: 0.7060  \n",
      " K: 2 K-SIGMA Threshold : ---thr 0.1572\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65539, 0: 59893})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29689, 1: 165}\n",
      "Test : Accuracy: 0.7620 Recall : 0.9954 FDR: 0.4530  F1-score: 0.7060  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.2343\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65522, 0: 59910})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29672, 1: 165}\n",
      "Test : Accuracy: 0.7621 Recall : 0.9954 FDR: 0.4529  F1-score: 0.7061  \n",
      "Train : time 149.17 s Epoch 5\n",
      "Train Loss: 0.0025\n",
      "--- Running Evaluation for Epoch 5 lr =0.001 wd 1e-06 ---\n",
      "-----------mse_loss mean :  0.0033 std: 0.1016\n",
      "Val: Accuracy: 0.9920  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.1049\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65556, 0: 59876})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29704, 1: 163}\n",
      "Test : Accuracy: 0.7619 Recall : 0.9955 FDR: 0.4531  F1-score: 0.7059  \n",
      " K: 1.25 K-SIGMA Threshold : ---thr 0.1303\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65542, 0: 59890})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29692, 1: 165}\n",
      "Test : Accuracy: 0.7620 Recall : 0.9954 FDR: 0.4530  F1-score: 0.7060  \n",
      " K: 1.5 K-SIGMA Threshold : ---thr 0.1557\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65531, 0: 59901})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29681, 1: 165}\n",
      "Test : Accuracy: 0.7621 Recall : 0.9954 FDR: 0.4529  F1-score: 0.7061  \n",
      " K: 1.75 K-SIGMA Threshold : ---thr 0.1811\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65527, 0: 59905})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29677, 1: 165}\n",
      "Test : Accuracy: 0.7621 Recall : 0.9954 FDR: 0.4529  F1-score: 0.7061  \n",
      " K: 2 K-SIGMA Threshold : ---thr 0.2065\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65518, 0: 59914})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29668, 1: 165}\n",
      "Test : Accuracy: 0.7622 Recall : 0.9954 FDR: 0.4528  F1-score: 0.7062  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.3082\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65504, 0: 59928})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29655, 1: 166}\n",
      "Test : Accuracy: 0.7623 Recall : 0.9954 FDR: 0.4527  F1-score: 0.7063  \n",
      "Train : time 157.94 s Epoch 6\n",
      "Train Loss: 0.0019\n",
      "--- Running Evaluation for Epoch 6 lr =0.001 wd 1e-06 ---\n",
      "-----------mse_loss mean :  0.0025 std: 0.0584\n",
      "Val: Accuracy: 0.9810  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.06093\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65700, 0: 59732})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29826, 1: 141}\n",
      "Test : Accuracy: 0.7611 Recall : 0.9961 FDR: 0.4540  F1-score: 0.7054  \n",
      " K: 1.25 K-SIGMA Threshold : ---thr 0.07553\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65645, 0: 59787})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29780, 1: 150}\n",
      "Test : Accuracy: 0.7614 Recall : 0.9958 FDR: 0.4537  F1-score: 0.7056  \n",
      " K: 1.5 K-SIGMA Threshold : ---thr 0.09013\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65613, 0: 59819})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29752, 1: 154}\n",
      "Test : Accuracy: 0.7616 Recall : 0.9957 FDR: 0.4534  F1-score: 0.7057  \n",
      " K: 1.75 K-SIGMA Threshold : ---thr 0.1047\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65597, 0: 59835})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29736, 1: 154}\n",
      "Test : Accuracy: 0.7617 Recall : 0.9957 FDR: 0.4533  F1-score: 0.7058  \n",
      " K: 2 K-SIGMA Threshold : ---thr 0.1193\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65583, 0: 59849})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29722, 1: 154}\n",
      "Test : Accuracy: 0.7618 Recall : 0.9957 FDR: 0.4532  F1-score: 0.7059  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.1777\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65540, 0: 59892})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29679, 1: 154}\n",
      "Test : Accuracy: 0.7622 Recall : 0.9957 FDR: 0.4528  F1-score: 0.7062  \n",
      "model AE is saved in best_models/AE_f1_0.94_recall_1.00_.pth\n",
      "\n",
      "==================  lr=0.001, wd=0.0001 ==================\n",
      "Train : time 142.29 s Epoch 1\n",
      "Train Loss: 0.1929\n",
      "--- Running Evaluation for Epoch 1 lr =0.001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0881 std: 0.3932\n",
      "Val: Accuracy: 0.9269  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.4813\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 95686, 1: 29746})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 3750, 1: 10011, 6: 8}\n",
      "Test : Accuracy: 0.8902 Recall : 0.7218 FDR: 0.1261  F1-score: 0.7906  \n",
      " K: 1.25 K-SIGMA Threshold : ---thr 0.5796\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 95699, 1: 29733})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 3740, 1: 10014, 6: 8}\n",
      "Test : Accuracy: 0.8903 Recall : 0.7217 FDR: 0.1258  F1-score: 0.7907  \n",
      " K: 1.5 K-SIGMA Threshold : ---thr 0.6779\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 96228, 1: 29204})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 3211, 1: 10014, 6: 8}\n",
      "Test : Accuracy: 0.8945 Recall : 0.7217 FDR: 0.1100  F1-score: 0.7971  \n",
      " K: 1.75 K-SIGMA Threshold : ---thr 0.7763\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 96233, 1: 29199})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 3207, 1: 10014, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8945 Recall : 0.7217 FDR: 0.1098  F1-score: 0.7971  \n",
      " K: 2 K-SIGMA Threshold : ---thr 0.8746\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 96776, 1: 28656})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2664, 1: 10014, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8989 Recall : 0.7217 FDR: 0.0930  F1-score: 0.8038  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.268\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 97314, 1: 28118})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2126, 1: 10014, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.9031 Recall : 0.7217 FDR: 0.0756  F1-score: 0.8106  \n",
      "Train : time 141.85 s Epoch 2\n",
      "Train Loss: 0.0464\n",
      "--- Running Evaluation for Epoch 2 lr =0.001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0127 std: 0.1945\n",
      "Val: Accuracy: 0.9746  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.2072\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65689, 0: 59743})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29839, 1: 165}\n",
      "Test : Accuracy: 0.7608 Recall : 0.9954 FDR: 0.4542  F1-score: 0.7050  \n",
      " K: 1.25 K-SIGMA Threshold : ---thr 0.2558\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65665, 0: 59767})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29815, 1: 165}\n",
      "Test : Accuracy: 0.7610 Recall : 0.9954 FDR: 0.4540  F1-score: 0.7052  \n",
      " K: 1.5 K-SIGMA Threshold : ---thr 0.3045\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65644, 0: 59788})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29794, 1: 165}\n",
      "Test : Accuracy: 0.7612 Recall : 0.9954 FDR: 0.4539  F1-score: 0.7053  \n",
      " K: 1.75 K-SIGMA Threshold : ---thr 0.3531\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 69303, 1: 56129})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 27860, 1: 7738, 6: 8}\n",
      "Test : Accuracy: 0.7161 Recall : 0.7849 FDR: 0.4964  F1-score: 0.6136  \n",
      " K: 2 K-SIGMA Threshold : ---thr 0.4017\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 98028, 1: 27404})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 224, 1: 8827, 6: 8}\n",
      "Test : Accuracy: 0.9278 Recall : 0.7547 FDR: 0.0082  F1-score: 0.8572  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.5962\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99248, 1: 26184})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 191, 1: 10014, 6: 8}\n",
      "Test : Accuracy: 0.9186 Recall : 0.7217 FDR: 0.0073  F1-score: 0.8358  \n",
      "Train : time 149.59 s Epoch 3\n",
      "Train Loss: 0.0131\n",
      "--- Running Evaluation for Epoch 3 lr =0.001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0132 std: 0.1843\n",
      "Val: Accuracy: 0.9714  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.1975\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65678, 0: 59754})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29828, 1: 165}\n",
      "Test : Accuracy: 0.7609 Recall : 0.9954 FDR: 0.4542  F1-score: 0.7051  \n",
      " K: 1.25 K-SIGMA Threshold : ---thr 0.2436\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65662, 0: 59770})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29812, 1: 165}\n",
      "Test : Accuracy: 0.7610 Recall : 0.9954 FDR: 0.4540  F1-score: 0.7052  \n",
      " K: 1.5 K-SIGMA Threshold : ---thr 0.2897\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65650, 0: 59782})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29800, 1: 165}\n",
      "Test : Accuracy: 0.7611 Recall : 0.9954 FDR: 0.4539  F1-score: 0.7053  \n",
      " K: 1.75 K-SIGMA Threshold : ---thr 0.3357\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65633, 0: 59799})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29783, 1: 165}\n",
      "Test : Accuracy: 0.7612 Recall : 0.9954 FDR: 0.4538  F1-score: 0.7054  \n",
      " K: 2 K-SIGMA Threshold : ---thr 0.3818\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 96940, 1: 28492})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 246, 1: 7761, 6: 8}\n",
      "Test : Accuracy: 0.9361 Recall : 0.7843 FDR: 0.0086  F1-score: 0.8757  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.5661\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99219, 1: 26213})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 220, 1: 10014, 6: 8}\n",
      "Test : Accuracy: 0.9183 Recall : 0.7217 FDR: 0.0084  F1-score: 0.8354  \n",
      "Train : time 143.80 s Epoch 4\n",
      "Train Loss: 0.0105\n",
      "--- Running Evaluation for Epoch 4 lr =0.001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0078 std: 0.1451\n",
      "Val: Accuracy: 0.9803  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.1528\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65664, 0: 59768})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29814, 1: 165}\n",
      "Test : Accuracy: 0.7610 Recall : 0.9954 FDR: 0.4540  F1-score: 0.7052  \n",
      " K: 1.25 K-SIGMA Threshold : ---thr 0.1891\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65646, 0: 59786})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29796, 1: 165}\n",
      "Test : Accuracy: 0.7611 Recall : 0.9954 FDR: 0.4539  F1-score: 0.7053  \n",
      " K: 1.5 K-SIGMA Threshold : ---thr 0.2254\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65636, 0: 59796})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29786, 1: 165}\n",
      "Test : Accuracy: 0.7612 Recall : 0.9954 FDR: 0.4538  F1-score: 0.7054  \n",
      " K: 1.75 K-SIGMA Threshold : ---thr 0.2617\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65624, 0: 59808})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29774, 1: 165}\n",
      "Test : Accuracy: 0.7613 Recall : 0.9954 FDR: 0.4537  F1-score: 0.7054  \n",
      " K: 2 K-SIGMA Threshold : ---thr 0.2979\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65622, 0: 59810})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29772, 1: 165}\n",
      "Test : Accuracy: 0.7613 Recall : 0.9954 FDR: 0.4537  F1-score: 0.7055  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.443\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 97457, 1: 27975})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 216, 1: 8248, 6: 8}\n",
      "Test : Accuracy: 0.9325 Recall : 0.7708 FDR: 0.0077  F1-score: 0.8676  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m AE_model \u001b[38;5;241m=\u001b[39m AE(input_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m76\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAE_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mshuffle_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43meval_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mcriterion_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmse\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mlearning_rates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1e-6\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mweight_decays\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1e-6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1e-5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mk_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1.25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1.75\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 67\u001b[0m, in \u001b[0;36mtrain_eval\u001b[0;34m(model, train_dataloader, val_dataloader, test_dataloader, learning_rates, weight_decays, shuffle_files, num_epochs, eval_epoch, criterion_method, k_range, train_model)\u001b[0m\n\u001b[1;32m     65\u001b[0m     recon, mu, logvar \u001b[38;5;241m=\u001b[39m model(sequences)\n\u001b[1;32m     66\u001b[0m     loss \u001b[38;5;241m=\u001b[39m vae_loss_function(recon, sequences, mu, logvar) \u001b[38;5;241m/\u001b[39msequences\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 67\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m AE_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     69\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/torch/_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    647\u001b[0m     )\n\u001b[0;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/torch/autograd/__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/torch/autograd/graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "AE_model = AE(input_dim=76)\n",
    "train_eval(AE_model,train_dataloader,val_dataloader,test_dataloader,shuffle_files=True,num_epochs=6,eval_epoch=1,criterion_method=\"mse\",learning_rates=[1e-3,1e-4,1e-5,1e-6],weight_decays=[1e-6,1e-4,1e-5],k_range=[1,1.25,1.5,1.75,2,3])\n",
    "# --- Running Evaluation for Epoch 6 lr =0.001 wd 1e-05 ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea756ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================  lr=0.0001, wd=0.0001 ==================\n",
      "Train : time 169.16 s Epoch 1\n",
      "Train Loss: 10.0493\n",
      "--- Running Evaluation for Epoch 1 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.1549 std: 0.6657\n",
      "Val: Accuracy: 0.8582  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.8206\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 96803, 1: 28629})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2427, 1: 9804, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.9024 Recall : 0.7275 FDR: 0.0848  F1-score: 0.8107  \n",
      " K: 3 K-SIGMA Threshold : ---thr 2.152\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 98798, 1: 26634})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 877, 1: 10248, 5: 1, 6: 9}\n",
      "Test : Accuracy: 0.9112 Recall : 0.7152 FDR: 0.0329  F1-score: 0.8223  \n",
      "model VAE is saved in best_models/VAE_f1_0.82_recall_0.73_.pth\n",
      "Train : time 170.87 s Epoch 2\n",
      "Train Loss: 8.6474\n",
      "--- Running Evaluation for Epoch 2 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.1444 std: 0.6262\n",
      "Val: Accuracy: 0.8639  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.7706\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 96610, 1: 28822})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2621, 1: 9806, 6: 8}\n",
      "Test : Accuracy: 0.9009 Recall : 0.7275 FDR: 0.0909  F1-score: 0.8082  \n",
      " K: 3 K-SIGMA Threshold : ---thr 2.023\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 98534, 1: 26898})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 848, 1: 9956, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.9138 Recall : 0.7233 FDR: 0.0315  F1-score: 0.8281  \n",
      "model VAE is saved in best_models/VAE_f1_0.83_recall_0.73_.pth\n",
      "Train : time 169.32 s Epoch 3\n",
      "Train Loss: 8.5968\n",
      "--- Running Evaluation for Epoch 3 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.1302 std: 0.5514\n",
      "Val: Accuracy: 0.8580  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.6816\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 96169, 1: 29263})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2989, 1: 9733, 6: 8}\n",
      "Test : Accuracy: 0.8985 Recall : 0.7295 FDR: 0.1021  F1-score: 0.8050  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.784\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 98500, 1: 26932})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 845, 1: 9919, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.9141 Recall : 0.7243 FDR: 0.0314  F1-score: 0.8289  \n",
      "model VAE is saved in best_models/VAE_f1_0.83_recall_0.73_.pth\n",
      "Train : time 174.03 s Epoch 4\n",
      "Train Loss: 8.5597\n",
      "--- Running Evaluation for Epoch 4 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.1224 std: 0.5074\n",
      "Val: Accuracy: 0.8533  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.6298\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 95122, 1: 30310})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 3962, 1: 9659, 6: 8}\n",
      "Test : Accuracy: 0.8913 Recall : 0.7316 FDR: 0.1307  F1-score: 0.7945  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.645\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 98285, 1: 27147})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 1042, 1: 9901, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.9127 Recall : 0.7248 FDR: 0.0384  F1-score: 0.8266  \n",
      "model VAE is saved in best_models/VAE_f1_0.83_recall_0.73_.pth\n",
      "Train : time 176.84 s Epoch 5\n",
      "Train Loss: 8.5344\n",
      "--- Running Evaluation for Epoch 5 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.1133 std: 0.4683\n",
      "Val: Accuracy: 0.8479  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.5815\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 94971, 1: 30461})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 3815, 1: 9362, 6: 7}\n",
      "Test : Accuracy: 0.8949 Recall : 0.7399 FDR: 0.1252  F1-score: 0.8017  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.518\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 98380, 1: 27052})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 954, 1: 9908, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.9133 Recall : 0.7246 FDR: 0.0353  F1-score: 0.8276  \n",
      "model VAE is saved in best_models/VAE_f1_0.83_recall_0.74_.pth\n",
      "Train : time 173.27 s Epoch 6\n",
      "Train Loss: 8.5196\n",
      "--- Running Evaluation for Epoch 6 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.1130 std: 0.4626\n",
      "Val: Accuracy: 0.8439  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.5756\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 94157, 1: 31275})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 4397, 1: 9130, 6: 7}\n",
      "Test : Accuracy: 0.8921 Recall : 0.7463 FDR: 0.1406  F1-score: 0.7989  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.501\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 98318, 1: 27114})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 997, 1: 9890, 5: 1, 6: 7}\n",
      "Test : Accuracy: 0.9131 Recall : 0.7252 FDR: 0.0368  F1-score: 0.8274  \n",
      "model VAE is saved in best_models/VAE_f1_0.83_recall_0.75_.pth\n"
     ]
    }
   ],
   "source": [
    "VAE_model = VAE(input_dim=76)\n",
    "train_eval(VAE_model,train_dataloader,val_dataloader,test_dataloader,shuffle_files=True,num_epochs=6,eval_epoch=1,criterion_method=\"mse\",learning_rates=[1e-2,1e-3,1e-4,1e-5,1e-6],weight_decays=[1e-4,1e-5],k_range=[1,2,3],k_range=[1,1.25,1.5,1.75,2,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54635226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================  lr=0.01, wd=0.0001 ==================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : time 228.85 s Epoch 1\n",
      "Generator Loss: 176.8262 Discriminator Loss: 5.3518\n",
      "--- Running Evaluation for Epoch 1 lr =0.01 wd 0.0001 ---\n",
      "-----------mse_loss mean :  3.5951 std: 3.4918\n",
      "Val: Accuracy: 0.6065  \n",
      " K: 1 K-SIGMA Threshold : ---thr 7.087\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 117049, 1: 8383})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5495, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.6921 Recall : 0.0802 FDR: 0.6555  F1-score: 0.1301  \n",
      " K: 3 K-SIGMA Threshold : ---thr 14.07\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 125309, 1: 123})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6, 1: 35861, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Test : Accuracy: 0.7138 Recall : 0.0032 FDR: 0.0488  F1-score: 0.0065  \n",
      "model AdversarialAutoencoder is saved in best_models/AdversarialAutoencoder_f1_0.13_recall_0.08_.pth\n",
      "Train : time 232.27 s Epoch 2\n",
      "Generator Loss: 236.1101 Discriminator Loss: 0.0166\n",
      "--- Running Evaluation for Epoch 2 lr =0.01 wd 0.0001 ---\n",
      "-----------mse_loss mean :  3.5951 std: 3.4917\n",
      "Val: Accuracy: 0.6065  \n",
      " K: 1 K-SIGMA Threshold : ---thr 7.087\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 117049, 1: 8383})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5495, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.6921 Recall : 0.0802 FDR: 0.6555  F1-score: 0.1301  \n",
      " K: 3 K-SIGMA Threshold : ---thr 14.07\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 125309, 1: 123})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6, 1: 35861, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Test : Accuracy: 0.7138 Recall : 0.0032 FDR: 0.0488  F1-score: 0.0065  \n",
      "Train : time 229.78 s Epoch 3\n",
      "Generator Loss: 233.6358 Discriminator Loss: 0.0430\n",
      "--- Running Evaluation for Epoch 3 lr =0.01 wd 0.0001 ---\n",
      "-----------mse_loss mean :  3.5011 std: 3.3216\n",
      "Val: Accuracy: 0.6067  \n",
      " K: 1 K-SIGMA Threshold : ---thr 6.823\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 103012, 1: 22420})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 19604, 1: 33164, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.5790 Recall : 0.0782 FDR: 0.8744  F1-score: 0.0964  \n",
      " K: 3 K-SIGMA Threshold : ---thr 13.47\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 125310, 1: 122})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5, 1: 35861, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Test : Accuracy: 0.7138 Recall : 0.0032 FDR: 0.0410  F1-score: 0.0065  \n",
      "Train : time 234.54 s Epoch 4\n",
      "Generator Loss: 306.7760 Discriminator Loss: 0.0391\n",
      "--- Running Evaluation for Epoch 4 lr =0.01 wd 0.0001 ---\n",
      "-----------mse_loss mean :  4.7396 std: 2.4142\n",
      "Val: Accuracy: 0.6105  \n",
      " K: 1 K-SIGMA Threshold : ---thr 7.154\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 121304, 1: 4128})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 3522, 1: 35374, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.6896 Recall : 0.0168 FDR: 0.8532  F1-score: 0.0302  \n",
      " K: 3 K-SIGMA Threshold : ---thr 11.98\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 125167, 1: 265})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 148, 1: 35861, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Test : Accuracy: 0.7126 Recall : 0.0032 FDR: 0.5585  F1-score: 0.0064  \n",
      "Train : time 233.78 s Epoch 5\n",
      "Generator Loss: 309.0570 Discriminator Loss: 0.0009\n",
      "--- Running Evaluation for Epoch 5 lr =0.01 wd 0.0001 ---\n",
      "-----------mse_loss mean :  4.7396 std: 2.4142\n",
      "Val: Accuracy: 0.6105  \n",
      " K: 1 K-SIGMA Threshold : ---thr 7.154\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 121304, 1: 4128})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 3522, 1: 35374, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.6896 Recall : 0.0168 FDR: 0.8532  F1-score: 0.0302  \n",
      " K: 3 K-SIGMA Threshold : ---thr 11.98\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 125167, 1: 265})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 148, 1: 35861, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Test : Accuracy: 0.7126 Recall : 0.0032 FDR: 0.5585  F1-score: 0.0064  \n",
      "Train : time 233.17 s Epoch 6\n",
      "Generator Loss: 308.6756 Discriminator Loss: 0.0006\n",
      "--- Running Evaluation for Epoch 6 lr =0.01 wd 0.0001 ---\n",
      "-----------mse_loss mean :  4.7396 std: 2.4142\n",
      "Val: Accuracy: 0.6105  \n",
      " K: 1 K-SIGMA Threshold : ---thr 7.154\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 121304, 1: 4128})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 3522, 1: 35374, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.6896 Recall : 0.0168 FDR: 0.8532  F1-score: 0.0302  \n",
      " K: 3 K-SIGMA Threshold : ---thr 11.98\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 125167, 1: 265})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 148, 1: 35861, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Test : Accuracy: 0.7126 Recall : 0.0032 FDR: 0.5585  F1-score: 0.0064  \n",
      "\n",
      "==================  lr=0.001, wd=0.0001 ==================\n",
      "Train : time 239.11 s Epoch 1\n",
      "Generator Loss: 4.1309 Discriminator Loss: 7.7194\n",
      "--- Running Evaluation for Epoch 1 lr =0.001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0184 std: 0.2063\n",
      "Val: Accuracy: 0.9813  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.2247\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65734, 0: 59698})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29884, 1: 165}\n",
      "Test : Accuracy: 0.7604 Recall : 0.9954 FDR: 0.4546  F1-score: 0.7047  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.6373\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99108, 1: 26324})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 331, 1: 10014, 6: 8}\n",
      "Test : Accuracy: 0.9175 Recall : 0.7217 FDR: 0.0126  F1-score: 0.8339  \n",
      "model AdversarialAutoencoder is saved in best_models/AdversarialAutoencoder_f1_0.83_recall_1.00_.pth\n",
      "Train : time 237.31 s Epoch 2\n",
      "Generator Loss: 1.6544 Discriminator Loss: 11.2261\n",
      "--- Running Evaluation for Epoch 2 lr =0.001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0301 std: 0.1836\n",
      "Val: Accuracy: 0.9382  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.2136\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65734, 0: 59698})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29884, 1: 165}\n",
      "Test : Accuracy: 0.7604 Recall : 0.9954 FDR: 0.4546  F1-score: 0.7047  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.5808\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99088, 1: 26344})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 351, 1: 10014, 6: 8}\n",
      "Test : Accuracy: 0.9173 Recall : 0.7217 FDR: 0.0133  F1-score: 0.8337  \n",
      "Train : time 235.84 s Epoch 3\n",
      "Generator Loss: 1.8781 Discriminator Loss: 15.6813\n",
      "--- Running Evaluation for Epoch 3 lr =0.001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0233 std: 0.1841\n",
      "Val: Accuracy: 0.9811  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.2074\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65734, 0: 59698})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29884, 1: 165}\n",
      "Test : Accuracy: 0.7604 Recall : 0.9954 FDR: 0.4546  F1-score: 0.7047  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.5756\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99036, 1: 26396})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 351, 1: 9962, 6: 8}\n",
      "Test : Accuracy: 0.9177 Recall : 0.7232 FDR: 0.0133  F1-score: 0.8346  \n",
      "model AdversarialAutoencoder is saved in best_models/AdversarialAutoencoder_f1_0.83_recall_1.00_.pth\n",
      "Train : time 236.47 s Epoch 4\n",
      "Generator Loss: 1.5950 Discriminator Loss: 16.2237\n",
      "--- Running Evaluation for Epoch 4 lr =0.001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0227 std: 0.1802\n",
      "Val: Accuracy: 0.9811  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.2029\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65734, 0: 59698})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29884, 1: 165}\n",
      "Test : Accuracy: 0.7604 Recall : 0.9954 FDR: 0.4546  F1-score: 0.7047  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.5634\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99088, 1: 26344})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 351, 1: 10014, 6: 8}\n",
      "Test : Accuracy: 0.9173 Recall : 0.7217 FDR: 0.0133  F1-score: 0.8337  \n",
      "Train : time 236.74 s Epoch 5\n",
      "Generator Loss: 1.5011 Discriminator Loss: 18.0652\n",
      "--- Running Evaluation for Epoch 5 lr =0.001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0215 std: 0.1836\n",
      "Val: Accuracy: 0.9897  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.2051\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65735, 0: 59697})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29884, 1: 164}\n",
      "Test : Accuracy: 0.7604 Recall : 0.9954 FDR: 0.4546  F1-score: 0.7047  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.5724\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99108, 1: 26324})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 331, 1: 10014, 6: 8}\n",
      "Test : Accuracy: 0.9175 Recall : 0.7217 FDR: 0.0126  F1-score: 0.8339  \n",
      "model AdversarialAutoencoder is saved in best_models/AdversarialAutoencoder_f1_0.83_recall_1.00_.pth\n",
      "Train : time 243.17 s Epoch 6\n",
      "Generator Loss: 1.2232 Discriminator Loss: 22.6538\n",
      "--- Running Evaluation for Epoch 6 lr =0.001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0167 std: 0.1769\n",
      "Val: Accuracy: 0.9844  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.1936\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65734, 0: 59698})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29884, 1: 165}\n",
      "Test : Accuracy: 0.7604 Recall : 0.9954 FDR: 0.4546  F1-score: 0.7047  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.5475\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 97255, 1: 28177})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 353, 1: 8183, 6: 8}\n",
      "Test : Accuracy: 0.9319 Recall : 0.7726 FDR: 0.0125  F1-score: 0.8669  \n",
      "model AdversarialAutoencoder is saved in best_models/AdversarialAutoencoder_f1_0.87_recall_1.00_.pth\n",
      "\n",
      "==================  lr=0.0001, wd=0.0001 ==================\n",
      "Train : time 232.10 s Epoch 1\n",
      "Generator Loss: 40.9228 Discriminator Loss: 4.7518\n",
      "--- Running Evaluation for Epoch 1 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0643 std: 0.5388\n",
      "Val: Accuracy: 0.9551  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.6031\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99089, 1: 26343})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 350, 1: 10014, 6: 8}\n",
      "Test : Accuracy: 0.9173 Recall : 0.7217 FDR: 0.0133  F1-score: 0.8337  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.681\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99092, 1: 26340})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 348, 1: 10014, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.9173 Recall : 0.7217 FDR: 0.0132  F1-score: 0.8337  \n",
      "Train : time 231.28 s Epoch 2\n",
      "Generator Loss: 3.6065 Discriminator Loss: 4.8913\n",
      "--- Running Evaluation for Epoch 2 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0446 std: 0.4188\n",
      "Val: Accuracy: 0.9826  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.4634\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99088, 1: 26344})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 351, 1: 10014, 6: 8}\n",
      "Test : Accuracy: 0.9173 Recall : 0.7217 FDR: 0.0133  F1-score: 0.8337  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.301\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99090, 1: 26342})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 350, 1: 10014, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.9173 Recall : 0.7217 FDR: 0.0133  F1-score: 0.8337  \n",
      "Train : time 236.68 s Epoch 3\n",
      "Generator Loss: 3.0012 Discriminator Loss: 3.5079\n",
      "--- Running Evaluation for Epoch 3 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0395 std: 0.3916\n",
      "Val: Accuracy: 0.9828  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.4311\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99087, 1: 26345})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 352, 1: 10014, 6: 8}\n",
      "Test : Accuracy: 0.9173 Recall : 0.7217 FDR: 0.0134  F1-score: 0.8336  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.214\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99090, 1: 26342})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 350, 1: 10014, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.9173 Recall : 0.7217 FDR: 0.0133  F1-score: 0.8337  \n",
      "Train : time 241.90 s Epoch 4\n",
      "Generator Loss: 2.7489 Discriminator Loss: 2.6974\n",
      "--- Running Evaluation for Epoch 4 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0353 std: 0.3443\n",
      "Val: Accuracy: 0.9830  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.3796\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 97859, 1: 27573})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 356, 1: 8790, 6: 8}\n",
      "Test : Accuracy: 0.9270 Recall : 0.7557 FDR: 0.0129  F1-score: 0.8560  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.068\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99090, 1: 26342})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 350, 1: 10014, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.9173 Recall : 0.7217 FDR: 0.0133  F1-score: 0.8337  \n",
      "Train : time 233.90 s Epoch 5\n",
      "Generator Loss: 2.5526 Discriminator Loss: 2.2999\n",
      "--- Running Evaluation for Epoch 5 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0324 std: 0.3124\n",
      "Val: Accuracy: 0.9797  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.3449\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 88780, 1: 36652})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2175, 1: 1538}\n",
      "Test : Accuracy: 0.9704 Recall : 0.9573 FDR: 0.0593  F1-score: 0.9489  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.9697\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99089, 1: 26343})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 350, 1: 10014, 6: 8}\n",
      "Test : Accuracy: 0.9173 Recall : 0.7217 FDR: 0.0133  F1-score: 0.8337  \n",
      "model AdversarialAutoencoder is saved in best_models/AdversarialAutoencoder_f1_0.95_recall_1.00_.pth\n",
      "Train : time 254.28 s Epoch 6\n",
      "Generator Loss: 2.3765 Discriminator Loss: 2.8582\n",
      "--- Running Evaluation for Epoch 6 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0304 std: 0.2940\n",
      "Val: Accuracy: 0.9831  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.3244\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 87437, 1: 37995})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2177, 1: 197}\n",
      "Test : Accuracy: 0.9811 Recall : 0.9945 FDR: 0.0573  F1-score: 0.9679  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.9123\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 98371, 1: 27061})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 350, 1: 9296, 6: 8}\n",
      "Test : Accuracy: 0.9230 Recall : 0.7417 FDR: 0.0129  F1-score: 0.8469  \n",
      "model AdversarialAutoencoder is saved in best_models/AdversarialAutoencoder_f1_0.97_recall_1.00_.pth\n"
     ]
    }
   ],
   "source": [
    "AAE_model = AdversarialAutoencoder()\n",
    "train_eval(AAE_model,train_dataloader,val_dataloader,test_dataloader,shuffle_files=False,num_epochs=6,eval_epoch=1,criterion_method=\"mse\",learning_rates=[1e-2,1e-3,1e-4,1e-5,1e-6],weight_decays=[1e-4,1e-5],k_range=[1,1.25,1.5,1.75,2,3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b21a73a",
   "metadata": {},
   "source": [
    "#### Evaluate pre-trained autoencoders  on the compromised-ied and compromised scada scenarios \n",
    "\n",
    "No exact labeling for the comp ied scenario results in low performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19349642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Trained_AE_model=AE(input_dim=76)\n",
    "Trained_AE_model.load_state_dict(torch.load(\"./best_models/AE_f1_0.97_recall_1.00_.pth\"))\n",
    "Trained_VAE_model=VAE(input_dim=76)\n",
    "Trained_VAE_model.load_state_dict(torch.load(\"./best_models/VAE_f1_0.83_recall_0.75_.pth\"))\n",
    "Trained_AAE_model=AdversarialAutoencoder()\n",
    "Trained_AAE_model.load_state_dict(torch.load(\"./best_models/AdversarialAutoencoder_f1_0.97_recall_1.00_.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d7e62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scenario : compromised-scada node ied1b\n",
      "----------- benign valid files: 3 ['dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-22-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-25-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-17-labeled.csv']\n",
      "----------compromised-scada attack  test files :  8 ['dataset/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-6-labeled.csv', 'dataset/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-3-labeled.csv', 'dataset/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-4-labeled.csv', 'dataset/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-1-labeled.csv', 'dataset/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-7-labeled.csv', 'dataset/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-0-labeled.csv', 'dataset/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-5-labeled.csv', 'dataset/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-2-labeled.csv']\n",
      "********** AdversarialAutoencoder **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0305 std: 0.2940\n",
      "Val: Accuracy: 0.9831  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.3245\n",
      "Counts of : original binary labels Counter({0: 701716, 1: 171557}) predicted binary labels Counter({0: 649808, 1: 223465})\n",
      "Counts of  original  labels: {0: 701716, 1: 170342, 2: 263, 3: 182, 4: 208, 5: 197, 6: 158, 7: 207}\n",
      "Counts of misclassified original labels: {0: 82595, 1: 30474, 2: 47, 3: 69, 4: 33, 5: 2, 6: 61, 7: 1}\n",
      "Test : Accuracy: 0.8703 Recall : 0.8211 FDR: 0.3696  F1-score: 0.7132  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.9125\n",
      "Counts of : original binary labels Counter({0: 701716, 1: 171557}) predicted binary labels Counter({0: 653077, 1: 220196})\n",
      "Counts of  original  labels: {0: 701716, 1: 170342, 2: 263, 3: 182, 4: 208, 5: 197, 6: 158, 7: 207}\n",
      "Counts of misclassified original labels: {0: 81328, 1: 32259, 2: 47, 3: 72, 4: 33, 5: 8, 6: 63, 7: 207}\n",
      "Test : Accuracy: 0.8694 Recall : 0.8095 FDR: 0.3693  F1-score: 0.7090  \n",
      "********** AE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0263 std: 0.2894\n",
      "Val: Accuracy: 0.9756  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.3157\n",
      "Counts of : original binary labels Counter({0: 701716, 1: 171557}) predicted binary labels Counter({0: 819742, 1: 53531})\n",
      "Counts of  original  labels: {0: 701716, 1: 170342, 2: 263, 3: 182, 4: 208, 5: 197, 6: 158, 7: 207}\n",
      "Counts of misclassified original labels: {0: 24156, 1: 141606, 2: 225, 3: 164, 4: 33, 5: 2, 6: 151, 7: 1}\n",
      "Test : Accuracy: 0.8095 Recall : 0.1712 FDR: 0.4513  F1-score: 0.2610  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.8944\n",
      "Counts of : original binary labels Counter({0: 701716, 1: 171557}) predicted binary labels Counter({0: 870057, 1: 3216})\n",
      "Counts of  original  labels: {0: 701716, 1: 170342, 2: 263, 3: 182, 4: 208, 5: 197, 6: 158, 7: 207}\n",
      "Counts of misclassified original labels: {0: 1692, 1: 169093, 2: 261, 3: 182, 4: 101, 5: 31, 6: 158, 7: 207}\n",
      "Test : Accuracy: 0.8034 Recall : 0.0089 FDR: 0.5261  F1-score: 0.0174  \n",
      "********** VAE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.1118 std: 0.4577\n",
      "Val: Accuracy: 0.8439  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.5696\n",
      "Counts of : original binary labels Counter({0: 701716, 1: 171557}) predicted binary labels Counter({0: 644137, 1: 229136})\n",
      "Counts of  original  labels: {0: 701716, 1: 170342, 2: 263, 3: 182, 4: 208, 5: 197, 6: 158, 7: 207}\n",
      "Counts of misclassified original labels: {0: 89740, 1: 31748, 2: 47, 3: 71, 4: 33, 5: 2, 6: 62, 7: 198}\n",
      "Test : Accuracy: 0.8604 Recall : 0.8125 FDR: 0.3916  F1-score: 0.6958  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.485\n",
      "Counts of : original binary labels Counter({0: 701716, 1: 171557}) predicted binary labels Counter({0: 649377, 1: 223896})\n",
      "Counts of  original  labels: {0: 701716, 1: 170342, 2: 263, 3: 182, 4: 208, 5: 197, 6: 158, 7: 207}\n",
      "Counts of misclassified original labels: {0: 84815, 1: 32050, 2: 47, 3: 71, 4: 33, 5: 8, 6: 63, 7: 204}\n",
      "Test : Accuracy: 0.8657 Recall : 0.8107 FDR: 0.3788  F1-score: 0.7034  \n",
      "scenario : compromised-ied node ied1b\n",
      "----------- benign valid files: 3 ['dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-22-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-25-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-17-labeled.csv']\n",
      "----------compromised-ied attack  test files :  6 ['dataset/ModbusDataset/attack/compromised-ied/ied1b/ied1b-network-captures/ready/vethc76bd3f-3-labeled.csv', 'dataset/ModbusDataset/attack/compromised-ied/ied1b/ied1b-network-captures/ready/vethc76bd3f-4-labeled.csv', 'dataset/ModbusDataset/attack/compromised-ied/ied1b/ied1b-network-captures/ready/vethc76bd3f-1-labeled.csv', 'dataset/ModbusDataset/attack/compromised-ied/ied1b/ied1b-network-captures/ready/vethc76bd3f-0-labeled.csv', 'dataset/ModbusDataset/attack/compromised-ied/ied1b/ied1b-network-captures/ready/vethc76bd3f-5-labeled.csv', 'dataset/ModbusDataset/attack/compromised-ied/ied1b/ied1b-network-captures/ready/vethc76bd3f-2-labeled.csv']\n",
      "********** AdversarialAutoencoder **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0305 std: 0.2940\n",
      "Val: Accuracy: 0.9831  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.3245\n",
      "Counts of : original binary labels Counter({0: 658934, 1: 362}) predicted binary labels Counter({0: 657143, 1: 2153})\n",
      "Counts of  original  labels: {0: 658934, 2: 66, 3: 78, 4: 52, 5: 62, 7: 60, 8: 44}\n",
      "Counts of misclassified original labels: {0: 2142, 2: 66, 3: 78, 4: 52, 5: 51, 7: 60, 8: 44}\n",
      "Test : Accuracy: 0.9962 Recall : 0.0304 FDR: 0.9949  F1-score: 0.0087  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.9125\n",
      "Counts of : original binary labels Counter({0: 658934, 1: 362}) predicted binary labels Counter({0: 657171, 1: 2125})\n",
      "Counts of  original  labels: {0: 658934, 2: 66, 3: 78, 4: 52, 5: 62, 7: 60, 8: 44}\n",
      "Counts of misclassified original labels: {0: 2114, 2: 66, 3: 78, 4: 52, 5: 51, 7: 60, 8: 44}\n",
      "Test : Accuracy: 0.9963 Recall : 0.0304 FDR: 0.9948  F1-score: 0.0088  \n",
      "********** AE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0263 std: 0.2894\n",
      "Val: Accuracy: 0.9756  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.3157\n",
      "Counts of : original binary labels Counter({0: 658934, 1: 362}) predicted binary labels Counter({0: 657261, 1: 2035})\n",
      "Counts of  original  labels: {0: 658934, 2: 66, 3: 78, 4: 52, 5: 62, 7: 60, 8: 44}\n",
      "Counts of misclassified original labels: {0: 2024, 2: 66, 3: 78, 4: 52, 5: 51, 7: 60, 8: 44}\n",
      "Test : Accuracy: 0.9964 Recall : 0.0304 FDR: 0.9946  F1-score: 0.0092  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.8944\n",
      "Counts of : original binary labels Counter({0: 658934, 1: 362}) predicted binary labels Counter({0: 658159, 1: 1137})\n",
      "Counts of  original  labels: {0: 658934, 2: 66, 3: 78, 4: 52, 5: 62, 7: 60, 8: 44}\n",
      "Counts of misclassified original labels: {0: 1127, 2: 66, 3: 78, 4: 52, 5: 52, 7: 60, 8: 44}\n",
      "Test : Accuracy: 0.9978 Recall : 0.0276 FDR: 0.9912  F1-score: 0.0133  \n",
      "********** VAE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.1122 std: 0.4601\n",
      "Val: Accuracy: 0.8438  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.5723\n",
      "Counts of : original binary labels Counter({0: 658934, 1: 362}) predicted binary labels Counter({0: 610145, 1: 49151})\n",
      "Counts of  original  labels: {0: 658934, 2: 66, 3: 78, 4: 52, 5: 62, 7: 60, 8: 44}\n",
      "Counts of misclassified original labels: {0: 49120, 2: 61, 3: 75, 4: 46, 5: 49, 7: 58, 8: 42}\n",
      "Test : Accuracy: 0.9250 Recall : 0.0856 FDR: 0.9994  F1-score: 0.0013  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.493\n",
      "Counts of : original binary labels Counter({0: 658934, 1: 362}) predicted binary labels Counter({0: 651212, 1: 8084})\n",
      "Counts of  original  labels: {0: 658934, 2: 66, 3: 78, 4: 52, 5: 62, 7: 60, 8: 44}\n",
      "Counts of misclassified original labels: {0: 8065, 2: 65, 3: 76, 4: 48, 5: 50, 7: 60, 8: 44}\n",
      "Test : Accuracy: 0.9872 Recall : 0.0525 FDR: 0.9976  F1-score: 0.0045  \n",
      "scenario : external node ied1a\n",
      "----------- benign valid files: 3 ['dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-22-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-25-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-17-labeled.csv']\n",
      "----------external attack  test files :  1 ['dataset/ModbusDataset/attack/external/ied1a/ied1a-network-capture/ready/veth4edc015-0-labeled.csv']\n",
      "********** AdversarialAutoencoder **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0305 std: 0.2940\n",
      "Val: Accuracy: 0.9831  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.3245\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 87437, 1: 37995})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2177, 1: 197}\n",
      "Test : Accuracy: 0.9811 Recall : 0.9945 FDR: 0.0573  F1-score: 0.9679  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.9125\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 98371, 1: 27061})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 350, 1: 9296, 6: 8}\n",
      "Test : Accuracy: 0.9230 Recall : 0.7417 FDR: 0.0129  F1-score: 0.8469  \n",
      "********** AE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0263 std: 0.2894\n",
      "Val: Accuracy: 0.9756  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.3157\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65725, 0: 59707})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29876, 1: 166}\n",
      "Test : Accuracy: 0.7605 Recall : 0.9954 FDR: 0.4546  F1-score: 0.7047  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.8944\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99111, 1: 26321})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 328, 1: 10014, 6: 8}\n",
      "Test : Accuracy: 0.9175 Recall : 0.7217 FDR: 0.0125  F1-score: 0.8340  \n",
      "********** VAE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.1128 std: 0.4613\n",
      "Val: Accuracy: 0.8444  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.574\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 94252, 1: 31180})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 4272, 1: 9099, 6: 8}\n",
      "Test : Accuracy: 0.8933 Recall : 0.7471 FDR: 0.1370  F1-score: 0.8009  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.497\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 98326, 1: 27106})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 980, 1: 9880, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.9133 Recall : 0.7254 FDR: 0.0362  F1-score: 0.8278  \n"
     ]
    }
   ],
   "source": [
    "for scenario in {\"external\",\"compromised-scada\",\"compromised-ied\"}:\n",
    "    if scenario!=\"external\":\n",
    "        print(\"scenario :\",scenario,\"node ied1b\")\n",
    "        test_files= [col for col in modbus.dataset[\"attack_dataset_dir\"][scenario] if col.find(\"ied1b\")!=-1]\n",
    "    else:\n",
    "        print(\"scenario :\",scenario,\"node ied1a\")\n",
    "        test_files= [col for col in modbus.dataset[\"attack_dataset_dir\"][scenario] if col.find(\"substation-wide-capture\")!=-1]        \n",
    "\n",
    "    print(\"----------- benign valid files:\",len(val_files),val_files)\n",
    "    print(f\"----------{scenario} attack  test files : \",len(test_files),test_files)\n",
    "    val_dataloader=DataLoader(ModbusFlowStream(\n",
    "                shuffle=False,\n",
    "                chunk_size=100,\n",
    "                batch_size=64,\n",
    "                csv_files=val_files,\n",
    "                scalers=loaded_scalers['network-wide']['min_max_scalers'],\n",
    "            ),batch_size=1,shuffle=False)\n",
    "    test_dataloader=DataLoader(ModbusFlowStream(\n",
    "                shuffle=False,\n",
    "                chunk_size=100,\n",
    "                batch_size=64,\n",
    "                csv_files=test_files,\n",
    "                scalers=loaded_scalers['network-wide']['min_max_scalers'],\n",
    "            ),batch_size=1,shuffle=False)\n",
    "    for trained_model in {Trained_AE_model,Trained_VAE_model,Trained_AAE_model}:\n",
    "        print(\"*\"*10,trained_model._get_name(),10*\"*\")\n",
    "        train_eval(trained_model,None,val_dataloader,test_dataloader,shuffle_files=False,num_epochs=1,eval_epoch=1,criterion_method=\"mse\",train_model=False,learning_rates=[0],weight_decays=[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e10197",
   "metadata": {},
   "source": [
    "### Part b: Federated learning \n",
    "####  non iid distribution of dataset (ip\\node based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f948763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 1. SETUP: INSTALL LIBRARIES AND IMPORT DEPENDENCIES\n",
    "# ==============================================================================\n",
    "# In a Kaggle notebook, run this cell first to install the necessary libraries.\n",
    "# !pip install -q flwr[simulation] torch torchvision pandas scikit-learn matplotlib seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc049d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import flwr as fl\n",
    "from collections import OrderedDict\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import seaborn as sns\n",
    "import os \n",
    "from flwr.common import Context # Make sure this import is added\n",
    "import random\n",
    "# Suppress warning messages for a cleaner output\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "# Set a seed for reproducibility\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "#global device\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on {DEVICE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e80a446",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================================================================\n",
    "#  FEDERATED LEARNING CLIENT: FlowerClient\n",
    "# ==============================================================================\n",
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    \"\"\"Flower client for training.\"\"\"\n",
    "    def __init__(self, cid, model, trainloader):\n",
    "        self.cid = cid\n",
    "        self.model = model\n",
    "        self.train_dataloader = trainloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n",
    "\n",
    "    def set_parameters(self, parameters):\n",
    "        params_dict = zip(self.model.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "        self.model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        model =self.model\n",
    "        lr = cfg.LEARNING_RATE\n",
    "        wd= cfg.WEIGHT_DECAY\n",
    "        \n",
    "        criterion = nn.MSELoss(reduction='sum').to(DEVICE)\n",
    "        if model._get_name()==\"AdversarialAutoencoder\":\n",
    "            adversarial_criterion= nn.BCELoss(reduction=\"sum\")\n",
    "            optimizer_D = optim.Adam(model.discriminator.parameters(), lr=lr, weight_decay=wd)\n",
    "            optimizer_G =  optim.Adam(list(model.encoder.parameters()) + list(model.decoder.parameters()), lr=lr, weight_decay=wd)\n",
    "        else:\n",
    "            AE_optimizer = optim.Adam(model.parameters(), lr=lr,weight_decay=wd)\n",
    "\n",
    "        if cfg.STRATEGY == \"FED_PROX\":\n",
    "            global_params_dict = {\n",
    "                k: torch.tensor(v, device=DEVICE) \n",
    "                for k, v in zip(self.model.state_dict().keys(), parameters)\n",
    "            }\n",
    "\n",
    "        for epoch in range(cfg.LOCAL_EPOCHS):\n",
    "                time_1 = time.time()\n",
    "                model.train()\n",
    "                train_loss = 0\n",
    "                ## for AAE\n",
    "                Discriminator_loss = 0\n",
    "                if cfg.SHUFFLE_FILES:\n",
    "                    sys_rand = SystemRandom()\n",
    "                    sys_rand.shuffle(self.train_dataloader.dataset.csv_files)\n",
    "                for sequences, _ in self.train_dataloader:\n",
    "                    sequences=sequences.squeeze().to(DEVICE)\n",
    "                    if model._get_name()==\"AdversarialAutoencoder\":\n",
    "                        target_ones= torch.ones(sequences.size(0), 1,device=DEVICE,dtype=torch.float)\n",
    "                        target_zeros= torch.zeros(sequences.size(0), 1,device=DEVICE,dtype=torch.float)\n",
    "                        random_latent = torch.randn(sequences.size(0), 2, device=DEVICE)\n",
    "                        optimizer_G.zero_grad()\n",
    "                        fake_z,decoded_seq = model(sequences)\n",
    "                        G_loss = 0.001*adversarial_criterion(model.discriminator(fake_z),target_ones ) + 0.999*criterion(decoded_seq, sequences)\n",
    "                        if cfg.STRATEGY == \"FED_PROX\":\n",
    "                            proximal_term_G = 0.0\n",
    "                            # Proximal term for ENCODER\n",
    "                            for name, local_param in model.encoder.named_parameters():\n",
    "                                global_param = global_params_dict['encoder.' + name]\n",
    "                                proximal_term_G += torch.pow((local_param - global_param).norm(2), 2)\n",
    "                            # Proximal term for DECODER\n",
    "                            for name, local_param in model.decoder.named_parameters():\n",
    "                                global_param = global_params_dict['decoder.' + name]\n",
    "                                proximal_term_G += torch.pow((local_param - global_param).norm(2), 2)\n",
    "                            \n",
    "                            G_loss += (cfg.PROXIMAL_MU / 2) * proximal_term_G\n",
    "                    \n",
    "                        G_loss.backward()\n",
    "                        optimizer_G.step()\n",
    "                        # 2) discriminator loss\n",
    "                        optimizer_D.zero_grad()\n",
    "                        real_loss = adversarial_criterion(model.discriminator(random_latent), target_ones)\n",
    "                        fake_loss = adversarial_criterion(model.discriminator(fake_z.detach()),  target_zeros)\n",
    "                        D_loss =  0.5*(real_loss + fake_loss)\n",
    "                        if cfg.STRATEGY == \"FED_PROX\":\n",
    "                            proximal_term_D = 0.0\n",
    "                            # Proximal term for DISCRIMINATOR\n",
    "                            for name, local_param in model.discriminator.named_parameters():\n",
    "                                global_param = global_params_dict['discriminator.' + name]\n",
    "                                proximal_term_D += torch.pow((local_param - global_param).norm(2), 2)\n",
    "                            D_loss += (cfg.PROXIMAL_MU / 2) * proximal_term_D\n",
    "                \n",
    "                        D_loss.backward()\n",
    "                        optimizer_D.step()\n",
    "                        train_loss+=G_loss.item()\n",
    "                        Discriminator_loss+=D_loss.item()   \n",
    "                    else:\n",
    "                        AE_optimizer.zero_grad()\n",
    "                        if model._get_name()==\"AE\":\n",
    "                            recon = model(sequences)\n",
    "                            loss = criterion(recon, sequences) / sequences.size(0)\n",
    "                        elif model._get_name()==\"VAE\" :\n",
    "                            recon, mu, logvar = model(sequences)\n",
    "                            loss = vae_loss_function(recon, sequences, mu, logvar) /sequences.size(0)\n",
    "                        if cfg.STRATEGY == \"FED_PROX\":\n",
    "                            proximal_term = 0.0\n",
    "                            for local_w, global_w in zip(model.parameters(), global_params):\n",
    "                                proximal_term += (local_w - global_w).norm(2)\n",
    "                            loss += (cfg.PROXIMAL_MU / 2) * proximal_term\n",
    "                        loss.backward()\n",
    "                        AE_optimizer.step()\n",
    "                        train_loss += loss.item()\n",
    "                print(f\"Train : time {(time.time()-time_1):.2f} s\",\n",
    "                f\"Epoch {epoch+1}\")\n",
    "                if model._get_name()==\"AdversarialAutoencoder\":\n",
    "                    print(f\"Generator Loss: {train_loss / len(self.train_dataloader):.4f}\",\n",
    "                        f\"Discriminator Loss: {Discriminator_loss / len(self.train_dataloader):.4f}\")\n",
    "                else:\n",
    "                    print(f\"Train Loss: {train_loss / len(self.train_dataloader):.4f}\")\n",
    "        return self.get_parameters(config={}), len(self.train_dataloader.dataset), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        return 0.0, 0, {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34efffc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================================================================\n",
    "#  SERVER-SIDE LOGIC AND SIMULATION START\n",
    "# ==============================================================================\n",
    "def client_fn(context: Context) -> FlowerClient:\n",
    "    \"\"\"Create a Flower client instance for a given client ID.\"\"\"\n",
    "    # The client's ID is retrieved from the context.\n",
    "    client_id = int(context.node_config[\"partition-id\"])\n",
    "    model = get_model().to(DEVICE)\n",
    "    trainloader = load_data_from_id(client_id,\"client\")\n",
    "    return FlowerClient(client_id, model, trainloader).to_client()\n",
    "\n",
    "\n",
    "def get_evaluate_fn():\n",
    "    \"\"\"Return an evaluation function for server-side evaluation.\"\"\"\n",
    "    val_dataloader = load_data_from_id(0,\"server\")\n",
    "    test_dataloader = load_data_from_id(1,\"server\")\n",
    "    eval_criterion = nn.MSELoss(reduction='none').to(DEVICE)\n",
    "    best_f1=0\n",
    "    best_recall=0\n",
    "\n",
    "    def evaluate(\n",
    "        server_round: int,\n",
    "        parameters: fl.common.NDArrays,\n",
    "        config: Dict[str, fl.common.Scalar],\n",
    "        train_model=True\n",
    "    ) -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:\n",
    "        nonlocal best_f1,best_recall\n",
    "        model = get_model() # Use the get_model function\n",
    "        params_dict = zip(model.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "        model.load_state_dict(state_dict, strict=True)\n",
    "        model.to(DEVICE)\n",
    "        model.eval()\n",
    "        # Evaluate part\n",
    "        all_val_losses = []\n",
    "        all_val_labels = []\n",
    "        print(f\"--- Running Evaluation for Server round {server_round} ---\")\n",
    "        with torch.no_grad():\n",
    "            for sequences, labels in val_dataloader:\n",
    "                sequences = sequences.squeeze().to(DEVICE) \n",
    "                if labels.sum()!=0:\n",
    "                    continue\n",
    "                if model._get_name()==\"AE\":\n",
    "                    recon = model(sequences)\n",
    "                elif model._get_name()==\"VAE\" :\n",
    "                    recon, _, _ = model(sequences)\n",
    "                elif model._get_name()==\"AdversarialAutoencoder\":\n",
    "                    _,recon= model(sequences)\n",
    "                val_loss = eval_criterion(recon, sequences)\n",
    "                if val_loss.dim() > 1:\n",
    "                    val_loss = val_loss\n",
    "                else:\n",
    "                    val_loss = val_loss.unsqueeze(dim=0)\n",
    "                    labels = labels.unsqueeze(dim=0)\n",
    "                if val_loss.dim()==3:\n",
    "                    ##GRU : mean of window\n",
    "                    val_loss = val_loss.mean(dim=1)\n",
    "                val_loss = val_loss.sum(dim=1)\n",
    "                all_val_losses.extend(val_loss.cpu().numpy())\n",
    "                all_val_labels.extend(labels.flatten().cpu().numpy())     \n",
    "        threshold_1,std_mse = compute_threshold(all_val_losses,k=0)\n",
    "\n",
    "        all_val_losses = np.array(all_val_losses).squeeze()  \n",
    "        all_val_labels = np.array(all_val_labels).squeeze()  \n",
    "        # If intrusion score > threshold, predict 1 (intrusion), else 0 (benign)\n",
    "        # For FDR, get True Positives (TP) and False Positives (FP)\n",
    "        \n",
    "        predictions = (all_val_losses > threshold_1).astype(int)\n",
    "\n",
    "        accuracy = accuracy_score(all_val_labels, predictions)\n",
    "        print(f\"Val: Accuracy: {accuracy:.4f}  \")\n",
    "        model.eval() \n",
    "\n",
    "        all_test_losses = []\n",
    "        all_test_labels = []\n",
    "        temp_best_recall =best_recall\n",
    "        temp_best_f1 =best_f1\n",
    "        with torch.no_grad():\n",
    "            for sequences, labels in test_dataloader:\n",
    "                sequences = sequences.squeeze().to(DEVICE)\n",
    "                labels = labels.squeeze().to(DEVICE)\n",
    "                if model._get_name()==\"AE\":\n",
    "                    recon = model(sequences)\n",
    "                elif model._get_name()==\"VAE\" :\n",
    "                    recon, mu, logvar = model(sequences)\n",
    "                elif model._get_name()==\"AdversarialAutoencoder\":\n",
    "                    _,recon= model(sequences)\n",
    "\n",
    "                intrusion_scores = eval_criterion(recon, sequences)\n",
    "                if intrusion_scores.dim() > 1:\n",
    "                    intrusion_scores = intrusion_scores\n",
    "                else:\n",
    "                    intrusion_scores = intrusion_scores.unsqueeze(dim=0)\n",
    "                    labels = labels.unsqueeze(dim=0)\n",
    "                if intrusion_scores.dim()==3:\n",
    "                    ##GRU : mean of window\n",
    "                    intrusion_scores = intrusion_scores.mean(dim=1)\n",
    "                intrusion_scores = intrusion_scores.sum(dim=1)\n",
    "                all_test_losses.extend(intrusion_scores.cpu().numpy())\n",
    "                all_test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        all_test_losses = np.array(all_test_losses)\n",
    "        all_test_labels = np.array(all_test_labels)\n",
    "\n",
    "        test_result = {}\n",
    "        for k in {1,3}:\n",
    "            threshold=threshold_1+k*std_mse\n",
    "            print(f\" K: {k} K-SIGMA Threshold : ---thr {threshold:.4}\")\n",
    "            predictions = (all_test_losses > threshold).astype(int)\n",
    "            binary_test_labels = (all_test_labels != 0).astype(int)\n",
    "\n",
    "            # Find the indices where the prediction was incorrect\n",
    "            misclassified_indices = np.where(binary_test_labels != predictions)[0]\n",
    "\n",
    "            # Get the original labels for those misclassified instances\n",
    "            misclassified_original_labels = all_test_labels[misclassified_indices]\n",
    "\n",
    "            # To get a summary count of which labels were misclassified\n",
    "            print(\"Counts of : original binary labels\",Counter(binary_test_labels),\"predicted binary labels\",Counter(predictions))\n",
    "            print(f\"Counts of  original  labels: {dict(sorted(Counter(all_test_labels).items()))}\")\n",
    "            print(f\"Counts of misclassified original labels: {dict(sorted(Counter(misclassified_original_labels).items()))}\")\n",
    "            accuracy = accuracy_score(binary_test_labels, predictions)\n",
    "            f1 = f1_score(binary_test_labels, predictions, zero_division=0)\n",
    "            recall = recall_score(binary_test_labels, predictions,zero_division=0)\n",
    "            _, fp, _, tp = confusion_matrix(binary_test_labels, predictions, labels=[0, 1]).ravel()\n",
    "            # FDR = FP / (FP + TP) \n",
    "            if (fp + tp) == 0:\n",
    "                fdr = 0.0 \n",
    "            else:\n",
    "                fdr = fp / (fp + tp)\n",
    "            test_result[k] = f\"k= {k} ,Test : Accuracy: {accuracy:.4f} Recall : {recall:.4f} FDR: {fdr:.4f}  F1-score: {f1:.4f} \"\n",
    "            print(test_result[k])\n",
    "            !mkdir fed_models -p\n",
    "            if f1>best_f1 :\n",
    "                best_f1=f1\n",
    "            if recall>best_recall:\n",
    "                best_recall=recall\n",
    "        if (best_recall>temp_best_recall or best_f1 > temp_best_f1):\n",
    "            if train_model:\n",
    "                save_path =\"fed_models/\"+model._get_name()+\"_f1_\"+f\"{best_f1:.2f}\" +\"_recall_\"+f\"{best_recall:.2f}\" +\"_.pth\"\n",
    "                torch.save(model.state_dict(),save_path)\n",
    "                print(\"model\",model._get_name(),\"is saved in\" ,save_path )\n",
    "        return np.sum(all_test_losses)/len(all_test_losses),test_result\n",
    "\n",
    "    return evaluate\n",
    "\n",
    "def get_initial_parameters(model_name: str):\n",
    "    \"\"\"\n",
    "    Initializes the model weights using Xavier uniform distribution\n",
    "    and returns them as a Flower Parameters object.\n",
    "    \"\"\"\n",
    "    \n",
    "    temp_model = get_model()\n",
    "    for param in temp_model.parameters():\n",
    "        if param.dim() > 1:\n",
    "            nn.init.xavier_uniform_(param)\n",
    "            \n",
    "    ndarrays = [val.cpu().numpy() for _, val in temp_model.state_dict().items()]\n",
    "    return ndarrays_to_parameters(ndarrays)\n",
    "\n",
    "\n",
    "def load_data_from_id(id: int, node = \"client\" ):\n",
    "    \"\"\"Loads the data for a specific training client.\"\"\"\n",
    "    if node == \"client\":\n",
    "        file_list = TRAIN_CLIENT_DATA_MAPPING[id]\n",
    "        shuffle=cfg.SHUFFLE_FILES\n",
    "    else: # server\n",
    "        file_list = SERVER_EVALUATION_DATA_MAPPING[id]\n",
    "        shuffle = False\n",
    "\n",
    "    train_loader=DataLoader(ModbusFlowStream(\n",
    "            shuffle=shuffle,\n",
    "            chunk_size=1,\n",
    "            batch_size=cfg.BATCH_SIZE ,\n",
    "            csv_files=file_list,\n",
    "            scalers=loaded_scalers['network-wide']['min_max_scalers'],\n",
    "        ),batch_size=1,shuffle=False)\n",
    "    return train_loader\n",
    "def get_model():\n",
    "    \"\"\"Returns the model specified in the config.\"\"\"\n",
    "    if cfg.MODEL_NAME == \"VAE\":\n",
    "        print(f\"Using Variational Autoencoder (VAE) \")\n",
    "        return VAE(input_dim=cfg.INPUT_DIM)\n",
    "    elif cfg.MODEL_NAME == \"AE\":\n",
    "        print(f\"Using Autoencoder (AE) \")\n",
    "        return AE(input_dim=cfg.INPUT_DIM)\n",
    "    elif cfg.MODEL_NAME ==\"AAE\":\n",
    "        print(f\"Using Adverserial Autoencoder (AAE) \")\n",
    "        return AdversarialAutoencoder()#76\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model name: {cfg.MODEL_NAME}. Choose 'AE' or 'VAE' or 'AAE'.\")\n",
    "\n",
    "def set_server_strategy():\n",
    "    evaluate_function = get_evaluate_fn()\n",
    "\n",
    "    if cfg.STRATEGY == \"FED_PROX\":\n",
    "        strategy = fl.server.strategy.FedProx(\n",
    "            fraction_fit=1.0, fraction_evaluate=0.0,\n",
    "            min_fit_clients=cfg.NUM_TRAIN_CLIENTS,\n",
    "            min_available_clients=cfg.NUM_TRAIN_CLIENTS,\n",
    "            evaluate_fn=evaluate_function,\n",
    "            proximal_mu=cfg.PROXIMAL_MU,\n",
    "            initial_parameters=get_initial_parameters(cfg.MODEL_NAME)\n",
    "        )\n",
    "        # The fl.server.strategy.FedProx in itself will not be different than FedAvg, the client needs to be adjusted.\n",
    "        print(\"Using FedProx strategy.\")\n",
    "    else:\n",
    "        strategy = fl.server.strategy.FedAvg(\n",
    "            fraction_fit=1.0, fraction_evaluate=0.0,\n",
    "            min_fit_clients=cfg.NUM_TRAIN_CLIENTS,\n",
    "            min_available_clients=cfg.NUM_TRAIN_CLIENTS,\n",
    "            evaluate_fn=evaluate_function,\n",
    "            initial_parameters=get_initial_parameters(cfg.MODEL_NAME)\n",
    "\n",
    "        )\n",
    "        print(f\"Using FedAvg strategy with {cfg.MODEL_NAME} model.\")\n",
    "    return strategy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bc0e13",
   "metadata": {},
   "source": [
    "#### External Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3219b1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================================================================\n",
    "#  DATA Distribution\n",
    "# ==============================================================================\n",
    "\n",
    "ied1b_train_files=[col for col in modbus.dataset[\"benign_dataset_dir\"] if col.find(\"ied1b\")!=-1][:]\n",
    "ied1a_train_files=[col for col in modbus.dataset[\"benign_dataset_dir\"] if col.find(\"ied1a\")!=-1][:]\n",
    "ied4c_train_files=[col for col in modbus.dataset[\"benign_dataset_dir\"] if col.find(\"ied4c\")!=-1][:]\n",
    "cent_agent_test_files=[col for col in modbus.dataset[\"benign_dataset_dir\"] if col.find(\"central-agent\")!=-1][:]\n",
    "test_files=[col for col in modbus.dataset[\"attack_dataset_dir\"][\"external\"] if col.find(\"ied1a\")!=-1][:]\n",
    "random.seed(42)\n",
    "val_files = []\n",
    "\n",
    "for list_files in [ied1b_train_files,ied1a_train_files,ied4c_train_files]: \n",
    "    random.shuffle(list_files)\n",
    "    val_files += list_files[-2:]\n",
    "TRAIN_CLIENT_DATA_MAPPING = {\n",
    "    0: ied1b_train_files[:-2],\n",
    "    1: ied1a_train_files[:-2],\n",
    "    2: ied4c_train_files[:-2],\n",
    "    3: cent_agent_test_files,\n",
    "}\n",
    "\n",
    "SERVER_EVALUATION_DATA_MAPPING = {\n",
    "    0: val_files,\n",
    "    1: test_files\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8580f738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " ['dataset/ModbusDataset/attack/external/ied1a/ied1a-network-capture/ready/veth4edc015-0-labeled.csv'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ied1b_train_files),len(TRAIN_CLIENT_DATA_MAPPING[0]),len(val_files),len(test_files),len(val_files),test_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c2c487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded scalers for 'network-wide'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==============================================================================\n",
    "#  CONFIGURATION: TWEAK  FEDERATED LEARNING EXPERIMENT\n",
    "# ==============================================================================\n",
    "class Config:\n",
    "    \"\"\"Global configuration class for the federated learning experiment.\"\"\"\n",
    "    # --- FL Parameters ---\n",
    "    NUM_TRAIN_CLIENTS = 4\n",
    "    NUM_ROUNDS = 5\n",
    "    LOCAL_EPOCHS = 6\n",
    "    BATCH_SIZE = 64\n",
    "    LEARNING_RATE = 5e-3\n",
    "    WEIGHT_DECAY = 1e-5\n",
    "    # --- Strategy Selection ---\n",
    "    # Choose from \"FED_AVG\", \"FED_PROX\"\n",
    "    STRATEGY = \"FED_AVG\" \n",
    "    PROXIMAL_MU = 0.1 # Proximal term for FedProx\n",
    "    # --- Model Selection ---\n",
    "    # Choose from \"AE\" (Autoencoder) or \"VAE\" (Variational Autoencoder) or \"AdverserialAutoencoder\"\n",
    "    MODEL_NAME = \"AE\"\n",
    "    INPUT_DIM = 76\n",
    "    # --- Anomaly Detection ---\n",
    "    SHUFFLE_FILES=  True\n",
    "# Instantiate the configuration\n",
    "cfg = Config()\n",
    "\n",
    "loaded_scalers = load_scalers(\"fitted_scalers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635dab53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n",
      "\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n",
      "\n",
      "\t\t$ flwr new  # Create a new Flower app from a template\n",
      "\n",
      "\t\t$ flwr run  # Run the Flower app in Simulation Mode\n",
      "\n",
      "\tUsing `start_simulation()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=5, no round_timeout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "Using FedAvg strategy with AE model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-20 09:57:30,514\tINFO worker.py:1771 -- Started a local Ray instance.\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'accelerator_type:G': 1.0, 'node:__internal_head__': 1.0, 'CPU': 4.0, 'object_store_memory': 3110452838.0, 'node:172.27.10.12': 1.0, 'memory': 6220905678.0, 'GPU': 1.0}\n",
      "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 4, 'num_gpus': 1}\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 1 actors\n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 0 ---\n",
      "-----------mse_loss mean :  16.5777 std: 1.1006\n",
      "Val: Accuracy: 0.1758  \n",
      " K: 1 K-SIGMA Threshold : ---thr 17.68\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 114643, 1: 10789})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2089, 1: 27300, 2: 1, 5: 1, 6: 13}\n",
      "k= 1 ,Test : Accuracy: 0.7656 Recall : 0.2416 FDR: 0.1936  F1-score: 0.3718 \n",
      " K: 3 K-SIGMA Threshold : ---thr 19.88\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 122536, 1: 2896})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 8, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7358 Recall : 0.0802 FDR: 0.0028  F1-score: 0.1484 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 17.022243127750496, {1: 'k= 1 ,Test : Accuracy: 0.7656 Recall : 0.2416 FDR: 0.1936  F1-score: 0.3718 ', 3: 'k= 3 ,Test : Accuracy: 0.7358 Recall : 0.0802 FDR: 0.0028  F1-score: 0.1484 '}\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model AE is saved in fed_models/AE_f1_0.37_recall_0.24_.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m /home/hamid_rd3/labeling/FLBased-ICS-NIDS-main/modbus.py:4: DeprecationWarning: \n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m (to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m but was not found to be installed on your system.\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m If this would cause problems for you,\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m   import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 56.60 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 1.0481\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 57.98 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.0203\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 53.98 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.0181\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 53.45 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.0172\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 54.35 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.0106\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 51.76 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.0064\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 37.78 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.1294\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 36.44 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.0027\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 38.21 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.0003\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 38.18 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.0003\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 36.08 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.0003\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 36.99 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.0003\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 1.11 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 4.6118\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 1.01 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 2.0534\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 1.14 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 2.0389\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 1.00 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 2.0392\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 1.06 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 2.0364\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 1.02 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 2.0363\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 61.98 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.8700\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 64.85 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.0216\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 65.83 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.0186\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 62.61 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.0176\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 67.22 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.0153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 1 ---\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 62.89 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.0122\n",
      "-----------mse_loss mean :  3.3778 std: 1.6996\n",
      "Val: Accuracy: 0.6474  \n",
      " K: 1 K-SIGMA Threshold : ---thr 5.077\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99258, 1: 26174})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 23286, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.5503 Recall : 0.0802 FDR: 0.8897  F1-score: 0.0929 \n",
      " K: 3 K-SIGMA Threshold : ---thr 8.477\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 122526, 1: 2906})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 18, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7358 Recall : 0.0802 FDR: 0.0062  F1-score: 0.1484 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (1, 3.444958971793482, {1: 'k= 1 ,Test : Accuracy: 0.5503 Recall : 0.0802 FDR: 0.8897  F1-score: 0.0929 ', 3: 'k= 3 ,Test : Accuracy: 0.7358 Recall : 0.0802 FDR: 0.0062  F1-score: 0.1484 '}, 975.7797216860004)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 1.00 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 1.3253\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 0.97 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.6862\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 1.02 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.5568\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 0.98 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.4891\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 1.04 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.4605\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 1.04 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.4514\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 64.42 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.8847\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 64.95 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.8661\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 62.11 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.8644\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 59.87 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.8640\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 59.85 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.8639\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 62.68 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.8639\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 54.33 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.8932\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 55.04 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.8722\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 53.22 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.8707\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 55.74 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.8705\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 55.38 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.8701\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 55.08 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.8700\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 36.37 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.0034\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 36.40 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.0003\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 35.27 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.0003\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 36.45 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.0003\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 35.16 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 2 ---\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 33.18 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.0003\n",
      "-----------mse_loss mean :  1.9087 std: 1.9552\n",
      "Val: Accuracy: 0.5900  \n",
      " K: 1 K-SIGMA Threshold : ---thr 3.864\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 97854, 1: 27578})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 24690, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.5391 Recall : 0.0802 FDR: 0.8953  F1-score: 0.0908 \n",
      " K: 3 K-SIGMA Threshold : ---thr 7.774\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 122500, 1: 2932})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 44, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7355 Recall : 0.0802 FDR: 0.0150  F1-score: 0.1483 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (2, 1.9851105828257543, {1: 'k= 1 ,Test : Accuracy: 0.5391 Recall : 0.0802 FDR: 0.8953  F1-score: 0.0908 ', 3: 'k= 3 ,Test : Accuracy: 0.7355 Recall : 0.0802 FDR: 0.0150  F1-score: 0.1483 '}, 1923.929670637)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 60.10 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.8661\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 59.03 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.8640\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 58.77 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.8637\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 61.35 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.8630\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 60.20 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.8627\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 66.67 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.8627\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 56.34 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.8720\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 57.43 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.8699\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 54.92 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.8691\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 54.36 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.8690\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 58.25 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.8688\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 60.75 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.8688\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 40.02 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.0005\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 40.16 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.0002\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 34.00 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.0002\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 38.01 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.0002\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 38.19 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.0002\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 39.15 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.0002\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 1.06 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.5450\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 1.00 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.2610\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 1.06 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.2475\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 1.00 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.2301\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 1.02 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.2113\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train : time 1.01 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=2121)\u001b[0m Train Loss: 0.1888\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m strategy\u001b[38;5;241m=\u001b[39mset_server_strategy()\n\u001b[0;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mfl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_simulation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_clients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNUM_TRAIN_CLIENTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mServerConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNUM_ROUNDS\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_resources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_cpus\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_gpus\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_cpus\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFederated learning simulation finished.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/flwr/simulation/legacy_app.py:361\u001b[0m, in \u001b[0;36mstart_simulation\u001b[0;34m(client_fn, num_clients, clients_ids, client_resources, server, config, strategy, client_manager, ray_init_args, keep_initialised, actor_type, actor_kwargs, actor_scheduling)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[0;32m--> 361\u001b[0m     hist \u001b[38;5;241m=\u001b[39m \u001b[43mrun_fl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitialized_server\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitialized_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m    366\u001b[0m     log(ERROR, ex)\n",
      "File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/flwr/server/server.py:492\u001b[0m, in \u001b[0;36mrun_fl\u001b[0;34m(server, config)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_fl\u001b[39m(\n\u001b[1;32m    488\u001b[0m     server: Server,\n\u001b[1;32m    489\u001b[0m     config: ServerConfig,\n\u001b[1;32m    490\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m History:\n\u001b[1;32m    491\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train a model on the given server and return the History object.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 492\u001b[0m     hist, elapsed_time \u001b[38;5;241m=\u001b[39m \u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mround_timeout\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    496\u001b[0m     log(INFO, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    497\u001b[0m     log(INFO, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[SUMMARY]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/flwr/server/server.py:115\u001b[0m, in \u001b[0;36mServer.fit\u001b[0;34m(self, num_rounds, timeout)\u001b[0m\n\u001b[1;32m    113\u001b[0m log(INFO, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[ROUND \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m, current_round)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# Train model and replace previous global model\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m res_fit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_round\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurrent_round\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res_fit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     parameters_prime, fit_metrics, _ \u001b[38;5;241m=\u001b[39m res_fit  \u001b[38;5;66;03m# fit_metrics_aggregated\u001b[39;00m\n",
      "File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/flwr/server/server.py:234\u001b[0m, in \u001b[0;36mServer.fit_round\u001b[0;34m(self, server_round, timeout)\u001b[0m\n\u001b[1;32m    226\u001b[0m log(\n\u001b[1;32m    227\u001b[0m     INFO,\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigure_fit: strategy sampled \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m clients (out of \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28mlen\u001b[39m(client_instructions),\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_manager\u001b[38;5;241m.\u001b[39mnum_available(),\n\u001b[1;32m    231\u001b[0m )\n\u001b[1;32m    233\u001b[0m \u001b[38;5;66;03m# Collect `fit` results from all clients participating in this round\u001b[39;00m\n\u001b[0;32m--> 234\u001b[0m results, failures \u001b[38;5;241m=\u001b[39m \u001b[43mfit_clients\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_instructions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_instructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_round\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m log(\n\u001b[1;32m    241\u001b[0m     INFO,\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggregate_fit: received \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m results and \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m failures\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28mlen\u001b[39m(results),\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28mlen\u001b[39m(failures),\n\u001b[1;32m    245\u001b[0m )\n\u001b[1;32m    247\u001b[0m \u001b[38;5;66;03m# Aggregate training results\u001b[39;00m\n",
      "File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/flwr/server/server.py:353\u001b[0m, in \u001b[0;36mfit_clients\u001b[0;34m(client_instructions, max_workers, timeout, group_id)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mThreadPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39mmax_workers) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m    349\u001b[0m     submitted_fs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    350\u001b[0m         executor\u001b[38;5;241m.\u001b[39msubmit(fit_client, client_proxy, ins, timeout, group_id)\n\u001b[1;32m    351\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m client_proxy, ins \u001b[38;5;129;01min\u001b[39;00m client_instructions\n\u001b[1;32m    352\u001b[0m     }\n\u001b[0;32m--> 353\u001b[0m     finished_fs, _ \u001b[38;5;241m=\u001b[39m \u001b[43mconcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubmitted_fs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Handled in the respective communication stack\u001b[39;49;00m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;66;03m# Gather results\u001b[39;00m\n\u001b[1;32m    359\u001b[0m results: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[ClientProxy, FitRes]] \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:307\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(fs, timeout, return_when)\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m DoneAndNotDoneFutures(done, not_done)\n\u001b[1;32m    305\u001b[0m     waiter \u001b[38;5;241m=\u001b[39m _create_and_install_waiters(fs, return_when)\n\u001b[0;32m--> 307\u001b[0m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fs:\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m f\u001b[38;5;241m.\u001b[39m_condition:\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "strategy=set_server_strategy()\n",
    "\n",
    "history = fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=cfg.NUM_TRAIN_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=cfg.NUM_ROUNDS),\n",
    "    strategy=strategy,\n",
    "    client_resources={\"num_cpus\": 4, \"num_gpus\": 1} if DEVICE.type == \"cuda\" else {\"num_cpus\": 4},\n",
    ")\n",
    "print(\"Federated learning simulation finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5f6d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n",
      "\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n",
      "\n",
      "\t\t$ flwr new  # Create a new Flower app from a template\n",
      "\n",
      "\t\t$ flwr run  # Run the Flower app in Simulation Mode\n",
      "\n",
      "\tUsing `start_simulation()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=5, no round_timeout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "Using FedProx strategy.\n",
      "Starting federated learning simulation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-19 22:44:11,045\tINFO worker.py:1771 -- Started a local Ray instance.\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'accelerator_type:G': 1.0, 'node:__internal_head__': 1.0, 'CPU': 4.0, 'object_store_memory': 2733051494.0, 'node:172.27.10.12': 1.0, 'memory': 5466102990.0, 'GPU': 1.0}\n",
      "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 4, 'num_gpus': 0.25}\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 1 actors\n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 0 ---\n",
      "-----------mse_loss mean :  17.3456 std: 1.2496\n",
      "Val: Accuracy: 0.1758  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 17.797824717775367, {1: 'k= 1 ,Test : Accuracy: 0.7775 Recall : 0.2762 FDR: 0.1560  F1-score: 0.4163 ', 3: 'k= 3 ,Test : Accuracy: 0.7358 Recall : 0.0802 FDR: 0.0028  F1-score: 0.1484 '}\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 18.6\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 113644, 1: 11788})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 1839, 1: 26040, 2: 1, 3: 1, 4: 1, 5: 1, 6: 21, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.7775 Recall : 0.2762 FDR: 0.1560  F1-score: 0.4163 \n",
      " K: 3 K-SIGMA Threshold : ---thr 21.09\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 122536, 1: 2896})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 8, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7358 Recall : 0.0802 FDR: 0.0028  F1-score: 0.1484 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m /home/hamid_rd3/labeling/FLBased-ICS-NIDS-main/modbus.py:4: DeprecationWarning: \n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m (to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m but was not found to be installed on your system.\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m If this would cause problems for you,\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m   import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 1.20 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 1.6840\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 1.07 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.6494\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 1.04 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.5715\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 0.99 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.5052\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 0.98 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.3730\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 1.07 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.3454\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 61.45 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0458\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 62.12 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0052\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 59.75 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0049\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 62.08 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0048\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 60.06 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0045\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 61.46 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0045\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 53.19 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0536\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 52.16 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0057\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 55.07 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0054\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 52.57 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0050\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 52.13 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0047\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 53.83 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0045\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 34.56 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0283\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 34.74 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0008\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 35.55 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0007\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 36.18 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0006\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 34.14 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 1 ---\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 35.05 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0006\n",
      "-----------mse_loss mean :  5.0821 std: 2.0178\n",
      "Val: Accuracy: 0.4407  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (1, 5.876791807513234, {1: 'k= 1 ,Test : Accuracy: 0.7758 Recall : 0.2704 FDR: 0.1594  F1-score: 0.4092 ', 3: 'k= 3 ,Test : Accuracy: 0.7138 Recall : 0.0034 FDR: 0.0081  F1-score: 0.0068 '}, 930.8592217459991)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 7.1\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 113848, 1: 11584})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 1846, 1: 26262, 2: 1, 5: 1, 6: 13}\n",
      "k= 1 ,Test : Accuracy: 0.7758 Recall : 0.2704 FDR: 0.1594  F1-score: 0.4092 \n",
      " K: 3 K-SIGMA Threshold : ---thr 11.14\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 125308, 1: 124})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 1, 1: 35855, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7138 Recall : 0.0034 FDR: 0.0081  F1-score: 0.0068 \n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 35.25 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0032\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 36.17 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0009\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 35.63 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0008\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 34.34 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0007\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 34.46 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0006\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 37.61 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0006\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 59.30 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0146\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 61.35 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0044\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 60.28 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0040\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 59.54 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0039\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 61.73 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0040\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 60.02 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0037\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 55.06 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0186\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 52.34 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0050\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 50.33 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0046\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 53.84 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0042\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 51.71 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0043\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 53.52 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0041\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 1.24 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.4738\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 1.05 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.1841\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 1.10 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.1640\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 1.00 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.1596\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 1.05 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.1527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 0.98 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.1526\n",
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 2 ---\n",
      "-----------mse_loss mean :  1.5576 std: 0.8414\n",
      "Val: Accuracy: 0.6508  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (2, 1.9883199911107214, {1: 'k= 1 ,Test : Accuracy: 0.8760 Recall : 0.7217 FDR: 0.1754  F1-score: 0.7697 ', 3: 'k= 3 ,Test : Accuracy: 0.7175 Recall : 0.0802 FDR: 0.4446  F1-score: 0.1401 '}, 1856.504111107999)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 2.399\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 93910, 1: 31522})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5530, 1: 10014, 5: 1, 6: 8}\n",
      "k= 1 ,Test : Accuracy: 0.8760 Recall : 0.7217 FDR: 0.1754  F1-score: 0.7697 \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.082\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 120232, 1: 5200})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2312, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7175 Recall : 0.0802 FDR: 0.4446  F1-score: 0.1401 \n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 34.85 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0011\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 35.45 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0007\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 36.47 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0008\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 33.99 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0005\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 33.33 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0006\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 35.49 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0005\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 52.73 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0134\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 50.67 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0043\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 53.62 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0040\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 50.78 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0041\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 51.87 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0040\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 53.12 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0040\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 59.20 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0056\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 59.82 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0038\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 59.96 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0037\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 59.05 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0035\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 60.40 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0037\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 60.64 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0037\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 1.04 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.5297\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 1.04 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.1951\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 0.97 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.1769\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 0.96 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.1647\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 0.97 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.1546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 3 ---\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 0.97 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.1505\n",
      "-----------mse_loss mean :  1.1870 std: 1.6022\n",
      "Val: Accuracy: 0.5563  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (3, 1.5157865666257415, {1: 'k= 1 ,Test : Accuracy: 0.6860 Recall : 0.0806 FDR: 0.6835  F1-score: 0.1285 ', 3: 'k= 3 ,Test : Accuracy: 0.7175 Recall : 0.0802 FDR: 0.4435  F1-score: 0.1402 '}, 2769.3617328869987)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 2.789\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 116256, 1: 9176})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6272, 1: 33076, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.6860 Recall : 0.0806 FDR: 0.6835  F1-score: 0.1285 \n",
      " K: 3 K-SIGMA Threshold : ---thr 5.993\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 120242, 1: 5190})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2302, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7175 Recall : 0.0802 FDR: 0.4435  F1-score: 0.1402 \n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 0.99 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.5226\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 1.03 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.1844\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 1.18 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.1682\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 1.05 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.1591\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 0.98 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.1529\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 1.00 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.1422\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 35.92 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0008\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 36.01 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0005\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 34.10 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0006\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 34.09 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0005\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 35.45 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0006\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 36.61 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0006\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 52.02 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0064\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 53.30 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0040\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 53.43 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0040\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 51.45 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0037\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 54.17 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0038\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 52.69 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0036\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 59.68 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0047\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 62.51 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0036\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 59.28 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0035\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 62.45 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0037\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 60.68 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 4 ---\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 60.04 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0036\n",
      "-----------mse_loss mean :  0.9290 std: 1.3892\n",
      "Val: Accuracy: 0.6156  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (4, 1.3770945113687096, {1: 'k= 1 ,Test : Accuracy: 0.8696 Recall : 0.7216 FDR: 0.1957  F1-score: 0.7607 ', 3: 'k= 3 ,Test : Accuracy: 0.7133 Recall : 0.0802 FDR: 0.4949  F1-score: 0.1384 '}, 3694.961857099999)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 2.318\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 93121, 1: 32311})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6324, 1: 10018, 5: 2, 6: 8}\n",
      "k= 1 ,Test : Accuracy: 0.8696 Recall : 0.7216 FDR: 0.1957  F1-score: 0.7607 \n",
      " K: 3 K-SIGMA Threshold : ---thr 5.097\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 119714, 1: 5718})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2830, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7133 Recall : 0.0802 FDR: 0.4949  F1-score: 0.1384 \n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 34.81 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0009\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 34.64 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0006\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 34.43 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0005\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 36.86 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0005\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 34.76 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0005\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 33.32 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0005\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 61.10 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0047\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 59.91 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0035\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 60.56 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0035\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 60.74 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0034\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 59.36 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0036\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 61.51 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0036\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 51.32 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0064\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 52.20 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0038\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 53.91 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0036\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 51.17 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0037\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 53.73 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0040\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 53.23 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.0037\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 1.00 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.5022\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 1.02 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.1921\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 1.16 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.1691\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 1.06 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.1600\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 1.00 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.1527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 5 ---\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train : time 1.01 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=85045)\u001b[0m Train Loss: 0.1481\n",
      "-----------mse_loss mean :  0.9481 std: 0.7556\n",
      "Val: Accuracy: 0.5806  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (5, 1.5623278449677913, {1: 'k= 1 ,Test : Accuracy: 0.8675 Recall : 0.7217 FDR: 0.2023  F1-score: 0.7578 ', 3: 'k= 3 ,Test : Accuracy: 0.7345 Recall : 0.0827 FDR: 0.0820  F1-score: 0.1517 '}, 4613.534135204998)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 5 round(s) in 4613.54s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, centralized):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 0: 17.797824717775367\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 5.876791807513234\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 1.9883199911107214\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 1.5157865666257415\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 4: 1.3770945113687096\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 5: 1.5623278449677913\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, centralized):\n",
      "\u001b[92mINFO \u001b[0m:      \t{1: [(0,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.7775 Recall : 0.2762 FDR: 0.1560  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.4163 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (1,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.7758 Recall : 0.2704 FDR: 0.1594  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.4092 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (2,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.8760 Recall : 0.7217 FDR: 0.1754  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.7697 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (3,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.6860 Recall : 0.0806 FDR: 0.6835  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1285 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (4,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.8696 Recall : 0.7216 FDR: 0.1957  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.7607 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (5,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.8675 Recall : 0.7217 FDR: 0.2023  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.7578 ')],\n",
      "\u001b[92mINFO \u001b[0m:      \t 3: [(0,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7358 Recall : 0.0802 FDR: 0.0028  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1484 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (1,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7138 Recall : 0.0034 FDR: 0.0081  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.0068 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (2,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7175 Recall : 0.0802 FDR: 0.4446  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1401 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (3,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7175 Recall : 0.0802 FDR: 0.4435  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1402 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (4,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7133 Recall : 0.0802 FDR: 0.4949  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1384 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (5,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7345 Recall : 0.0827 FDR: 0.0820  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1517 ')]}\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 1.704\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 92847, 1: 32585})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6593, 1: 10014, 5: 1, 6: 8}\n",
      "k= 1 ,Test : Accuracy: 0.8675 Recall : 0.7217 FDR: 0.2023  F1-score: 0.7578 \n",
      " K: 3 K-SIGMA Threshold : ---thr 3.215\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 122188, 1: 3244})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 266, 1: 33002, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7345 Recall : 0.0827 FDR: 0.0820  F1-score: 0.1517 \n",
      "Federated learning simulation finished.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Instantiate the configuration\n",
    "cfg.STRATEGY=\"FED_PROX\"\n",
    "strategy=set_server_strategy()\n",
    "\n",
    "# --- Start the Simulation ---\n",
    "print(\"Starting federated learning simulation...\")\n",
    "history = fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=cfg.NUM_TRAIN_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=cfg.NUM_ROUNDS),\n",
    "    strategy=strategy,\n",
    "    client_resources={\"num_cpus\": 4, \"num_gpus\": 1} if DEVICE.type == \"cuda\" else {\"num_cpus\": 4},\n",
    ")\n",
    "print(\"Federated learning simulation finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8515c34",
   "metadata": {},
   "source": [
    "### VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cb200f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n",
      "\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n",
      "\n",
      "\t\t$ flwr new  # Create a new Flower app from a template\n",
      "\n",
      "\t\t$ flwr run  # Run the Flower app in Simulation Mode\n",
      "\n",
      "\tUsing `start_simulation()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=5, no round_timeout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Variational Autoencoder (VAE) \n",
      "Using FedAvg strategy with VAE model.\n",
      "Starting federated learning simulation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-20 00:01:35,904\tINFO worker.py:1771 -- Started a local Ray instance.\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'accelerator_type:G': 1.0, 'node:__internal_head__': 1.0, 'CPU': 4.0, 'memory': 5452224923.0, 'node:172.27.10.12': 1.0, 'object_store_memory': 2726112460.0, 'GPU': 1.0}\n",
      "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 4, 'num_gpus': 0.25}\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 1 actors\n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Variational Autoencoder (VAE) \n",
      "--- Running Evaluation for Server round 0 ---\n",
      "-----------mse_loss mean :  17.0604 std: 1.1685\n",
      "Val: Accuracy: 0.1754  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 17.48678766184068, {1: 'k= 1 ,Test : Accuracy: 0.7431 Recall : 0.1763 FDR: 0.2867  F1-score: 0.2827 ', 3: 'k= 3 ,Test : Accuracy: 0.7358 Recall : 0.0802 FDR: 0.0028  F1-score: 0.1484 '}\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 18.23\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 116533, 1: 8899})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2551, 1: 29637, 2: 1, 3: 1, 4: 1, 5: 1, 6: 26}\n",
      "k= 1 ,Test : Accuracy: 0.7431 Recall : 0.1763 FDR: 0.2867  F1-score: 0.2827 \n",
      " K: 3 K-SIGMA Threshold : ---thr 20.57\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 122536, 1: 2896})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 8, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7358 Recall : 0.0802 FDR: 0.0028  F1-score: 0.1484 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m /home/hamid_rd3/labeling/FLBased-ICS-NIDS-main/modbus.py:4: DeprecationWarning: \n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m (to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m but was not found to be installed on your system.\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m If this would cause problems for you,\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m   import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 72.81 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 12.2964\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 71.71 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 9.4120\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 71.31 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 9.2382\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 72.48 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 9.1610\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 70.04 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 9.1318\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 72.35 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 9.1121\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 62.10 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 13.1149\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 62.38 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 9.2415\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 62.05 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 9.0985\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 62.92 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 9.0595\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 61.68 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 9.0468\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 63.91 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 9.0351\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 1.35 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 50.3503\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 1.28 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 40.8220\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 1.21 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 29.7209\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 1.21 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 25.0544\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 1.16 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 24.1660\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 1.21 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 23.8438\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 41.81 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 8.8792\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 40.44 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 5.7324\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 42.87 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 5.7307\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 42.18 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 5.7294\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 39.82 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 5.7273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Variational Autoencoder (VAE) \n",
      "--- Running Evaluation for Server round 1 ---\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 40.25 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 5.7215\n",
      "-----------mse_loss mean :  2.7199 std: 3.0201\n",
      "Val: Accuracy: 0.5904  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (1, 2.3519830465909815, {1: 'k= 1 ,Test : Accuracy: 0.6012 Recall : 0.0802 FDR: 0.8540  F1-score: 0.1035 ', 3: 'k= 3 ,Test : Accuracy: 0.7127 Recall : 0.0032 FDR: 0.5375  F1-score: 0.0065 '}, 1089.5348550050003)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 5.74\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 105651, 1: 19781})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 16893, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.6012 Recall : 0.0802 FDR: 0.8540  F1-score: 0.1035 \n",
      " K: 3 K-SIGMA Threshold : ---thr 11.78\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 125179, 1: 253})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 136, 1: 35861, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7127 Recall : 0.0032 FDR: 0.5375  F1-score: 0.0065 \n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 62.08 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 9.3868\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 62.12 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 9.0674\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 62.40 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 9.0381\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 61.70 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 9.0222\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 61.68 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 9.0173\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 61.23 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 9.0077\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 42.14 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 5.7740\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 40.65 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 5.7247\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 40.13 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 5.7190\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 41.18 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 5.7103\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 41.72 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 5.7010\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 40.87 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 5.6967\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 75.13 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 9.3314\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 73.00 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 9.0468\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 70.62 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 9.0226\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 70.99 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 9.0099\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 70.70 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 9.0031\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 70.95 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 8.9945\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 1.25 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 41.4499\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 1.18 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 28.8844\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 1.16 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 23.9417\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 1.20 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 22.0458\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 1.15 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 21.3463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Variational Autoencoder (VAE) \n",
      "--- Running Evaluation for Server round 2 ---\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 1.25 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 21.0290\n",
      "-----------mse_loss mean :  2.2259 std: 2.8629\n",
      "Val: Accuracy: 0.6274  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (2, 2.144526516359462, {1: 'k= 1 ,Test : Accuracy: 0.6133 Recall : 0.0802 FDR: 0.8419  F1-score: 0.1064 ', 3: 'k= 3 ,Test : Accuracy: 0.7137 Recall : 0.0032 FDR: 0.0714  F1-score: 0.0065 '}, 2171.562568911999)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 5.089\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 107168, 1: 18264})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 15376, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.6133 Recall : 0.0802 FDR: 0.8419  F1-score: 0.1064 \n",
      " K: 3 K-SIGMA Threshold : ---thr 10.81\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 125306, 1: 126})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 9, 1: 35861, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7137 Recall : 0.0032 FDR: 0.0714  F1-score: 0.0065 \n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 42.62 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 5.7738\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 41.10 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 5.7182\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 39.81 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 5.7021\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 40.87 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 5.6950\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 42.54 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 5.6937\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 39.51 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 5.6935\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 71.01 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 9.0658\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 69.63 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 8.9995\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 70.59 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 8.9905\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 69.67 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 8.9832\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 71.94 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 8.9762\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 69.16 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 8.9695\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 1.14 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 34.8719\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 1.26 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 23.9898\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 1.14 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 21.6133\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 1.18 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 20.9700\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 1.22 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 20.6824\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 1.22 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 20.4858\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 63.06 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 9.0828\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 61.18 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 9.0107\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 60.94 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 9.0018\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 62.20 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 8.9939\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 60.12 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 8.9856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Variational Autoencoder (VAE) \n",
      "--- Running Evaluation for Server round 3 ---\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 63.76 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 8.9803\n",
      "-----------mse_loss mean :  2.6372 std: 3.2484\n",
      "Val: Accuracy: 0.6245  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (3, 2.374795706039926, {1: 'k= 1 ,Test : Accuracy: 0.5886 Recall : 0.0802 FDR: 0.8648  F1-score: 0.1007 ', 3: 'k= 3 ,Test : Accuracy: 0.7138 Recall : 0.0032 FDR: 0.0000  F1-score: 0.0065 '}, 3244.8208170830003)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 5.886\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 104073, 1: 21359})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 18471, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.5886 Recall : 0.0802 FDR: 0.8648  F1-score: 0.1007 \n",
      " K: 3 K-SIGMA Threshold : ---thr 12.38\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 125315, 1: 117})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {1: 35861, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7138 Recall : 0.0032 FDR: 0.0000  F1-score: 0.0065 \n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 41.68 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 5.7637\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 40.77 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 5.7110\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 41.45 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 5.6965\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 40.17 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 5.6933\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 40.72 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 5.6932\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 41.21 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 5.6927\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 1.19 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 28.6651\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 1.15 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 23.6550\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 1.16 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 22.0275\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 1.14 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 21.2558\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 1.36 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 20.9777\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 1.31 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 20.7941\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 71.72 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 9.0395\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 72.10 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 8.9683\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 72.13 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 8.9611\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 73.23 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 8.9576\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 70.34 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 8.9515\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 72.88 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 8.9501\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 62.78 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 9.0646\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 62.92 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 8.9761\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 61.37 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 8.9714\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 63.87 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 8.9621\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 63.19 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 8.9581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Variational Autoencoder (VAE) \n",
      "--- Running Evaluation for Server round 4 ---\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 61.81 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 8.9553\n",
      "-----------mse_loss mean :  2.5702 std: 3.1840\n",
      "Val: Accuracy: 0.6259  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (4, 2.344022558039416, {1: 'k= 1 ,Test : Accuracy: 0.5888 Recall : 0.0802 FDR: 0.8647  F1-score: 0.1007 ', 3: 'k= 3 ,Test : Accuracy: 0.7138 Recall : 0.0032 FDR: 0.0168  F1-score: 0.0065 '}, 4332.562985601999)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 5.754\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 104089, 1: 21343})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 18455, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.5888 Recall : 0.0802 FDR: 0.8647  F1-score: 0.1007 \n",
      " K: 3 K-SIGMA Threshold : ---thr 12.12\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 125313, 1: 119})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2, 1: 35861, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7138 Recall : 0.0032 FDR: 0.0168  F1-score: 0.0065 \n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 41.84 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 5.7630\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 41.63 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 5.7160\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 41.40 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 5.7095\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 41.99 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 5.6970\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 42.81 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 5.6937\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 41.97 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 5.6932\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 1.21 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 27.9002\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 1.18 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 22.0929\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 1.24 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 21.5298\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 1.22 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 21.1484\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 1.19 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 20.8350\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 1.36 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 20.5731\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 62.81 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 9.0366\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 63.10 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 8.9599\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 62.32 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 8.9516\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 60.77 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 8.9498\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 63.09 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 8.9462\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 61.01 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 8.9426\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 71.94 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 9.0194\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 69.93 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 8.9519\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 73.07 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 8.9442\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 70.48 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 8.9418\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 72.43 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 8.9386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train : time 71.87 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=114602)\u001b[0m Train Loss: 8.9327\n",
      "Using Variational Autoencoder (VAE) \n",
      "--- Running Evaluation for Server round 5 ---\n",
      "-----------mse_loss mean :  2.3608 std: 3.0397\n",
      "Val: Accuracy: 0.6403  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (5, 2.2330802247432873, {1: 'k= 1 ,Test : Accuracy: 0.6019 Recall : 0.0802 FDR: 0.8534  F1-score: 0.1037 ', 3: 'k= 3 ,Test : Accuracy: 0.7137 Recall : 0.0032 FDR: 0.0640  F1-score: 0.0065 '}, 5421.410711401)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 5 round(s) in 5421.41s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, centralized):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 0: 17.48678766184068\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 2.3519830465909815\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 2.144526516359462\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 2.374795706039926\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 4: 2.344022558039416\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 5: 2.2330802247432873\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, centralized):\n",
      "\u001b[92mINFO \u001b[0m:      \t{1: [(0,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.7431 Recall : 0.1763 FDR: 0.2867  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.2827 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (1,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.6012 Recall : 0.0802 FDR: 0.8540  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1035 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (2,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.6133 Recall : 0.0802 FDR: 0.8419  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1064 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (3,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.5886 Recall : 0.0802 FDR: 0.8648  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1007 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (4,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.5888 Recall : 0.0802 FDR: 0.8647  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1007 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (5,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.6019 Recall : 0.0802 FDR: 0.8534  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1037 ')],\n",
      "\u001b[92mINFO \u001b[0m:      \t 3: [(0,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7358 Recall : 0.0802 FDR: 0.0028  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1484 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (1,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7127 Recall : 0.0032 FDR: 0.5375  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.0065 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (2,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7137 Recall : 0.0032 FDR: 0.0714  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.0065 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (3,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7138 Recall : 0.0032 FDR: 0.0000  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.0065 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (4,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7138 Recall : 0.0032 FDR: 0.0168  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.0065 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (5,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7137 Recall : 0.0032 FDR: 0.0640  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.0065 ')]}\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 5.401\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 105738, 1: 19694})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 16806, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.6019 Recall : 0.0802 FDR: 0.8534  F1-score: 0.1037 \n",
      " K: 3 K-SIGMA Threshold : ---thr 11.48\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 125307, 1: 125})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 8, 1: 35861, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7137 Recall : 0.0032 FDR: 0.0640  F1-score: 0.0065 \n",
      "Federated learning simulation finished.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the configuration\n",
    "cfg.STRATEGY=\"FED_AVG\"\n",
    "cfg.MODEL_NAME=\"VAE\"\n",
    "cfg.LEARNING_RATE=1e-4\n",
    "cfg.WEIGHT_DECAY=1e-4\n",
    "strategy=set_server_strategy()\n",
    "\n",
    "# --- Start the Simulation ---\n",
    "print(\"Starting federated learning simulation...\")\n",
    "history = fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=cfg.NUM_TRAIN_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=cfg.NUM_ROUNDS),\n",
    "    strategy=strategy,\n",
    "    client_resources={\"num_cpus\": 4, \"num_gpus\": 1} if DEVICE.type == \"cuda\" else {\"num_cpus\": 4},\n",
    ")\n",
    "print(\"Federated learning simulation finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b129e9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n",
      "\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n",
      "\n",
      "\t\t$ flwr new  # Create a new Flower app from a template\n",
      "\n",
      "\t\t$ flwr run  # Run the Flower app in Simulation Mode\n",
      "\n",
      "\tUsing `start_simulation()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=5, no round_timeout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Variational Autoencoder (VAE) \n",
      "Using FedProx strategy.\n",
      "Starting federated learning simulation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-20 01:32:28,909\tINFO worker.py:1771 -- Started a local Ray instance.\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'accelerator_type:G': 1.0, 'node:__internal_head__': 1.0, 'CPU': 4.0, 'memory': 5452325684.0, 'node:172.27.10.12': 1.0, 'object_store_memory': 2726162841.0, 'GPU': 1.0}\n",
      "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 4, 'num_gpus': 0.25}\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 1 actors\n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Variational Autoencoder (VAE) \n",
      "--- Running Evaluation for Server round 0 ---\n",
      "-----------mse_loss mean :  16.8727 std: 1.1193\n",
      "Val: Accuracy: 0.1757  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 17.26894253460042, {1: 'k= 1 ,Test : Accuracy: 0.7546 Recall : 0.1978 FDR: 0.2097  F1-score: 0.3163 ', 3: 'k= 3 ,Test : Accuracy: 0.7358 Recall : 0.0802 FDR: 0.0028  F1-score: 0.1484 '}\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 17.99\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 116420, 1: 9012})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 1890, 1: 28866, 2: 1, 3: 1, 5: 1, 6: 23, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.7546 Recall : 0.1978 FDR: 0.2097  F1-score: 0.3163 \n",
      " K: 3 K-SIGMA Threshold : ---thr 20.23\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 122536, 1: 2896})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 8, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7358 Recall : 0.0802 FDR: 0.0028  F1-score: 0.1484 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m /home/hamid_rd3/labeling/FLBased-ICS-NIDS-main/modbus.py:4: DeprecationWarning: \n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m (to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m but was not found to be installed on your system.\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m If this would cause problems for you,\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m   import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 66.10 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.7806\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 65.24 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 6.3982\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 65.94 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 6.3351\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 66.22 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 6.3240\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 64.62 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 6.3197\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 66.36 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 6.3168\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 114.97 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 13.1440\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 112.52 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 10.3261\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 113.07 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 10.2632\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 113.36 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 10.2122\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 113.15 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 10.1828\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 113.40 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 10.1714\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 1.89 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 51.1173\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 1.91 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 43.8402\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 1.86 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 32.5946\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 1.87 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 26.7379\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 2.13 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 24.9357\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 2.16 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 24.2128\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 99.80 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 13.6123\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 97.53 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 10.3484\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 99.59 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 10.2873\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 100.11 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 10.2369\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 95.25 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 10.2125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Variational Autoencoder (VAE) \n",
      "--- Running Evaluation for Server round 1 ---\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 99.11 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 10.2004\n",
      "-----------mse_loss mean :  1.8899 std: 2.6959\n",
      "Val: Accuracy: 0.6960  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (1, 1.9630337553415396, {1: 'k= 1 ,Test : Accuracy: 0.6270 Recall : 0.0824 FDR: 0.8223  F1-score: 0.1126 ', 3: 'k= 3 ,Test : Accuracy: 0.7104 Recall : 0.0032 FDR: 0.7865  F1-score: 0.0064 '}, 1707.5057951399976)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 4.586\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 108728, 1: 16704})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 13736, 1: 33012, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.6270 Recall : 0.0824 FDR: 0.8223  F1-score: 0.1126 \n",
      " K: 3 K-SIGMA Threshold : ---thr 9.978\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 124884, 1: 548})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 431, 1: 35861, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7104 Recall : 0.0032 FDR: 0.7865  F1-score: 0.0064 \n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 101.20 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.4660\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 101.73 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.3959\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 97.98 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.3937\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 98.00 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.3931\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 101.06 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.3919\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 99.46 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.3910\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 64.03 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 6.0441\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 64.84 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 5.9672\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 64.23 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 5.9665\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 63.54 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 5.9663\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 65.25 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 5.9661\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 65.15 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 5.9667\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 2.15 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 40.5044\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 2.18 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 30.6020\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 2.24 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 25.8454\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 2.18 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 23.6403\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 2.15 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 22.6005\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 2.22 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 21.8704\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 111.05 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.4367\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 114.10 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.3746\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 112.90 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.3675\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 114.18 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.3718\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 111.13 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.3720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Variational Autoencoder (VAE) \n",
      "--- Running Evaluation for Server round 2 ---\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 111.92 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.3701\n",
      "-----------mse_loss mean :  0.5973 std: 1.1829\n",
      "Val: Accuracy: 0.8149  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (2, 1.351347368494483, {1: 'k= 1 ,Test : Accuracy: 0.8371 Recall : 0.7464 FDR: 0.2961  F1-score: 0.7246 ', 3: 'k= 3 ,Test : Accuracy: 0.7285 Recall : 0.1131 FDR: 0.3421  F1-score: 0.1930 '}, 3408.333446384)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 1.78\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 87243, 1: 38189})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 11306, 1: 9123, 5: 1, 6: 8}\n",
      "k= 1 ,Test : Accuracy: 0.8371 Recall : 0.7464 FDR: 0.2961  F1-score: 0.7246 \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.146\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 119240, 1: 6192})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2118, 1: 31906, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7285 Recall : 0.1131 FDR: 0.3421  F1-score: 0.1930 \n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 1.92 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 43.4242\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 1.94 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 31.8801\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 1.98 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 25.6689\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 1.96 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 22.9928\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 1.93 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 21.8931\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 1.91 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 21.4174\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 67.92 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 6.0353\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 65.01 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 5.9592\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 66.03 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 5.9588\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 64.93 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 5.9585\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 65.56 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 5.9588\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 65.04 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 5.9589\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 99.83 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.2848\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 98.78 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.2757\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 98.79 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.2754\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 97.72 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.2728\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 100.32 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.2756\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 96.10 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.2724\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 114.06 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.2616\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 112.86 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.2525\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 113.50 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.2512\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 113.63 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.2514\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 110.43 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.2521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Variational Autoencoder (VAE) \u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 110.66 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.2514\n",
      "\n",
      "--- Running Evaluation for Server round 3 ---\n",
      "-----------mse_loss mean :  0.6131 std: 1.2898\n",
      "Val: Accuracy: 0.8374  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (3, 1.4179871862842017, {1: 'k= 1 ,Test : Accuracy: 0.8378 Recall : 0.7509 FDR: 0.2962  F1-score: 0.7266 ', 3: 'k= 3 ,Test : Accuracy: 0.7246 Recall : 0.1056 FDR: 0.3801  F1-score: 0.1805 '}, 5106.929563776997)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 1.903\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 87009, 1: 38423})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 11379, 1: 8963, 5: 1, 6: 7}\n",
      "k= 1 ,Test : Accuracy: 0.8378 Recall : 0.7509 FDR: 0.2962  F1-score: 0.7266 \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.483\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 119296, 1: 6136})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2332, 1: 32176, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7246 Recall : 0.1056 FDR: 0.3801  F1-score: 0.1805 \n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 98.57 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.2574\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 99.75 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.2481\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 101.25 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.2450\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 101.57 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.2473\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 99.11 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.2456\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 99.56 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.2489\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 1.95 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 44.1571\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 2.21 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 32.0877\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 2.02 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 25.6942\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 1.79 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 23.1524\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 1.82 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 22.0915\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 1.79 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 21.5816\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 66.07 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 6.0212\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 64.65 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 5.9473\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 66.39 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 5.9468\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 65.97 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 5.9470\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 65.09 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 5.9470\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 67.11 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 5.9475\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 114.27 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.2337\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 116.04 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.2246\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 113.73 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.2243\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 114.92 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.2253\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 110.42 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.2254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Variational Autoencoder (VAE) \n",
      "--- Running Evaluation for Server round 4 ---\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 113.92 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.2256\n",
      "-----------mse_loss mean :  0.6491 std: 1.3994\n",
      "Val: Accuracy: 0.8448  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (4, 1.4602253362379616, {1: 'k= 1 ,Test : Accuracy: 0.8367 Recall : 0.7512 FDR: 0.2986  F1-score: 0.7254 ', 3: 'k= 3 ,Test : Accuracy: 0.7231 Recall : 0.1059 FDR: 0.3990  F1-score: 0.1801 '}, 6823.0685326819985)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 2.049\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 86860, 1: 38572})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 11519, 1: 8953, 5: 1, 6: 8}\n",
      "k= 1 ,Test : Accuracy: 0.8367 Recall : 0.7512 FDR: 0.2986  F1-score: 0.7254 \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.847\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 119086, 1: 6346})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2532, 1: 32166, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7231 Recall : 0.1059 FDR: 0.3990  F1-score: 0.1801 \n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 116.32 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.2204\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 114.80 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.2129\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 114.75 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.2119\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 114.64 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.2141\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 114.24 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.2131\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 112.23 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.2128\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 101.46 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.2435\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 100.88 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.2369\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 101.18 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.2345\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 100.71 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.2344\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 99.76 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.2339\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 101.52 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 9.2368\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 1.88 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 43.9701\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 1.95 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 31.7712\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 1.88 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 25.5316\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 1.98 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 23.1676\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 1.91 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 22.1262\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 1.93 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 21.5785\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 66.41 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 6.0114\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 64.19 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 5.9368\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 65.25 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 5.9372\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 64.17 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 5.9371\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 65.04 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 5.9385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Variational Autoencoder (VAE) \n",
      "--- Running Evaluation for Server round 5 ---\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train : time 66.27 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=145612)\u001b[0m Train Loss: 5.9367\n",
      "-----------mse_loss mean :  0.6594 std: 1.4168\n",
      "Val: Accuracy: 0.8433  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (5, 1.5015305852972127, {1: 'k= 1 ,Test : Accuracy: 0.8332 Recall : 0.7540 FDR: 0.3075  F1-score: 0.7219 ', 3: 'k= 3 ,Test : Accuracy: 0.7237 Recall : 0.1076 FDR: 0.3937  F1-score: 0.1828 '}, 8544.440030182002)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 5 round(s) in 8544.44s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, centralized):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 0: 17.26894253460042\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 1.9630337553415396\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 1.351347368494483\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 1.4179871862842017\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 4: 1.4602253362379616\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 5: 1.5015305852972127\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, centralized):\n",
      "\u001b[92mINFO \u001b[0m:      \t{1: [(0,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.7546 Recall : 0.1978 FDR: 0.2097  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.3163 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (1,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.6270 Recall : 0.0824 FDR: 0.8223  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1126 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (2,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.8371 Recall : 0.7464 FDR: 0.2961  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.7246 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (3,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.8378 Recall : 0.7509 FDR: 0.2962  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.7266 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (4,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.8367 Recall : 0.7512 FDR: 0.2986  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.7254 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (5,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.8332 Recall : 0.7540 FDR: 0.3075  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.7219 ')],\n",
      "\u001b[92mINFO \u001b[0m:      \t 3: [(0,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7358 Recall : 0.0802 FDR: 0.0028  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1484 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (1,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7104 Recall : 0.0032 FDR: 0.7865  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.0064 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (2,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7285 Recall : 0.1131 FDR: 0.3421  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1930 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (3,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7246 Recall : 0.1056 FDR: 0.3801  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1805 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (4,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7231 Recall : 0.1059 FDR: 0.3990  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1801 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (5,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7237 Recall : 0.1076 FDR: 0.3937  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1828 ')]}\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 2.076\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 86219, 1: 39213})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 12058, 1: 8851, 5: 1, 6: 8}\n",
      "k= 1 ,Test : Accuracy: 0.8332 Recall : 0.7540 FDR: 0.3075  F1-score: 0.7219 \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.91\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 119041, 1: 6391})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2516, 1: 32105, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7237 Recall : 0.1076 FDR: 0.3937  F1-score: 0.1828 \n",
      "Federated learning simulation finished.\n"
     ]
    }
   ],
   "source": [
    "cfg.STRATEGY=\"FED_PROX\"\n",
    "strategy=set_server_strategy()\n",
    "\n",
    "print(\"Starting federated learning simulation...\")\n",
    "history = fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=cfg.NUM_TRAIN_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=cfg.NUM_ROUNDS),\n",
    "    strategy=strategy,\n",
    "    client_resources={\"num_cpus\": 4, \"num_gpus\": 1} if DEVICE.type == \"cuda\" else {\"num_cpus\": 4},\n",
    ")\n",
    "print(\"Federated learning simulation finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fad8408",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n",
      "\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n",
      "\n",
      "\t\t$ flwr new  # Create a new Flower app from a template\n",
      "\n",
      "\t\t$ flwr run  # Run the Flower app in Simulation Mode\n",
      "\n",
      "\tUsing `start_simulation()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=5, no round_timeout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Adverserial Autoencoder (AAE) \n",
      "Using FedAvg strategy with AAE model.\n",
      "Starting federated learning simulation...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# --- Start the Simulation ---\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting federated learning simulation...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mfl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_simulation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_clients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNUM_TRAIN_CLIENTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mServerConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNUM_ROUNDS\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_resources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_cpus\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_gpus\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNUM_TRAIN_CLIENTS\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_cpus\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFederated learning simulation finished.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/flwr/simulation/legacy_app.py:262\u001b[0m, in \u001b[0;36mstart_simulation\u001b[0;34m(client_fn, num_clients, clients_ids, client_resources, server, config, strategy, client_manager, ray_init_args, keep_initialised, actor_type, actor_kwargs, actor_scheduling)\u001b[0m\n\u001b[1;32m    259\u001b[0m     ray\u001b[38;5;241m.\u001b[39mshutdown()\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# Initialize Ray\u001b[39;00m\n\u001b[0;32m--> 262\u001b[0m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mray_init_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m cluster_resources \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39mcluster_resources()\n\u001b[1;32m    264\u001b[0m log(\n\u001b[1;32m    265\u001b[0m     INFO,\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFlower VCE: Ray initialized with resources: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    267\u001b[0m     cluster_resources,\n\u001b[1;32m    268\u001b[0m )\n",
      "File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py:103\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/ray/_private/worker.py:1664\u001b[0m, in \u001b[0;36minit\u001b[0;34m(address, num_cpus, num_gpus, resources, labels, object_store_memory, local_mode, ignore_reinit_error, include_dashboard, dashboard_host, dashboard_port, job_config, configure_logging, logging_level, logging_format, logging_config, log_to_driver, namespace, runtime_env, storage, **kwargs)\u001b[0m\n\u001b[1;32m   1631\u001b[0m     ray_params \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39m_private\u001b[38;5;241m.\u001b[39mparameter\u001b[38;5;241m.\u001b[39mRayParams(\n\u001b[1;32m   1632\u001b[0m         node_ip_address\u001b[38;5;241m=\u001b[39m_node_ip_address,\n\u001b[1;32m   1633\u001b[0m         object_ref_seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1658\u001b[0m         node_name\u001b[38;5;241m=\u001b[39m_node_name,\n\u001b[1;32m   1659\u001b[0m     )\n\u001b[1;32m   1660\u001b[0m     \u001b[38;5;66;03m# Start the Ray processes. We set shutdown_at_exit=False because we\u001b[39;00m\n\u001b[1;32m   1661\u001b[0m     \u001b[38;5;66;03m# shutdown the node in the ray.shutdown call that happens in the atexit\u001b[39;00m\n\u001b[1;32m   1662\u001b[0m     \u001b[38;5;66;03m# handler. We still spawn a reaper process in case the atexit handler\u001b[39;00m\n\u001b[1;32m   1663\u001b[0m     \u001b[38;5;66;03m# isn't called.\u001b[39;00m\n\u001b[0;32m-> 1664\u001b[0m     _global_node \u001b[38;5;241m=\u001b[39m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_private\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m        \u001b[49m\u001b[43mray_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mray_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshutdown_at_exit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspawn_reaper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m        \u001b[49m\u001b[43mray_init_cluster\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1672\u001b[0m     \u001b[38;5;66;03m# In this case, we are connecting to an existing cluster.\u001b[39;00m\n\u001b[1;32m   1673\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num_cpus \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m num_gpus \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/ray/_private/node.py:333\u001b[0m, in \u001b[0;36mNode.__init__\u001b[0;34m(self, ray_params, head, shutdown_at_exit, spawn_reaper, connect_only, default_worker, ray_init_cluster)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# Start processes.\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head:\n\u001b[0;32m--> 333\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_head_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m connect_only:\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_ray_processes()\n",
      "File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/ray/_private/node.py:1351\u001b[0m, in \u001b[0;36mNode.start_head_processes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1348\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gcs_client \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1350\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_gcs_server()\n\u001b[0;32m-> 1351\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_gcs_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1352\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_cluster_info_to_kv()\n\u001b[1;32m   1354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ray_params\u001b[38;5;241m.\u001b[39mno_monitor:\n",
      "File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/ray/_private/node.py:712\u001b[0m, in \u001b[0;36mNode.get_gcs_client\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_gcs_client\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gcs_client \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 712\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_gcs_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gcs_client\n",
      "File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/ray/_private/node.py:728\u001b[0m, in \u001b[0;36mNode._init_gcs_client\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    727\u001b[0m     gcs_address \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgcs_address\n\u001b[0;32m--> 728\u001b[0m     client \u001b[38;5;241m=\u001b[39m \u001b[43mGcsClient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[43m        \u001b[49m\u001b[43maddress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgcs_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcluster_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ray_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcluster_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Hex string\u001b[39;49;00m\n\u001b[1;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcluster_id \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mcluster_id\n\u001b[1;32m    733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead:\n\u001b[1;32m    734\u001b[0m         \u001b[38;5;66;03m# Send a simple request to make sure GCS is alive\u001b[39;00m\n\u001b[1;32m    735\u001b[0m         \u001b[38;5;66;03m# if it's a head node.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Instantiate the configuration\n",
    "cfg.STRATEGY=\"FED_AVG\"\n",
    "cfg.MODEL_NAME=\"AAE\"\n",
    "cfg.LEARNING_RATE=1e-4\n",
    "strategy=set_server_strategy()\n",
    "\n",
    "# --- Start the Simulation ---\n",
    "print(\"Starting federated learning simulation...\")\n",
    "history = fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=cfg.NUM_TRAIN_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=cfg.NUM_ROUNDS),\n",
    "    strategy=strategy,\n",
    "    client_resources={\"num_cpus\": 4, \"num_gpus\": 1} if DEVICE.type == \"cuda\" else {\"num_cpus\": 4},\n",
    ")\n",
    "print(\"Federated learning simulation finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055eb90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the configuration\n",
    "cfg.STRATEGY=\"FED_PROX\"\n",
    "cfg.MODEL_NAME=\"AAE\"\n",
    "cfg.LEARNING_RATE=1e-4\n",
    "strategy=set_server_strategy()\n",
    "\n",
    "# --- Start the Simulation ---\n",
    "print(\"Starting federated learning simulation...\")\n",
    "history = fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=cfg.NUM_TRAIN_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=cfg.NUM_ROUNDS),\n",
    "    strategy=strategy,\n",
    "    client_resources={\"num_cpus\": 4, \"num_gpus\": 1/cfg.NUM_TRAIN_CLIENTS} if DEVICE.type == \"cuda\" else {\"num_cpus\": 4},\n",
    ")\n",
    "print(\"Federated learning simulation finished.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7758849,
     "sourceId": 12309500,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 250292947,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "vnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
