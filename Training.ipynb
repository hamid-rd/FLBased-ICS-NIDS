{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12309500,"sourceType":"datasetVersion","datasetId":7758849},{"sourceId":250292947,"sourceType":"kernelVersion"}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"d32826f1-1369-4eb5-a21b-0e6e548cded3","cell_type":"markdown","source":"### Download and make the dataset ready in Kaggle \n","metadata":{}},{"id":"26c2ad5c-f43a-4b40-a647-ecc58c71ff16","cell_type":"code","source":"\n# ## uncomment if The zip file of the dataset isn't downloaded,extraced \n# !pip install gdown\n# Copy the link. The file ID is the long string of characters between d/ and /view.\n#For example, in the URL https://drive.google.com/file/d/1aBcDeFgHiJkLmNoPqRsTuVwXyZ/view?usp=sharing, \n#the file ID is 1aBcDeFgHiJkLmNoPqRsTuVwXyZ\n# !mkdir /kaggle/tmp\n# !gdown  1pzXpA5Cz0DJmjRsLxlqRNnJq-kOUvojb -O /kaggle/tmp/Labeled_CICMODBUS2023.zip\n# !unzip /kaggle/tmp/Labeled_CICMODBUS2023.zip -d /kaggle/working/\n\n# # ## uncomment if the python modules (modbus.py,utils.py ,...) not cloned  and added to the path \n\n# !git clone https://github.com/hamid-rd/FLBased-ICS-NIDS.git\n# import sys\n# # Add the repository folder to the Python path\n# repo_path = '/kaggle/working/FLBased-ICS-NIDS'\n# repo_input_path = '/kaggle/input/training/FLBased-ICS-NIDS'\n# dataset_path = '/kaggle/input/training/'\n\n# for path in {repo_path,repo_input_path,dataset_path}:\n#     if path not in sys.path:\n#         sys.path.append(path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T16:17:38.692671Z","iopub.execute_input":"2025-07-13T16:17:38.693282Z","iopub.status.idle":"2025-07-13T16:20:31.990912Z","shell.execute_reply.started":"2025-07-13T16:17:38.693248Z","shell.execute_reply":"2025-07-13T16:20:31.990108Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\nRequirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.6)\nRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.13.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.4.26)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1pzXpA5Cz0DJmjRsLxlqRNnJq-kOUvojb\nFrom (redirected): https://drive.google.com/uc?id=1pzXpA5Cz0DJmjRsLxlqRNnJq-kOUvojb&confirm=t&uuid=d8e1c4d9-f327-45b8-bd78-ecb863cd1471\nTo: /kaggle/tmp/Labeled_CICMODBUS2023.zip\n100%|███████████████████████████████████████| 12.3G/12.3G [01:34<00:00, 130MB/s]\nArchive:  /kaggle/tmp/Labeled_CICMODBUS2023.zip\n extracting: /kaggle/working/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-25-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-30-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-26-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-17-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-18-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-19-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-24-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-28-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-22-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-23-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-21-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-32-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-29-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-31-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-16-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-27-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-14-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-20-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-15-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/ied4c/ied4c-network-capture/ready/veth8bc3408-normal-11-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/ied4c/ied4c-network-capture/ready/veth8bc3408-normal-6-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/ied4c/ied4c-network-capture/ready/veth8bc3408-normal-7-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/ied4c/ied4c-network-capture/ready/veth8bc3408-normal-9-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/ied4c/ied4c-network-capture/ready/veth8bc3408-normal-5-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/ied4c/ied4c-network-capture/ready/veth8bc3408-normal-8-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/ied4c/ied4c-network-capture/ready/veth8bc3408-normal-4-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/ied4c/ied4c-network-capture/ready/veth8bc3408-normal-10-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/ied1b/ied1b-network-capture/ready/vethd9e14c0-normal-9-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/ied1b/ied1b-network-capture/ready/vethd9e14c0-normal-4-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/ied1b/ied1b-network-capture/ready/vethd9e14c0-normal-8-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/ied1b/ied1b-network-capture/ready/vethd9e14c0-normal-6-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/ied1b/ied1b-network-capture/ready/vethd9e14c0-normal-5-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/ied1b/ied1b-network-capture/ready/vethd9e14c0-normal-10-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/ied1b/ied1b-network-capture/ready/vethd9e14c0-normal-7-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/scada-hmi/scada-hmi-network-capture/ready/veth5bbeaa2-normal-28-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/scada-hmi/scada-hmi-network-capture/ready/veth5bbeaa2-normal-22-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/scada-hmi/scada-hmi-network-capture/ready/veth5bbeaa2-normal-16-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/scada-hmi/scada-hmi-network-capture/ready/veth5bbeaa2-normal-14-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/scada-hmi/scada-hmi-network-capture/ready/veth5bbeaa2-normal-19-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/scada-hmi/scada-hmi-network-capture/ready/veth5bbeaa2-normal-24-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/scada-hmi/scada-hmi-network-capture/ready/veth5bbeaa2-normal-20-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/scada-hmi/scada-hmi-network-capture/ready/veth5bbeaa2-normal-21-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/scada-hmi/scada-hmi-network-capture/ready/veth5bbeaa2-normal-27-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/scada-hmi/scada-hmi-network-capture/ready/veth5bbeaa2-normal-30-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/scada-hmi/scada-hmi-network-capture/ready/veth5bbeaa2-normal-26-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/scada-hmi/scada-hmi-network-capture/ready/veth5bbeaa2-normal-25-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/scada-hmi/scada-hmi-network-capture/ready/veth5bbeaa2-normal-31-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/scada-hmi/scada-hmi-network-capture/ready/veth5bbeaa2-normal-17-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/scada-hmi/scada-hmi-network-capture/ready/veth5bbeaa2-normal-23-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/scada-hmi/scada-hmi-network-capture/ready/veth5bbeaa2-normal-29-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/scada-hmi/scada-hmi-network-capture/ready/veth5bbeaa2-normal-13-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/scada-hmi/scada-hmi-network-capture/ready/veth5bbeaa2-normal-18-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/scada-hmi/scada-hmi-network-capture/ready/veth5bbeaa2-normal-15-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/central-agent/central-agent-network-capture/ready/veth460b141-normal-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/ied1a/ied1a-network-capture/ready/veth4edc015-normal-11-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/ied1a/ied1a-network-capture/ready/veth4edc015-normal-4-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/ied1a/ied1a-network-capture/ready/veth4edc015-normal-10-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/ied1a/ied1a-network-capture/ready/veth4edc015-normal-6-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/ied1a/ied1a-network-capture/ready/veth4edc015-normal-5-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/ied1a/ied1a-network-capture/ready/veth4edc015-normal-7-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/ied1a/ied1a-network-capture/ready/veth4edc015-normal-9-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/benign/ied1a/ied1a-network-capture/ready/veth4edc015-normal-8-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/external/network-wide/ready/network-wide-normal-1-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/external/network-wide/ready/network-wide-normal-0-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/external/ied4c/ied4c-network-capture/ready/veth8bc3408-0-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/external/external-attacker/external-attacker-network-capture/ready/veth665f3cf-0-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/external/ied1b/ied1b-network-capture/ready/vethd9e14c0-0-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/external/scada-hmi/scada-hmi-network-capture/ready/veth5bbeaa2-0-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/external/central-agent/central-agent-network-capture/ready/veth460b141-0-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/external/ied1a/ied1a-network-capture/ready/veth4edc015-0-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/ied4c/ied4c-network-captures/ready/vethe685ac9-0-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/ied4c/ied4c-network-captures/ready/vethe685ac9-5-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/ied4c/ied4c-network-captures/ready/vethe685ac9-1-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/ied4c/ied4c-network-captures/ready/vethe685ac9-2-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/ied4c/ied4c-network-captures/ready/vethe685ac9-4-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/ied4c/ied4c-network-captures/ready/vethe685ac9-3-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-6-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-3-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-4-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-1-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-7-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-0-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-5-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-2-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/scada-hmi/scada-hmi-network-capture/ready/veth291ab9a-0-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/scada-hmi/scada-hmi-network-capture/ready/veth291ab9a-14-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/scada-hmi/scada-hmi-network-capture/ready/veth291ab9a-13-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/scada-hmi/scada-hmi-network-capture/ready/veth291ab9a-1-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/scada-hmi/scada-hmi-network-capture/ready/veth291ab9a-16-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/scada-hmi/scada-hmi-network-capture/ready/veth291ab9a-3-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/scada-hmi/scada-hmi-network-capture/ready/veth291ab9a-11-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/scada-hmi/scada-hmi-network-capture/ready/veth291ab9a-8-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/scada-hmi/scada-hmi-network-capture/ready/veth291ab9a-7-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/scada-hmi/scada-hmi-network-capture/ready/veth291ab9a-5-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/scada-hmi/scada-hmi-network-capture/ready/veth291ab9a-12-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/scada-hmi/scada-hmi-network-capture/ready/veth291ab9a-9-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/scada-hmi/scada-hmi-network-capture/ready/veth291ab9a-6-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/scada-hmi/scada-hmi-network-capture/ready/veth291ab9a-2-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/scada-hmi/scada-hmi-network-capture/ready/veth291ab9a-15-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/scada-hmi/scada-hmi-network-capture/ready/veth291ab9a-4-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/scada-hmi/scada-hmi-network-capture/ready/veth291ab9a-10-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/central-agent/central-agent-network-captures/ready/vethffb308b-1-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/central-agent/central-agent-network-captures/ready/vethffb308b-0-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/ied1a/ied1a-network-captures/ready/veth3614724-3-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/ied1a/ied1a-network-captures/ready/veth3614724-4-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/ied1a/ied1a-network-captures/ready/veth3614724-0-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/ied1a/ied1a-network-captures/ready/veth3614724-1-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/ied1a/ied1a-network-captures/ready/veth3614724-2-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/ied1a/ied1a-network-captures/ready/veth3614724-5-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/substation-wide-capture/ready/substation-14-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/substation-wide-capture/ready/substation-13-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/substation-wide-capture/ready/substation-15-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/substation-wide-capture/ready/substation-4-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/substation-wide-capture/ready/substation-10-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/substation-wide-capture/ready/substation-3-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/substation-wide-capture/ready/substation-17-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/substation-wide-capture/ready/substation-8-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/substation-wide-capture/ready/substation-5-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/substation-wide-capture/ready/substation-0-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/substation-wide-capture/ready/substation-11-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/substation-wide-capture/ready/substation-2-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/substation-wide-capture/ready/substation-9-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/substation-wide-capture/ready/substation-1-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/substation-wide-capture/ready/substation-6-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/substation-wide-capture/ready/substation-12-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/substation-wide-capture/ready/substation-7-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-scada/substation-wide-capture/ready/substation-16-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-ied/ied4c/ied4c-network-captures/ready/vethe685ac9-0-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-ied/ied4c/ied4c-network-captures/ready/vethe685ac9-5-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-ied/ied4c/ied4c-network-captures/ready/vethe685ac9-1-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-ied/ied4c/ied4c-network-captures/ready/vethe685ac9-2-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-ied/ied4c/ied4c-network-captures/ready/vethe685ac9-4-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-ied/ied4c/ied4c-network-captures/ready/vethe685ac9-3-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-ied/ied1b/ied1b-network-captures/ready/vethc76bd3f-3-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-ied/ied1b/ied1b-network-captures/ready/vethc76bd3f-4-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-ied/ied1b/ied1b-network-captures/ready/vethc76bd3f-1-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-ied/ied1b/ied1b-network-captures/ready/vethc76bd3f-0-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-ied/ied1b/ied1b-network-captures/ready/vethc76bd3f-5-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-ied/ied1b/ied1b-network-captures/ready/vethc76bd3f-2-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-2-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-10-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-19-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-17-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-0-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-9-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-15-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-3-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-7-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-14-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-12-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-18-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-6-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-16-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-8-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-1-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-13-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-4-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-5-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-11-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-ied/central-agent/central-agent-network-captures/ready/vethffb308b-2-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-ied/central-agent/central-agent-network-captures/ready/vethffb308b-4-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-ied/central-agent/central-agent-network-captures/ready/vethffb308b-3-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-ied/central-agent/central-agent-network-captures/ready/vethffb308b-1-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-ied/central-agent/central-agent-network-captures/ready/vethffb308b-0-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-ied/ied1a/ied1a-network-captures/ready/veth3614724-3-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-ied/ied1a/ied1a-network-captures/ready/veth3614724-4-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-ied/ied1a/ied1a-network-captures/ready/veth3614724-0-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-ied/ied1a/ied1a-network-captures/ready/veth3614724-1-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-ied/ied1a/ied1a-network-captures/ready/veth3614724-2-labeled.csv  \n extracting: /kaggle/working/ModbusDataset/attack/compromised-ied/ied1a/ied1a-network-captures/ready/veth3614724-5-labeled.csv  \nfatal: destination path 'FLBased-ICS-NIDS' already exists and is not an empty directory.\n","output_type":"stream"}],"execution_count":18},{"id":"601bb537-782e-4266-b619-48cdad4fe6a5","cell_type":"code","source":"# To test if every thing is okay (modbus.py class and correct number of founded csv files )\nfrom modbus import ModbusDataset,ModbusFlowStream\n\n# dataset_directory = \"/kaggle/working/ModbusDataset\" \ndataset_directory = \"/kaggle/input/training/ModbusDataset\" \n\nmodbus = ModbusDataset(dataset_directory,\"ready\")\nmodbus.summary_print()\n\n# Don't forget to save version in kaggle (to save outputs written on the disk (/kaggle/working/))  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T16:25:34.077721Z","iopub.execute_input":"2025-07-13T16:25:34.078617Z","iopub.status.idle":"2025-07-13T16:25:34.430103Z","shell.execute_reply.started":"2025-07-13T16:25:34.078584Z","shell.execute_reply":"2025-07-13T16:25:34.429493Z"}},"outputs":[{"name":"stdout","text":" The CIC Modbus Dataset contains network (pcap) captures and attack logs from a simulated substation network.\n                The dataset is categorized into two groups: an attack dataset and a benign dataset\n                The attack dataset includes network traffic captures that simulate various types of Modbus protocol attacks in a substation environment.\n                The attacks are reconnaissance, query flooding, loading payloads, delay response, modify length parameters, false data injection, stacking Modbus frames, brute force write and baseline replay.\n                These attacks are based of some techniques in the MITRE ICS ATT&CK framework.\n                On the other hand, the benign dataset consists of normal network traffic captures representing legitimate Modbus communication within the substation network.\n                The purpose of this dataset is to facilitate research, analysis, and development of intrusion detection systems, anomaly detection algorithms and other security mechanisms for substation networks using the Modbus protocol.\n                https://www.unb.ca/cic/datasets/modbus-2023.html\n                In my custom PyTorch Dataset class,\n                I utilize the Enhanced CICflowMeter and the Attack logs correlation to extract and label sequential data flows,\n                preparing them for batch processing with the DataLoader, which is crucial for AI model training.\n                https://github.com/hamid-rd/FLBased-ICS-NIDS/tree/main\n\n                \ncsv files  in the dataset directory founded with the filter:  ready\n{\n    \"total_dataset_num\": 170,\n    \"benign_dataset_num\": 62,\n    \"attack_dataset_num\": {\n        \"total_num\": 108,\n        \"external_num\": 8,\n        \"compromised-ied_num\": 43,\n        \"compromised-scada_num\": 57\n    },\n    \"attack_logs_num\": {\n        \"total_num\": 0,\n        \"external_num\": [],\n        \"compromised-ied_num\": 0,\n        \"compromised-scada_num\": 0\n    }\n}\n","output_type":"stream"}],"execution_count":19},{"id":"5d238262","cell_type":"markdown","source":"### Unsupervised GRU-VAE training  ","metadata":{}},{"id":"a2c01e06","cell_type":"code","source":"import torch \nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np # For standard deviation calculation\nfrom modbus import ModbusDataset,ModbusFlowStream\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix,recall_score\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nimport time\nfrom utils import load_scalers\nfrom random import SystemRandom\nfrom sklearn.model_selection import train_test_split\nimport itertools\nimport torch.nn.init as init\n# from pythresh.thresholds.zscore import ZSCORE\n# from pythresh.thresholds.mad import MAD\n# from pythresh.thresholds.iqr import IQR\n# from pythresh.thresholds.aucp import AUCP\n\n# def compute_threshold(mse_values,k=1):\n#     # \"\"\"\n#     # K-SIGMA\n#     # Computes the anomaly detection threshold (for marking sample as Intrusion if the IS was greater )\n#     # based on the mean and standard deviation of Mean Squared Error (MSE) values.\n#     # Formula: thr = mean(MSE) + std(MSE)\n\n#     # Args:\n#     #     mse_values (torch.Tensor or list/np.array): A tensor or list of MSE values\n#     #                                                 obtained from the validation set.\n\n#     # Returns:\n#     #     float: The calculated threshold.\n#     # \"\"\"\n      ## example usage :\n#       a=compute_threshold([1,2,3])\n        # for (k,v) in a.items() :\n            # print(k,v)\n#     \"\"\"\n#     Computes anomaly detection thresholds using four different methods from pythresh.\n\n#     Args:\n#         mse_values (torch.Tensor or list/np.array): A tensor, list, or numpy array of \n#                                                        MSE values from the validation set.\n\n#     Returns:\n#         dict: A dictionary containing the calculated thresholds for each method.\n#               Returns an empty dictionary if the input is empty.\n#     \"\"\"\n\n#     if not isinstance(mse_values, torch.Tensor):\n#         mse_values = torch.tensor(mse_values, dtype=torch.float32)\n#     if isinstance(mse_values, torch.Tensor):\n#         mse_np = mse_values.detach().cpu().numpy()\n#     else:\n#         mse_np = np.array(mse_values, dtype=np.float32)\n#     if mse_values.numel() == 0:\n#         return 0.0 \n    \n#     zscore_thresholder = ZSCORE()\n#     mad_thresholder = MAD()\n#     iqr_thresholder = IQR()\n#     aucp_thresholder = AUCP()\n    \n#     # 2. Calculate the threshold from each method\n\n#     mean_mse = torch.mean(mse_values)\n#     std_mse = torch.std(mse_values)\n#     # print(\"-----------\",mean_mse,std_mse)\n#     # print(sorted(list((mse_values)))[-10:-1])\n#     k_sigma_threshold = mean_mse + k*std_mse\n#     thresholds = {\n#         'ZSCORE': zscore_thresholder.fit(mse_np).thresh_,\n#         'MAD': mad_thresholder.fit(mse_np).thresh_,\n#         'IQR': iqr_thresholder.fit(mse_np).thresh_,\n#         'AUCP': aucp_thresholder.fit(mse_np).thresh_,\n#         'K-SIGMA' :k_sigma_threshold.cpu().detach().numpy()\n#     }\n#     return thresholds\n#     # return threshold.item() \n\ndef compute_threshold(mse_values,k=1):\n\n    \"\"\"\n    K-SIGMA\n    Computes the anomaly detection threshold (for marking sample as Intrusion if the IS was greater )\n    based on the mean and standard deviation of Mean Squared Error (MSE) values.\n    Formula: thr = mean(MSE) + std(MSE)\n    Args:\n    mse_values (torch.Tensor or list/np.array): A tensor or list of MSE values\n\n                            obtained from the validation set.\n    Returns:\n    float: The calculated threshold.\n\n    \"\"\"\n    if not isinstance(mse_values, torch.Tensor):\n        mse_values = torch.tensor(mse_values, dtype=torch.float32)\n    if mse_values.numel() == 0:\n        return 0.0\n    mean_mse = torch.mean(mse_values)\n    std_mse = torch.std(mse_values)\n    print(\"-----------\",mean_mse,std_mse)\n    print(sorted(list((mse_values)))[-10:-1])\n    threshold = mean_mse + k*std_mse\n    return threshold.item()\n\ndef vae_loss_function(recon_x, x, mu, logvar,beta =1):\n    \"\"\"\n    VAE loss function.\n    \"\"\"\n    BCE = nn.functional.mse_loss(recon_x, x, reduction='sum')\n    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n    return (BCE + beta*KLD)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T16:25:38.158509Z","iopub.execute_input":"2025-07-13T16:25:38.158958Z","iopub.status.idle":"2025-07-13T16:25:38.167563Z","shell.execute_reply.started":"2025-07-13T16:25:38.158938Z","shell.execute_reply":"2025-07-13T16:25:38.166807Z"}},"outputs":[],"execution_count":20},{"id":"f36620d9","cell_type":"code","source":"# import numpy as np\n# # train the KNN detector\n# from pyod.models.knn import KNN\n# from pythresh.thresholds.clust import CLUST\n# from pythresh.thresholds.comb import COMB\n# from sklearn.dummy import DummyClassifier\n\n# def my_custom_loss_func(y_true, y_pred):\n#     diff = np.abs(y_true - y_pred).max()\n#     return float(np.log1p(diff))\n# # score will negate the return value of my_custom_loss_func,\n# # which will be np.log(2), 0.693, given the values for X\n# # and y defined below.\n# X = [[1], [0],[2], [10],[1], [1],[1], [1],[1], [1]]\n# y = [0, 1,1,1,1,1,1,1,0,0]\n\n# clf = KNN()\n# clf.fit(X)\n\n# # get outlier likelihood scores\n# decision_scores = clf.decision_scores_\n# print(decision_scores)\n# # # get outlier labels\n# thres = COMB(thresholders = [CLUST(method='bgm', random_state=1234),\n# CLUST(method='bgm', random_state=42),\n# CLUST(method='bgm', random_state=9685),\n# CLUST(method='bgm', random_state=111222)])\n# thres = CLUST\n# thres.fit(decision_scores)\n# print(thres.thresh_)\n# labels = thres.labels_ # or thres.predict(decision_scores)\n# print(labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-12T18:13:13.140510Z","iopub.execute_input":"2025-07-12T18:13:13.141395Z","iopub.status.idle":"2025-07-12T18:13:13.146618Z","shell.execute_reply.started":"2025-07-12T18:13:13.141357Z","shell.execute_reply":"2025-07-12T18:13:13.145557Z"}},"outputs":[],"execution_count":11},{"id":"f9478520","cell_type":"code","source":"dataset_directory = \"/kaggle/input/training/ModbusDataset\" # change this to the folder contain benign and attack subdirs\nmodbus = ModbusDataset(dataset_directory,\"ready\")\nmodbus.summary_print()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T16:25:42.807033Z","iopub.execute_input":"2025-07-13T16:25:42.807302Z","iopub.status.idle":"2025-07-13T16:25:42.941019Z","shell.execute_reply.started":"2025-07-13T16:25:42.807283Z","shell.execute_reply":"2025-07-13T16:25:42.940221Z"}},"outputs":[{"name":"stdout","text":" The CIC Modbus Dataset contains network (pcap) captures and attack logs from a simulated substation network.\n                The dataset is categorized into two groups: an attack dataset and a benign dataset\n                The attack dataset includes network traffic captures that simulate various types of Modbus protocol attacks in a substation environment.\n                The attacks are reconnaissance, query flooding, loading payloads, delay response, modify length parameters, false data injection, stacking Modbus frames, brute force write and baseline replay.\n                These attacks are based of some techniques in the MITRE ICS ATT&CK framework.\n                On the other hand, the benign dataset consists of normal network traffic captures representing legitimate Modbus communication within the substation network.\n                The purpose of this dataset is to facilitate research, analysis, and development of intrusion detection systems, anomaly detection algorithms and other security mechanisms for substation networks using the Modbus protocol.\n                https://www.unb.ca/cic/datasets/modbus-2023.html\n                In my custom PyTorch Dataset class,\n                I utilize the Enhanced CICflowMeter and the Attack logs correlation to extract and label sequential data flows,\n                preparing them for batch processing with the DataLoader, which is crucial for AI model training.\n                https://github.com/hamid-rd/FLBased-ICS-NIDS/tree/main\n\n                \ncsv files  in the dataset directory founded with the filter:  ready\n{\n    \"total_dataset_num\": 170,\n    \"benign_dataset_num\": 62,\n    \"attack_dataset_num\": {\n        \"total_num\": 108,\n        \"external_num\": 8,\n        \"compromised-ied_num\": 43,\n        \"compromised-scada_num\": 57\n    },\n    \"attack_logs_num\": {\n        \"total_num\": 0,\n        \"external_num\": [],\n        \"compromised-ied_num\": 0,\n        \"compromised-scada_num\": 0\n    }\n}\n","output_type":"stream"}],"execution_count":21},{"id":"514b5a5e","cell_type":"code","source":"csv_files=[col for col in modbus.dataset[\"benign_dataset_dir\"] if col.find(\"network-wide\")!=-1]\nsys_rand = SystemRandom()\nsys_rand.shuffle(csv_files)\ntrain_files,_ = train_test_split(csv_files,test_size=0.2,shuffle=True)\nval_files = [col for col in modbus.dataset[\"benign_dataset_dir\"] if col.find(\"ied1b\")!=-1]\ntest_files=[col for col in modbus.dataset[\"attack_dataset_dir\"][\"compromised-scada\"] if col.find(\"ied1b\")!=-1][0:4]\nprint(\"ied1b comp ied attack ->\\n test: \",len(test_files),test_files)\nprint(\"----------- Network-wide number of csv files -> \\n ----------- train :\",len(train_files),train_files,\"\\n -------- valid:\",len(val_files),val_files)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T16:25:47.060429Z","iopub.execute_input":"2025-07-13T16:25:47.060754Z","iopub.status.idle":"2025-07-13T16:25:47.067878Z","shell.execute_reply.started":"2025-07-13T16:25:47.060733Z","shell.execute_reply":"2025-07-13T16:25:47.067291Z"}},"outputs":[{"name":"stdout","text":"ied1b comp ied attack ->\n test:  4 ['/kaggle/input/training/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-6-labeled.csv', '/kaggle/input/training/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-0-labeled.csv', '/kaggle/input/training/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-1-labeled.csv', '/kaggle/input/training/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-7-labeled.csv']\n----------- Network-wide number of csv files -> \n ----------- train : 15 ['/kaggle/input/training/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-32-labeled.csv', '/kaggle/input/training/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-15-labeled.csv', '/kaggle/input/training/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-30-labeled.csv', '/kaggle/input/training/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-25-labeled.csv', '/kaggle/input/training/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-17-labeled.csv', '/kaggle/input/training/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-21-labeled.csv', '/kaggle/input/training/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-16-labeled.csv', '/kaggle/input/training/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-19-labeled.csv', '/kaggle/input/training/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-24-labeled.csv', '/kaggle/input/training/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-28-labeled.csv', '/kaggle/input/training/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-26-labeled.csv', '/kaggle/input/training/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-20-labeled.csv', '/kaggle/input/training/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-27-labeled.csv', '/kaggle/input/training/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-29-labeled.csv', '/kaggle/input/training/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-14-labeled.csv'] \n -------- valid: 7 ['/kaggle/input/training/ModbusDataset/benign/ied1b/ied1b-network-capture/ready/vethd9e14c0-normal-6-labeled.csv', '/kaggle/input/training/ModbusDataset/benign/ied1b/ied1b-network-capture/ready/vethd9e14c0-normal-8-labeled.csv', '/kaggle/input/training/ModbusDataset/benign/ied1b/ied1b-network-capture/ready/vethd9e14c0-normal-5-labeled.csv', '/kaggle/input/training/ModbusDataset/benign/ied1b/ied1b-network-capture/ready/vethd9e14c0-normal-10-labeled.csv', '/kaggle/input/training/ModbusDataset/benign/ied1b/ied1b-network-capture/ready/vethd9e14c0-normal-9-labeled.csv', '/kaggle/input/training/ModbusDataset/benign/ied1b/ied1b-network-capture/ready/vethd9e14c0-normal-7-labeled.csv', '/kaggle/input/training/ModbusDataset/benign/ied1b/ied1b-network-capture/ready/vethd9e14c0-normal-4-labeled.csv']\n","output_type":"stream"}],"execution_count":22},{"id":"510ea189","cell_type":"code","source":"def _init_weights( module):\n    ## for one layer apply Xavier Initialization\n    if isinstance(module, nn.Linear):\n        init.xavier_normal_(module.weight)\n        if module.bias is not None:\n            init.zeros_(module.bias)\n    return module\n# AutoEncoder (AE)\nclass AE(nn.Module):\n    \"\"\"\n    Encoder: (89-64-32)\n    Decoder: (32-64-89)\n    \"\"\"\n    def __init__(self):\n        super(AE, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Linear(89, 64),\n            nn.ReLU(),\n            nn.Linear(64, 32),\n            nn.ReLU()\n        )\n        self.decoder = nn.Sequential(\n            nn.Linear(32, 64),\n            nn.ReLU(),\n            nn.Linear(64, 89),\n            nn.ReLU()\n        )\n\n    def forward(self, x):\n        z = self.encoder(x)\n        x_recon = self.decoder(z)\n        return x_recon\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T16:14:44.541882Z","iopub.execute_input":"2025-07-13T16:14:44.542531Z","iopub.status.idle":"2025-07-13T16:14:44.550154Z","shell.execute_reply.started":"2025-07-13T16:14:44.542501Z","shell.execute_reply":"2025-07-13T16:14:44.549125Z"}},"outputs":[],"execution_count":15},{"id":"a2d2e0ca","cell_type":"code","source":"from collections import Counter\n\ndef train_eval(model,train_dataloader,val_dataloader,test_dataloader,learning_rates= [5e-5,1e-5,1e-6,5e-6,1e-7],\n               weight_decays=[1e-5,1e-4,1e-7],shuffle_files=True,num_epochs=50):\n    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    criterion = nn.MSELoss(reduction='sum').to(device)\n    eval_criterion = nn.MSELoss(reduction='none').to(device)\n    for lr, wd in itertools.product(learning_rates, weight_decays):\n        if model._get_name()==\"AdversarialAutoencoder\":\n            adversarial_criterion= nn.BCELoss(reduction=\"sum\")\n            optimizer_D = optim.SGD(model.discriminator.parameters(), lr=lr, weight_decay=wd)\n            optimizer_G =  optim.SGD(list(model.encoder.parameters()) + list(model.decoder.parameters()), lr=lr, weight_decay=wd)\n        else:\n            AE_optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd)\n        print(f\"\\n==================  lr={lr}, wd={wd} ==================\")\n        model.apply(_init_weights)\n        for epoch in range(num_epochs):\n            time_1 = time.time()\n            model.train()\n            train_loss = 0\n            ## for AAE\n            Discriminator_loss = 0\n            if shuffle_files:\n                sys_rand = SystemRandom()\n                sys_rand.shuffle(AE_train_dataset.file_order_indices)\n            for sequences, _ in train_dataloader:\n                sequences=sequences.squeeze().to(device)\n                if model._get_name()==\"AdversarialAutoencoder\":\n                    target_ones= torch.ones(sequences.size(0), 1,device=device,dtype=torch.float)\n                    target_zeros= torch.zeros(sequences.size(0), 1,device=device,dtype=torch.float)\n                    random_latent = torch.randn(sequences.size(0), 2, device=device)\n                    optimizer_G.zero_grad()\n                    fake_z,decoded_seq = model(sequences)\n                    G_loss = 0.001*adversarial_criterion(model.discriminator(fake_z),target_ones ) + 0.999*criterion(decoded_seq, sequences)\n                    G_loss.backward()\n                    optimizer_G.step()\n                    # 2) discriminator loss\n                    optimizer_D.zero_grad()\n                    real_loss = adversarial_criterion(model.discriminator(random_latent), target_ones)\n                    fake_loss = adversarial_criterion(model.discriminator(fake_z.detach()),  target_zeros)\n                    D_loss = 0.5*(real_loss + fake_loss)\n                    D_loss.backward()\n                    optimizer_D.step()\n                    train_loss+=G_loss.item()\n                    Discriminator_loss+=D_loss.item()   \n                else:\n                    AE_optimizer.zero_grad()\n                    if model._get_name()==\"AE\":\n                        recon = model(sequences)\n                        loss = criterion(recon, sequences) / sequences.size(0)\n                    elif model._get_name()==\"VAE\" or model._get_name()==\"GRUVAE\":\n                        recon, mu, logvar = model(sequences)\n                        loss = vae_loss_function(recon, sequences, mu, logvar) /sequences.size(0)\n                    loss.backward()\n                    AE_optimizer.step()\n                    train_loss += loss.item()\n            print(f\"Train : time {(time.time()-time_1):.2f} s\",\n            f\"Epoch {epoch+1}\")\n            if model._get_name()==\"AdversarialAutoencoder\":\n                print(f\"Generator Loss: {train_loss / len(train_dataloader):.4f}\",\n                    f\"Discriminator Loss: {Discriminator_loss / len(train_dataloader):.4f}\")\n            else:\n                print(f\"Train Loss: {train_loss / len(train_dataloader):.4f}\")\n            # Evaluate part\n            if (epoch + 1) % 5 == 0:\n                model.eval() \n                all_val_losses = []\n                all_val_labels = []\n                print(f\"--- Running Evaluation for Epoch {epoch+1} lr ={lr} wd {wd} ---\")\n                with torch.no_grad():\n                    for sequences, labels in val_dataloader:\n                        sequences = sequences.squeeze().to(device)        \n                        if model._get_name()==\"AE\":\n                            recon = model(sequences)\n                        elif model._get_name()==\"VAE\" or model._get_name()==\"GRUVAE\" :\n                            recon, _, _ = model(sequences)\n                        elif model._get_name()==\"AdversarialAutoencoder\":\n                            _,recon= model(sequences)\n                        val_loss = eval_criterion(recon, sequences)\n                        if val_loss.dim() > 1:\n                            intrusion_scores = val_loss\n                        else:\n                            intrusion_scores = val_loss.unsqueeze(dim=0)\n                        intrusion_scores = intrusion_scores.sum(dim=1)\n                        all_val_losses.extend(intrusion_scores.cpu().numpy())\n                        all_val_labels.extend(labels.flatten().cpu().numpy())            \n                threshold_1 = compute_threshold(all_val_losses,k=1)\n                # threshold_2 = compute_threshold(all_val_losses,k=2)\n                # threshold_3 = compute_threshold(all_val_losses,k=3)\n                # threshold_10 = compute_threshold(all_val_losses,k=10)\n                # threshold_ = compute_threshold(all_val_losses,k=100)\n\n                # print(f\"Computed Threshold: {threshold:.4f}\")\n                all_val_losses = np.array(all_val_losses).squeeze()  \n                all_val_labels = np.array(all_val_labels).squeeze()  \n                # If intrusion score > threshold, predict 1 (intrusion), else 0 (benign)\n                # For FDR, get True Positives (TP) and False Positives (FP)\n                \n                predictions = (all_val_losses > threshold_1).astype(int)\n                accuracy = accuracy_score(all_val_labels, predictions)\n                print(f\"Val: Accuracy: {accuracy:.4f}  \")\n                model.eval() \n                all_test_losses = []\n                all_test_labels = []\n                with torch.no_grad():\n                    for sequences, labels in test_dataloader:\n                        sequences = sequences.squeeze().to(device)\n                        labels = labels.squeeze().to(device)\n                        if model._get_name()==\"AE\":\n                            recon = model(sequences)\n                        elif model._get_name()==\"VAE\"  or model._get_name()==\"GRUVAE\":\n                            recon, mu, logvar = model(sequences)\n                        elif model._get_name()==\"AdversarialAutoencoder\":\n                            _,recon= model(sequences)\n                        test_loss = eval_criterion(recon, sequences)\n                        if test_loss.dim() > 1:\n                            intrusion_scores = test_loss\n                        else:\n                            intrusion_scores = test_loss.unsqueeze(dim=0)\n                        intrusion_scores = intrusion_scores.sum(dim=1).squeeze()\n                        ### remove labels =1 (don't consider replay attack)\n                        mask = labels != 1\n\n                        filtered_scores = intrusion_scores[mask]\n                        filtered_labels = labels[mask]\n                \n                        # Move to CPU and convert to numpy\n                        all_test_losses.extend(filtered_scores.cpu().numpy())\n                        all_test_labels.extend(filtered_labels.cpu().numpy())\n\n                all_test_losses = np.array(all_test_losses)\n                all_test_labels = np.array(all_test_labels)\n                # for threshold in {threshold_1,threshold_2,threshold_3,threshold_10,threshold_100}:\n                for threshold in {threshold_1}:\n\n                    print(\"---thr:\",threshold)\n                    predictions = (all_test_losses > threshold).astype(int)\n                    binary_test_labels = (all_test_labels != 0).astype(int)\n                    # --- Start of new code ---\n\n                    # Find the indices where the prediction was incorrect\n                    misclassified_indices = np.where(binary_test_labels != predictions)[0]\n\n                    # Get the original labels for those misclassified instances\n                    misclassified_original_labels = all_test_labels[misclassified_indices]\n\n                    # # Get the predicted labels for the misclassified instances\n                    # misclassified_predictions = predictions[misclassified_indices]\n\n                    # To get a summary count of which labels were misclassified\n                    print(Counter(predictions),Counter(binary_test_labels))\n                    print(f\"Counts of  labels: {dict(sorted(Counter(all_test_labels).items()))}\")\n                    print(f\"Counts of misclassified original labels: {dict(sorted(Counter(misclassified_original_labels).items()))}\")\n\n                    # # For a more detailed view, you can see the original label and what it was predicted as\n                    # print(\"\\n--- Detailed Misclassifications (Original Label -> Predicted Binary) ---\")\n                    # for i in range(len(misclassified_original_labels)):\n                    #     original_label = misclassified_original_labels[i]\n                    #     predicted_label = misclassified_predictions[i]\n                    #     print(f\"Original Label: {original_label} -> Predicted as: {predicted_label}\")\n\n                    accuracy = accuracy_score(binary_test_labels, predictions)\n                    f1 = f1_score(binary_test_labels, predictions, zero_division=0)\n                    recall = recall_score(binary_test_labels, predictions,zero_division=0)\n                    _, fp, _, tp = confusion_matrix(binary_test_labels, predictions, labels=[0, 1]).ravel()\n                    # FDR = FP / (FP + TP) \n                    if (fp + tp) == 0:\n                        fdr = 0.0 \n                    else:\n                        fdr = fp / (fp + tp)\n                    print(f\"Test : Accuracy: {accuracy:.4f} Recall : {recall:.4f} FDR: {fdr:.4f}  F1-score: {f1:.4f}  \")\n\n        # thresholds = compute_threshold(all_val_losses,k=3)\n        #         # print(f\"Computed Threshold: {threshold:.4f}\")\n        #         all_val_losses = np.array(all_val_losses).squeeze()  \n        #         all_val_labels = np.array(all_val_labels).squeeze()  \n        #         # If intrusion score > threshold, predict 1 (intrusion), else 0 (benign)\n        #         # For FDR, get True Positives (TP) and False Positives (FP)\n        #         for key,thresh_value in thresholds.items():\n        #             print(\"*******\",key,thresh_value,\"threshold\")\n        #             predictions = (all_val_losses > thresh_value).astype(int)\n        #             accuracy = accuracy_score(all_val_labels, predictions)\n        #             print(f\"Val: Accuracy: {accuracy:.4f}  \")\n        #             model.eval() \n        #             all_test_losses = []\n        #             all_test_labels = []\n        #             with torch.no_grad():\n        #                 for sequences, labels in test_dataloader:","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T08:02:58.407931Z","iopub.execute_input":"2025-07-13T08:02:58.408647Z","iopub.status.idle":"2025-07-13T08:02:58.430831Z","shell.execute_reply.started":"2025-07-13T08:02:58.408625Z","shell.execute_reply":"2025-07-13T08:02:58.430062Z"}},"outputs":[],"execution_count":15},{"id":"eac4698b","cell_type":"code","source":"loaded_scalers = load_scalers(\"/kaggle/working/FLBased-ICS-NIDS/fitted_scalers\")\n#standard_scalers\n\nAE_train_dataset=ModbusFlowStream( \n    shuffle=True,chunk_size=20,batch_size=64,csv_files=val_files[:-3],scalers=loaded_scalers['network-wide']['min_max_scalers'],window_size=1,\n    \n)\n\nAE_train_dataloader=DataLoader(AE_train_dataset,batch_size=1,shuffle=False,pin_memory=True, prefetch_factor=2,num_workers=4)\n\nAE_val_dataloader=DataLoader(ModbusFlowStream( \n    shuffle=False,chunk_size=1,batch_size=64,csv_files=val_files[-3:],scalers=loaded_scalers['network-wide']['min_max_scalers'],window_size=1\n),batch_size=1,shuffle=False,pin_memory=True)\n\nAE_test_dataloader=DataLoader(ModbusFlowStream(shuffle=False,chunk_size=1,batch_size=64,csv_files=test_files[:],scalers=loaded_scalers['network-wide']['min_max_scalers'],window_size=1),batch_size=1,shuffle=False,pin_memory=True)\ndevice=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nAE_model = AE().to(device)\nlr = 0.01\nwd= 1e-4\nshuffle_files =True\nAE_optimizer = optim.SGD(AE_model.parameters(), lr=lr, weight_decay=wd)\ncriterion = nn.MSELoss(reduction='sum').to(device)\neval_criterion = nn.MSELoss(reduction='none').to(device)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T08:12:06.827779Z","iopub.execute_input":"2025-07-13T08:12:06.828444Z","iopub.status.idle":"2025-07-13T08:12:07.034947Z","shell.execute_reply.started":"2025-07-13T08:12:06.828415Z","shell.execute_reply":"2025-07-13T08:12:07.034115Z"}},"outputs":[{"name":"stdout","text":"Successfully loaded scalers for 'network-wide'\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator MinMaxScaler from version 1.6.1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\nhttps://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 1.6.1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\nhttps://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n  warnings.warn(\n","output_type":"stream"}],"execution_count":28},{"id":"f2284b8a","cell_type":"code","source":"print(AE_train_dataset.scalers)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-12T19:21:40.140096Z","iopub.execute_input":"2025-07-12T19:21:40.140809Z","iopub.status.idle":"2025-07-12T19:21:40.148883Z","shell.execute_reply.started":"2025-07-12T19:21:40.140788Z","shell.execute_reply":"2025-07-12T19:21:40.148227Z"},"_kg_hide-input":true},"outputs":[{"name":"stdout","text":"{'Protocol': MinMaxScaler(), 'Flow Duration': MinMaxScaler(), 'Total Fwd Packet': MinMaxScaler(), 'Total Bwd packets': MinMaxScaler(), 'Total Length of Fwd Packet': MinMaxScaler(), 'Total Length of Bwd Packet': MinMaxScaler(), 'Fwd Packet Length Max': MinMaxScaler(), 'Fwd Packet Length Min': MinMaxScaler(), 'Fwd Packet Length Mean': MinMaxScaler(), 'Fwd Packet Length Std': MinMaxScaler(), 'Bwd Packet Length Max': MinMaxScaler(), 'Bwd Packet Length Min': MinMaxScaler(), 'Bwd Packet Length Mean': MinMaxScaler(), 'Bwd Packet Length Std': MinMaxScaler(), 'Flow Bytes/s': MinMaxScaler(), 'Flow Packets/s': MinMaxScaler(), 'Flow IAT Mean': MinMaxScaler(), 'Flow IAT Std': MinMaxScaler(), 'Flow IAT Max': MinMaxScaler(), 'Flow IAT Min': MinMaxScaler(), 'Fwd IAT Total': MinMaxScaler(), 'Fwd IAT Mean': MinMaxScaler(), 'Fwd IAT Std': MinMaxScaler(), 'Fwd IAT Max': MinMaxScaler(), 'Fwd IAT Min': MinMaxScaler(), 'Bwd IAT Total': MinMaxScaler(), 'Bwd IAT Mean': MinMaxScaler(), 'Bwd IAT Std': MinMaxScaler(), 'Bwd IAT Max': MinMaxScaler(), 'Bwd IAT Min': MinMaxScaler(), 'Fwd PSH Flags': MinMaxScaler(), 'Bwd PSH Flags': MinMaxScaler(), 'Fwd URG Flags': MinMaxScaler(), 'Bwd URG Flags': MinMaxScaler(), 'Fwd RST Flags': MinMaxScaler(), 'Bwd RST Flags': MinMaxScaler(), 'Fwd Header Length': MinMaxScaler(), 'Bwd Header Length': MinMaxScaler(), 'Fwd Packets/s': MinMaxScaler(), 'Bwd Packets/s': MinMaxScaler(), 'Packet Length Min': MinMaxScaler(), 'Packet Length Max': MinMaxScaler(), 'Packet Length Mean': MinMaxScaler(), 'Packet Length Std': MinMaxScaler(), 'Packet Length Variance': MinMaxScaler(), 'FIN Flag Count': MinMaxScaler(), 'SYN Flag Count': MinMaxScaler(), 'RST Flag Count': MinMaxScaler(), 'PSH Flag Count': MinMaxScaler(), 'ACK Flag Count': MinMaxScaler(), 'URG Flag Count': MinMaxScaler(), 'CWR Flag Count': MinMaxScaler(), 'ECE Flag Count': MinMaxScaler(), 'Down/Up Ratio': MinMaxScaler(), 'Average Packet Size': MinMaxScaler(), 'Fwd Segment Size Avg': MinMaxScaler(), 'Bwd Segment Size Avg': MinMaxScaler(), 'Fwd Bytes/Bulk Avg': MinMaxScaler(), 'Fwd Packet/Bulk Avg': MinMaxScaler(), 'Fwd Bulk Rate Avg': MinMaxScaler(), 'Bwd Bytes/Bulk Avg': MinMaxScaler(), 'Bwd Packet/Bulk Avg': MinMaxScaler(), 'Bwd Bulk Rate Avg': MinMaxScaler(), 'Subflow Fwd Packets': MinMaxScaler(), 'Subflow Fwd Bytes': MinMaxScaler(), 'Subflow Bwd Packets': MinMaxScaler(), 'Subflow Bwd Bytes': MinMaxScaler(), 'FWD Init Win Bytes': MinMaxScaler(), 'Bwd Init Win Bytes': MinMaxScaler(), 'Fwd Act Data Pkts': MinMaxScaler(), 'Bwd Act Data Pkts': MinMaxScaler(), 'Fwd Seg Size Min': MinMaxScaler(), 'Bwd Seg Size Min': MinMaxScaler(), 'Active Mean': MinMaxScaler(), 'Active Std': MinMaxScaler(), 'Active Max': MinMaxScaler(), 'Active Min': MinMaxScaler(), 'Idle Mean': MinMaxScaler(), 'Idle Std': MinMaxScaler(), 'Idle Max': MinMaxScaler(), 'Idle Min': MinMaxScaler(), 'ICMP Code': MinMaxScaler(), 'ICMP Type': MinMaxScaler(), 'Fwd TCP Retrans. Count': MinMaxScaler(), 'Bwd TCP Retrans. Count': MinMaxScaler(), 'Total TCP Retrans. Count': MinMaxScaler(), 'Total Connection Flow Time': MinMaxScaler()}\n","output_type":"stream"}],"execution_count":62},{"id":"227d8bee","cell_type":"code","source":"train_eval(AE_model,AE_train_dataloader,AE_val_dataloader,AE_test_dataloader)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T08:12:10.320428Z","iopub.execute_input":"2025-07-13T08:12:10.321013Z","iopub.status.idle":"2025-07-13T08:13:26.731289Z","shell.execute_reply.started":"2025-07-13T08:12:10.320989Z","shell.execute_reply":"2025-07-13T08:13:26.729573Z"}},"outputs":[{"name":"stdout","text":"\n==================  lr=5e-05, wd=1e-05 ==================\nTrain : time 36.23 s Epoch 1\nTrain Loss: 3.5386\nTrain : time 33.80 s Epoch 2\nTrain Loss: 2.8849\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/3429833867.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAE_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAE_train_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAE_val_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAE_test_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_35/3187001028.py\u001b[0m in \u001b[0;36mtrain_eval\u001b[0;34m(model, train_dataloader, val_dataloader, test_dataloader, learning_rates, weight_decays, shuffle_files, num_epochs)\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0msys_rand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSystemRandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0msys_rand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAE_train_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_order_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m                 \u001b[0msequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"AdversarialAutoencoder\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1459\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1410\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1412\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":29},{"id":"9c26d631","cell_type":"code","source":"train_eval(AE_model,AE_train_dataloader,AE_val_dataloader,AE_test_dataloader)\n","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","==================  lr=5e-05, wd=1e-05 ==================\n","Train : time 115.05 s Epoch 1\n","Train Loss: 3.1154\n","--- Running Evaluation for Epoch 1 lr =5e-05 wd 1e-05 ---\n","----------- tensor(2.0512) tensor(0.0694)\n","[tensor(6.1216), tensor(6.1216), tensor(6.1216), tensor(6.1216), tensor(6.1216), tensor(6.1216), tensor(6.1216), tensor(6.1216), tensor(6.1216)]\n","Val: Accuracy: 0.9994  \n","---thr: 2.120652437210083\n","Counter({0: 362790, 1: 127374}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 37535, 1: 16464, 2: 33, 3: 40, 5: 1, 6: 32, 7: 1}\n","Test : Accuracy: 0.8896 Recall : 0.8443 FDR: 0.2947  F1-score: 0.7686  \n","Train : time 111.38 s Epoch 2\n","Train Loss: 2.1930\n","--- Running Evaluation for Epoch 2 lr =5e-05 wd 1e-05 ---\n","----------- tensor(2.0472) tensor(0.0684)\n","[tensor(6.0578), tensor(6.0578), tensor(6.0578), tensor(6.0578), tensor(6.0578), tensor(6.0578), tensor(6.0578), tensor(6.0578), tensor(6.0578)]\n","Val: Accuracy: 0.9994  \n","---thr: 2.1156232357025146\n","Counter({0: 362790, 1: 127374}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 37535, 1: 16464, 2: 33, 3: 40, 5: 1, 6: 32, 7: 1}\n","Test : Accuracy: 0.8896 Recall : 0.8443 FDR: 0.2947  F1-score: 0.7686  \n","Train : time 108.39 s Epoch 3\n","Train Loss: 2.1807\n","--- Running Evaluation for Epoch 3 lr =5e-05 wd 1e-05 ---\n","----------- tensor(2.0450) tensor(0.0680)\n","[tensor(6.0337), tensor(6.0337), tensor(6.0337), tensor(6.0337), tensor(6.0337), tensor(6.0337), tensor(6.0337), tensor(6.0337), tensor(6.0337)]\n","Val: Accuracy: 0.9994  \n","---thr: 2.1130287647247314\n","Counter({0: 362790, 1: 127374}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 37535, 1: 16464, 2: 33, 3: 40, 5: 1, 6: 32, 7: 1}\n","Test : Accuracy: 0.8896 Recall : 0.8443 FDR: 0.2947  F1-score: 0.7686  \n","Train : time 119.04 s Epoch 4\n","Train Loss: 2.1760\n","--- Running Evaluation for Epoch 4 lr =5e-05 wd 1e-05 ---\n","----------- tensor(2.0420) tensor(0.0679)\n","[tensor(6.0222), tensor(6.0222), tensor(6.0222), tensor(6.0222), tensor(6.0222), tensor(6.0222), tensor(6.0222), tensor(6.0222), tensor(6.0222)]\n","Val: Accuracy: 0.9994  \n","---thr: 2.1098482608795166\n","Counter({0: 362790, 1: 127374}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 37535, 1: 16464, 2: 33, 3: 40, 5: 1, 6: 32, 7: 1}\n","Test : Accuracy: 0.8896 Recall : 0.8443 FDR: 0.2947  F1-score: 0.7686  \n","Train : time 112.69 s Epoch 5\n","Train Loss: 2.1723\n","--- Running Evaluation for Epoch 5 lr =5e-05 wd 1e-05 ---\n","----------- tensor(2.0407) tensor(0.0677)\n","[tensor(6.0094), tensor(6.0094), tensor(6.0094), tensor(6.0094), tensor(6.0094), tensor(6.0094), tensor(6.0094), tensor(6.0094), tensor(6.0094)]\n","Val: Accuracy: 0.9994  \n","---thr: 2.1083552837371826\n","Counter({0: 362790, 1: 127374}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 37535, 1: 16464, 2: 33, 3: 40, 5: 1, 6: 32, 7: 1}\n","Test : Accuracy: 0.8896 Recall : 0.8443 FDR: 0.2947  F1-score: 0.7686  \n","Train : time 129.74 s Epoch 6\n","Train Loss: 2.1694\n","--- Running Evaluation for Epoch 6 lr =5e-05 wd 1e-05 ---\n","----------- tensor(2.0428) tensor(0.0674)\n","[tensor(5.9939), tensor(5.9939), tensor(5.9939), tensor(5.9939), tensor(5.9939), tensor(5.9939), tensor(5.9939), tensor(5.9939), tensor(5.9939)]\n","Val: Accuracy: 0.9994  \n","---thr: 2.110151529312134\n","Counter({0: 362790, 1: 127374}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 37535, 1: 16464, 2: 33, 3: 40, 5: 1, 6: 32, 7: 1}\n","Test : Accuracy: 0.8896 Recall : 0.8443 FDR: 0.2947  F1-score: 0.7686  \n","Train : time 116.53 s Epoch 7\n","Train Loss: 2.1668\n","--- Running Evaluation for Epoch 7 lr =5e-05 wd 1e-05 ---\n","----------- tensor(2.0416) tensor(0.0672)\n","[tensor(5.9838), tensor(5.9838), tensor(5.9838), tensor(5.9838), tensor(5.9838), tensor(5.9838), tensor(5.9838), tensor(5.9838), tensor(5.9838)]\n","Val: Accuracy: 0.9994  \n","---thr: 2.1088764667510986\n","Counter({0: 362790, 1: 127374}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 37535, 1: 16464, 2: 33, 3: 40, 5: 1, 6: 32, 7: 1}\n","Test : Accuracy: 0.8896 Recall : 0.8443 FDR: 0.2947  F1-score: 0.7686  \n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAE_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43mAE_train_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mAE_val_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mAE_test_dataloader\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[53], line 49\u001b[0m, in \u001b[0;36mtrain_eval\u001b[0;34m(model, train_dataloader, val_dataloader, test_dataloader, learning_rates, weight_decays, shuffle_files, num_epochs)\u001b[0m\n\u001b[1;32m     47\u001b[0m AE_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model\u001b[38;5;241m.\u001b[39m_get_name()\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAE\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 49\u001b[0m     recon \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(recon, sequences) \u001b[38;5;241m/\u001b[39m sequences\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model\u001b[38;5;241m.\u001b[39m_get_name()\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVAE\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n","File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n","Cell \u001b[0;32mIn[9], line 31\u001b[0m, in \u001b[0;36mAE.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     30\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x)\n\u001b[0;32m---> 31\u001b[0m     x_recon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x_recon\n","File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n","File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/torch/nn/modules/container.py:240\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 240\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n","File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"execution_count":54},{"id":"aa71c4da","cell_type":"code","source":"train_eval(AE_model,AE_train_dataloader,AE_val_dataloader,AE_test_dataloader)\n","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","================== Evaluate lr=0.01, wd=0.0001 ==================\n","Train : time 96.0562 Epoch 0\n","Train Loss: 0.8941\n","\n","--- Running Evaluation for Epoch 1 lr =0.01 wd 0.0001 ---\n","Computed Threshold: 0.0179\n","Val: Accuracy: 0.9124  \n","[0 0 0 ... 0 0 0]\n","[0 0 0 ... 0 0 0]\n","Counter({0: 364401, 1: 125763}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: Counter({0: 383754, 1: 105690, 2: 178, 4: 125, 5: 118, 7: 112, 3: 101, 6: 86})\n","Counts of misclassified labels: Counter({0: 37095, 1: 17516, 7: 112, 3: 43, 6: 34, 2: 33, 4: 3, 5: 1})\n","Test : Accuracy: 0.8881 Recall : 0.8333 FDR: 0.2950  F1-score: 0.7638  \n","Train : time 95.1892 Epoch 1\n","Train Loss: 0.8722\n","\n","--- Running Evaluation for Epoch 2 lr =0.01 wd 0.0001 ---\n","Computed Threshold: 0.0179\n","Val: Accuracy: 0.9117  \n","[0 0 0 ... 0 0 0]\n","[0 0 0 ... 0 0 0]\n","Counter({0: 364596, 1: 125568}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: Counter({0: 383754, 1: 105690, 2: 178, 4: 125, 5: 118, 7: 112, 3: 101, 6: 86})\n","Counts of misclassified labels: Counter({0: 36903, 1: 17516, 7: 112, 3: 43, 6: 34, 2: 33, 4: 6, 5: 1})\n","Test : Accuracy: 0.8885 Recall : 0.8332 FDR: 0.2939  F1-score: 0.7644  \n","Train : time 94.1066 Epoch 2\n","Train Loss: 0.8676\n","\n","--- Running Evaluation for Epoch 3 lr =0.01 wd 0.0001 ---\n","Computed Threshold: 0.0168\n","Val: Accuracy: 0.9134  \n","[0 0 0 ... 0 0 0]\n","[0 0 0 ... 0 0 0]\n","Counter({0: 364591, 1: 125573}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: Counter({0: 383754, 1: 105690, 2: 178, 4: 125, 5: 118, 7: 112, 3: 101, 6: 86})\n","Counts of misclassified labels: Counter({0: 36904, 1: 17515, 7: 112, 3: 43, 6: 34, 2: 33, 4: 3, 5: 1})\n","Test : Accuracy: 0.8885 Recall : 0.8333 FDR: 0.2939  F1-score: 0.7644  \n","Train : time 91.9188 Epoch 3\n","Train Loss: 0.8404\n","\n","--- Running Evaluation for Epoch 4 lr =0.01 wd 0.0001 ---\n","Computed Threshold: 0.0168\n","Val: Accuracy: 0.9135  \n","[0 0 0 ... 0 0 0]\n","[0 0 0 ... 0 0 0]\n","Counter({0: 480446, 1: 9718}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: Counter({0: 383754, 1: 105690, 2: 178, 4: 125, 5: 118, 7: 112, 3: 101, 6: 86})\n","Counts of misclassified labels: Counter({1: 100610, 0: 4427, 2: 168, 7: 112, 3: 98, 6: 86, 4: 44, 5: 1})\n","Test : Accuracy: 0.7847 Recall : 0.0497 FDR: 0.4555  F1-score: 0.0911  \n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAE_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43mAE_train_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mAE_val_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mAE_test_dataloader\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[23], line 27\u001b[0m, in \u001b[0;36mtrain_eval\u001b[0;34m(model, train_dataloader, val_dataloader, test_dataloader, learning_rates, weight_decays, shuffle_files, epochs)\u001b[0m\n\u001b[1;32m     25\u001b[0m     sys_rand \u001b[38;5;241m=\u001b[39m SystemRandom()\n\u001b[1;32m     26\u001b[0m     sys_rand\u001b[38;5;241m.\u001b[39mshuffle(AE_train_dataset\u001b[38;5;241m.\u001b[39mfile_order_indices)\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sequences, _ \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[1;32m     28\u001b[0m     sequences\u001b[38;5;241m=\u001b[39msequences\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model\u001b[38;5;241m.\u001b[39m_get_name()\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdversarialAutoencoder\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n","File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    739\u001b[0m ):\n","File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:789\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    788\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    791\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[0;32m~/labeling/FLBased-ICS-NIDS-main/modbus.py:322\u001b[0m, in \u001b[0;36mModbusFlowStream.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_next_chunk()\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_row_in_chunk_idx \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_len_chunk_data:\n\u001b[0;32m--> 322\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_next_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m    323\u001b[0m end_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_row_in_chunk_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_len_chunk_data)\n\u001b[1;32m    324\u001b[0m \u001b[38;5;66;03m# Slice the data and labels directly from the pre-converted tensors\u001b[39;00m\n","File \u001b[0;32m~/labeling/FLBased-ICS-NIDS-main/modbus.py:238\u001b[0m, in \u001b[0;36mModbusFlowStream._load_next_chunk\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    235\u001b[0m     chunk_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(chunk_file_paths, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcp1252\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    236\u001b[0m                                     usecols\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumeric_cols_to_scale\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_column), low_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m :\n\u001b[0;32m--> 238\u001b[0m     chunk_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([pd\u001b[38;5;241m.\u001b[39mread_csv(file, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcp1252\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    239\u001b[0m                                     usecols\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m column: column \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munuseful_features, low_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m chunk_file_paths],\n\u001b[1;32m    240\u001b[0m                                     ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshuffle:\n\u001b[1;32m    243\u001b[0m     chunk_df \u001b[38;5;241m=\u001b[39m chunk_df\u001b[38;5;241m.\u001b[39msample(frac\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","File \u001b[0;32m~/labeling/FLBased-ICS-NIDS-main/modbus.py:238\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    235\u001b[0m     chunk_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(chunk_file_paths, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcp1252\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    236\u001b[0m                                     usecols\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumeric_cols_to_scale\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_column), low_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m :\n\u001b[0;32m--> 238\u001b[0m     chunk_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcp1252\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munuseful_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m chunk_file_paths],\n\u001b[1;32m    240\u001b[0m                                     ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshuffle:\n\u001b[1;32m    243\u001b[0m     chunk_df \u001b[38;5;241m=\u001b[39m chunk_df\u001b[38;5;241m.\u001b[39msample(frac\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1024\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1011\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1012\u001b[0m     dialect,\n\u001b[1;32m   1013\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1021\u001b[0m )\n\u001b[1;32m   1022\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:624\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1921\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1914\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1916\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1917\u001b[0m     (\n\u001b[1;32m   1918\u001b[0m         index,\n\u001b[1;32m   1919\u001b[0m         columns,\n\u001b[1;32m   1920\u001b[0m         col_dict,\n\u001b[0;32m-> 1921\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1923\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1925\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n","File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:239\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 239\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_first_chunk:\n","File \u001b[0;32mparsers.pyx:820\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mparsers.pyx:921\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mparsers.pyx:1012\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m~/labeling/FLBased-ICS-NIDS-main/modbus.py:239\u001b[0m, in \u001b[0;36mModbusFlowStream._load_next_chunk.<locals>.<lambda>\u001b[0;34m(column)\u001b[0m\n\u001b[1;32m    235\u001b[0m     chunk_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(chunk_file_paths, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcp1252\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    236\u001b[0m                                     usecols\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumeric_cols_to_scale\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_column), low_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m :\n\u001b[1;32m    238\u001b[0m     chunk_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([pd\u001b[38;5;241m.\u001b[39mread_csv(file, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcp1252\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m--> 239\u001b[0m                                     usecols\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m column: column \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munuseful_features, low_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m chunk_file_paths],\n\u001b[1;32m    240\u001b[0m                                     ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshuffle:\n\u001b[1;32m    243\u001b[0m     chunk_df \u001b[38;5;241m=\u001b[39m chunk_df\u001b[38;5;241m.\u001b[39msample(frac\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"execution_count":24},{"id":"0c7f4d44","cell_type":"code","source":"\n# Variational AutoEncoder (VAE)\nclass VAE(nn.Module):\n    \"\"\"\n    Encoder: (89-64-64-32 for mu and log_var)\n    Decoder: (32-64-64-89)\n    return x_recon, mu, logvar\n    \"\"\"\n    def __init__(self):\n        super(VAE, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Linear(89, 64),\n            nn.ReLU(),\n            nn.Linear(64, 64),\n            nn.ReLU()\n        )\n        self.fc_mu = nn.Linear(64, 32)\n        self.fc_logvar = nn.Linear(64, 32)\n        self.decoder = nn.Sequential(\n            nn.Linear(32, 64),\n            nn.ReLU(),\n            nn.Linear(64, 64),\n            nn.ReLU(),\n            nn.Linear(64, 89),\n            nn.ReLU()\n        )\n\n    def reparameterize(self, mu, logvar):\n        std = torch.exp(0.5 * logvar)\n        eps = torch.randn_like(std)\n        return mu + eps * std\n\n    def forward(self, x):\n        h = self.encoder(x)\n        mu = self.fc_mu(h)\n        logvar = self.fc_logvar(h)\n        z = self.reparameterize(mu, logvar)\n        x_recon = self.decoder(z)\n        return x_recon, mu, logvar\n\n","metadata":{},"outputs":[],"execution_count":55},{"id":"29df511f","cell_type":"code","source":"VAE_model = VAE().to(device=device)\ntrain_eval(VAE_model,AE_train_dataloader,AE_val_dataloader,AE_test_dataloader)\n","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","==================  lr=5e-05, wd=1e-05 ==================\n","Train : time 161.09 s Epoch 1\n","Train Loss: 3.6338\n","--- Running Evaluation for Epoch 1 lr =5e-05 wd 1e-05 ---\n","----------- tensor(1.4726) tensor(0.3744)\n","[tensor(10.1306), tensor(10.1807), tensor(10.1918), tensor(10.3417), tensor(10.8254), tensor(11.2557), tensor(11.2946), tensor(11.5391), tensor(12.5028)]\n","Val: Accuracy: 0.8675  \n","---thr: 1.8469618558883667\n","Counter({0: 391335, 1: 98829}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 61252, 1: 68332, 2: 116, 3: 73, 4: 45, 5: 104, 6: 64, 7: 99}\n","Test : Accuracy: 0.7346 Recall : 0.3531 FDR: 0.6198  F1-score: 0.3662  \n","Train : time 154.61 s Epoch 2\n","Train Loss: 2.8694\n","--- Running Evaluation for Epoch 2 lr =5e-05 wd 1e-05 ---\n","----------- tensor(1.3536) tensor(0.3585)\n","[tensor(9.8622), tensor(10.1911), tensor(10.2131), tensor(10.4283), tensor(10.4542), tensor(10.6005), tensor(10.7521), tensor(10.9942), tensor(11.3552)]\n","Val: Accuracy: 0.8692  \n","---thr: 1.712066888809204\n","Counter({0: 391572, 1: 98592}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 60853, 1: 68167, 2: 119, 3: 69, 4: 44, 5: 104, 6: 64, 7: 104}\n","Test : Accuracy: 0.7358 Recall : 0.3547 FDR: 0.6172  F1-score: 0.3682  \n","Train : time 151.35 s Epoch 3\n","Train Loss: 2.7597\n","--- Running Evaluation for Epoch 3 lr =5e-05 wd 1e-05 ---\n","----------- tensor(1.2918) tensor(0.4475)\n","[tensor(9.9736), tensor(9.9758), tensor(9.9929), tensor(10.1114), tensor(10.1360), tensor(10.1754), tensor(10.1933), tensor(10.8906), tensor(11.1933)]\n","Val: Accuracy: 0.8576  \n","---thr: 1.7393275499343872\n","Counter({0: 399072, 1: 91092}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 61060, 1: 75856, 2: 125, 3: 73, 4: 45, 5: 105, 6: 71, 7: 103}\n","Test : Accuracy: 0.7196 Recall : 0.2822 FDR: 0.6703  F1-score: 0.3041  \n","Train : time 253.87 s Epoch 4\n","Train Loss: 2.6389\n","--- Running Evaluation for Epoch 4 lr =5e-05 wd 1e-05 ---\n","----------- tensor(1.1594) tensor(0.8141)\n","[tensor(10.5655), tensor(10.5687), tensor(10.6018), tensor(10.6895), tensor(10.7000), tensor(10.8672), tensor(10.9198), tensor(11.3385), tensor(11.4990)]\n","Val: Accuracy: 0.8654  \n","---thr: 1.9734703302383423\n","Counter({0: 410054, 1: 80110}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 56452, 1: 82192, 2: 147, 3: 81, 4: 58, 5: 104, 6: 72, 7: 98}\n","Test : Accuracy: 0.7160 Recall : 0.2223 FDR: 0.7047  F1-score: 0.2537  \n","Train : time 264.22 s Epoch 5\n","Train Loss: 2.3970\n","--- Running Evaluation for Epoch 5 lr =5e-05 wd 1e-05 ---\n","----------- tensor(0.9694) tensor(0.9527)\n","[tensor(11.8613), tensor(11.9569), tensor(12.3532), tensor(12.3841), tensor(12.5037), tensor(12.7991), tensor(12.8246), tensor(12.8349), tensor(13.4319)]\n","Val: Accuracy: 0.8938  \n","---thr: 1.9220633506774902\n","Counter({0: 399106, 1: 91058}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 52857, 1: 67703, 2: 113, 3: 80, 4: 50, 5: 104, 6: 61, 7: 98}\n","Test : Accuracy: 0.7530 Recall : 0.3590 FDR: 0.5805  F1-score: 0.3869  \n","Train : time 259.58 s Epoch 6\n","Train Loss: 2.3079\n","--- Running Evaluation for Epoch 6 lr =5e-05 wd 1e-05 ---\n","----------- tensor(0.9256) tensor(0.9484)\n","[tensor(11.4926), tensor(11.5535), tensor(11.6271), tensor(11.7426), tensor(11.8173), tensor(12.1027), tensor(12.1961), tensor(12.3192), tensor(12.3967)]\n","Val: Accuracy: 0.9013  \n","---thr: 1.8739399909973145\n","Counter({0: 400424, 1: 89740}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 50952, 1: 67133, 2: 114, 3: 66, 4: 48, 5: 103, 6: 59, 7: 99}\n","Test : Accuracy: 0.7581 Recall : 0.3645 FDR: 0.5678  F1-score: 0.3955  \n","Train : time 288.98 s Epoch 7\n","Train Loss: 2.2706\n","--- Running Evaluation for Epoch 7 lr =5e-05 wd 1e-05 ---\n","----------- tensor(0.9132) tensor(0.9580)\n","[tensor(11.7853), tensor(11.8365), tensor(11.9032), tensor(11.9118), tensor(12.1150), tensor(12.2448), tensor(12.3717), tensor(12.3927), tensor(12.9742)]\n","Val: Accuracy: 0.9052  \n","---thr: 1.871187686920166\n","Counter({0: 405055, 1: 85109}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 47929, 1: 68740, 2: 115, 3: 74, 4: 36, 5: 104, 6: 62, 7: 99}\n","Test : Accuracy: 0.7610 Recall : 0.3494 FDR: 0.5631  F1-score: 0.3883  \n","Train : time 271.21 s Epoch 8\n","Train Loss: 2.2437\n","--- Running Evaluation for Epoch 8 lr =5e-05 wd 1e-05 ---\n","----------- tensor(0.8900) tensor(0.9575)\n","[tensor(12.2766), tensor(12.5855), tensor(12.9041), tensor(13.6095), tensor(13.7198), tensor(13.9337), tensor(13.9962), tensor(14.4135), tensor(14.7261)]\n","Val: Accuracy: 0.9083  \n","---thr: 1.8475145101547241\n","Counter({0: 402942, 1: 87222}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 48273, 1: 66960, 2: 115, 3: 73, 4: 39, 5: 105, 6: 72, 7: 97}\n","Test : Accuracy: 0.7639 Recall : 0.3660 FDR: 0.5534  F1-score: 0.4023  \n","Train : time 138.37 s Epoch 9\n","Train Loss: 2.2137\n","--- Running Evaluation for Epoch 9 lr =5e-05 wd 1e-05 ---\n","----------- tensor(0.8944) tensor(0.9607)\n","[tensor(11.5623), tensor(11.5698), tensor(11.7605), tensor(11.7651), tensor(11.7798), tensor(12.1138), tensor(12.5448), tensor(12.8819), tensor(13.9749)]\n","Val: Accuracy: 0.9122  \n","---thr: 1.85508394241333\n","Counter({0: 404408, 1: 85756}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 47118, 1: 67265, 2: 119, 3: 73, 4: 44, 5: 104, 6: 70, 7: 97}\n","Test : Accuracy: 0.7656 Recall : 0.3631 FDR: 0.5494  F1-score: 0.4021  \n","Train : time 149.30 s Epoch 10\n","Train Loss: 2.1929\n","--- Running Evaluation for Epoch 10 lr =5e-05 wd 1e-05 ---\n","----------- tensor(0.8815) tensor(0.9562)\n","[tensor(11.3269), tensor(11.4663), tensor(11.4861), tensor(11.5344), tensor(11.5487), tensor(11.8007), tensor(11.8125), tensor(11.8431), tensor(12.2002)]\n","Val: Accuracy: 0.9130  \n","---thr: 1.837618350982666\n","Counter({0: 401211, 1: 88953}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 48045, 1: 65021, 2: 107, 3: 68, 4: 41, 5: 105, 6: 58, 7: 102}\n","Test : Accuracy: 0.7683 Recall : 0.3844 FDR: 0.5401  F1-score: 0.4188  \n","\n","==================  lr=5e-05, wd=0.0001 ==================\n","Train : time 163.34 s Epoch 1\n","Train Loss: 3.5671\n","--- Running Evaluation for Epoch 1 lr =5e-05 wd 0.0001 ---\n","----------- tensor(1.2441) tensor(0.3583)\n","[tensor(10.2657), tensor(10.5828), tensor(10.6089), tensor(10.7334), tensor(11.1777), tensor(11.2778), tensor(11.9145), tensor(12.0456), tensor(13.0734)]\n","Val: Accuracy: 0.8830  \n","---thr: 1.6023273468017578\n","Counter({0: 352153, 1: 138011}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 68460, 1: 36500, 2: 62, 3: 51, 4: 19, 5: 102, 6: 43, 7: 82}\n","Test : Accuracy: 0.7851 Recall : 0.6536 FDR: 0.4960  F1-score: 0.5691  \n","Train : time 157.58 s Epoch 2\n","Train Loss: 2.7280\n","--- Running Evaluation for Epoch 2 lr =5e-05 wd 0.0001 ---\n","----------- tensor(1.1337) tensor(0.3330)\n","[tensor(10.2171), tensor(10.2914), tensor(10.3561), tensor(10.7092), tensor(10.8391), tensor(11.1920), tensor(11.2177), tensor(11.5213), tensor(11.9452)]\n","Val: Accuracy: 0.8835  \n","---thr: 1.4667290449142456\n","Counter({0: 337638, 1: 152526}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 72095, 1: 25657, 2: 55, 3: 43, 4: 18, 5: 100, 6: 36, 7: 70}\n","Test : Accuracy: 0.7999 Recall : 0.7559 FDR: 0.4727  F1-score: 0.6212  \n","Train : time 165.65 s Epoch 3\n","Train Loss: 2.6251\n","--- Running Evaluation for Epoch 3 lr =5e-05 wd 0.0001 ---\n","----------- tensor(1.0701) tensor(0.3990)\n","[tensor(10.0707), tensor(10.0980), tensor(10.1039), tensor(10.1774), tensor(10.2348), tensor(10.2472), tensor(10.3072), tensor(10.3152), tensor(11.0411)]\n","Val: Accuracy: 0.8649  \n","---thr: 1.4690532684326172\n","Counter({0: 327620, 1: 162544}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 79207, 1: 22748, 2: 35, 3: 44, 4: 21, 5: 103, 6: 38, 7: 84}\n","Test : Accuracy: 0.7913 Recall : 0.7832 FDR: 0.4873  F1-score: 0.6197  \n","Train : time 151.83 s Epoch 4\n","Train Loss: 2.5321\n","--- Running Evaluation for Epoch 4 lr =5e-05 wd 0.0001 ---\n","----------- tensor(1.0048) tensor(0.6681)\n","[tensor(9.7223), tensor(9.8724), tensor(9.8856), tensor(10.0513), tensor(10.1669), tensor(10.1884), tensor(10.6271), tensor(11.0234), tensor(11.3857)]\n","Val: Accuracy: 0.8496  \n","---thr: 1.6728665828704834\n","Counter({0: 341683, 1: 148481}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 79185, 1: 36752, 2: 60, 3: 48, 4: 23, 5: 104, 6: 40, 7: 87}\n","Test : Accuracy: 0.7627 Recall : 0.6512 FDR: 0.5333  F1-score: 0.5437  \n","Train : time 187.69 s Epoch 5\n","Train Loss: 2.3177\n","--- Running Evaluation for Epoch 5 lr =5e-05 wd 0.0001 ---\n","----------- tensor(0.7703) tensor(0.9409)\n","[tensor(10.4860), tensor(10.4913), tensor(10.5004), tensor(10.5560), tensor(10.8943), tensor(10.9979), tensor(11.2829), tensor(11.4835), tensor(12.1775)]\n","Val: Accuracy: 0.8857  \n","---thr: 1.7111538648605347\n","Counter({0: 344844, 1: 145320}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 69531, 1: 30258, 2: 56, 3: 44, 4: 27, 5: 103, 6: 37, 7: 96}\n","Test : Accuracy: 0.7957 Recall : 0.7122 FDR: 0.4785  F1-score: 0.6021  \n","Train : time 195.11 s Epoch 6\n","Train Loss: 2.1654\n","--- Running Evaluation for Epoch 6 lr =5e-05 wd 0.0001 ---\n","----------- tensor(0.7297) tensor(1.0001)\n","[tensor(11.8435), tensor(11.9684), tensor(12.0801), tensor(12.0803), tensor(12.0920), tensor(12.4387), tensor(13.0843), tensor(13.3377), tensor(14.0246)]\n","Val: Accuracy: 0.8990  \n","---thr: 1.7297940254211426\n","Counter({0: 356765, 1: 133399}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 63348, 1: 35983, 2: 64, 3: 53, 4: 25, 5: 102, 6: 41, 7: 91}\n","Test : Accuracy: 0.7966 Recall : 0.6583 FDR: 0.4749  F1-score: 0.5842  \n","Train : time 194.91 s Epoch 7\n","Train Loss: 2.1076\n","--- Running Evaluation for Epoch 7 lr =5e-05 wd 0.0001 ---\n","----------- tensor(0.6950) tensor(0.9942)\n","[tensor(11.1034), tensor(11.1721), tensor(11.2266), tensor(11.2574), tensor(11.5968), tensor(11.8203), tensor(12.0820), tensor(12.2329), tensor(12.4533)]\n","Val: Accuracy: 0.9058  \n","---thr: 1.6892244815826416\n","Counter({0: 356785, 1: 133379}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 61909, 1: 34556, 2: 64, 3: 50, 4: 27, 5: 104, 6: 44, 7: 95}\n","Test : Accuracy: 0.8024 Recall : 0.6716 FDR: 0.4642  F1-score: 0.5961  \n","Train : time 193.78 s Epoch 8\n","Train Loss: 2.0737\n","--- Running Evaluation for Epoch 8 lr =5e-05 wd 0.0001 ---\n","----------- tensor(0.6738) tensor(1.0101)\n","[tensor(10.7879), tensor(10.8266), tensor(10.8401), tensor(10.8848), tensor(10.8875), tensor(10.9675), tensor(11.3077), tensor(11.9579), tensor(12.2132)]\n","Val: Accuracy: 0.9097  \n","---thr: 1.6839066743850708\n","Counter({0: 360009, 1: 130155}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 59771, 1: 35640, 2: 61, 3: 54, 4: 24, 5: 104, 6: 44, 7: 99}\n","Test : Accuracy: 0.8046 Recall : 0.6614 FDR: 0.4592  F1-score: 0.5950  \n","Train : time 198.85 s Epoch 9\n","Train Loss: 2.0461\n","--- Running Evaluation for Epoch 9 lr =5e-05 wd 0.0001 ---\n","----------- tensor(0.6591) tensor(1.0213)\n","[tensor(11.0989), tensor(11.1784), tensor(11.3318), tensor(11.3470), tensor(11.3717), tensor(11.4700), tensor(11.5752), tensor(11.7608), tensor(11.9511)]\n","Val: Accuracy: 0.9127  \n","---thr: 1.6803791522979736\n","Counter({0: 360951, 1: 129213}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 58804, 1: 35603, 2: 76, 3: 53, 4: 26, 5: 103, 6: 43, 7: 97}\n","Test : Accuracy: 0.8066 Recall : 0.6617 FDR: 0.4551  F1-score: 0.5976  \n","Train : time 195.85 s Epoch 10\n","Train Loss: 2.0238\n","--- Running Evaluation for Epoch 10 lr =5e-05 wd 0.0001 ---\n","----------- tensor(0.6430) tensor(1.0252)\n","[tensor(11.0638), tensor(11.1710), tensor(11.1815), tensor(11.1962), tensor(11.2456), tensor(11.2545), tensor(11.4197), tensor(11.5214), tensor(11.6650)]\n","Val: Accuracy: 0.9150  \n","---thr: 1.668224811553955\n","Counter({0: 359001, 1: 131163}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 59109, 1: 33974, 2: 63, 3: 54, 4: 21, 5: 103, 6: 42, 7: 99}\n","Test : Accuracy: 0.8093 Recall : 0.6771 FDR: 0.4507  F1-score: 0.6066  \n","\n","==================  lr=5e-05, wd=1e-07 ==================\n","Train : time 197.06 s Epoch 1\n","Train Loss: 3.3778\n","--- Running Evaluation for Epoch 1 lr =5e-05 wd 1e-07 ---\n","----------- tensor(1.2174) tensor(0.3226)\n","[tensor(10.2660), tensor(10.3474), tensor(10.3799), tensor(10.4029), tensor(10.5257), tensor(10.7530), tensor(10.9243), tensor(10.9272), tensor(11.0966)]\n","Val: Accuracy: 0.8795  \n","---thr: 1.539924144744873\n","Counter({0: 340757, 1: 149407}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 72379, 1: 29040, 2: 55, 3: 47, 4: 25, 5: 100, 6: 35, 7: 80}\n","Test : Accuracy: 0.7924 Recall : 0.7239 FDR: 0.4844  F1-score: 0.6022  \n","Train : time 197.01 s Epoch 2\n","Train Loss: 2.7195\n","--- Running Evaluation for Epoch 2 lr =5e-05 wd 1e-07 ---\n","----------- tensor(1.0939) tensor(0.3340)\n","[tensor(10.3962), tensor(10.4232), tensor(10.5678), tensor(10.6546), tensor(10.9994), tensor(11.0601), tensor(11.0854), tensor(11.2134), tensor(11.3834)]\n","Val: Accuracy: 0.8743  \n","---thr: 1.4279851913452148\n","Counter({0: 327541, 1: 162623}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 77174, 1: 20644, 2: 40, 3: 42, 4: 19, 5: 101, 6: 28, 7: 87}\n","Test : Accuracy: 0.7998 Recall : 0.8030 FDR: 0.4746  F1-score: 0.6352  \n","Train : time 195.56 s Epoch 3\n","Train Loss: 2.6065\n","--- Running Evaluation for Epoch 3 lr =5e-05 wd 1e-07 ---\n","----------- tensor(1.0488) tensor(0.4356)\n","[tensor(9.9363), tensor(9.9928), tensor(10.0012), tensor(10.0389), tensor(10.1079), tensor(10.3201), tensor(10.8014), tensor(11.0001), tensor(11.0966)]\n","Val: Accuracy: 0.8559  \n","---thr: 1.4844390153884888\n","Counter({0: 323273, 1: 166891}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 82677, 1: 21876, 2: 42, 3: 41, 4: 20, 5: 101, 6: 30, 7: 86}\n","Test : Accuracy: 0.7860 Recall : 0.7914 FDR: 0.4954  F1-score: 0.6163  \n","Train : time 195.87 s Epoch 4\n","Train Loss: 2.4897\n","--- Running Evaluation for Epoch 4 lr =5e-05 wd 1e-07 ---\n","----------- tensor(0.9543) tensor(0.8016)\n","[tensor(10.0617), tensor(10.0888), tensor(10.0994), tensor(10.2096), tensor(10.2349), tensor(10.2367), tensor(10.4567), tensor(10.9923), tensor(11.0085)]\n","Val: Accuracy: 0.8600  \n","---thr: 1.7558081150054932\n","Counter({0: 364450, 1: 125714}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 70437, 1: 50705, 2: 86, 3: 54, 4: 38, 5: 103, 6: 53, 7: 94}\n","Test : Accuracy: 0.7520 Recall : 0.5195 FDR: 0.5603  F1-score: 0.4763  \n","Train : time 195.29 s Epoch 5\n","Train Loss: 2.2476\n","--- Running Evaluation for Epoch 5 lr =5e-05 wd 1e-07 ---\n","----------- tensor(0.7638) tensor(1.0054)\n","[tensor(10.9500), tensor(11.1224), tensor(11.2189), tensor(11.6684), tensor(11.8103), tensor(11.8522), tensor(12.0615), tensor(12.5485), tensor(12.6303)]\n","Val: Accuracy: 0.8916  \n","---thr: 1.769195318222046\n","Counter({0: 362856, 1: 127308}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 63646, 1: 42355, 2: 70, 3: 57, 4: 28, 5: 104, 6: 39, 7: 95}\n","Test : Accuracy: 0.7829 Recall : 0.5983 FDR: 0.4999  F1-score: 0.5448  \n","Train : time 192.67 s Epoch 6\n","Train Loss: 2.1430\n","--- Running Evaluation for Epoch 6 lr =5e-05 wd 1e-07 ---\n","----------- tensor(0.6924) tensor(1.0042)\n","[tensor(11.5819), tensor(11.7066), tensor(11.7317), tensor(11.8869), tensor(12.1239), tensor(12.1663), tensor(12.1864), tensor(12.8114), tensor(12.8629)]\n","Val: Accuracy: 0.9025  \n","---thr: 1.6966090202331543\n","Counter({0: 358356, 1: 131808}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 62564, 1: 36767, 2: 73, 3: 56, 4: 26, 5: 104, 6: 42, 7: 98}\n","Test : Accuracy: 0.7965 Recall : 0.6507 FDR: 0.4747  F1-score: 0.5813  \n","Train : time 194.25 s Epoch 7\n","Train Loss: 2.0988\n","--- Running Evaluation for Epoch 7 lr =5e-05 wd 1e-07 ---\n","----------- tensor(0.6549) tensor(1.0025)\n","[tensor(11.2182), tensor(11.2525), tensor(11.2929), tensor(11.3685), tensor(11.4043), tensor(11.4590), tensor(11.4675), tensor(11.7399), tensor(12.6842)]\n","Val: Accuracy: 0.9063  \n","---thr: 1.657369613647461\n","Counter({0: 354443, 1: 135721}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 62408, 1: 32726, 2: 55, 3: 50, 4: 25, 5: 105, 6: 42, 7: 94}\n","Test : Accuracy: 0.8052 Recall : 0.6890 FDR: 0.4598  F1-score: 0.6056  \n","Train : time 196.21 s Epoch 8\n","Train Loss: 2.0718\n","--- Running Evaluation for Epoch 8 lr =5e-05 wd 1e-07 ---\n","----------- tensor(0.6352) tensor(1.0173)\n","[tensor(11.2193), tensor(11.2358), tensor(11.7090), tensor(11.8038), tensor(11.8830), tensor(11.9088), tensor(12.4001), tensor(13.1680), tensor(13.2970)]\n","Val: Accuracy: 0.9105  \n","---thr: 1.6525044441223145\n","Counter({0: 356054, 1: 134110}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 60873, 1: 32792, 2: 58, 3: 55, 4: 23, 5: 105, 6: 39, 7: 101}\n","Test : Accuracy: 0.8081 Recall : 0.6883 FDR: 0.4539  F1-score: 0.6090  \n","Train : time 191.09 s Epoch 9\n","Train Loss: 2.0417\n","--- Running Evaluation for Epoch 9 lr =5e-05 wd 1e-07 ---\n","----------- tensor(0.6111) tensor(1.0250)\n","[tensor(11.1991), tensor(11.2346), tensor(11.3920), tensor(11.6627), tensor(11.8160), tensor(12.0591), tensor(12.7371), tensor(12.9213), tensor(13.5349)]\n","Val: Accuracy: 0.9120  \n","---thr: 1.6361526250839233\n","Counter({0: 353481, 1: 136683}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 61290, 1: 30645, 2: 59, 3: 46, 4: 24, 5: 104, 6: 41, 7: 98}\n","Test : Accuracy: 0.8117 Recall : 0.7085 FDR: 0.4484  F1-score: 0.6203  \n","Train : time 241.18 s Epoch 10\n","Train Loss: 2.0247\n","--- Running Evaluation for Epoch 10 lr =5e-05 wd 1e-07 ---\n","----------- tensor(0.5858) tensor(1.0199)\n","[tensor(10.8171), tensor(10.8795), tensor(11.0078), tensor(11.0557), tensor(11.1063), tensor(11.5486), tensor(11.6369), tensor(11.8892), tensor(11.9676)]\n","Val: Accuracy: 0.9140  \n","---thr: 1.6057381629943848\n","Counter({0: 349125, 1: 141039}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 62128, 1: 27152, 2: 53, 3: 41, 4: 22, 5: 104, 6: 35, 7: 92}\n","Test : Accuracy: 0.8171 Recall : 0.7416 FDR: 0.4405  F1-score: 0.6378  \n","\n","==================  lr=1e-05, wd=1e-05 ==================\n","Train : time 148.40 s Epoch 1\n","Train Loss: 5.1882\n","--- Running Evaluation for Epoch 1 lr =1e-05 wd 1e-05 ---\n","----------- tensor(1.9215) tensor(0.6390)\n","[tensor(10.6107), tensor(10.7395), tensor(10.7833), tensor(10.9668), tensor(11.0749), tensor(11.1527), tensor(11.2465), tensor(11.2967), tensor(11.8879)]\n","Val: Accuracy: 0.8563  \n","---thr: 2.5604825019836426\n","Counter({0: 363499, 1: 126665}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 71961, 1: 51267, 2: 88, 3: 54, 4: 51, 5: 102, 6: 53, 7: 91}\n","Test : Accuracy: 0.7477 Recall : 0.5141 FDR: 0.5681  F1-score: 0.4694  \n","Train : time 137.21 s Epoch 2\n","Train Loss: 3.4421\n","--- Running Evaluation for Epoch 2 lr =1e-05 wd 1e-05 ---\n","----------- tensor(1.5428) tensor(0.5140)\n","[tensor(10.4157), tensor(10.5574), tensor(10.6968), tensor(10.7084), tensor(10.8116), tensor(10.9968), tensor(11.6813), tensor(11.7763), tensor(12.7163)]\n","Val: Accuracy: 0.8597  \n","---thr: 2.0568017959594727\n","Counter({0: 361117, 1: 129047}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 71603, 1: 48558, 2: 81, 3: 60, 4: 35, 5: 101, 6: 47, 7: 84}\n","Test : Accuracy: 0.7540 Recall : 0.5398 FDR: 0.5549  F1-score: 0.4879  \n","Train : time 136.00 s Epoch 3\n","Train Loss: 3.1146\n","--- Running Evaluation for Epoch 3 lr =1e-05 wd 1e-05 ---\n","----------- tensor(1.3962) tensor(0.4535)\n","[tensor(10.1359), tensor(10.1845), tensor(10.3401), tensor(10.3523), tensor(10.5705), tensor(10.6649), tensor(11.0022), tensor(11.0739), tensor(11.3684)]\n","Val: Accuracy: 0.8642  \n","---thr: 1.8497049808502197\n","Counter({0: 359086, 1: 131078}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 70979, 1: 45897, 2: 86, 3: 55, 4: 35, 5: 104, 6: 45, 7: 89}\n","Test : Accuracy: 0.7607 Recall : 0.5648 FDR: 0.5415  F1-score: 0.5061  \n","Train : time 135.13 s Epoch 4\n","Train Loss: 2.9600\n","--- Running Evaluation for Epoch 4 lr =1e-05 wd 1e-05 ---\n","----------- tensor(1.2783) tensor(0.4158)\n","[tensor(10.5726), tensor(10.8944), tensor(11.2257), tensor(11.5342), tensor(11.6364), tensor(11.6839), tensor(12.1212), tensor(12.4778), tensor(12.5520)]\n","Val: Accuracy: 0.8687  \n","---thr: 1.6941604614257812\n","Counter({0: 351006, 1: 139158}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 72130, 1: 38993, 2: 67, 3: 57, 4: 27, 5: 102, 6: 51, 7: 85}\n","Test : Accuracy: 0.7725 Recall : 0.6299 FDR: 0.5183  F1-score: 0.5459  \n","Train : time 143.27 s Epoch 5\n","Train Loss: 2.8712\n","--- Running Evaluation for Epoch 5 lr =1e-05 wd 1e-05 ---\n","----------- tensor(1.2289) tensor(0.3951)\n","[tensor(9.9485), tensor(9.9999), tensor(10.0269), tensor(10.1030), tensor(10.1800), tensor(10.2711), tensor(10.4161), tensor(10.4727), tensor(10.5546)]\n","Val: Accuracy: 0.8714  \n","---thr: 1.6240452527999878\n","Counter({0: 346177, 1: 143987}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 73067, 1: 35121, 2: 56, 3: 51, 4: 25, 5: 102, 6: 50, 7: 85}\n","Test : Accuracy: 0.7785 Recall : 0.6665 FDR: 0.5075  F1-score: 0.5665  \n","Train : time 164.44 s Epoch 6\n","Train Loss: 2.8167\n","--- Running Evaluation for Epoch 6 lr =1e-05 wd 1e-05 ---\n","----------- tensor(1.2210) tensor(0.3902)\n","[tensor(10.2083), tensor(10.4768), tensor(10.5634), tensor(10.5651), tensor(10.5773), tensor(10.5870), tensor(10.6612), tensor(10.9120), tensor(12.1366)]\n","Val: Accuracy: 0.8734  \n","---thr: 1.6111822128295898\n","Counter({0: 347034, 1: 143130}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 72275, 1: 35182, 2: 66, 3: 55, 4: 22, 5: 100, 6: 41, 7: 89}\n","Test : Accuracy: 0.7800 Recall : 0.6659 FDR: 0.5050  F1-score: 0.5679  \n","Train : time 162.66 s Epoch 7\n","Train Loss: 2.7579\n","--- Running Evaluation for Epoch 7 lr =1e-05 wd 1e-05 ---\n","----------- tensor(1.1604) tensor(0.3825)\n","[tensor(10.0222), tensor(10.0534), tensor(10.1035), tensor(10.1711), tensor(10.3016), tensor(10.3886), tensor(10.8798), tensor(11.2740), tensor(11.3318)]\n","Val: Accuracy: 0.8721  \n","---thr: 1.5428811311721802\n","Counter({0: 340056, 1: 150108}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 74417, 1: 30373, 2: 51, 3: 43, 4: 23, 5: 101, 6: 37, 7: 91}\n","Test : Accuracy: 0.7855 Recall : 0.7113 FDR: 0.4958  F1-score: 0.5901  \n","Train : time 170.54 s Epoch 8\n","Train Loss: 2.7278\n","--- Running Evaluation for Epoch 8 lr =1e-05 wd 1e-05 ---\n","----------- tensor(1.1602) tensor(0.3912)\n","[tensor(9.7892), tensor(9.7954), tensor(9.8558), tensor(9.8738), tensor(10.0034), tensor(10.3632), tensor(10.4157), tensor(10.4190), tensor(10.6249)]\n","Val: Accuracy: 0.8715  \n","---thr: 1.5514005422592163\n","Counter({0: 341563, 1: 148601}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 73881, 1: 31337, 2: 56, 3: 49, 4: 19, 5: 100, 6: 42, 7: 87}\n","Test : Accuracy: 0.7846 Recall : 0.7022 FDR: 0.4972  F1-score: 0.5860  \n","Train : time 164.12 s Epoch 9\n","Train Loss: 2.6969\n","--- Running Evaluation for Epoch 9 lr =1e-05 wd 1e-05 ---\n","----------- tensor(1.1387) tensor(0.4027)\n","[tensor(9.3008), tensor(9.3830), tensor(9.4963), tensor(9.6027), tensor(9.7352), tensor(10.3630), tensor(10.3923), tensor(11.5318), tensor(11.6627)]\n","Val: Accuracy: 0.8710  \n","---thr: 1.5413649082183838\n","Counter({0: 339428, 1: 150736}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 74810, 1: 30137, 2: 48, 3: 48, 4: 21, 5: 102, 6: 41, 7: 87}\n","Test : Accuracy: 0.7852 Recall : 0.7135 FDR: 0.4963  F1-score: 0.5905  \n","Train : time 133.77 s Epoch 10\n","Train Loss: 2.6711\n","--- Running Evaluation for Epoch 10 lr =1e-05 wd 1e-05 ---\n","----------- tensor(1.1169) tensor(0.4201)\n","[tensor(9.9899), tensor(10.0422), tensor(10.1406), tensor(10.1792), tensor(10.4091), tensor(10.4189), tensor(10.4200), tensor(10.6469), tensor(11.5596)]\n","Val: Accuracy: 0.8703  \n","---thr: 1.5369759798049927\n","Counter({0: 338069, 1: 152095}) Counter({0: 383754, 1: 106410})\n","Counts of  labels: {0: 383754, 1: 105690, 2: 178, 3: 101, 4: 125, 5: 118, 6: 86, 7: 112}\n","Counts of misclassified original labels: {0: 75481, 1: 29438, 2: 54, 3: 49, 4: 21, 5: 103, 6: 44, 7: 87}\n","Test : Accuracy: 0.7852 Recall : 0.7200 FDR: 0.4963  F1-score: 0.5927  \n","\n","==================  lr=1e-05, wd=0.0001 ==================\n"]}],"execution_count":null},{"id":"b6081d07","cell_type":"code","source":"\nVAE_model = VAE().to(device=device)\ntrain_eval(VAE_model,AE_train_dataloader,AE_val_dataloader,AE_test_dataloader)\n\n\n# for epoch in range(3):\n#     time_1 = time.time()\n#     train_loss = 0\n#     AE_model.train()\n#     if shuffle_files:\n#         sys_rand = SystemRandom()\n#         sys_rand.shuffle(AE_dataset.file_order_indices)\n#     for sequences, _ in AE_dataloader:\n#         sequences = sequences.squeeze().to(device)\n#         VAE_optimizer.zero_grad()\n#         recon, mu, logvar = VAE_model(sequences)\n#         loss = vae_loss_function(recon, sequences, mu, logvar)\n#         loss.backward()\n#         VAE_optimizer.step()\n#         train_loss += loss.item()\n#     print(\"time\",time.time()-time_1,f\"Epoch {epoch}, Train Loss: {train_loss / len(AE_dataloader)}\")\n","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","================== Evaluate lr=0.01, wd=0.0001 ==================\n","Train : time 141.5818 Epoch 0 Train Loss: 97.8765\n","\n","--- Running Evaluation for Epoch 1 lr =0.01 wd 0.0001 ---\n","Computed Threshold: 0.0206\n","Val: Accuracy: 0.9378  \n","Test : Accuracy: 0.8535 Recall : 0.8524 FDR: 0.3822  F1-score: 0.7164  \n","Train : time 139.1011 Epoch 1 Train Loss: 93.5440\n","\n","--- Running Evaluation for Epoch 2 lr =0.01 wd 0.0001 ---\n","Computed Threshold: 0.0382\n","Val: Accuracy: 0.8970  \n","Test : Accuracy: 0.8366 Recall : 0.8565 FDR: 0.4156  F1-score: 0.6948  \n","\n","================== Evaluate lr=0.01, wd=1e-05 ==================\n","Train : time 135.4118 Epoch 0 Train Loss: 102.8192\n","\n","--- Running Evaluation for Epoch 1 lr =0.01 wd 1e-05 ---\n","Computed Threshold: 0.0314\n","Val: Accuracy: 0.8984  \n","Test : Accuracy: 0.2174 Recall : 0.9999 FDR: 0.7829  F1-score: 0.3568  \n","Train : time 134.7249 Epoch 1 Train Loss: 102.6428\n","\n","--- Running Evaluation for Epoch 2 lr =0.01 wd 1e-05 ---\n","Computed Threshold: 0.0322\n","Val: Accuracy: 0.8927  \n","Test : Accuracy: 0.2171 Recall : 1.0000 FDR: 0.7829  F1-score: 0.3567  \n","\n","================== Evaluate lr=0.01, wd=1e-06 ==================\n","Train : time 134.4829 Epoch 0 Train Loss: 104.2518\n","\n","--- Running Evaluation for Epoch 1 lr =0.01 wd 1e-06 ---\n","Computed Threshold: 0.0177\n","Val: Accuracy: 0.9337  \n","Test : Accuracy: 0.8099 Recall : 0.8636 FDR: 0.4612  F1-score: 0.6636  \n","Train : time 136.0765 Epoch 1 Train Loss: 90.2909\n","\n","--- Running Evaluation for Epoch 2 lr =0.01 wd 1e-06 ---\n","Computed Threshold: 0.0343\n","Val: Accuracy: 0.8991  \n","Test : Accuracy: 0.8530 Recall : 0.8530 FDR: 0.3832  F1-score: 0.7159  \n","\n","================== Evaluate lr=0.001, wd=0.0001 ==================\n","Train : time 136.5938 Epoch 0 Train Loss: 95.5846\n","\n","--- Running Evaluation for Epoch 1 lr =0.001 wd 0.0001 ---\n","Computed Threshold: 0.0196\n","Val: Accuracy: 0.9336  \n","Test : Accuracy: 0.8549 Recall : 0.8525 FDR: 0.3793  F1-score: 0.7184  \n","Train : time 140.2261 Epoch 1 Train Loss: 85.7759\n","\n","--- Running Evaluation for Epoch 2 lr =0.001 wd 0.0001 ---\n","Computed Threshold: 0.0192\n","Val: Accuracy: 0.9459  \n","Test : Accuracy: 0.8641 Recall : 0.8503 FDR: 0.3589  F1-score: 0.7310  \n","\n","================== Evaluate lr=0.001, wd=1e-05 ==================\n","Train : time 138.3106 Epoch 0 Train Loss: 93.6457\n","\n","--- Running Evaluation for Epoch 1 lr =0.001 wd 1e-05 ---\n","Computed Threshold: 0.0212\n","Val: Accuracy: 0.9177  \n","Test : Accuracy: 0.8457 Recall : 0.8543 FDR: 0.3981  F1-score: 0.7062  \n","Train : time 134.6083 Epoch 1 Train Loss: 86.1772\n","\n","--- Running Evaluation for Epoch 2 lr =0.001 wd 1e-05 ---\n","Computed Threshold: 0.0187\n","Val: Accuracy: 0.9421  \n","Test : Accuracy: 0.8573 Recall : 0.8521 FDR: 0.3742  F1-score: 0.7216  \n","\n","================== Evaluate lr=0.001, wd=1e-06 ==================\n","Train : time 136.1477 Epoch 0 Train Loss: 99.5214\n","\n","--- Running Evaluation for Epoch 1 lr =0.001 wd 1e-06 ---\n","Computed Threshold: 0.0192\n","Val: Accuracy: 0.9012  \n","Test : Accuracy: 0.8543 Recall : 0.8526 FDR: 0.3806  F1-score: 0.7175  \n","Train : time 135.3940 Epoch 1 Train Loss: 88.1068\n","\n","--- Running Evaluation for Epoch 2 lr =0.001 wd 1e-06 ---\n","Computed Threshold: 0.0194\n","Val: Accuracy: 0.9470  \n","Test : Accuracy: 0.8604 Recall : 0.8510 FDR: 0.3674  F1-score: 0.7257  \n","\n","================== Evaluate lr=0.0001, wd=0.0001 ==================\n","Train : time 135.7181 Epoch 0 Train Loss: 103.1032\n","\n","--- Running Evaluation for Epoch 1 lr =0.0001 wd 0.0001 ---\n","Computed Threshold: 0.0177\n","Val: Accuracy: 0.9241  \n","Test : Accuracy: 0.8526 Recall : 0.8531 FDR: 0.3841  F1-score: 0.7154  \n","Train : time 136.3915 Epoch 1 Train Loss: 87.1517\n","\n","--- Running Evaluation for Epoch 2 lr =0.0001 wd 0.0001 ---\n","Computed Threshold: 0.0186\n","Val: Accuracy: 0.9370  \n","Test : Accuracy: 0.8594 Recall : 0.8512 FDR: 0.3696  F1-score: 0.7244  \n","\n","================== Evaluate lr=0.0001, wd=1e-05 ==================\n","Train : time 136.6951 Epoch 0 Train Loss: 105.1742\n","\n","--- Running Evaluation for Epoch 1 lr =0.0001 wd 1e-05 ---\n","Computed Threshold: 0.0181\n","Val: Accuracy: 0.9300  \n","Test : Accuracy: 0.8505 Recall : 0.8536 FDR: 0.3885  F1-score: 0.7125  \n","Train : time 134.5713 Epoch 1 Train Loss: 86.9760\n","\n","--- Running Evaluation for Epoch 2 lr =0.0001 wd 1e-05 ---\n","Computed Threshold: 0.0185\n","Val: Accuracy: 0.9335  \n","Test : Accuracy: 0.8570 Recall : 0.8521 FDR: 0.3749  F1-score: 0.7212  \n","\n","================== Evaluate lr=0.0001, wd=1e-06 ==================\n","Train : time 136.1035 Epoch 0 Train Loss: 106.1062\n","\n","--- Running Evaluation for Epoch 1 lr =0.0001 wd 1e-06 ---\n","Computed Threshold: 0.0194\n","Val: Accuracy: 0.9186  \n","Test : Accuracy: 0.8510 Recall : 0.8530 FDR: 0.3874  F1-score: 0.7131  \n","Train : time 135.7051 Epoch 1 Train Loss: 89.3941\n","\n","--- Running Evaluation for Epoch 2 lr =0.0001 wd 1e-06 ---\n","Computed Threshold: 0.0198\n","Val: Accuracy: 0.9342  \n","Test : Accuracy: 0.8613 Recall : 0.8507 FDR: 0.3652  F1-score: 0.7271  \n","\n","================== Evaluate lr=1e-05, wd=0.0001 ==================\n","Train : time 136.9625 Epoch 0 Train Loss: 171.3044\n","\n","--- Running Evaluation for Epoch 1 lr =1e-05 wd 0.0001 ---\n","Computed Threshold: 0.0417\n","Val: Accuracy: 0.8669  \n","Test : Accuracy: 0.3565 Recall : 0.9690 FDR: 0.7517  F1-score: 0.3953  \n","Train : time 134.8269 Epoch 1 Train Loss: 121.9192\n","\n","--- Running Evaluation for Epoch 2 lr =1e-05 wd 0.0001 ---\n","Computed Threshold: 0.0276\n","Val: Accuracy: 0.8930  \n","Test : Accuracy: 0.6191 Recall : 0.9077 FDR: 0.6468  F1-score: 0.5085  \n","\n","================== Evaluate lr=1e-05, wd=1e-05 ==================\n","Train : time 148.1193 Epoch 0 Train Loss: 168.1857\n","\n","--- Running Evaluation for Epoch 1 lr =1e-05 wd 1e-05 ---\n","Computed Threshold: 0.0438\n","Val: Accuracy: 0.8706  \n","Test : Accuracy: 0.4983 Recall : 0.9369 FDR: 0.7058  F1-score: 0.4478  \n","Train : time 155.5730 Epoch 1 Train Loss: 122.4959\n","\n","--- Running Evaluation for Epoch 2 lr =1e-05 wd 1e-05 ---\n","Computed Threshold: 0.0339\n","Val: Accuracy: 0.8936  \n","Test : Accuracy: 0.6163 Recall : 0.9100 FDR: 0.6483  F1-score: 0.5073  \n","\n","================== Evaluate lr=1e-05, wd=1e-06 ==================\n","Train : time 141.7032 Epoch 0 Train Loss: 165.6943\n","\n","--- Running Evaluation for Epoch 1 lr =1e-05 wd 1e-06 ---\n","Computed Threshold: 0.0430\n","Val: Accuracy: 0.8676  \n","Test : Accuracy: 0.3934 Recall : 0.9612 FDR: 0.7414  F1-score: 0.4076  \n","Train : time 149.8323 Epoch 1 Train Loss: 125.1951\n","\n","--- Running Evaluation for Epoch 2 lr =1e-05 wd 1e-06 ---\n","Computed Threshold: 0.0342\n","Val: Accuracy: 0.8924  \n","Test : Accuracy: 0.5095 Recall : 0.9337 FDR: 0.7014  F1-score: 0.4525  \n"]}],"execution_count":null},{"id":"48a5bd88","cell_type":"code","source":"\nclass AAE_Encoder(nn.Module):\n    def __init__(self):\n        \"\"\"\n        Encoder(Generator):(89-16-4-2)\n        \"\"\"\n        super(AAE_Encoder, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Linear(89, 16),\n            nn.LeakyReLU(0.2),\n            nn.Linear(16, 4),\n            nn.LeakyReLU(0.2),\n            nn.Linear(4, 2))\n    def forward(self, x):\n        return self.encoder(x)\nclass AAE_Decoder(nn.Module):\n    def __init__(self):\n        super(AAE_Decoder, self).__init__()\n        self.decoder = nn.Sequential(\n            nn.Linear(2, 4),\n            nn.LeakyReLU(),\n            nn.Linear(4, 16),\n            nn.LeakyReLU(),\n            nn.Linear(16, 89),\n            nn.LeakyReLU()\n        )\n    def forward(self, x):\n        return self.decoder(x)\nclass AAE_Discriminator(nn.Module):\n    def __init__(self):\n        super(AAE_Discriminator, self).__init__()\n        # corrected to 2-16-4-1\n        self.discriminator = nn.Sequential(\n            nn.Linear(2, 16),\n            nn.LeakyReLU(),\n            nn.Linear(16, 4),\n            nn.LeakyReLU(),\n            nn.Linear(4, 1), \n            nn.Sigmoid()\n        )    \n    def forward(self, x):\n        return self.discriminator(x)\n \nclass AdversarialAutoencoder(nn.Module):\n    def __init__(self):\n        super(AdversarialAutoencoder, self).__init__()\n        self.encoder = AAE_Encoder()\n        self.decoder = AAE_Decoder()\n        self.discriminator = AAE_Discriminator()\n    def forward(self, x):\n        fake_z = self.encoder(x)\n        x_recon = self.decoder(fake_z)\n        return fake_z,x_recon\n","metadata":{},"outputs":[],"execution_count":29},{"id":"8f371a05","cell_type":"code","source":"\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\naae_model = AdversarialAutoencoder().to(device)\ndevice = next(aae_model.parameters()).device\nprint(f\"Model device (Method 1): {device}\")\nprint(next(aae_model.decoder.parameters()).device)\nprint(aae_model._get_name())\ntrain_eval(aae_model,AE_train_dataloader,AE_val_dataloader,AE_test_dataloader)\n\n# for epoch in range(num_epochs):\n#     # aae_encoder.train()\n#     # aae_decoder.train()\n#     # aae_discriminator.train()\n#     aae_model.train()\n#     if shuffle_files:\n#         sys_rand = SystemRandom()\n#         sys_rand.shuffle(AE_dataset.file_order_indices)\n#     for sequences,_ in AE_dataloader:\n#         sequences=sequences.squeeze().to(device)\n#         # 1) reconstruction + generator loss\n#         optimizer_G.zero_grad()\n#         fake_z = aae_encoder(sequences)\n#         decoded_seq = aae_decoder(fake_z)\n#         G_loss = 0.001*adversarial_loss(aae_discriminator(fake_z),  torch.ones(sequences.size(0), 2,device=device)) + 0.999*reconstruction_loss(decoded_seq, sequences)\n#         G_loss.backward()\n#         optimizer_G.step()\n#         # 2) discriminator loss\n#         optimizer_D.zero_grad()\n#         real_loss = adversarial_loss(aae_discriminator(torch.randn(sequences.size(0), 2, device=device)),  torch.ones(sequences.size(0), 2,device=device))\n#         fake_loss = adversarial_loss(aae_discriminator(fake_z.detach()),  torch.zeros(sequences.size(0), 2,device=device))\n#         D_loss = 0.5*(real_loss + fake_loss)\n#         D_loss.backward()\n#         optimizer_D.step()\n#     # print loss\n#     print(\n#             \"[Epoch %d/%d] [G loss: %f] [D loss: %f]\"\n#             % (epoch, num_epochs, G_loss.item(), D_loss.item())\n#          )","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model device (Method 1): cuda:0\n","cuda:0\n","AdversarialAutoencoder\n","\n","================== Evaluate lr=0.01, wd=0.0001 ==================\n","Train : time 253.4021 Epoch 0\n","Generator Loss: 0.8527 Discriminator Loss: 61.5562\n","\n","--- Running Evaluation for Epoch 1 lr =0.01 wd 0.0001 ---\n","Computed Threshold: 0.0011\n","Val: Accuracy: 0.9964  \n","Test : Accuracy: 0.8894 Recall : 0.8443 FDR: 0.2954  F1-score: 0.7681  \n","Train : time 228.5464 Epoch 1\n","Generator Loss: 0.5067 Discriminator Loss: 60.1043\n","\n","--- Running Evaluation for Epoch 2 lr =0.01 wd 0.0001 ---\n","Computed Threshold: 0.0011\n","Val: Accuracy: 0.9939  \n","Test : Accuracy: 0.8894 Recall : 0.8443 FDR: 0.2954  F1-score: 0.7682  \n","\n","================== Evaluate lr=0.01, wd=1e-05 ==================\n","Train : time 210.8485 Epoch 0\n","Generator Loss: 1.1983 Discriminator Loss: 299.7112\n","\n","--- Running Evaluation for Epoch 1 lr =0.01 wd 1e-05 ---\n","Computed Threshold: 0.0014\n","Val: Accuracy: 0.9957  \n","Test : Accuracy: 0.8894 Recall : 0.8443 FDR: 0.2954  F1-score: 0.7681  \n","Train : time 207.1711 Epoch 1\n","Generator Loss: 0.5891 Discriminator Loss: 57.8186\n","\n","--- Running Evaluation for Epoch 2 lr =0.01 wd 1e-05 ---\n","Computed Threshold: 0.0012\n","Val: Accuracy: 0.9948  \n","Test : Accuracy: 0.8894 Recall : 0.8443 FDR: 0.2954  F1-score: 0.7681  \n","\n","================== Evaluate lr=0.01, wd=1e-06 ==================\n","Train : time 222.9285 Epoch 0\n","Generator Loss: 1.1046 Discriminator Loss: 46.7173\n","\n","--- Running Evaluation for Epoch 1 lr =0.01 wd 1e-06 ---\n","Computed Threshold: 0.0020\n","Val: Accuracy: 0.9969  \n","Test : Accuracy: 0.8894 Recall : 0.8443 FDR: 0.2954  F1-score: 0.7681  \n","Train : time 236.7508 Epoch 1\n","Generator Loss: 1.0842 Discriminator Loss: 60.5046\n","\n","--- Running Evaluation for Epoch 2 lr =0.01 wd 1e-06 ---\n","Computed Threshold: 0.0023\n","Val: Accuracy: 0.9931  \n","Test : Accuracy: 0.8894 Recall : 0.8443 FDR: 0.2954  F1-score: 0.7681  \n","\n","================== Evaluate lr=0.001, wd=0.0001 ==================\n","Train : time 232.1753 Epoch 0\n","Generator Loss: 3.4004 Discriminator Loss: 48.3463\n","\n","--- Running Evaluation for Epoch 1 lr =0.001 wd 0.0001 ---\n","Computed Threshold: 0.0011\n","Val: Accuracy: 0.9966  \n","Test : Accuracy: 0.8894 Recall : 0.8443 FDR: 0.2954  F1-score: 0.7681  \n","Train : time 242.4341 Epoch 1\n","Generator Loss: 0.4077 Discriminator Loss: 50.4980\n","\n","--- Running Evaluation for Epoch 2 lr =0.001 wd 0.0001 ---\n","Computed Threshold: 0.0010\n","Val: Accuracy: 0.9967  \n","Test : Accuracy: 0.8897 Recall : 0.8443 FDR: 0.2943  F1-score: 0.7688  \n","\n","================== Evaluate lr=0.001, wd=1e-05 ==================\n","Train : time 221.1261 Epoch 0\n","Generator Loss: 1.6774 Discriminator Loss: 40.1020\n","\n","--- Running Evaluation for Epoch 1 lr =0.001 wd 1e-05 ---\n","Computed Threshold: 0.0018\n","Val: Accuracy: 0.9967  \n","Test : Accuracy: 0.8894 Recall : 0.8443 FDR: 0.2954  F1-score: 0.7681  \n","Train : time 239.5897 Epoch 1\n","Generator Loss: 0.5316 Discriminator Loss: 53.9577\n","\n","--- Running Evaluation for Epoch 2 lr =0.001 wd 1e-05 ---\n","Computed Threshold: 0.0008\n","Val: Accuracy: 0.9969  \n","Test : Accuracy: 0.8894 Recall : 0.8442 FDR: 0.2954  F1-score: 0.7681  \n","\n","================== Evaluate lr=0.001, wd=1e-06 ==================\n","Train : time 209.5135 Epoch 0\n","Generator Loss: 2.9068 Discriminator Loss: 39.0097\n","\n","--- Running Evaluation for Epoch 1 lr =0.001 wd 1e-06 ---\n","Computed Threshold: 0.0012\n","Val: Accuracy: 0.9964  \n","Test : Accuracy: 0.8894 Recall : 0.8443 FDR: 0.2954  F1-score: 0.7681  \n","Train : time 259.2067 Epoch 1\n","Generator Loss: 0.3805 Discriminator Loss: 52.0293\n","\n","--- Running Evaluation for Epoch 2 lr =0.001 wd 1e-06 ---\n","Computed Threshold: 0.0009\n","Val: Accuracy: 0.9964  \n","Test : Accuracy: 0.8897 Recall : 0.8442 FDR: 0.2943  F1-score: 0.7688  \n","\n","================== Evaluate lr=0.0001, wd=0.0001 ==================\n","Train : time 217.9773 Epoch 0\n","Generator Loss: 29.6505 Discriminator Loss: 26.5341\n","\n","--- Running Evaluation for Epoch 1 lr =0.0001 wd 0.0001 ---\n","Computed Threshold: 0.0024\n","Val: Accuracy: 0.9939  \n","Test : Accuracy: 0.8894 Recall : 0.8443 FDR: 0.2954  F1-score: 0.7681  \n","Train : time 234.4891 Epoch 1\n","Generator Loss: 1.7832 Discriminator Loss: 44.4554\n","\n","--- Running Evaluation for Epoch 2 lr =0.0001 wd 0.0001 ---\n","Computed Threshold: 0.0016\n","Val: Accuracy: 0.9950  \n","Test : Accuracy: 0.8894 Recall : 0.8443 FDR: 0.2954  F1-score: 0.7681  \n","\n","================== Evaluate lr=0.0001, wd=1e-05 ==================\n","Train : time 232.3771 Epoch 0\n","Generator Loss: 13.3208 Discriminator Loss: 45.0669\n","\n","--- Running Evaluation for Epoch 1 lr =0.0001 wd 1e-05 ---\n","Computed Threshold: 0.0015\n","Val: Accuracy: 0.9920  \n","Test : Accuracy: 0.8894 Recall : 0.8443 FDR: 0.2954  F1-score: 0.7681  \n","Train : time 237.0694 Epoch 1\n","Generator Loss: 0.5830 Discriminator Loss: 30.6276\n","\n","--- Running Evaluation for Epoch 2 lr =0.0001 wd 1e-05 ---\n","Computed Threshold: 0.0020\n","Val: Accuracy: 0.9970  \n","Test : Accuracy: 0.8894 Recall : 0.8443 FDR: 0.2954  F1-score: 0.7681  \n","\n","================== Evaluate lr=0.0001, wd=1e-06 ==================\n","Train : time 255.5520 Epoch 0\n","Generator Loss: 8.3159 Discriminator Loss: 33.0867\n","\n","--- Running Evaluation for Epoch 1 lr =0.0001 wd 1e-06 ---\n","Computed Threshold: 0.0018\n","Val: Accuracy: 0.9939  \n","Test : Accuracy: 0.8894 Recall : 0.8443 FDR: 0.2954  F1-score: 0.7681  \n","Train : time 232.1961 Epoch 1\n","Generator Loss: 0.8245 Discriminator Loss: 30.6750\n","\n","--- Running Evaluation for Epoch 2 lr =0.0001 wd 1e-06 ---\n","Computed Threshold: 0.0020\n","Val: Accuracy: 0.9939  \n","Test : Accuracy: 0.8894 Recall : 0.8443 FDR: 0.2954  F1-score: 0.7681  \n","\n","================== Evaluate lr=1e-05, wd=0.0001 ==================\n","Train : time 232.0385 Epoch 0\n","Generator Loss: 96.4000 Discriminator Loss: 34.8106\n","\n","--- Running Evaluation for Epoch 1 lr =1e-05 wd 0.0001 ---\n","Computed Threshold: 0.0055\n","Val: Accuracy: 0.9916  \n","Test : Accuracy: 0.8894 Recall : 0.8443 FDR: 0.2954  F1-score: 0.7681  \n","Train : time 229.6131 Epoch 1\n","Generator Loss: 5.2372 Discriminator Loss: 9.0938\n","\n","--- Running Evaluation for Epoch 2 lr =1e-05 wd 0.0001 ---\n","Computed Threshold: 0.0047\n","Val: Accuracy: 0.9940  \n","Test : Accuracy: 0.8894 Recall : 0.8443 FDR: 0.2954  F1-score: 0.7681  \n","\n","================== Evaluate lr=1e-05, wd=1e-05 ==================\n","Train : time 257.6845 Epoch 0\n","Generator Loss: 98.1880 Discriminator Loss: 64.7304\n","\n","--- Running Evaluation for Epoch 1 lr =1e-05 wd 1e-05 ---\n","Computed Threshold: 0.0104\n","Val: Accuracy: 0.9076  \n","Test : Accuracy: 0.8894 Recall : 0.8443 FDR: 0.2954  F1-score: 0.7681  \n","Train : time 196.7555 Epoch 1\n","Generator Loss: 9.3170 Discriminator Loss: 29.8478\n","\n","--- Running Evaluation for Epoch 2 lr =1e-05 wd 1e-05 ---\n","Computed Threshold: 0.0047\n","Val: Accuracy: 0.9913  \n","Test : Accuracy: 0.8894 Recall : 0.8443 FDR: 0.2954  F1-score: 0.7681  \n","\n","================== Evaluate lr=1e-05, wd=1e-06 ==================\n","Train : time 196.0246 Epoch 0\n","Generator Loss: 111.8188 Discriminator Loss: 51.5895\n","\n","--- Running Evaluation for Epoch 1 lr =1e-05 wd 1e-06 ---\n","Computed Threshold: 0.0062\n","Val: Accuracy: 0.9913  \n","Test : Accuracy: 0.8894 Recall : 0.8443 FDR: 0.2954  F1-score: 0.7681  \n","Train : time 194.2053 Epoch 1\n","Generator Loss: 4.6856 Discriminator Loss: 14.4423\n","\n","--- Running Evaluation for Epoch 2 lr =1e-05 wd 1e-06 ---\n","Computed Threshold: 0.0052\n","Val: Accuracy: 0.9940  \n","Test : Accuracy: 0.8894 Recall : 0.8443 FDR: 0.2954  F1-score: 0.7681  \n"]}],"execution_count":28},{"id":"54635226","cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\naae_model = AdversarialAutoencoder().to(device)\ndevice = next(aae_model.parameters()).device\nprint(f\"Model device (Method 1): {device}\")\nprint(next(aae_model.decoder.parameters()).device)\nprint(aae_model._get_name())\ntrain_eval(aae_model,AE_train_dataloader,AE_val_dataloader,AE_test_dataloader)\n","metadata":{},"outputs":[],"execution_count":null},{"id":"c3698c58","cell_type":"code","source":"# GRU-VAE\nclass GRUVAE(nn.Module):\n    \"\"\"\n    Gated Recurrent Unit : num_layers=2, hidden_size=256, dropout=0.01,window size (seq_len)= 40\n    \"\"\"\n    def __init__(self, input_dim=89, hidden_dim=256, latent_dim=32, num_layers=2, dropout=0.01):\n        super(GRUVAE, self).__init__()\n        self.encoder_gru = nn.GRU(\n            input_size=input_dim,\n            hidden_size=hidden_dim,\n            num_layers=num_layers,\n            dropout=dropout,\n            batch_first=True\n        )\n        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n        self.fc_z_to_hidden = nn.Linear(latent_dim, hidden_dim)\n        self.decoder_gru = nn.GRU(\n            input_size=input_dim,\n            hidden_size=hidden_dim,\n            num_layers=num_layers,\n            dropout=dropout,\n            batch_first=True\n        )\n        self.fc_out = nn.Linear(hidden_dim, input_dim)\n\n    def reparameterize(self, mu, logvar):\n        std = torch.exp(0.5 * logvar)\n        eps = torch.randn_like(std)\n        return mu + eps * std\n\n    def forward(self, x):\n        # x shape: [batch_size, seq_len, input_dim=89]\n        _, hidden = self.encoder_gru(x) \n        h = hidden[-1]  # [batch_size, hidden_dim]\n        mu = self.fc_mu(h)  \n        logvar = self.fc_logvar(h)  \n        z = self.reparameterize(mu, logvar)  # [batch_size, latent_dim]\n        # repeat and feed latent z as input trick\n        h0 = self.fc_z_to_hidden(z).unsqueeze(0).repeat(self.encoder_gru.num_layers, 1, 1)  # [num_layers, batch_size, hidden_dim]\n        # Initialize decoder input with zeros \n        decoder_input = torch.zeros_like(x)\n        output, _ = self.decoder_gru(decoder_input, h0)  # [batch_size, seq_len, hidden_dim]\n        x_recon = self.fc_out(output)  # [batch_size, seq_len, input_dim]\n        return x_recon, mu, logvar\n","metadata":{},"outputs":[],"execution_count":35},{"id":"799e51d8","cell_type":"code","source":"loaded_scalers = load_scalers(\"fitted_scalers\")\nRNN_train_dataset=ModbusFlowStream( \n    shuffle=False,chunk_size=1,batch_size=64,csv_files=val_files[:-3],\n    scalers=loaded_scalers['network-wide']['min_max_scalers'],window_size=30\n)\nRNN_train_dataloadder=DataLoader(RNN_train_dataset,batch_size=1,shuffle=False)\nRNN_test_dataset=ModbusFlowStream( \n    shuffle=False,chunk_size=1,batch_size=64,csv_files=val_files[-3:],\n    scalers=loaded_scalers['network-wide']['min_max_scalers'],window_size=30\n)\nRNN_test_dataset=ModbusFlowStream( \n    shuffle=False,chunk_size=1,batch_size=64,csv_files=test_files,\n    scalers=loaded_scalers['network-wide']['min_max_scalers'],window_size=30\n)\nRNN_test_dataloadder=DataLoader(RNN_test_dataset,batch_size=1,shuffle=False)\n\ndevice=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nGRU_VAE_model = GRUVAE().to(device)\nlr = 0.01\nwd= 1e-4\nshuffle_files =True\nGRU_VAE_optimizer = optim.SGD(GRU_VAE_model.parameters(), lr=lr, weight_decay=wd)\n\n","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Successfully loaded scalers for 'network-wide'\n"]}],"execution_count":39},{"id":"9ee7735e","cell_type":"code","source":"train_eval(GRU_VAE_model,RNN_train_dataloadder,RNN_test_dataloader,RNN_test_dataloader)\n","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","==================  lr=5e-05, wd=1e-05 ==================\n","Train : time 219.29 s Epoch 1\n","Train Loss: 4.8276\n","--- Running Evaluation for Epoch 1 lr =5e-05 wd 1e-05 ---\n"]},{"name":"stderr","output_type":"stream","text":["/home/hamid_rd3/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([9, 30, 89])) that is different to the input size (torch.Size([64, 30, 89])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"ename":"RuntimeError","evalue":"The size of tensor a (64) must match the size of tensor b (9) at non-singleton dimension 0","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGRU_VAE_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43mRNN_train_dataloadder\u001b[49m\u001b[43m,\u001b[49m\u001b[43mRNN_test_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43mRNN_test_dataset\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[41], line 79\u001b[0m, in \u001b[0;36mtrain_eval\u001b[0;34m(model, train_dataloader, val_dataloader, test_dataloader, learning_rates, weight_decays, shuffle_files, num_epochs)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model\u001b[38;5;241m.\u001b[39m_get_name()\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdversarialAutoencoder\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     78\u001b[0m     _,recon\u001b[38;5;241m=\u001b[39m model(sequences)\n\u001b[0;32m---> 79\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m \u001b[43meval_criterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msequences\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val_loss\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     81\u001b[0m     intrusion_scores \u001b[38;5;241m=\u001b[39m val_loss\n","File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n","File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/torch/nn/modules/loss.py:610\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 610\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/torch/nn/functional.py:3884\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction, weight)\u001b[0m\n\u001b[1;32m   3881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3882\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3884\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3887\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m weight\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize():\n","File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/torch/functional.py:77\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tensors):\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[38;5;241m*\u001b[39mtensors)\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (64) must match the size of tensor b (9) at non-singleton dimension 0"]}],"execution_count":42},{"id":"97bb352b","cell_type":"code","source":"for epoch in range(3):\n    time_1 = time.time()\n    train_loss = 0\n    GRU_VAE_model.train()\n    if shuffle_files:\n        sys_rand = SystemRandom()\n        sys_rand.shuffle(RNN_dataset.file_order_indices)\n    for sequences, _ in RNN_dataloadder:\n        sequences = sequences.squeeze().to(device)\n        GRU_VAE_optimizer.zero_grad()\n        recon, mu, logvar = GRU_VAE_model(sequences)\n        loss = vae_loss_function(recon, sequences, mu, logvar)/sequences.size(0)\n        loss.backward()\n        GRU_VAE_optimizer.step()\n        train_loss += loss.item()\n    print(\"time\",time.time()-time_1,f\"Epoch {epoch}, Train Loss: {train_loss/len(RNN_dataloadder)}\")\n","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["time 103.30588173866272 Epoch 0, Train Loss: 127700652.60516566\n","time 95.60702395439148 Epoch 1, Train Loss: 70232281.69612122\n","time 94.19640827178955 Epoch 2, Train Loss: 3457994.1813964844\n"]}],"execution_count":6}]}