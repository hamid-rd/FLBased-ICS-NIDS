{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d32826f1-1369-4eb5-a21b-0e6e548cded3",
   "metadata": {},
   "source": [
    "### Download and make the dataset ready in Kaggle \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26c2ad5c-f43a-4b40-a647-ecc58c71ff16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T16:17:38.693282Z",
     "iopub.status.busy": "2025-07-13T16:17:38.692671Z",
     "iopub.status.idle": "2025-07-13T16:20:31.990912Z",
     "shell.execute_reply": "2025-07-13T16:20:31.990108Z",
     "shell.execute_reply.started": "2025-07-13T16:17:38.693248Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# ## uncomment if The zip file of the dataset isn't downloaded,extraced \n",
    "# !pip install gdown\n",
    "# Copy the link. The file ID is the long string of characters between d/ and /view.\n",
    "#For example, in the URL https://drive.google.com/file/d/1aBcDeFgHiJkLmNoPqRsTuVwXyZ/view?usp=sharing, \n",
    "#the file ID is 1aBcDeFgHiJkLmNoPqRsTuVwXyZ\n",
    "# !mkdir /kaggle/tmp\n",
    "# !gdown  1pzXpA5Cz0DJmjRsLxlqRNnJq-kOUvojb -O /kaggle/tmp/Labeled_CICMODBUS2023.zip\n",
    "# !unzip /kaggle/tmp/Labeled_CICMODBUS2023.zip -d /kaggle/working/\n",
    "\n",
    "# # ## uncomment if the python modules (modbus.py,utils.py ,...) not cloned  and added to the path \n",
    "\n",
    "# !git clone https://github.com/hamid-rd/FLBased-ICS-NIDS.git\n",
    "# import sys\n",
    "# # Add the repository folder to the Python path\n",
    "# repo_path = '/kaggle/working/FLBased-ICS-NIDS'\n",
    "# repo_input_path = '/kaggle/input/training/FLBased-ICS-NIDS'\n",
    "# dataset_path = '/kaggle/input/training/'\n",
    "\n",
    "# for path in {repo_path,repo_input_path,dataset_path}:\n",
    "#     if path not in sys.path:\n",
    "#         sys.path.append(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "601bb537-782e-4266-b619-48cdad4fe6a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T16:25:34.078617Z",
     "iopub.status.busy": "2025-07-13T16:25:34.077721Z",
     "iopub.status.idle": "2025-07-13T16:25:34.430103Z",
     "shell.execute_reply": "2025-07-13T16:25:34.429493Z",
     "shell.execute_reply.started": "2025-07-13T16:25:34.078584Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The CIC Modbus Dataset contains network (pcap) captures and attack logs from a simulated substation network.\n",
      "                The dataset is categorized into two groups: an attack dataset and a benign dataset\n",
      "                The attack dataset includes network traffic captures that simulate various types of Modbus protocol attacks in a substation environment.\n",
      "                The attacks are reconnaissance, query flooding, loading payloads, delay response, modify length parameters, false data injection, stacking Modbus frames, brute force write and baseline replay.\n",
      "                These attacks are based of some techniques in the MITRE ICS ATT&CK framework.\n",
      "                On the other hand, the benign dataset consists of normal network traffic captures representing legitimate Modbus communication within the substation network.\n",
      "                The purpose of this dataset is to facilitate research, analysis, and development of intrusion detection systems, anomaly detection algorithms and other security mechanisms for substation networks using the Modbus protocol.\n",
      "                https://www.unb.ca/cic/datasets/modbus-2023.html\n",
      "                In my custom PyTorch Dataset class,\n",
      "                I utilize the Enhanced CICflowMeter and the Attack logs correlation to extract and label sequential data flows,\n",
      "                preparing them for batch processing with the DataLoader, which is crucial for AI model training.\n",
      "                https://github.com/hamid-rd/FLBased-ICS-NIDS/tree/main\n",
      "\n",
      "                \n",
      "csv files  in the dataset directory founded with the filter:  ready\n",
      "{\n",
      "    \"total_dataset_num\": 170,\n",
      "    \"benign_dataset_num\": 62,\n",
      "    \"attack_dataset_num\": {\n",
      "        \"total_num\": 108,\n",
      "        \"external_num\": 8,\n",
      "        \"compromised-ied_num\": 43,\n",
      "        \"compromised-scada_num\": 57\n",
      "    },\n",
      "    \"attack_logs_num\": {\n",
      "        \"total_num\": 0,\n",
      "        \"external_num\": [],\n",
      "        \"compromised-ied_num\": 0,\n",
      "        \"compromised-scada_num\": 0\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# To test if every thing is okay (modbus.py class and correct number of founded csv files )\n",
    "from modbus import ModbusDataset,ModbusFlowStream\n",
    "\n",
    "# dataset_directory = \"/kaggle/working/ModbusDataset\" \n",
    "# dataset_directory = \"/kaggle/input/training/ModbusDataset\" \n",
    "dataset_directory = \"dataset\" \n",
    "\n",
    "modbus = ModbusDataset(dataset_directory,\"ready\")\n",
    "modbus.summary_print()\n",
    "\n",
    "# Don't forget to save version in kaggle (to save outputs written on the disk (/kaggle/working/))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d238262",
   "metadata": {},
   "source": [
    "### Unsupervised Autoencoder training  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2c01e06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T16:25:38.158958Z",
     "iopub.status.busy": "2025-07-13T16:25:38.158509Z",
     "iopub.status.idle": "2025-07-13T16:25:38.167563Z",
     "shell.execute_reply": "2025-07-13T16:25:38.166807Z",
     "shell.execute_reply.started": "2025-07-13T16:25:38.158938Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np # For standard deviation calculation\n",
    "from modbus import ModbusDataset,ModbusFlowStream\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix,recall_score\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "from utils import load_scalers\n",
    "import random\n",
    "from random import SystemRandom\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import torch.nn.init as init\n",
    "import flwr as fl\n",
    "import ray\n",
    "from collections import Counter\n",
    "from flwr.common import ndarrays_to_parameters\n",
    "\n",
    "def compute_threshold(mse_values,k=1):\n",
    "\n",
    "    \"\"\"\n",
    "    K-SIGMA\n",
    "    Computes the anomaly detection threshold (for marking sample as Intrusion if the IS was greater )\n",
    "    based on the mean and standard deviation of Mean Squared Error (MSE) values.\n",
    "    Formula: thr = mean(MSE) + std(MSE)\n",
    "    Args:\n",
    "    mse_values (torch.Tensor or list/np.array): A tensor or list of MSE values\n",
    "\n",
    "                            obtained from the validation set.\n",
    "    Returns:\n",
    "    float: The calculated threshold.\n",
    "    float: The calculated std.\n",
    "\n",
    "    \"\"\"\n",
    "    if not isinstance(mse_values, torch.Tensor):\n",
    "        mse_values = torch.tensor(mse_values, dtype=torch.float32)\n",
    "    if mse_values.numel() == 0:\n",
    "        return 0.0\n",
    "    mean_mse = torch.mean(mse_values)\n",
    "    std_mse = torch.std(mse_values)\n",
    "    print(\"-----------mse_loss mean : \",f\"{mean_mse.item():.4f}\",\"std:\",f\"{std_mse.item():.4f}\")\n",
    "    threshold = mean_mse + k*std_mse\n",
    "    return threshold.item(),std_mse.item()\n",
    "\n",
    "def vae_loss_function(recon_x, x, mu, logvar,beta =1):\n",
    "    \"\"\"\n",
    "    VAE loss function.\n",
    "    \"\"\"\n",
    "    BCE = nn.functional.mse_loss(recon_x, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return (BCE + beta*KLD)\n",
    "\n",
    "def _init_weights( module):\n",
    "    ## for one layer apply Xavier Initialization\n",
    "    if isinstance(module, nn.Linear):\n",
    "        init.xavier_normal_(module.weight)\n",
    "        if module.bias is not None:\n",
    "            init.zeros_(module.bias)\n",
    "    return module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9478520",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T16:25:42.807302Z",
     "iopub.status.busy": "2025-07-13T16:25:42.807033Z",
     "iopub.status.idle": "2025-07-13T16:25:42.941019Z",
     "shell.execute_reply": "2025-07-13T16:25:42.940221Z",
     "shell.execute_reply.started": "2025-07-13T16:25:42.807283Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The CIC Modbus Dataset contains network (pcap) captures and attack logs from a simulated substation network.\n",
      "                The dataset is categorized into two groups: an attack dataset and a benign dataset\n",
      "                The attack dataset includes network traffic captures that simulate various types of Modbus protocol attacks in a substation environment.\n",
      "                The attacks are reconnaissance, query flooding, loading payloads, delay response, modify length parameters, false data injection, stacking Modbus frames, brute force write and baseline replay.\n",
      "                These attacks are based of some techniques in the MITRE ICS ATT&CK framework.\n",
      "                On the other hand, the benign dataset consists of normal network traffic captures representing legitimate Modbus communication within the substation network.\n",
      "                The purpose of this dataset is to facilitate research, analysis, and development of intrusion detection systems, anomaly detection algorithms and other security mechanisms for substation networks using the Modbus protocol.\n",
      "                https://www.unb.ca/cic/datasets/modbus-2023.html\n",
      "                In my custom PyTorch Dataset class,\n",
      "                I utilize the Enhanced CICflowMeter and the Attack logs correlation to extract and label sequential data flows,\n",
      "                preparing them for batch processing with the DataLoader, which is crucial for AI model training.\n",
      "                https://github.com/hamid-rd/FLBased-ICS-NIDS/tree/main\n",
      "\n",
      "                \n",
      "csv files  in the dataset directory founded with the filter:  ready\n",
      "{\n",
      "    \"total_dataset_num\": 170,\n",
      "    \"benign_dataset_num\": 62,\n",
      "    \"attack_dataset_num\": {\n",
      "        \"total_num\": 108,\n",
      "        \"external_num\": 8,\n",
      "        \"compromised-ied_num\": 43,\n",
      "        \"compromised-scada_num\": 57\n",
      "    },\n",
      "    \"attack_logs_num\": {\n",
      "        \"total_num\": 0,\n",
      "        \"external_num\": [],\n",
      "        \"compromised-ied_num\": 0,\n",
      "        \"compromised-scada_num\": 0\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# dataset_directory = \"/kaggle/input/training/ModbusDataset\" # change this to the folder contain benign and attack subdirs\n",
    "dataset_directory = \"dataset\" \n",
    "modbus = ModbusDataset(dataset_directory,\"ready\")\n",
    "modbus.summary_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dede4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# AutoEncoder (AE)\n",
    "class AE(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder: (89-64-32)\n",
    "    Decoder: (32-64-89)\n",
    "    \"\"\"\n",
    "    def __init__(self,input_dim=89):\n",
    "        super(AE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        x_recon = self.decoder(z)\n",
    "        return x_recon\n",
    "\n",
    "\n",
    "# Variational AutoEncoder (VAE)\n",
    "class VAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder: (89-64-64-32 for mu and log_var)\n",
    "    Decoder: (32-64-64-89)\n",
    "    return x_recon, mu, logvar\n",
    "    \"\"\"\n",
    "    def __init__(self,input_dim=89):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(64, 32)\n",
    "        self.fc_logvar = nn.Linear(64, 32)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, input_dim),\n",
    "            nn.Sigmoid()\n",
    "                    )\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu = self.fc_mu(h)\n",
    "        logvar = self.fc_logvar(h)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_recon = self.decoder(z)\n",
    "        return x_recon, mu, logvar\n",
    "\n",
    "    \n",
    "class AAE_Encoder(nn.Module):\n",
    "    def __init__(self,input_dim=76):\n",
    "        \"\"\"\n",
    "        Encoder(Generator):(89-16-4-2)\n",
    "        \"\"\"\n",
    "        super(AAE_Encoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 16),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(16, 4),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(4, 2))\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "class AAE_Decoder(nn.Module):\n",
    "    def __init__(self,input_dim=76):\n",
    "        super(AAE_Decoder, self).__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2, 4),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(4, 16),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(16, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.decoder(x)\n",
    "class AAE_Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AAE_Discriminator, self).__init__()\n",
    "        # corrected to 2-16-4-1\n",
    "        self.discriminator = nn.Sequential(\n",
    "            nn.Linear(2, 16),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(16, 4),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(4, 1), \n",
    "            nn.Sigmoid()\n",
    "        )    \n",
    "    def forward(self, x):\n",
    "        return self.discriminator(x)\n",
    " \n",
    "class AdversarialAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AdversarialAutoencoder, self).__init__()\n",
    "        self.encoder = AAE_Encoder()\n",
    "        self.decoder = AAE_Decoder()\n",
    "        self.discriminator = AAE_Discriminator()\n",
    "    def forward(self, x):\n",
    "        fake_z = self.encoder(x)\n",
    "        x_recon = self.decoder(fake_z)\n",
    "        return fake_z,x_recon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436b79f1",
   "metadata": {},
   "source": [
    "### Centralized part \n",
    "\n",
    "##### You can go from here right to the FL part\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2d2e0ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T08:02:58.408647Z",
     "iopub.status.busy": "2025-07-13T08:02:58.407931Z",
     "iopub.status.idle": "2025-07-13T08:02:58.430831Z",
     "shell.execute_reply": "2025-07-13T08:02:58.430062Z",
     "shell.execute_reply.started": "2025-07-13T08:02:58.408625Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_eval(model,train_dataloader,val_dataloader,test_dataloader,learning_rates= [5e-6,1e-7,5e-5,1e-5,1e-6],\n",
    "               weight_decays=[1e-5,1e-4,1e-7],shuffle_files=True,num_epochs=20,eval_epoch=4,criterion_method=\"mse\", k_range=[1,3],train_model=True):\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model=model.to(device)\n",
    "    if criterion_method==\"bce\":\n",
    "        criterion = nn.BCELoss(reduction='sum').to(device)\n",
    "        eval_criterion = nn.BCELoss(reduction='none').to(device)\n",
    "    else: #mse\n",
    "        criterion = nn.MSELoss(reduction='sum').to(device)\n",
    "        eval_criterion = nn.MSELoss(reduction='none').to(device)\n",
    "    best_f1=0 #to save best version of the model during test\n",
    "    best_recall=0 #to save best version of the model during test\n",
    "\n",
    "    for lr, wd in itertools.product(learning_rates, weight_decays):\n",
    "        if model._get_name()==\"AdversarialAutoencoder\":\n",
    "            adversarial_criterion= nn.BCELoss(reduction=\"sum\")\n",
    "            optimizer_D = optim.SGD(model.discriminator.parameters(), lr=lr, weight_decay=wd)\n",
    "            optimizer_G =  optim.SGD(list(model.encoder.parameters()) + list(model.decoder.parameters()), lr=lr, weight_decay=wd)\n",
    "        else:\n",
    "            AE_optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "            ### new code\n",
    "            # AE_optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "        print(f\"\\n==================  lr={lr}, wd={wd} ==================\")\n",
    "        if train_model==True:\n",
    "            model.apply(_init_weights)\n",
    "        for epoch in range(num_epochs):\n",
    "            if train_model==True:\n",
    "                time_1 = time.time()\n",
    "                model.train()\n",
    "                train_loss = 0\n",
    "                ## for AAE\n",
    "                Discriminator_loss = 0\n",
    "                if shuffle_files:\n",
    "                    sys_rand = SystemRandom()\n",
    "                    sys_rand.shuffle(train_dataloader.dataset.csv_files)\n",
    "                for sequences, labels in train_dataloader:\n",
    "                    sequences=sequences.squeeze().to(device)\n",
    "                    if labels.sum()!=0:\n",
    "                        continue\n",
    "                    if model._get_name()==\"AdversarialAutoencoder\":\n",
    "                        target_ones= torch.ones(sequences.size(0), 1,device=device,dtype=torch.float)\n",
    "                        target_zeros= torch.zeros(sequences.size(0), 1,device=device,dtype=torch.float)\n",
    "                        random_latent = torch.randn(sequences.size(0), 2, device=device)\n",
    "                        optimizer_G.zero_grad()\n",
    "                        fake_z,decoded_seq = model(sequences)\n",
    "                        G_loss = 0.001*adversarial_criterion(model.discriminator(fake_z),target_ones ) + 0.999*criterion(decoded_seq, sequences)\n",
    "                        G_loss.backward()\n",
    "                        optimizer_G.step()\n",
    "                        # 2) discriminator loss\n",
    "                        optimizer_D.zero_grad()\n",
    "                        real_loss = adversarial_criterion(model.discriminator(random_latent), target_ones)\n",
    "                        fake_loss = adversarial_criterion(model.discriminator(fake_z.detach()),  target_zeros)\n",
    "                        D_loss = 0.5*(real_loss + fake_loss)\n",
    "                        D_loss.backward()\n",
    "                        optimizer_D.step()\n",
    "                        train_loss+=G_loss.item()\n",
    "                        Discriminator_loss+=D_loss.item()   \n",
    "                    else:\n",
    "                        AE_optimizer.zero_grad()\n",
    "                        if model._get_name()==\"AE\":\n",
    "                            recon = model(sequences)\n",
    "                            loss = criterion(recon, sequences) / sequences.size(0)\n",
    "                        elif model._get_name()==\"VAE\" or model._get_name()==\"GRUVAE\":\n",
    "                            recon, mu, logvar = model(sequences)\n",
    "                            loss = vae_loss_function(recon, sequences, mu, logvar) /sequences.size(0)\n",
    "                        loss.backward()\n",
    "                        AE_optimizer.step()\n",
    "                        train_loss += loss.item()\n",
    "                print(f\"Train : time {(time.time()-time_1):.2f} s\",\n",
    "                f\"Epoch {epoch+1}\")\n",
    "                if model._get_name()==\"AdversarialAutoencoder\":\n",
    "                    print(f\"Generator Loss: {train_loss / len(train_dataloader):.4f}\",\n",
    "                        f\"Discriminator Loss: {Discriminator_loss / len(train_dataloader):.4f}\")\n",
    "                else:\n",
    "                    print(f\"Train Loss: {train_loss / len(train_dataloader):.4f}\")\n",
    "            # Evaluate part\n",
    "            if (epoch + 1) % eval_epoch == 0:\n",
    "                model.eval() \n",
    "                all_val_losses = []\n",
    "                all_val_labels = []\n",
    "                print(f\"--- Running Evaluation for Epoch {epoch+1} lr ={lr} wd {wd} ---\")\n",
    "                with torch.no_grad():\n",
    "                    for sequences, labels in val_dataloader:\n",
    "                        sequences = sequences.squeeze().to(device) \n",
    "                        if labels.sum()!=0:\n",
    "                            continue\n",
    "                        if criterion_method==\"bce\":\n",
    "                            ## may test features be greater than 1 after scaling \n",
    "                            sequences=torch.clamp(sequences, min=0.0, max=1.0)      \n",
    "                        if model._get_name()==\"AE\":\n",
    "                            recon = model(sequences)\n",
    "                        elif model._get_name()==\"VAE\" or model._get_name()==\"GRUVAE\" :\n",
    "                            recon, _, _ = model(sequences)\n",
    "                        elif model._get_name()==\"AdversarialAutoencoder\":\n",
    "                            _,recon= model(sequences)\n",
    "                        val_loss = eval_criterion(recon, sequences)\n",
    "                        if val_loss.dim() > 1:\n",
    "                            val_loss = val_loss\n",
    "                        else:\n",
    "                            val_loss = val_loss.unsqueeze(dim=0)\n",
    "                            labels = labels.unsqueeze(dim=0)\n",
    "                        if val_loss.dim()==3:\n",
    "                            ##GRU : mean of window\n",
    "                            val_loss = val_loss.mean(dim=1)\n",
    "                        val_loss = val_loss.sum(dim=1)\n",
    "                        all_val_losses.extend(val_loss.cpu().numpy())\n",
    "                        all_val_labels.extend(labels.flatten().cpu().numpy())     \n",
    "                threshold_1,std_mse = compute_threshold(all_val_losses,k=0)\n",
    "\n",
    "                all_val_losses = np.array(all_val_losses).squeeze()  \n",
    "                all_val_labels = np.array(all_val_labels).squeeze()  \n",
    "                # If intrusion score > threshold, predict 1 (intrusion), else 0 (benign)\n",
    "                # For FDR, get True Positives (TP) and False Positives (FP)\n",
    "                \n",
    "                predictions = (all_val_losses > threshold_1).astype(int)\n",
    "\n",
    "                accuracy = accuracy_score(all_val_labels, predictions)\n",
    "                print(f\"Val: Accuracy: {accuracy:.4f}  \")\n",
    "                model.eval() \n",
    "                all_test_losses = []\n",
    "                all_test_labels = []\n",
    "                with torch.no_grad():\n",
    "                    for sequences, labels in test_dataloader:\n",
    "                        sequences = sequences.squeeze().to(device)\n",
    "                        labels = labels.squeeze().to(device)\n",
    "                        if criterion_method==\"bce\":\n",
    "                            ## may test features be greater than 1 after scaling \n",
    "                            sequences=torch.clamp(sequences, min=0.0, max=1.0)\n",
    "                        if model._get_name()==\"AE\":\n",
    "                            recon = model(sequences)\n",
    "                        elif model._get_name()==\"VAE\"  or model._get_name()==\"GRUVAE\":\n",
    "                            recon, mu, logvar = model(sequences)\n",
    "                        elif model._get_name()==\"AdversarialAutoencoder\":\n",
    "                            _,recon= model(sequences)\n",
    "\n",
    "                        intrusion_scores = eval_criterion(recon, sequences)\n",
    "                        if intrusion_scores.dim() > 1:\n",
    "                            intrusion_scores = intrusion_scores\n",
    "                        else:\n",
    "                            intrusion_scores = intrusion_scores.unsqueeze(dim=0)\n",
    "                            labels = labels.unsqueeze(dim=0)\n",
    "                        if intrusion_scores.dim()==3:\n",
    "                            ##GRU : mean of window\n",
    "                            intrusion_scores = intrusion_scores.mean(dim=1)\n",
    "                        intrusion_scores = intrusion_scores.sum(dim=1)\n",
    "                        all_test_losses.extend(intrusion_scores.cpu().numpy())\n",
    "                        all_test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "                all_test_losses = np.array(all_test_losses)\n",
    "                all_test_labels = np.array(all_test_labels)\n",
    "                temp_best_recall =best_recall\n",
    "                temp_best_f1 =best_f1\n",
    "\n",
    "                for k in k_range:\n",
    "                    threshold=threshold_1+k*std_mse\n",
    "                    print(f\" K: {k} K-SIGMA Threshold : ---thr {threshold:.4}\")\n",
    "                    predictions = (all_test_losses > threshold).astype(int)\n",
    "                    binary_test_labels = (all_test_labels != 0).astype(int)\n",
    "\n",
    "                    # Find the indices where the prediction was incorrect\n",
    "                    misclassified_indices = np.where(binary_test_labels != predictions)[0]\n",
    "\n",
    "                    # Get the original labels for those misclassified instances\n",
    "                    misclassified_original_labels = all_test_labels[misclassified_indices]\n",
    "\n",
    "                    # To get a summary count of which labels were misclassified\n",
    "                    print(\"Counts of : original binary labels\",Counter(binary_test_labels),\"predicted binary labels\",Counter(predictions))\n",
    "                    print(f\"Counts of  original  labels: {dict(sorted(Counter(all_test_labels).items()))}\")\n",
    "                    print(f\"Counts of misclassified original labels: {dict(sorted(Counter(misclassified_original_labels).items()))}\")\n",
    "                    accuracy = accuracy_score(binary_test_labels, predictions)\n",
    "                    f1 = f1_score(binary_test_labels, predictions, zero_division=0)\n",
    "                    recall = recall_score(binary_test_labels, predictions,zero_division=0)\n",
    "                    _, fp, _, tp = confusion_matrix(binary_test_labels, predictions, labels=[0, 1]).ravel()\n",
    "                    # FDR = FP / (FP + TP) \n",
    "                    if (fp + tp) == 0:\n",
    "                        fdr = 0.0 \n",
    "                    else:\n",
    "                        fdr = fp / (fp + tp)\n",
    "                    print(f\"Test : Accuracy: {accuracy:.4f} Recall : {recall:.4f} FDR: {fdr:.4f}  F1-score: {f1:.4f}  \")\n",
    "                    !mkdir best_models -p\n",
    "                    if f1>best_f1 :\n",
    "                        best_f1=f1\n",
    "                    if recall>best_recall:\n",
    "                        best_recall=recall\n",
    "                if (best_recall>temp_best_recall or best_f1 > temp_best_f1):\n",
    "                    if train_model==True:\n",
    "                        save_path =\"best_models/\"+model._get_name()+\"_f1_\"+f\"{best_f1:.2f}\" +\"_recall_\"+f\"{best_recall:.2f}\" +\"_.pth\"\n",
    "                        torch.save(model.state_dict(),save_path)\n",
    "                        print(\"model\",model._get_name(),\"is saved in\" ,save_path )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfeeeaf",
   "metadata": {},
   "source": [
    "#### Centralized : external scenario -> ied1a node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db440aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ied1b comp ied attack ->\n",
      " test:  1 ['dataset/ModbusDataset/attack/external/ied1a/ied1a-network-capture/ready/veth4edc015-0-labeled.csv']\n",
      "----------- Network-wide number of csv files -> \n",
      " ----------- train : 16 ['dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-16-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-31-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-18-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-23-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-19-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-27-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-20-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-24-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-29-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-14-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-21-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-30-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-32-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-26-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-15-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-28-labeled.csv'] \n",
      " -------- valid: 3 ['dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-22-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-25-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-17-labeled.csv']\n"
     ]
    }
   ],
   "source": [
    "# train_files=[col for col in modbus.dataset[\"benign_dataset_dir\"] if col.find(\"network-wide\")!=-1]\n",
    "train_files=[col for col in modbus.dataset[\"benign_dataset_dir\"] if col.find(\"network-wide\")!=-1][:]\n",
    "test_files=[col for col in modbus.dataset[\"attack_dataset_dir\"][\"external\"] if col.find(\"ied1a\")!=-1]\n",
    "random.seed(42)\n",
    "random.shuffle(train_files)\n",
    "random.shuffle(test_files)\n",
    "val_files = train_files[-3:]\n",
    "train_files = train_files[:-3]\n",
    "print(\"ied1b comp ied attack ->\\n test: \",len(test_files),test_files)\n",
    "print(\"----------- Network-wide number of csv files -> \\n ----------- train :\",len(train_files),train_files,\"\\n -------- valid:\",len(val_files),val_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb2505cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded scalers for 'network-wide'\n"
     ]
    }
   ],
   "source": [
    "### Try The Copy-on-Write (CoW) technique, share the same single copy of the dataset in memory with multiple forked workers from the main process\n",
    "# Ensure to have enough memory for saving large tensors in the ram \n",
    "###### else use chunk_size =1 and read the files iteratively\n",
    "\n",
    "use_cow=True\n",
    "window_size=1\n",
    "loaded_scalers=load_scalers('fitted_scalers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eac4698b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T08:12:06.828444Z",
     "iopub.status.busy": "2025-07-13T08:12:06.827779Z",
     "iopub.status.idle": "2025-07-13T08:12:07.034947Z",
     "shell.execute_reply": "2025-07-13T08:12:07.034115Z",
     "shell.execute_reply.started": "2025-07-13T08:12:06.828415Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cow Processing datasets...\n",
      "  - Creating 'train' dataset...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  - Creating \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m dataset...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# 1. Create the primary ModbusFlowStream dataset\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m datasets[name] \u001b[38;5;241m=\u001b[39m \u001b[43mModbusFlowStream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlarge_chunk_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcsv_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfiles\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscalers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloaded_scalers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnetwork-wide\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmin_max_scalers\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow_size\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# 2. Call __getitem__(0) once to load the entire dataset chunk into memory\u001b[39;00m\n\u001b[1;32m     47\u001b[0m datasets[name]\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/labeling/FLBased-ICS-NIDS-main/modbus.py:167\u001b[0m, in \u001b[0;36mModbusFlowStream.__init__\u001b[0;34m(self, csv_files, chunk_size, batch_size, scalers, shuffle, unuseful_features, window_size)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprotocol_encoder \u001b[38;5;241m=\u001b[39m OneHotEncoder(handle_unknown\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m, sparse_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_encoders()\n\u001b[0;32m--> 167\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_calculate_total_rows\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/labeling/FLBased-ICS-NIDS-main/modbus.py:299\u001b[0m, in \u001b[0;36mModbusFlowStream._calculate_total_rows\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcsv_files,\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcsv_files)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot convertable to python list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 299\u001b[0m total_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mceil\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcount_rows\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwindow_size\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv_files\u001b[49m\u001b[43m)\u001b[49m            \n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_rows\n",
      "File \u001b[0;32m~/labeling/FLBased-ICS-NIDS-main/modbus.py:299\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcsv_files,\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcsv_files)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot convertable to python list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 299\u001b[0m total_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mceil((\u001b[43mcount_rows\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_size\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size)) \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcsv_files)            \n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_rows\n",
      "File \u001b[0;32m~/labeling/FLBased-ICS-NIDS-main/modbus.py:292\u001b[0m, in \u001b[0;36mModbusFlowStream._calculate_total_rows.<locals>.count_rows\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcount_rows\u001b[39m(file_path):\n\u001b[0;32m--> 292\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-l\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(result\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39msplit()[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 505\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    507\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:1154\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1151\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1154\u001b[0m     stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_communicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:2021\u001b[0m, in \u001b[0;36mPopen._communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   2014\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timeout(endtime, orig_timeout,\n\u001b[1;32m   2015\u001b[0m                         stdout, stderr,\n\u001b[1;32m   2016\u001b[0m                         skip_check_and_raise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   2017\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(  \u001b[38;5;66;03m# Impossible :)\u001b[39;00m\n\u001b[1;32m   2018\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_check_timeout(..., skip_check_and_raise=True) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2019\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfailed to raise TimeoutExpired.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 2021\u001b[0m ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2022\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timeout(endtime, orig_timeout, stdout, stderr)\n\u001b[1;32m   2024\u001b[0m \u001b[38;5;66;03m# XXX Rewrite these to use non-blocking I/O on the file\u001b[39;00m\n\u001b[1;32m   2025\u001b[0m \u001b[38;5;66;03m# objects; they are no longer using C stdio!\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# This cell Initializes and returns train, validation, and test dataloaders.\n",
    "\n",
    "# This function supports two strategies for data loading:\n",
    "# 1. Copy-on-Write (use_cow=True): Loads the entire dataset into RAM. This is fast\n",
    "#     but memory-intensive. It allows multiple worker processes to share the same\n",
    "#     dataset copy in memory, which is efficient for multiprocessing.\n",
    "# 2. Iterative (use_cow=False): Reads data from files in small chunks. This is\n",
    "#     slower but uses significantly less memory, suitable for very large datasets\n",
    "#     that don't fit in RAM.\n",
    "\n",
    "#     train_files (list): List of file paths for the training dataset.\n",
    "#     val_files (list): List of file paths for the validation dataset.\n",
    "#     test_files (list): List of file paths for the test dataset.\n",
    "#     window_size (int): The size of the sliding window for sequence data.\n",
    "#     use_cow (bool, optional): If True, uses the Copy-on-Write strategy. \n",
    "#                                 Defaults to True.\n",
    "\n",
    "#      return        (train_dataloader, val_dataloader, test_dataloader)\n",
    "\n",
    "if use_cow==True:\n",
    "    large_chunk_size = modbus.dataset[\"metadata\"][\"founded_files_num\"][\"total_dataset_num\"]\n",
    "\n",
    "    dataset_configs = {\n",
    "        \"train\": {\"files\": train_files},\n",
    "        \"val\": {\"files\": val_files},\n",
    "        \"test\": {\"files\": test_files},\n",
    "    }\n",
    "    datasets = {}\n",
    "    ae_datasets = {}\n",
    "\n",
    "    print(\"Cow Processing datasets...\")\n",
    "\n",
    "    for name, config in dataset_configs.items():\n",
    "        print(f\"  - Creating '{name}' dataset...\")\n",
    "        \n",
    "        # 1. Create the primary ModbusFlowStream dataset\n",
    "        datasets[name] = ModbusFlowStream(\n",
    "            shuffle=False,\n",
    "            chunk_size=large_chunk_size,\n",
    "            batch_size=1,\n",
    "            csv_files=config[\"files\"],\n",
    "            scalers=loaded_scalers['network-wide']['min_max_scalers'],\n",
    "            window_size=window_size\n",
    "        )\n",
    "        \n",
    "        # 2. Call __getitem__(0) once to load the entire dataset chunk into memory\n",
    "        datasets[name].__getitem__(0)\n",
    "        \n",
    "        # used for specific AE training/evaluation without re-reading files.\n",
    "        ae_datasets[name] = ModbusFlowStream(\n",
    "            shuffle=False,  # AE data is typically processed in order\n",
    "            chunk_size=large_chunk_size,\n",
    "            batch_size=1,\n",
    "            csv_files=[],  # No CSV files needed as we copy the data directly\n",
    "            scalers=None,   # Data is already scaled from the original dataset\n",
    "            window_size=window_size\n",
    "        )\n",
    "        \n",
    "        # 4. Manually copy the loaded data and properties to the AE dataset\n",
    "\n",
    "        ae_datasets[name].current_chunk_data =  datasets[name].current_chunk_data\n",
    "        ae_datasets[name].current_len_chunk_data =  datasets[name].current_len_chunk_data\n",
    "        ae_datasets[name].current_chunk_labels =  datasets[name].current_chunk_labels\n",
    "        ae_datasets[name].total_batches =  datasets[name].total_batches\n",
    "        \n",
    "        print(f\"  - Finished '{name}' dataset.\")\n",
    "    train_dataloader=DataLoader(ae_datasets['train'],batch_size=64,shuffle=True,num_workers=4,persistent_workers=True,prefetch_factor=2,pin_memory=True)\n",
    "    val_dataloader=DataLoader(ae_datasets['val'],batch_size=64,shuffle=False,num_workers=4,persistent_workers=True,prefetch_factor=2,pin_memory=True)\n",
    "    test_dataloader=DataLoader(ae_datasets['test'],batch_size=64,shuffle=False,num_workers=4,persistent_workers=True,prefetch_factor=2,pin_memory=True)\n",
    "\n",
    "else :\n",
    "    train_dataloader=DataLoader(ModbusFlowStream( \n",
    "        shuffle=True,chunk_size=1,batch_size=64,csv_files=train_files,scalers=loaded_scalers['network-wide']['min_max_scalers'],window_size=window_size\n",
    "    ),  batch_size=1,shuffle=False)\n",
    "    val_dataloader=DataLoader(ModbusFlowStream( \n",
    "        shuffle=False,chunk_size=1,batch_size=64,csv_files=val_files,scalers=loaded_scalers['network-wide']['min_max_scalers'],window_size=window_size\n",
    "    ),batch_size=1,shuffle=False)\n",
    "    test_dataloader=DataLoader(ModbusFlowStream(shuffle=False,chunk_size=1,batch_size=64,csv_files=test_files,scalers=loaded_scalers['network-wide']['min_max_scalers'],window_size=window_size),\n",
    "                               batch_size=1,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69406aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36907 7195 1960\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataloader),len(val_dataloader),len(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e82123e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================  lr=5e-05, wd=0.0001 ==================\n",
      "Train : time 146.63 s Epoch 1\n",
      "Train Loss: 0.2344\n",
      "--- Running Evaluation for Epoch 1 lr =5e-05 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0034 std: 0.0535\n",
      "Val: Accuracy: 0.9253  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.05691\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65735, 0: 59697})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29816, 1: 96}\n",
      "Test : Accuracy: 0.7615 Recall : 0.9973 FDR: 0.4536  F1-score: 0.7060  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.164\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65589, 0: 59843})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29739, 1: 165}\n",
      "Test : Accuracy: 0.7616 Recall : 0.9954 FDR: 0.4534  F1-score: 0.7057  \n",
      "model AE is saved in best_models/AE_f1_0.71_recall_1.00_.pth\n",
      "Train : time 142.75 s Epoch 2\n",
      "Train Loss: 0.0025\n",
      "--- Running Evaluation for Epoch 2 lr =5e-05 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0029 std: 0.0475\n",
      "Val: Accuracy: 0.9012  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.05044\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65763, 0: 59669})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29817, 1: 69}\n",
      "Test : Accuracy: 0.7617 Recall : 0.9981 FDR: 0.4534  F1-score: 0.7064  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.1454\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65578, 0: 59854})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29728, 1: 165}\n",
      "Test : Accuracy: 0.7617 Recall : 0.9954 FDR: 0.4533  F1-score: 0.7058  \n",
      "model AE is saved in best_models/AE_f1_0.71_recall_1.00_.pth\n",
      "Train : time 143.07 s Epoch 3\n",
      "Train Loss: 0.0023\n",
      "--- Running Evaluation for Epoch 3 lr =5e-05 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0028 std: 0.0467\n",
      "Val: Accuracy: 0.8911  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.04951\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65757, 0: 59675})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29810, 1: 68}\n",
      "Test : Accuracy: 0.7618 Recall : 0.9981 FDR: 0.4533  F1-score: 0.7064  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.143\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65583, 0: 59849})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29733, 1: 165}\n",
      "Test : Accuracy: 0.7616 Recall : 0.9954 FDR: 0.4534  F1-score: 0.7057  \n",
      "model AE is saved in best_models/AE_f1_0.71_recall_1.00_.pth\n",
      "Train : time 141.63 s Epoch 4\n",
      "Train Loss: 0.0022\n",
      "--- Running Evaluation for Epoch 4 lr =5e-05 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0027 std: 0.0455\n",
      "Val: Accuracy: 0.8849  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.04819\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65760, 0: 59672})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29812, 1: 67}\n",
      "Test : Accuracy: 0.7618 Recall : 0.9981 FDR: 0.4533  F1-score: 0.7064  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.1391\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65575, 0: 59857})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29725, 1: 165}\n",
      "Test : Accuracy: 0.7617 Recall : 0.9954 FDR: 0.4533  F1-score: 0.7058  \n",
      "model AE is saved in best_models/AE_f1_0.71_recall_1.00_.pth\n",
      "Train : time 144.34 s Epoch 5\n",
      "Train Loss: 0.0022\n",
      "--- Running Evaluation for Epoch 5 lr =5e-05 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0026 std: 0.0449\n",
      "Val: Accuracy: 0.8799  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.04749\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65762, 0: 59670})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29814, 1: 67}\n",
      "Test : Accuracy: 0.7618 Recall : 0.9981 FDR: 0.4534  F1-score: 0.7064  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.1372\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65571, 0: 59861})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29721, 1: 165}\n",
      "Test : Accuracy: 0.7617 Recall : 0.9954 FDR: 0.4533  F1-score: 0.7058  \n",
      "Train : time 144.64 s Epoch 6\n",
      "Train Loss: 0.0021\n",
      "--- Running Evaluation for Epoch 6 lr =5e-05 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0025 std: 0.0432\n",
      "Val: Accuracy: 0.8718  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.04572\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65756, 0: 59676})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29807, 1: 66}\n",
      "Test : Accuracy: 0.7618 Recall : 0.9982 FDR: 0.4533  F1-score: 0.7065  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.1321\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65552, 0: 59880})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29702, 1: 165}\n",
      "Test : Accuracy: 0.7619 Recall : 0.9954 FDR: 0.4531  F1-score: 0.7059  \n",
      "model AE is saved in best_models/AE_f1_0.71_recall_1.00_.pth\n",
      "\n",
      "==================  lr=0.0001, wd=0.0001 ==================\n",
      "Train : time 145.33 s Epoch 1\n",
      "Train Loss: 0.1134\n",
      "--- Running Evaluation for Epoch 1 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0031 std: 0.0516\n",
      "Val: Accuracy: 0.9092  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.0547\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65739, 0: 59693})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29823, 1: 99}\n",
      "Test : Accuracy: 0.7614 Recall : 0.9973 FDR: 0.4537  F1-score: 0.7059  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.1579\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65585, 0: 59847})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29735, 1: 165}\n",
      "Test : Accuracy: 0.7616 Recall : 0.9954 FDR: 0.4534  F1-score: 0.7057  \n",
      "Train : time 144.60 s Epoch 2\n",
      "Train Loss: 0.0024\n",
      "--- Running Evaluation for Epoch 2 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0029 std: 0.0490\n",
      "Val: Accuracy: 0.8961  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.05192\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65762, 0: 59670})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29823, 1: 76}\n",
      "Test : Accuracy: 0.7616 Recall : 0.9979 FDR: 0.4535  F1-score: 0.7062  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.15\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65580, 0: 59852})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29730, 1: 165}\n",
      "Test : Accuracy: 0.7617 Recall : 0.9954 FDR: 0.4533  F1-score: 0.7057  \n",
      "Train : time 146.62 s Epoch 3\n",
      "Train Loss: 0.0023\n",
      "--- Running Evaluation for Epoch 3 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0028 std: 0.0489\n",
      "Val: Accuracy: 0.8930  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.05172\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65773, 0: 59659})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29825, 1: 67}\n",
      "Test : Accuracy: 0.7617 Recall : 0.9981 FDR: 0.4535  F1-score: 0.7063  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.1495\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65583, 0: 59849})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29733, 1: 165}\n",
      "Test : Accuracy: 0.7616 Recall : 0.9954 FDR: 0.4534  F1-score: 0.7057  \n",
      "Train : time 143.51 s Epoch 4\n",
      "Train Loss: 0.0022\n",
      "--- Running Evaluation for Epoch 4 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0028 std: 0.0468\n",
      "Val: Accuracy: 0.8855  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.04957\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65777, 0: 59655})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29828, 1: 66}\n",
      "Test : Accuracy: 0.7617 Recall : 0.9982 FDR: 0.4535  F1-score: 0.7063  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.1432\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65579, 0: 59853})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29729, 1: 165}\n",
      "Test : Accuracy: 0.7617 Recall : 0.9954 FDR: 0.4533  F1-score: 0.7058  \n",
      "Train : time 144.70 s Epoch 5\n",
      "Train Loss: 0.0022\n",
      "--- Running Evaluation for Epoch 5 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0026 std: 0.0427\n",
      "Val: Accuracy: 0.8763  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.04534\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65794, 0: 59638})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29837, 1: 58}\n",
      "Test : Accuracy: 0.7617 Recall : 0.9984 FDR: 0.4535  F1-score: 0.7064  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.1308\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65592, 0: 59840})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29739, 1: 162}\n",
      "Test : Accuracy: 0.7616 Recall : 0.9955 FDR: 0.4534  F1-score: 0.7057  \n",
      "model AE is saved in best_models/AE_f1_0.71_recall_1.00_.pth\n",
      "Train : time 141.73 s Epoch 6\n",
      "Train Loss: 0.0021\n",
      "--- Running Evaluation for Epoch 6 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0024 std: 0.0341\n",
      "Val: Accuracy: 0.8562  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.03648\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65829, 0: 59603})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29849, 1: 35}\n",
      "Test : Accuracy: 0.7618 Recall : 0.9990 FDR: 0.4534  F1-score: 0.7066  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.1047\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65612, 0: 59820})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29751, 1: 154}\n",
      "Test : Accuracy: 0.7616 Recall : 0.9957 FDR: 0.4534  F1-score: 0.7057  \n",
      "model AE is saved in best_models/AE_f1_0.71_recall_1.00_.pth\n",
      "\n",
      "==================  lr=1e-05, wd=0.0001 ==================\n",
      "Train : time 142.50 s Epoch 1\n",
      "Train Loss: 1.1822\n",
      "--- Running Evaluation for Epoch 1 lr =1e-05 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0089 std: 0.0942\n",
      "Val: Accuracy: 0.9451  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.1031\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65745, 0: 59687})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29884, 1: 154}\n",
      "Test : Accuracy: 0.7605 Recall : 0.9957 FDR: 0.4545  F1-score: 0.7048  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.2915\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65591, 0: 59841})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29742, 1: 166}\n",
      "Test : Accuracy: 0.7616 Recall : 0.9954 FDR: 0.4534  F1-score: 0.7056  \n",
      "Train : time 148.04 s Epoch 2\n",
      "Train Loss: 0.0051\n",
      "--- Running Evaluation for Epoch 2 lr =1e-05 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0046 std: 0.0753\n",
      "Val: Accuracy: 0.9530  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.07989\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65673, 0: 59759})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29811, 1: 153}\n",
      "Test : Accuracy: 0.7611 Recall : 0.9958 FDR: 0.4539  F1-score: 0.7053  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.2305\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65564, 0: 59868})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29714, 1: 165}\n",
      "Test : Accuracy: 0.7618 Recall : 0.9954 FDR: 0.4532  F1-score: 0.7059  \n",
      "Train : time 137.49 s Epoch 3\n",
      "Train Loss: 0.0036\n",
      "--- Running Evaluation for Epoch 3 lr =1e-05 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0040 std: 0.0656\n",
      "Val: Accuracy: 0.9513  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.06961\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65680, 0: 59752})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29808, 1: 143}\n",
      "Test : Accuracy: 0.7612 Recall : 0.9960 FDR: 0.4538  F1-score: 0.7055  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.2008\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65576, 0: 59856})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29726, 1: 165}\n",
      "Test : Accuracy: 0.7617 Recall : 0.9954 FDR: 0.4533  F1-score: 0.7058  \n",
      "Train : time 126.94 s Epoch 4\n",
      "Train Loss: 0.0032\n",
      "--- Running Evaluation for Epoch 4 lr =1e-05 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0036 std: 0.0589\n",
      "Val: Accuracy: 0.9401  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.06257\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65703, 0: 59729})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29813, 1: 125}\n",
      "Test : Accuracy: 0.7613 Recall : 0.9965 FDR: 0.4538  F1-score: 0.7057  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.1804\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65580, 0: 59852})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29730, 1: 165}\n",
      "Test : Accuracy: 0.7617 Recall : 0.9954 FDR: 0.4533  F1-score: 0.7057  \n",
      "Train : time 126.66 s Epoch 5\n",
      "Train Loss: 0.0029\n",
      "--- Running Evaluation for Epoch 5 lr =1e-05 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0034 std: 0.0540\n",
      "Val: Accuracy: 0.9259  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.05733\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65728, 0: 59704})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29818, 1: 105}\n",
      "Test : Accuracy: 0.7614 Recall : 0.9971 FDR: 0.4537  F1-score: 0.7059  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.1652\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65583, 0: 59849})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29733, 1: 165}\n",
      "Test : Accuracy: 0.7616 Recall : 0.9954 FDR: 0.4534  F1-score: 0.7057  \n",
      "Train : time 135.75 s Epoch 6\n",
      "Train Loss: 0.0027\n",
      "--- Running Evaluation for Epoch 6 lr =1e-05 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0032 std: 0.0525\n",
      "Val: Accuracy: 0.9140  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.05571\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65729, 0: 59703})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29814, 1: 100}\n",
      "Test : Accuracy: 0.7615 Recall : 0.9972 FDR: 0.4536  F1-score: 0.7060  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.1607\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65583, 0: 59849})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29733, 1: 165}\n",
      "Test : Accuracy: 0.7616 Recall : 0.9954 FDR: 0.4534  F1-score: 0.7057  \n",
      "\n",
      "==================  lr=1e-06, wd=0.0001 ==================\n",
      "Train : time 130.60 s Epoch 1\n",
      "Train Loss: 10.9083\n",
      "--- Running Evaluation for Epoch 1 lr =1e-06 wd 0.0001 ---\n",
      "-----------mse_loss mean :  3.8178 std: 1.5310\n",
      "Val: Accuracy: 0.6168  \n",
      " K: 1 K-SIGMA Threshold : ---thr 5.349\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 117090, 1: 8342})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5454, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.6924 Recall : 0.0802 FDR: 0.6538  F1-score: 0.1302  \n",
      " K: 3 K-SIGMA Threshold : ---thr 8.411\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 121385, 1: 4047})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 1159, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.7267 Recall : 0.0802 FDR: 0.2864  F1-score: 0.1442  \n",
      "Train : time 132.05 s Epoch 2\n",
      "Train Loss: 1.4384\n",
      "--- Running Evaluation for Epoch 2 lr =1e-06 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.4225 std: 0.8288\n",
      "Val: Accuracy: 0.8593  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.251\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 92831, 1: 32601})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6609, 1: 10014, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8674 Recall : 0.7217 FDR: 0.2027  F1-score: 0.7576  \n",
      " K: 3 K-SIGMA Threshold : ---thr 2.909\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 120175, 1: 5257})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2369, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.7170 Recall : 0.0802 FDR: 0.4506  F1-score: 0.1399  \n",
      "model AE is saved in best_models/AE_f1_0.76_recall_1.00_.pth\n",
      "Train : time 137.07 s Epoch 3\n",
      "Train Loss: 0.1863\n",
      "--- Running Evaluation for Epoch 3 lr =1e-06 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0893 std: 0.4225\n",
      "Val: Accuracy: 0.8069  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.5118\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 98844, 1: 26588})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 595, 1: 10014, 6: 8}\n",
      "Test : Accuracy: 0.9154 Recall : 0.7217 FDR: 0.0224  F1-score: 0.8304  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.357\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99101, 1: 26331})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 339, 1: 10014, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.9174 Recall : 0.7217 FDR: 0.0129  F1-score: 0.8338  \n",
      "model AE is saved in best_models/AE_f1_0.83_recall_1.00_.pth\n",
      "Train : time 128.78 s Epoch 4\n",
      "Train Loss: 0.0714\n",
      "--- Running Evaluation for Epoch 4 lr =1e-06 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0572 std: 0.3491\n",
      "Val: Accuracy: 0.8886  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.4063\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 97867, 1: 27565})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 353, 1: 8795, 6: 8}\n",
      "Test : Accuracy: 0.9270 Recall : 0.7556 FDR: 0.0128  F1-score: 0.8560  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.105\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99090, 1: 26342})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 350, 1: 10014, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.9173 Recall : 0.7217 FDR: 0.0133  F1-score: 0.8337  \n",
      "model AE is saved in best_models/AE_f1_0.86_recall_1.00_.pth\n",
      "Train : time 130.61 s Epoch 5\n",
      "Train Loss: 0.0476\n",
      "--- Running Evaluation for Epoch 5 lr =1e-06 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0380 std: 0.2520\n",
      "Val: Accuracy: 0.9206  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.29\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65734, 0: 59698})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29884, 1: 165}\n",
      "Test : Accuracy: 0.7604 Recall : 0.9954 FDR: 0.4546  F1-score: 0.7047  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.7939\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99090, 1: 26342})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 350, 1: 10014, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.9173 Recall : 0.7217 FDR: 0.0133  F1-score: 0.8337  \n",
      "Train : time 132.13 s Epoch 6\n",
      "Train Loss: 0.0306\n",
      "--- Running Evaluation for Epoch 6 lr =1e-06 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0236 std: 0.1793\n",
      "Val: Accuracy: 0.9412  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.2029\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65745, 0: 59687})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29884, 1: 154}\n",
      "Test : Accuracy: 0.7605 Recall : 0.9957 FDR: 0.4545  F1-score: 0.7048  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.5615\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99088, 1: 26344})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 351, 1: 10014, 6: 8}\n",
      "Test : Accuracy: 0.9173 Recall : 0.7217 FDR: 0.0133  F1-score: 0.8337  \n"
     ]
    }
   ],
   "source": [
    "# train_eval(AE_model,AE_train_dataloader,AE_val_dataloader,AE_test_dataloader,shuffle_files=True,num_epochs=20,eval_epoch=1,criterion_method=\"bce\",learning_rates=[5e-4],weight_decays=[0])\n",
    "AE_model = AE(input_dim=76)\n",
    "train_eval(AE_model,train_dataloader,val_dataloader,test_dataloader,shuffle_files=False,num_epochs=6,eval_epoch=1,criterion_method=\"mse\",learning_rates=[5e-5,1e-4,1e-5,1e-6],weight_decays=[1e-4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea756ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================  lr=0.01, wd=1e-05 ==================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : time 172.20 s Epoch 1\n",
      "Train Loss: 1.3981\n",
      "--- Running Evaluation for Epoch 1 lr =0.01 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.4596 std: 1.4261\n",
      "Val: Accuracy: 0.8703  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.886\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 94568, 1: 30864})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 4486, 1: 9628, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8874 Recall : 0.7324 FDR: 0.1453  F1-score: 0.7888  \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.738\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 118842, 1: 6590})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2580, 1: 31971, 2: 1, 3: 1, 4: 1, 5: 2, 6: 28, 7: 1}\n",
      "Test : Accuracy: 0.7243 Recall : 0.1113 FDR: 0.3915  F1-score: 0.1882  \n",
      "model VAE is saved in best_models/VAE_f1_0.79_recall_0.73_.pth\n",
      "Train : time 160.39 s Epoch 2\n",
      "Train Loss: 1.3734\n",
      "--- Running Evaluation for Epoch 2 lr =0.01 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.4440 std: 1.2936\n",
      "Val: Accuracy: 0.8453  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.738\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 93806, 1: 31626})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5220, 1: 9600, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8818 Recall : 0.7332 FDR: 0.1651  F1-score: 0.7808  \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.325\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 118701, 1: 6731})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2662, 1: 31912, 2: 1, 3: 1, 4: 1, 5: 2, 6: 28, 7: 1}\n",
      "Test : Accuracy: 0.7241 Recall : 0.1130 FDR: 0.3955  F1-score: 0.1904  \n",
      "model VAE is saved in best_models/VAE_f1_0.79_recall_0.73_.pth\n",
      "Train : time 170.35 s Epoch 3\n",
      "Train Loss: 1.3690\n",
      "--- Running Evaluation for Epoch 3 lr =0.01 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.3673 std: 1.1786\n",
      "Val: Accuracy: 0.8492  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.546\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 94952, 1: 30480})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 4315, 1: 9841, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8871 Recall : 0.7265 FDR: 0.1416  F1-score: 0.7870  \n",
      " K: 3 K-SIGMA Threshold : ---thr 3.903\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 120321, 1: 5111})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 1737, 1: 32606, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.7259 Recall : 0.0937 FDR: 0.3399  F1-score: 0.1641  \n",
      "Train : time 170.38 s Epoch 4\n",
      "Train Loss: 1.3672\n",
      "--- Running Evaluation for Epoch 4 lr =0.01 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.4180 std: 1.3006\n",
      "Val: Accuracy: 0.8525  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.719\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 94932, 1: 30500})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 4267, 1: 9773, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8880 Recall : 0.7284 FDR: 0.1399  F1-score: 0.7888  \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.32\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 119899, 1: 5533})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2065, 1: 32512, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.7241 Recall : 0.0963 FDR: 0.3732  F1-score: 0.1669  \n",
      "Train : time 170.86 s Epoch 5\n",
      "Train Loss: 1.3666\n",
      "--- Running Evaluation for Epoch 5 lr =0.01 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.3316 std: 1.1037\n",
      "Val: Accuracy: 0.8503  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.435\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 95515, 1: 29917})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 3868, 1: 9957, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8897 Recall : 0.7233 FDR: 0.1293  F1-score: 0.7902  \n",
      " K: 3 K-SIGMA Threshold : ---thr 3.643\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 121249, 1: 4183})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 1167, 1: 32964, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.7276 Recall : 0.0837 FDR: 0.2790  F1-score: 0.1501  \n",
      "model VAE is saved in best_models/VAE_f1_0.79_recall_0.73_.pth\n",
      "Train : time 171.69 s Epoch 6\n",
      "Train Loss: 1.3676\n",
      "--- Running Evaluation for Epoch 6 lr =0.01 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.3823 std: 1.2034\n",
      "Val: Accuracy: 0.8466  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.586\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 94985, 1: 30447})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 4404, 1: 9963, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8854 Recall : 0.7231 FDR: 0.1446  F1-score: 0.7837  \n",
      " K: 3 K-SIGMA Threshold : ---thr 3.993\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 120437, 1: 4995})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 1602, 1: 32587, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.7272 Recall : 0.0942 FDR: 0.3207  F1-score: 0.1655  \n",
      "\n",
      "==================  lr=0.001, wd=1e-05 ==================\n",
      "Train : time 170.15 s Epoch 1\n",
      "Train Loss: 1.3943\n",
      "--- Running Evaluation for Epoch 1 lr =0.001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.3444 std: 1.1186\n",
      "Val: Accuracy: 0.8567  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.463\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 94329, 1: 31103})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 4750, 1: 9653, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8851 Recall : 0.7317 FDR: 0.1527  F1-score: 0.7853  \n",
      " K: 3 K-SIGMA Threshold : ---thr 3.7\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 117582, 1: 7850})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2190, 1: 30320, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.7405 Recall : 0.1572 FDR: 0.2790  F1-score: 0.2581  \n",
      "Train : time 172.15 s Epoch 2\n",
      "Train Loss: 1.3376\n",
      "--- Running Evaluation for Epoch 2 lr =0.001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.3917 std: 1.2378\n",
      "Val: Accuracy: 0.8512  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.63\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 94219, 1: 31213})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 4877, 1: 9670, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8840 Recall : 0.7313 FDR: 0.1562  F1-score: 0.7835  \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.105\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 116525, 1: 8907})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2336, 1: 29413, 2: 1, 3: 1, 4: 1, 5: 2, 6: 25, 7: 1}\n",
      "Test : Accuracy: 0.7466 Recall : 0.1825 FDR: 0.2623  F1-score: 0.2926  \n",
      "Train : time 173.37 s Epoch 3\n",
      "Train Loss: 1.3329\n",
      "--- Running Evaluation for Epoch 3 lr =0.001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.4234 std: 1.2786\n",
      "Val: Accuracy: 0.8418  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.702\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 93708, 1: 31724})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5348, 1: 9630, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8805 Recall : 0.7324 FDR: 0.1686  F1-score: 0.7788  \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.259\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 117701, 1: 7731})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2483, 1: 30734, 2: 1, 4: 1, 5: 2, 6: 28, 7: 1}\n",
      "Test : Accuracy: 0.7349 Recall : 0.1457 FDR: 0.3212  F1-score: 0.2399  \n",
      "Train : time 167.97 s Epoch 4\n",
      "Train Loss: 1.3318\n",
      "--- Running Evaluation for Epoch 4 lr =0.001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.3556 std: 1.1125\n",
      "Val: Accuracy: 0.8551  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.468\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 93972, 1: 31460})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5079, 1: 9625, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8827 Recall : 0.7325 FDR: 0.1614  F1-score: 0.7819  \n",
      " K: 3 K-SIGMA Threshold : ---thr 3.693\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 116792, 1: 8640})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2417, 1: 29761, 2: 1, 3: 1, 4: 1, 5: 2, 6: 25, 7: 1}\n",
      "Test : Accuracy: 0.7432 Recall : 0.1728 FDR: 0.2797  F1-score: 0.2787  \n",
      "Train : time 177.67 s Epoch 5\n",
      "Train Loss: 1.3302\n",
      "--- Running Evaluation for Epoch 5 lr =0.001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.3762 std: 1.2052\n",
      "Val: Accuracy: 0.8536  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.581\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 94301, 1: 31131})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 4784, 1: 9659, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8848 Recall : 0.7316 FDR: 0.1537  F1-score: 0.7848  \n",
      " K: 3 K-SIGMA Threshold : ---thr 3.992\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 117781, 1: 7651})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2383, 1: 30714, 2: 1, 3: 1, 4: 1, 5: 2, 6: 27, 7: 1}\n",
      "Test : Accuracy: 0.7359 Recall : 0.1463 FDR: 0.3115  F1-score: 0.2413  \n",
      "Train : time 167.47 s Epoch 6\n",
      "Train Loss: 1.3305\n",
      "--- Running Evaluation for Epoch 6 lr =0.001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.3631 std: 1.1598\n",
      "Val: Accuracy: 0.8468  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.523\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 94004, 1: 31428})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5104, 1: 9682, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8820 Recall : 0.7309 FDR: 0.1624  F1-score: 0.7806  \n",
      " K: 3 K-SIGMA Threshold : ---thr 3.842\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 118384, 1: 7048})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2178, 1: 31114, 2: 1, 3: 1, 4: 1, 5: 2, 6: 25, 7: 1}\n",
      "Test : Accuracy: 0.7343 Recall : 0.1352 FDR: 0.3090  F1-score: 0.2262  \n",
      "\n",
      "==================  lr=0.0001, wd=1e-05 ==================\n",
      "Train : time 170.14 s Epoch 1\n",
      "Train Loss: 1.6603\n",
      "--- Running Evaluation for Epoch 1 lr =0.0001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.3987 std: 1.1653\n",
      "Val: Accuracy: 0.8263  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.564\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 92256, 1: 33176})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6341, 1: 9171, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8763 Recall : 0.7451 FDR: 0.1911  F1-score: 0.7757  \n",
      " K: 3 K-SIGMA Threshold : ---thr 3.894\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 110564, 1: 14868})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 3244, 1: 24366, 4: 1, 5: 2, 6: 22}\n",
      "Test : Accuracy: 0.7797 Recall : 0.3228 FDR: 0.2182  F1-score: 0.4569  \n",
      "model VAE is saved in best_models/VAE_f1_0.79_recall_0.75_.pth\n",
      "Train : time 161.29 s Epoch 2\n",
      "Train Loss: 1.3500\n",
      "--- Running Evaluation for Epoch 2 lr =0.0001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.3881 std: 1.1983\n",
      "Val: Accuracy: 0.8448  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.586\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 93165, 1: 32267})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5602, 1: 9341, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8808 Recall : 0.7404 FDR: 0.1736  F1-score: 0.7810  \n",
      " K: 3 K-SIGMA Threshold : ---thr 3.983\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 114450, 1: 10982})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2820, 1: 27821, 2: 1, 3: 1, 4: 1, 5: 2, 6: 26, 7: 1}\n",
      "Test : Accuracy: 0.7555 Recall : 0.2266 FDR: 0.2568  F1-score: 0.3473  \n",
      "Train : time 163.88 s Epoch 3\n",
      "Train Loss: 1.3347\n",
      "--- Running Evaluation for Epoch 3 lr =0.0001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.3831 std: 1.2016\n",
      "Val: Accuracy: 0.8476  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.585\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 93390, 1: 32042})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5474, 1: 9438, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8810 Recall : 0.7377 FDR: 0.1708  F1-score: 0.7808  \n",
      " K: 3 K-SIGMA Threshold : ---thr 3.988\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 116990, 1: 8442})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2668, 1: 30207, 2: 1, 3: 1, 4: 1, 5: 2, 6: 28, 7: 1}\n",
      "Test : Accuracy: 0.7376 Recall : 0.1603 FDR: 0.3160  F1-score: 0.2598  \n",
      "Train : time 163.23 s Epoch 4\n",
      "Train Loss: 1.3321\n",
      "--- Running Evaluation for Epoch 4 lr =0.0001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.4149 std: 1.3007\n",
      "Val: Accuracy: 0.8546  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.716\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 93269, 1: 32163})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5569, 1: 9412, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8805 Recall : 0.7384 FDR: 0.1731  F1-score: 0.7801  \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.317\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 116962, 1: 8470})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2980, 1: 30490, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.7329 Recall : 0.1524 FDR: 0.3518  F1-score: 0.2468  \n",
      "Train : time 161.77 s Epoch 5\n",
      "Train Loss: 1.3300\n",
      "--- Running Evaluation for Epoch 5 lr =0.0001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.4016 std: 1.2130\n",
      "Val: Accuracy: 0.8459  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.615\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 92674, 1: 32758})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6082, 1: 9330, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8771 Recall : 0.7407 FDR: 0.1857  F1-score: 0.7758  \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.04\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 116907, 1: 8525})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2981, 1: 30437, 2: 1, 3: 1, 4: 1, 5: 2, 6: 28, 7: 1}\n",
      "Test : Accuracy: 0.7333 Recall : 0.1539 FDR: 0.3497  F1-score: 0.2489  \n",
      "Train : time 162.48 s Epoch 6\n",
      "Train Loss: 1.3294\n",
      "--- Running Evaluation for Epoch 6 lr =0.0001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.3712 std: 1.1718\n",
      "Val: Accuracy: 0.8489  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.543\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 93139, 1: 32293})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5728, 1: 9442, 5: 1, 6: 7}\n",
      "Test : Accuracy: 0.8790 Recall : 0.7376 FDR: 0.1774  F1-score: 0.7778  \n",
      " K: 3 K-SIGMA Threshold : ---thr 3.887\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 116659, 1: 8773})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2758, 1: 29970, 3: 1, 4: 1, 5: 2, 6: 25, 7: 1}\n",
      "Test : Accuracy: 0.7388 Recall : 0.1670 FDR: 0.3144  F1-score: 0.2686  \n"
     ]
    }
   ],
   "source": [
    "VAE_model = VAE(input_dim=76)\n",
    "train_eval(VAE_model,train_dataloader,val_dataloader,test_dataloader,shuffle_files=False,num_epochs=6,eval_epoch=1,criterion_method=\"mse\",learning_rates=[1e-2,1e-3,1e-4],weight_decays=[1e-5],k_range=[1,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54635226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================  lr=0.01, wd=0.0001 ==================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : time 228.85 s Epoch 1\n",
      "Generator Loss: 176.8262 Discriminator Loss: 5.3518\n",
      "--- Running Evaluation for Epoch 1 lr =0.01 wd 0.0001 ---\n",
      "-----------mse_loss mean :  3.5951 std: 3.4918\n",
      "Val: Accuracy: 0.6065  \n",
      " K: 1 K-SIGMA Threshold : ---thr 7.087\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 117049, 1: 8383})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5495, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.6921 Recall : 0.0802 FDR: 0.6555  F1-score: 0.1301  \n",
      " K: 3 K-SIGMA Threshold : ---thr 14.07\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 125309, 1: 123})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6, 1: 35861, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Test : Accuracy: 0.7138 Recall : 0.0032 FDR: 0.0488  F1-score: 0.0065  \n",
      "model AdversarialAutoencoder is saved in best_models/AdversarialAutoencoder_f1_0.13_recall_0.08_.pth\n",
      "Train : time 232.27 s Epoch 2\n",
      "Generator Loss: 236.1101 Discriminator Loss: 0.0166\n",
      "--- Running Evaluation for Epoch 2 lr =0.01 wd 0.0001 ---\n",
      "-----------mse_loss mean :  3.5951 std: 3.4917\n",
      "Val: Accuracy: 0.6065  \n",
      " K: 1 K-SIGMA Threshold : ---thr 7.087\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 117049, 1: 8383})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5495, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.6921 Recall : 0.0802 FDR: 0.6555  F1-score: 0.1301  \n",
      " K: 3 K-SIGMA Threshold : ---thr 14.07\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 125309, 1: 123})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6, 1: 35861, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Test : Accuracy: 0.7138 Recall : 0.0032 FDR: 0.0488  F1-score: 0.0065  \n",
      "Train : time 229.78 s Epoch 3\n",
      "Generator Loss: 233.6358 Discriminator Loss: 0.0430\n",
      "--- Running Evaluation for Epoch 3 lr =0.01 wd 0.0001 ---\n",
      "-----------mse_loss mean :  3.5011 std: 3.3216\n",
      "Val: Accuracy: 0.6067  \n",
      " K: 1 K-SIGMA Threshold : ---thr 6.823\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 103012, 1: 22420})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 19604, 1: 33164, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.5790 Recall : 0.0782 FDR: 0.8744  F1-score: 0.0964  \n",
      " K: 3 K-SIGMA Threshold : ---thr 13.47\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 125310, 1: 122})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5, 1: 35861, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Test : Accuracy: 0.7138 Recall : 0.0032 FDR: 0.0410  F1-score: 0.0065  \n",
      "Train : time 234.54 s Epoch 4\n",
      "Generator Loss: 306.7760 Discriminator Loss: 0.0391\n",
      "--- Running Evaluation for Epoch 4 lr =0.01 wd 0.0001 ---\n",
      "-----------mse_loss mean :  4.7396 std: 2.4142\n",
      "Val: Accuracy: 0.6105  \n",
      " K: 1 K-SIGMA Threshold : ---thr 7.154\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 121304, 1: 4128})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 3522, 1: 35374, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.6896 Recall : 0.0168 FDR: 0.8532  F1-score: 0.0302  \n",
      " K: 3 K-SIGMA Threshold : ---thr 11.98\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 125167, 1: 265})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 148, 1: 35861, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Test : Accuracy: 0.7126 Recall : 0.0032 FDR: 0.5585  F1-score: 0.0064  \n",
      "Train : time 233.78 s Epoch 5\n",
      "Generator Loss: 309.0570 Discriminator Loss: 0.0009\n",
      "--- Running Evaluation for Epoch 5 lr =0.01 wd 0.0001 ---\n",
      "-----------mse_loss mean :  4.7396 std: 2.4142\n",
      "Val: Accuracy: 0.6105  \n",
      " K: 1 K-SIGMA Threshold : ---thr 7.154\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 121304, 1: 4128})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 3522, 1: 35374, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.6896 Recall : 0.0168 FDR: 0.8532  F1-score: 0.0302  \n",
      " K: 3 K-SIGMA Threshold : ---thr 11.98\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 125167, 1: 265})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 148, 1: 35861, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Test : Accuracy: 0.7126 Recall : 0.0032 FDR: 0.5585  F1-score: 0.0064  \n",
      "Train : time 233.17 s Epoch 6\n",
      "Generator Loss: 308.6756 Discriminator Loss: 0.0006\n",
      "--- Running Evaluation for Epoch 6 lr =0.01 wd 0.0001 ---\n",
      "-----------mse_loss mean :  4.7396 std: 2.4142\n",
      "Val: Accuracy: 0.6105  \n",
      " K: 1 K-SIGMA Threshold : ---thr 7.154\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 121304, 1: 4128})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 3522, 1: 35374, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.6896 Recall : 0.0168 FDR: 0.8532  F1-score: 0.0302  \n",
      " K: 3 K-SIGMA Threshold : ---thr 11.98\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 125167, 1: 265})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 148, 1: 35861, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Test : Accuracy: 0.7126 Recall : 0.0032 FDR: 0.5585  F1-score: 0.0064  \n",
      "\n",
      "==================  lr=0.001, wd=0.0001 ==================\n",
      "Train : time 239.11 s Epoch 1\n",
      "Generator Loss: 4.1309 Discriminator Loss: 7.7194\n",
      "--- Running Evaluation for Epoch 1 lr =0.001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0184 std: 0.2063\n",
      "Val: Accuracy: 0.9813  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.2247\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65734, 0: 59698})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29884, 1: 165}\n",
      "Test : Accuracy: 0.7604 Recall : 0.9954 FDR: 0.4546  F1-score: 0.7047  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.6373\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99108, 1: 26324})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 331, 1: 10014, 6: 8}\n",
      "Test : Accuracy: 0.9175 Recall : 0.7217 FDR: 0.0126  F1-score: 0.8339  \n",
      "model AdversarialAutoencoder is saved in best_models/AdversarialAutoencoder_f1_0.83_recall_1.00_.pth\n",
      "Train : time 237.31 s Epoch 2\n",
      "Generator Loss: 1.6544 Discriminator Loss: 11.2261\n",
      "--- Running Evaluation for Epoch 2 lr =0.001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0301 std: 0.1836\n",
      "Val: Accuracy: 0.9382  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.2136\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65734, 0: 59698})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29884, 1: 165}\n",
      "Test : Accuracy: 0.7604 Recall : 0.9954 FDR: 0.4546  F1-score: 0.7047  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.5808\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99088, 1: 26344})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 351, 1: 10014, 6: 8}\n",
      "Test : Accuracy: 0.9173 Recall : 0.7217 FDR: 0.0133  F1-score: 0.8337  \n",
      "Train : time 235.84 s Epoch 3\n",
      "Generator Loss: 1.8781 Discriminator Loss: 15.6813\n",
      "--- Running Evaluation for Epoch 3 lr =0.001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0233 std: 0.1841\n",
      "Val: Accuracy: 0.9811  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.2074\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65734, 0: 59698})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29884, 1: 165}\n",
      "Test : Accuracy: 0.7604 Recall : 0.9954 FDR: 0.4546  F1-score: 0.7047  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.5756\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99036, 1: 26396})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 351, 1: 9962, 6: 8}\n",
      "Test : Accuracy: 0.9177 Recall : 0.7232 FDR: 0.0133  F1-score: 0.8346  \n",
      "model AdversarialAutoencoder is saved in best_models/AdversarialAutoencoder_f1_0.83_recall_1.00_.pth\n",
      "Train : time 236.47 s Epoch 4\n",
      "Generator Loss: 1.5950 Discriminator Loss: 16.2237\n",
      "--- Running Evaluation for Epoch 4 lr =0.001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0227 std: 0.1802\n",
      "Val: Accuracy: 0.9811  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.2029\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65734, 0: 59698})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29884, 1: 165}\n",
      "Test : Accuracy: 0.7604 Recall : 0.9954 FDR: 0.4546  F1-score: 0.7047  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.5634\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99088, 1: 26344})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 351, 1: 10014, 6: 8}\n",
      "Test : Accuracy: 0.9173 Recall : 0.7217 FDR: 0.0133  F1-score: 0.8337  \n",
      "Train : time 236.74 s Epoch 5\n",
      "Generator Loss: 1.5011 Discriminator Loss: 18.0652\n",
      "--- Running Evaluation for Epoch 5 lr =0.001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0215 std: 0.1836\n",
      "Val: Accuracy: 0.9897  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.2051\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65735, 0: 59697})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29884, 1: 164}\n",
      "Test : Accuracy: 0.7604 Recall : 0.9954 FDR: 0.4546  F1-score: 0.7047  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.5724\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99108, 1: 26324})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 331, 1: 10014, 6: 8}\n",
      "Test : Accuracy: 0.9175 Recall : 0.7217 FDR: 0.0126  F1-score: 0.8339  \n",
      "model AdversarialAutoencoder is saved in best_models/AdversarialAutoencoder_f1_0.83_recall_1.00_.pth\n",
      "Train : time 243.17 s Epoch 6\n",
      "Generator Loss: 1.2232 Discriminator Loss: 22.6538\n",
      "--- Running Evaluation for Epoch 6 lr =0.001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0167 std: 0.1769\n",
      "Val: Accuracy: 0.9844  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.1936\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65734, 0: 59698})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29884, 1: 165}\n",
      "Test : Accuracy: 0.7604 Recall : 0.9954 FDR: 0.4546  F1-score: 0.7047  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.5475\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 97255, 1: 28177})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 353, 1: 8183, 6: 8}\n",
      "Test : Accuracy: 0.9319 Recall : 0.7726 FDR: 0.0125  F1-score: 0.8669  \n",
      "model AdversarialAutoencoder is saved in best_models/AdversarialAutoencoder_f1_0.87_recall_1.00_.pth\n",
      "\n",
      "==================  lr=0.0001, wd=0.0001 ==================\n",
      "Train : time 232.10 s Epoch 1\n",
      "Generator Loss: 40.9228 Discriminator Loss: 4.7518\n",
      "--- Running Evaluation for Epoch 1 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0643 std: 0.5388\n",
      "Val: Accuracy: 0.9551  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.6031\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99089, 1: 26343})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 350, 1: 10014, 6: 8}\n",
      "Test : Accuracy: 0.9173 Recall : 0.7217 FDR: 0.0133  F1-score: 0.8337  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.681\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99092, 1: 26340})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 348, 1: 10014, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.9173 Recall : 0.7217 FDR: 0.0132  F1-score: 0.8337  \n",
      "Train : time 231.28 s Epoch 2\n",
      "Generator Loss: 3.6065 Discriminator Loss: 4.8913\n",
      "--- Running Evaluation for Epoch 2 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0446 std: 0.4188\n",
      "Val: Accuracy: 0.9826  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.4634\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99088, 1: 26344})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 351, 1: 10014, 6: 8}\n",
      "Test : Accuracy: 0.9173 Recall : 0.7217 FDR: 0.0133  F1-score: 0.8337  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.301\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99090, 1: 26342})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 350, 1: 10014, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.9173 Recall : 0.7217 FDR: 0.0133  F1-score: 0.8337  \n",
      "Train : time 236.68 s Epoch 3\n",
      "Generator Loss: 3.0012 Discriminator Loss: 3.5079\n",
      "--- Running Evaluation for Epoch 3 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0395 std: 0.3916\n",
      "Val: Accuracy: 0.9828  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.4311\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99087, 1: 26345})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 352, 1: 10014, 6: 8}\n",
      "Test : Accuracy: 0.9173 Recall : 0.7217 FDR: 0.0134  F1-score: 0.8336  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.214\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99090, 1: 26342})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 350, 1: 10014, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.9173 Recall : 0.7217 FDR: 0.0133  F1-score: 0.8337  \n",
      "Train : time 241.90 s Epoch 4\n",
      "Generator Loss: 2.7489 Discriminator Loss: 2.6974\n",
      "--- Running Evaluation for Epoch 4 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0353 std: 0.3443\n",
      "Val: Accuracy: 0.9830  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.3796\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 97859, 1: 27573})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 356, 1: 8790, 6: 8}\n",
      "Test : Accuracy: 0.9270 Recall : 0.7557 FDR: 0.0129  F1-score: 0.8560  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.068\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99090, 1: 26342})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 350, 1: 10014, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.9173 Recall : 0.7217 FDR: 0.0133  F1-score: 0.8337  \n",
      "Train : time 233.90 s Epoch 5\n",
      "Generator Loss: 2.5526 Discriminator Loss: 2.2999\n",
      "--- Running Evaluation for Epoch 5 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0324 std: 0.3124\n",
      "Val: Accuracy: 0.9797  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.3449\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 88780, 1: 36652})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2175, 1: 1538}\n",
      "Test : Accuracy: 0.9704 Recall : 0.9573 FDR: 0.0593  F1-score: 0.9489  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.9697\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99089, 1: 26343})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 350, 1: 10014, 6: 8}\n",
      "Test : Accuracy: 0.9173 Recall : 0.7217 FDR: 0.0133  F1-score: 0.8337  \n",
      "model AdversarialAutoencoder is saved in best_models/AdversarialAutoencoder_f1_0.95_recall_1.00_.pth\n",
      "Train : time 254.28 s Epoch 6\n",
      "Generator Loss: 2.3765 Discriminator Loss: 2.8582\n",
      "--- Running Evaluation for Epoch 6 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0304 std: 0.2940\n",
      "Val: Accuracy: 0.9831  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.3244\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 87437, 1: 37995})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2177, 1: 197}\n",
      "Test : Accuracy: 0.9811 Recall : 0.9945 FDR: 0.0573  F1-score: 0.9679  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.9123\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 98371, 1: 27061})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 350, 1: 9296, 6: 8}\n",
      "Test : Accuracy: 0.9230 Recall : 0.7417 FDR: 0.0129  F1-score: 0.8469  \n",
      "model AdversarialAutoencoder is saved in best_models/AdversarialAutoencoder_f1_0.97_recall_1.00_.pth\n"
     ]
    }
   ],
   "source": [
    "AAE_model = AdversarialAutoencoder()\n",
    "train_eval(AAE_model,train_dataloader,val_dataloader,test_dataloader,shuffle_files=False,num_epochs=6,eval_epoch=1,criterion_method=\"mse\",learning_rates=[1e-2,1e-3,1e-4],weight_decays=[1e-4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b21a73a",
   "metadata": {},
   "source": [
    "#### Evaluate pre-trained autoencoders  on the compromised-ied and compromised scada scenarios \n",
    "\n",
    "No exact labeling for the comp ied scenario results in low performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19349642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Trained_AE_model=AE(input_dim=76)\n",
    "Trained_AE_model.load_state_dict(torch.load(\"./best_models/AE_f1_0.86_recall_1.00_.pth\"))\n",
    "Trained_VAE_model=VAE(input_dim=76)\n",
    "Trained_VAE_model.load_state_dict(torch.load(\"./best_models/VAE_f1_0.79_recall_0.75_.pth\"))\n",
    "Trained_AAE_model=AdversarialAutoencoder()\n",
    "Trained_AAE_model.load_state_dict(torch.load(\"./best_models/AdversarialAutoencoder_f1_0.97_recall_1.00_.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3d7e62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scenario : compromised-scada node ied1b\n",
      "----------- benign valid files: 3 ['dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-22-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-25-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-17-labeled.csv']\n",
      "----------compromised-scada attack  test files :  8 ['dataset/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-6-labeled.csv', 'dataset/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-3-labeled.csv', 'dataset/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-4-labeled.csv', 'dataset/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-1-labeled.csv', 'dataset/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-7-labeled.csv', 'dataset/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-0-labeled.csv', 'dataset/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-5-labeled.csv', 'dataset/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-2-labeled.csv']\n",
      "********** AdversarialAutoencoder **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0305 std: 0.2940\n",
      "Val: Accuracy: 0.9831  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.3245\n",
      "Counts of : original binary labels Counter({0: 701716, 1: 171557}) predicted binary labels Counter({0: 649808, 1: 223465})\n",
      "Counts of  original  labels: {0: 701716, 1: 170342, 2: 263, 3: 182, 4: 208, 5: 197, 6: 158, 7: 207}\n",
      "Counts of misclassified original labels: {0: 82595, 1: 30474, 2: 47, 3: 69, 4: 33, 5: 2, 6: 61, 7: 1}\n",
      "Test : Accuracy: 0.8703 Recall : 0.8211 FDR: 0.3696  F1-score: 0.7132  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.9125\n",
      "Counts of : original binary labels Counter({0: 701716, 1: 171557}) predicted binary labels Counter({0: 653077, 1: 220196})\n",
      "Counts of  original  labels: {0: 701716, 1: 170342, 2: 263, 3: 182, 4: 208, 5: 197, 6: 158, 7: 207}\n",
      "Counts of misclassified original labels: {0: 81328, 1: 32259, 2: 47, 3: 72, 4: 33, 5: 8, 6: 63, 7: 207}\n",
      "Test : Accuracy: 0.8694 Recall : 0.8095 FDR: 0.3693  F1-score: 0.7090  \n",
      "********** AE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0572 std: 0.3491\n",
      "Val: Accuracy: 0.8886  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.4063\n",
      "Counts of : original binary labels Counter({0: 701716, 1: 171557}) predicted binary labels Counter({0: 652911, 1: 220362})\n",
      "Counts of  original  labels: {0: 701716, 1: 170342, 2: 263, 3: 182, 4: 208, 5: 197, 6: 158, 7: 207}\n",
      "Counts of misclassified original labels: {0: 81469, 1: 32240, 2: 47, 3: 72, 4: 33, 5: 2, 6: 63, 7: 207}\n",
      "Test : Accuracy: 0.8693 Recall : 0.8096 FDR: 0.3697  F1-score: 0.7088  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.104\n",
      "Counts of : original binary labels Counter({0: 701716, 1: 171557}) predicted binary labels Counter({0: 653078, 1: 220195})\n",
      "Counts of  original  labels: {0: 701716, 1: 170342, 2: 263, 3: 182, 4: 208, 5: 197, 6: 158, 7: 207}\n",
      "Counts of misclassified original labels: {0: 81327, 1: 32259, 2: 47, 3: 72, 4: 33, 5: 8, 6: 63, 7: 207}\n",
      "Test : Accuracy: 0.8694 Recall : 0.8095 FDR: 0.3693  F1-score: 0.7090  \n",
      "********** VAE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.4013 std: 1.1737\n",
      "Val: Accuracy: 0.8273  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.575\n",
      "Counts of : original binary labels Counter({0: 701716, 1: 171557}) predicted binary labels Counter({0: 628033, 1: 245240})\n",
      "Counts of  original  labels: {0: 701716, 1: 170342, 2: 263, 3: 182, 4: 208, 5: 197, 6: 158, 7: 207}\n",
      "Counts of misclassified original labels: {0: 104995, 1: 30903, 2: 42, 3: 69, 4: 32, 5: 7, 6: 62, 7: 197}\n",
      "Test : Accuracy: 0.8439 Recall : 0.8175 FDR: 0.4281  F1-score: 0.6730  \n",
      " K: 3 K-SIGMA Threshold : ---thr 3.922\n",
      "Counts of : original binary labels Counter({0: 701716, 1: 171557}) predicted binary labels Counter({0: 827813, 1: 45460})\n",
      "Counts of  original  labels: {0: 701716, 1: 170342, 2: 263, 3: 182, 4: 208, 5: 197, 6: 158, 7: 207}\n",
      "Counts of misclassified original labels: {0: 26034, 1: 151031, 2: 233, 3: 163, 4: 191, 5: 168, 6: 144, 7: 201}\n",
      "Test : Accuracy: 0.7960 Recall : 0.1132 FDR: 0.5727  F1-score: 0.1790  \n",
      "scenario : compromised-ied node ied1b\n",
      "----------- benign valid files: 3 ['dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-22-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-25-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-17-labeled.csv']\n",
      "----------compromised-ied attack  test files :  6 ['dataset/ModbusDataset/attack/compromised-ied/ied1b/ied1b-network-captures/ready/vethc76bd3f-3-labeled.csv', 'dataset/ModbusDataset/attack/compromised-ied/ied1b/ied1b-network-captures/ready/vethc76bd3f-4-labeled.csv', 'dataset/ModbusDataset/attack/compromised-ied/ied1b/ied1b-network-captures/ready/vethc76bd3f-1-labeled.csv', 'dataset/ModbusDataset/attack/compromised-ied/ied1b/ied1b-network-captures/ready/vethc76bd3f-0-labeled.csv', 'dataset/ModbusDataset/attack/compromised-ied/ied1b/ied1b-network-captures/ready/vethc76bd3f-5-labeled.csv', 'dataset/ModbusDataset/attack/compromised-ied/ied1b/ied1b-network-captures/ready/vethc76bd3f-2-labeled.csv']\n",
      "********** AdversarialAutoencoder **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0305 std: 0.2940\n",
      "Val: Accuracy: 0.9831  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.3245\n",
      "Counts of : original binary labels Counter({0: 658934, 1: 362}) predicted binary labels Counter({0: 657143, 1: 2153})\n",
      "Counts of  original  labels: {0: 658934, 2: 66, 3: 78, 4: 52, 5: 62, 7: 60, 8: 44}\n",
      "Counts of misclassified original labels: {0: 2142, 2: 66, 3: 78, 4: 52, 5: 51, 7: 60, 8: 44}\n",
      "Test : Accuracy: 0.9962 Recall : 0.0304 FDR: 0.9949  F1-score: 0.0087  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.9125\n",
      "Counts of : original binary labels Counter({0: 658934, 1: 362}) predicted binary labels Counter({0: 657171, 1: 2125})\n",
      "Counts of  original  labels: {0: 658934, 2: 66, 3: 78, 4: 52, 5: 62, 7: 60, 8: 44}\n",
      "Counts of misclassified original labels: {0: 2114, 2: 66, 3: 78, 4: 52, 5: 51, 7: 60, 8: 44}\n",
      "Test : Accuracy: 0.9963 Recall : 0.0304 FDR: 0.9948  F1-score: 0.0088  \n",
      "********** AE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0572 std: 0.3491\n",
      "Val: Accuracy: 0.8886  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.4063\n",
      "Counts of : original binary labels Counter({0: 658934, 1: 362}) predicted binary labels Counter({0: 657266, 1: 2030})\n",
      "Counts of  original  labels: {0: 658934, 2: 66, 3: 78, 4: 52, 5: 62, 7: 60, 8: 44}\n",
      "Counts of misclassified original labels: {0: 2019, 2: 66, 3: 78, 4: 52, 5: 51, 7: 60, 8: 44}\n",
      "Test : Accuracy: 0.9964 Recall : 0.0304 FDR: 0.9946  F1-score: 0.0092  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.104\n",
      "Counts of : original binary labels Counter({0: 658934, 1: 362}) predicted binary labels Counter({0: 658151, 1: 1145})\n",
      "Counts of  original  labels: {0: 658934, 2: 66, 3: 78, 4: 52, 5: 62, 7: 60, 8: 44}\n",
      "Counts of misclassified original labels: {0: 1134, 2: 66, 3: 78, 4: 52, 5: 51, 7: 60, 8: 44}\n",
      "Test : Accuracy: 0.9977 Recall : 0.0304 FDR: 0.9904  F1-score: 0.0146  \n",
      "********** VAE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.4011 std: 1.1726\n",
      "Val: Accuracy: 0.8271  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.574\n",
      "Counts of : original binary labels Counter({0: 658934, 1: 362}) predicted binary labels Counter({0: 583984, 1: 75312})\n",
      "Counts of  original  labels: {0: 658934, 2: 66, 3: 78, 4: 52, 5: 62, 7: 60, 8: 44}\n",
      "Counts of misclassified original labels: {0: 75257, 2: 58, 3: 73, 4: 47, 5: 45, 7: 52, 8: 32}\n",
      "Test : Accuracy: 0.8854 Recall : 0.1519 FDR: 0.9993  F1-score: 0.0015  \n",
      " K: 3 K-SIGMA Threshold : ---thr 3.919\n",
      "Counts of : original binary labels Counter({0: 658934, 1: 362}) predicted binary labels Counter({0: 644857, 1: 14439})\n",
      "Counts of  original  labels: {0: 658934, 2: 66, 3: 78, 4: 52, 5: 62, 7: 60, 8: 44}\n",
      "Counts of misclassified original labels: {0: 14424, 2: 64, 3: 76, 4: 51, 5: 55, 7: 60, 8: 41}\n",
      "Test : Accuracy: 0.9776 Recall : 0.0414 FDR: 0.9990  F1-score: 0.0020  \n",
      "scenario : external node ied1a\n",
      "----------- benign valid files: 3 ['dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-22-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-25-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-17-labeled.csv']\n",
      "----------external attack  test files :  1 ['dataset/ModbusDataset/attack/external/ied1a/ied1a-network-capture/ready/veth4edc015-0-labeled.csv']\n",
      "********** AdversarialAutoencoder **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0305 std: 0.2940\n",
      "Val: Accuracy: 0.9831  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.3245\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 87437, 1: 37995})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2177, 1: 197}\n",
      "Test : Accuracy: 0.9811 Recall : 0.9945 FDR: 0.0573  F1-score: 0.9679  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.9125\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 98371, 1: 27061})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 350, 1: 9296, 6: 8}\n",
      "Test : Accuracy: 0.9230 Recall : 0.7417 FDR: 0.0129  F1-score: 0.8469  \n",
      "********** AE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0572 std: 0.3491\n",
      "Val: Accuracy: 0.8886  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.4063\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 97867, 1: 27565})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 353, 1: 8795, 6: 8}\n",
      "Test : Accuracy: 0.9270 Recall : 0.7556 FDR: 0.0128  F1-score: 0.8560  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.104\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99090, 1: 26342})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 350, 1: 10014, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.9173 Recall : 0.7217 FDR: 0.0133  F1-score: 0.8337  \n",
      "********** VAE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.4040 std: 1.1783\n",
      "Val: Accuracy: 0.8268  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.582\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 92178, 1: 33254})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6402, 1: 9155, 5: 1, 6: 7}\n",
      "Test : Accuracy: 0.8759 Recall : 0.7456 FDR: 0.1925  F1-score: 0.7753  \n",
      " K: 3 K-SIGMA Threshold : ---thr 3.939\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 110661, 1: 14771})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 3212, 1: 24424, 2: 1, 3: 1, 5: 2, 6: 27, 7: 1}\n",
      "Test : Accuracy: 0.7794 Recall : 0.3209 FDR: 0.2175  F1-score: 0.4552  \n"
     ]
    }
   ],
   "source": [
    "for scenario in {\"external\",\"compromised-scada\",\"compromised-ied\"}:\n",
    "    if scenario!=\"external\":\n",
    "        print(\"scenario :\",scenario,\"node ied1b\")\n",
    "        test_files= [col for col in modbus.dataset[\"attack_dataset_dir\"][scenario] if col.find(\"ied1b\")!=-1]\n",
    "    else:\n",
    "        print(\"scenario :\",scenario,\"node ied1a\")\n",
    "        test_files= [col for col in modbus.dataset[\"attack_dataset_dir\"][scenario] if col.find(\"ied1a\")!=-1]        \n",
    "\n",
    "    print(\"----------- benign valid files:\",len(val_files),val_files)\n",
    "    print(f\"----------{scenario} attack  test files : \",len(test_files),test_files)\n",
    "    val_dataloader=DataLoader(ModbusFlowStream(\n",
    "                shuffle=False,\n",
    "                chunk_size=100,\n",
    "                batch_size=64,\n",
    "                csv_files=val_files,\n",
    "                scalers=loaded_scalers['network-wide']['min_max_scalers'],\n",
    "            ),batch_size=1,shuffle=False)\n",
    "    test_dataloader=DataLoader(ModbusFlowStream(\n",
    "                shuffle=False,\n",
    "                chunk_size=100,\n",
    "                batch_size=64,\n",
    "                csv_files=test_files,\n",
    "                scalers=loaded_scalers['network-wide']['min_max_scalers'],\n",
    "            ),batch_size=1,shuffle=False)\n",
    "    for trained_model in {Trained_AE_model,Trained_VAE_model,Trained_AAE_model}:\n",
    "        print(\"*\"*10,trained_model._get_name(),10*\"*\")\n",
    "        train_eval(trained_model,None,val_dataloader,test_dataloader,shuffle_files=False,num_epochs=1,eval_epoch=1,criterion_method=\"mse\",train_model=False,learning_rates=[0],weight_decays=[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e10197",
   "metadata": {},
   "source": [
    "### FedAvg - non iid distribution (ip based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f948763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 1. SETUP: INSTALL LIBRARIES AND IMPORT DEPENDENCIES\n",
    "# ==============================================================================\n",
    "# In a Kaggle notebook, run this cell first to install the necessary libraries.\n",
    "# !pip install -q flwr[simulation] torch torchvision pandas scikit-learn matplotlib seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc049d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import flwr as fl\n",
    "from collections import OrderedDict\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import seaborn as sns\n",
    "import os \n",
    "from flwr.common import Context # Make sure this import is added\n",
    "import random\n",
    "# Suppress warning messages for a cleaner output\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "# Set a seed for reproducibility\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "#global device\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on {DEVICE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e80a446",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================================================================\n",
    "#  FEDERATED LEARNING CLIENT: FlowerClient\n",
    "# ==============================================================================\n",
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    \"\"\"Flower client for training.\"\"\"\n",
    "    def __init__(self, cid, model, trainloader):\n",
    "        self.cid = cid\n",
    "        self.model = model\n",
    "        self.train_dataloader = trainloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n",
    "\n",
    "    def set_parameters(self, parameters):\n",
    "        params_dict = zip(self.model.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "        self.model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        model =self.model\n",
    "        lr = cfg.LEARNING_RATE\n",
    "        wd= cfg.WEIGHT_DECAY\n",
    "        \n",
    "        criterion = nn.MSELoss(reduction='sum').to(DEVICE)\n",
    "        if model._get_name()==\"AdversarialAutoencoder\":\n",
    "            adversarial_criterion= nn.BCELoss(reduction=\"sum\")\n",
    "            optimizer_D = optim.Adam(model.discriminator.parameters(), lr=lr, weight_decay=wd)\n",
    "            optimizer_G =  optim.Adam(list(model.encoder.parameters()) + list(model.decoder.parameters()), lr=lr, weight_decay=wd)\n",
    "        else:\n",
    "            AE_optimizer = optim.Adam(model.parameters(), lr=lr,weight_decay=wd)\n",
    "\n",
    "        if cfg.STRATEGY == \"FED_PROX\":\n",
    "            global_params = [torch.tensor(p, device=DEVICE) for p in parameters]\n",
    "\n",
    "        for epoch in range(cfg.LOCAL_EPOCHS):\n",
    "                time_1 = time.time()\n",
    "                model.train()\n",
    "                train_loss = 0\n",
    "                ## for AAE\n",
    "                Discriminator_loss = 0\n",
    "                if cfg.SHUFFLE_FILES:\n",
    "                    sys_rand = SystemRandom()\n",
    "                    sys_rand.shuffle(self.train_dataloader.dataset.csv_files)\n",
    "                for sequences, _ in self.train_dataloader:\n",
    "                    sequences=sequences.squeeze().to(DEVICE)\n",
    "                    if model._get_name()==\"AdversarialAutoencoder\":\n",
    "                        target_ones= torch.ones(sequences.size(0), 1,device=DEVICE,dtype=torch.float)\n",
    "                        target_zeros= torch.zeros(sequences.size(0), 1,device=DEVICE,dtype=torch.float)\n",
    "                        random_latent = torch.randn(sequences.size(0), 2, device=DEVICE)\n",
    "                        optimizer_G.zero_grad()\n",
    "                        fake_z,decoded_seq = model(sequences)\n",
    "                        G_loss = 0.001*adversarial_criterion(model.discriminator(fake_z),target_ones ) + 0.999*criterion(decoded_seq, sequences)\n",
    "                        G_loss.backward()\n",
    "                        optimizer_G.step()\n",
    "                        # 2) discriminator loss\n",
    "                        optimizer_D.zero_grad()\n",
    "                        real_loss = adversarial_criterion(model.discriminator(random_latent), target_ones)\n",
    "                        fake_loss = adversarial_criterion(model.discriminator(fake_z.detach()),  target_zeros)\n",
    "                        D_loss =  0.001*0.5*(real_loss + fake_loss)\n",
    "                        D_loss.backward()\n",
    "                        optimizer_D.step()\n",
    "                        train_loss+=G_loss.item()\n",
    "                        Discriminator_loss+=D_loss.item()   \n",
    "                    else:\n",
    "                        AE_optimizer.zero_grad()\n",
    "                        if model._get_name()==\"AE\":\n",
    "                            recon = model(sequences)\n",
    "                            loss = criterion(recon, sequences) / sequences.size(0)\n",
    "                        elif model._get_name()==\"VAE\" or model._get_name()==\"GRUVAE\":\n",
    "                            recon, mu, logvar = model(sequences)\n",
    "                            loss = vae_loss_function(recon, sequences, mu, logvar) /sequences.size(0)\n",
    "                            if cfg.STRATEGY == \"FED_PROX\":\n",
    "                                proximal_term = 0.0\n",
    "                                for local_w, global_w in zip(model.parameters(), global_params):\n",
    "                                    proximal_term += (local_w - global_w).norm(2)\n",
    "                                loss += (cfg.PROXIMAL_MU / 2) * proximal_term\n",
    "                        loss.backward()\n",
    "                        AE_optimizer.step()\n",
    "                        train_loss += loss.item()\n",
    "                print(f\"Train : time {(time.time()-time_1):.2f} s\",\n",
    "                f\"Epoch {epoch+1}\")\n",
    "                if model._get_name()==\"AdversarialAutoencoder\":\n",
    "                    print(f\"Generator Loss: {train_loss / len(self.train_dataloader):.4f}\",\n",
    "                        f\"Discriminator Loss: {Discriminator_loss / len(self.train_dataloader):.4f}\")\n",
    "                else:\n",
    "                    print(f\"Train Loss: {train_loss / len(self.train_dataloader):.4f}\")\n",
    "        return self.get_parameters(config={}), len(self.train_dataloader.dataset), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        return 0.0, 0, {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34efffc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================================================================\n",
    "# 6. SERVER-SIDE LOGIC AND SIMULATION START\n",
    "# ==============================================================================\n",
    "def client_fn(context: Context) -> FlowerClient:\n",
    "    \"\"\"Create a Flower client instance for a given client ID.\"\"\"\n",
    "    # The client's ID is retrieved from the context.\n",
    "    client_id = int(context.node_config[\"partition-id\"])\n",
    "    model = get_model().to(DEVICE)\n",
    "    trainloader = load_data_from_id(client_id,\"client\")\n",
    "    return FlowerClient(client_id, model, trainloader).to_client()\n",
    "\n",
    "def get_evaluate_fn():\n",
    "    \"\"\"Return an evaluation function for server-side evaluation.\"\"\"\n",
    "    # val_dataloader = load_data_from_id(0,\"server\")\n",
    "    # test_dataloader = load_data_from_id(1,\"server\")\n",
    "    val_dataloader = load_data_from_id(0,\"server\")\n",
    "    test_dataloader = load_data_from_id(1,\"server\")\n",
    "    eval_criterion = nn.MSELoss(reduction='none').to(DEVICE)\n",
    "\n",
    "    def evaluate(\n",
    "        server_round: int,\n",
    "        parameters: fl.common.NDArrays,\n",
    "        config: Dict[str, fl.common.Scalar],\n",
    "    ) -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:\n",
    "        model = get_model() # Use the get_model function\n",
    "        params_dict = zip(model.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "        model.load_state_dict(state_dict, strict=True)\n",
    "        model.to(DEVICE)\n",
    "        model.eval()\n",
    "        # Evaluate part\n",
    "        all_val_losses = []\n",
    "        all_val_labels = []\n",
    "        print(f\"--- Running Evaluation for Server round {server_round} ---\")\n",
    "        with torch.no_grad():\n",
    "            for sequences, labels in val_dataloader:\n",
    "                sequences = sequences.squeeze().to(DEVICE) \n",
    "                if labels.sum()!=0:\n",
    "                    continue\n",
    "                if model._get_name()==\"AE\":\n",
    "                    recon = model(sequences)\n",
    "                elif model._get_name()==\"VAE\" or model._get_name()==\"GRUVAE\" :\n",
    "                    recon, _, _ = model(sequences)\n",
    "                elif model._get_name()==\"AdversarialAutoencoder\":\n",
    "                    _,recon= model(sequences)\n",
    "                val_loss = eval_criterion(recon, sequences)\n",
    "                if val_loss.dim() > 1:\n",
    "                    val_loss = val_loss\n",
    "                else:\n",
    "                    val_loss = val_loss.unsqueeze(dim=0)\n",
    "                    labels = labels.unsqueeze(dim=0)\n",
    "                if val_loss.dim()==3:\n",
    "                    ##GRU : mean of window\n",
    "                    val_loss = val_loss.mean(dim=1)\n",
    "                val_loss = val_loss.sum(dim=1)\n",
    "                all_val_losses.extend(val_loss.cpu().numpy())\n",
    "                all_val_labels.extend(labels.flatten().cpu().numpy())     \n",
    "        threshold_1,std_mse = compute_threshold(all_val_losses,k=0)\n",
    "\n",
    "        all_val_losses = np.array(all_val_losses).squeeze()  \n",
    "        all_val_labels = np.array(all_val_labels).squeeze()  \n",
    "        # If intrusion score > threshold, predict 1 (intrusion), else 0 (benign)\n",
    "        # For FDR, get True Positives (TP) and False Positives (FP)\n",
    "        \n",
    "        predictions = (all_val_losses > threshold_1).astype(int)\n",
    "\n",
    "        accuracy = accuracy_score(all_val_labels, predictions)\n",
    "        print(f\"Val: Accuracy: {accuracy:.4f}  \")\n",
    "        model.eval() \n",
    "\n",
    "        all_test_losses = []\n",
    "        all_test_labels = []\n",
    "        with torch.no_grad():\n",
    "            for sequences, labels in test_dataloader:\n",
    "                sequences = sequences.squeeze().to(DEVICE)\n",
    "                labels = labels.squeeze().to(DEVICE)\n",
    "                if model._get_name()==\"AE\":\n",
    "                    recon = model(sequences)\n",
    "                elif model._get_name()==\"VAE\"  or model._get_name()==\"GRUVAE\":\n",
    "                    recon, mu, logvar = model(sequences)\n",
    "                elif model._get_name()==\"AdversarialAutoencoder\":\n",
    "                    _,recon= model(sequences)\n",
    "\n",
    "                intrusion_scores = eval_criterion(recon, sequences)\n",
    "                if intrusion_scores.dim() > 1:\n",
    "                    intrusion_scores = intrusion_scores\n",
    "                else:\n",
    "                    intrusion_scores = intrusion_scores.unsqueeze(dim=0)\n",
    "                    labels = labels.unsqueeze(dim=0)\n",
    "                if intrusion_scores.dim()==3:\n",
    "                    ##GRU : mean of window\n",
    "                    intrusion_scores = intrusion_scores.mean(dim=1)\n",
    "                intrusion_scores = intrusion_scores.sum(dim=1)\n",
    "                all_test_losses.extend(intrusion_scores.cpu().numpy())\n",
    "                all_test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        all_test_losses = np.array(all_test_losses)\n",
    "        all_test_labels = np.array(all_test_labels)\n",
    "        test_result = {}\n",
    "        for k in {1,3}:\n",
    "            threshold=threshold_1+k*std_mse\n",
    "            print(f\" K: {k} K-SIGMA Threshold : ---thr {threshold:.4}\")\n",
    "            predictions = (all_test_losses > threshold).astype(int)\n",
    "            binary_test_labels = (all_test_labels != 0).astype(int)\n",
    "\n",
    "            # Find the indices where the prediction was incorrect\n",
    "            misclassified_indices = np.where(binary_test_labels != predictions)[0]\n",
    "\n",
    "            # Get the original labels for those misclassified instances\n",
    "            misclassified_original_labels = all_test_labels[misclassified_indices]\n",
    "\n",
    "            # To get a summary count of which labels were misclassified\n",
    "            print(\"Counts of : original binary labels\",Counter(binary_test_labels),\"predicted binary labels\",Counter(predictions))\n",
    "            print(f\"Counts of  original  labels: {dict(sorted(Counter(all_test_labels).items()))}\")\n",
    "            print(f\"Counts of misclassified original labels: {dict(sorted(Counter(misclassified_original_labels).items()))}\")\n",
    "            accuracy = accuracy_score(binary_test_labels, predictions)\n",
    "            f1 = f1_score(binary_test_labels, predictions, zero_division=0)\n",
    "            recall = recall_score(binary_test_labels, predictions,zero_division=0)\n",
    "            _, fp, _, tp = confusion_matrix(binary_test_labels, predictions, labels=[0, 1]).ravel()\n",
    "            # FDR = FP / (FP + TP) \n",
    "            if (fp + tp) == 0:\n",
    "                fdr = 0.0 \n",
    "            else:\n",
    "                fdr = fp / (fp + tp)\n",
    "            test_result[k] = f\"k= {k} ,Test : Accuracy: {accuracy:.4f} Recall : {recall:.4f} FDR: {fdr:.4f}  F1-score: {f1:.4f} \"\n",
    "            print(test_result[k])\n",
    "        return np.sum(all_test_losses)/len(all_test_losses),test_result\n",
    "    return evaluate\n",
    "\n",
    "def get_initial_parameters(model_name: str):\n",
    "    \"\"\"\n",
    "    Initializes the model weights using Xavier uniform distribution\n",
    "    and returns them as a Flower Parameters object.\n",
    "    \"\"\"\n",
    "    \n",
    "    temp_model = get_model()\n",
    "    for param in temp_model.parameters():\n",
    "        if param.dim() > 1:\n",
    "            nn.init.xavier_uniform_(param)\n",
    "            \n",
    "    ndarrays = [val.cpu().numpy() for _, val in temp_model.state_dict().items()]\n",
    "    return ndarrays_to_parameters(ndarrays)\n",
    "\n",
    "\n",
    "def load_data_from_id(id: int, node = \"client\" ):\n",
    "    \"\"\"Loads the data for a specific training client.\"\"\"\n",
    "    if node == \"client\":\n",
    "        file_list = TRAIN_CLIENT_DATA_MAPPING[id]\n",
    "        shuffle=cfg.SHUFFLE_FILES\n",
    "    else: # server\n",
    "        file_list = SERVER_EVALUATION_DATA_MAPPING[id]\n",
    "        shuffle = False\n",
    "\n",
    "    train_loader=DataLoader(ModbusFlowStream(\n",
    "            shuffle=shuffle,\n",
    "            chunk_size=1,\n",
    "            batch_size=cfg.BATCH_SIZE ,\n",
    "            csv_files=file_list,\n",
    "            scalers=loaded_scalers['network-wide']['min_max_scalers'],\n",
    "        ),batch_size=1,shuffle=False)\n",
    "    return train_loader\n",
    "def get_model():\n",
    "    \"\"\"Returns the model specified in the config.\"\"\"\n",
    "    if cfg.MODEL_NAME == \"VAE\":\n",
    "        print(f\"Using Variational Autoencoder (VAE) \")\n",
    "        return VAE(input_dim=cfg.INPUT_DIM)\n",
    "    elif cfg.MODEL_NAME == \"AE\":\n",
    "        print(f\"Using Autoencoder (AE) \")\n",
    "        return AE(input_dim=cfg.INPUT_DIM)\n",
    "    elif cfg.MODEL_NAME ==\"AdverserialAutoencoder\":\n",
    "        print(f\"Using Adverserial Autoencoder (AAE) \")\n",
    "        return AdverserialAutoencoder(input_dim=76)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model name: {cfg.MODEL_NAME}. Choose 'AE' or 'VAE' or 'AdverserialAutoencoder'.\")\n",
    "\n",
    "def set_server_strategy():\n",
    "    evaluate_function = get_evaluate_fn()\n",
    "\n",
    "    if cfg.STRATEGY == \"FED_PROX\":\n",
    "        strategy = fl.server.strategy.FedProx(\n",
    "            fraction_fit=1.0, fraction_evaluate=0.0,\n",
    "            min_fit_clients=cfg.NUM_TRAIN_CLIENTS,\n",
    "            min_available_clients=cfg.NUM_TRAIN_CLIENTS,\n",
    "            evaluate_fn=evaluate_function,\n",
    "            proximal_mu=cfg.PROXIMAL_MU,\n",
    "            initial_parameters=get_initial_parameters(cfg.MODEL_NAME)\n",
    "        )\n",
    "        print(\"Using FedProx strategy.\")\n",
    "    else:\n",
    "        strategy = fl.server.strategy.FedAvg(\n",
    "            fraction_fit=1.0, fraction_evaluate=0.0,\n",
    "            min_fit_clients=cfg.NUM_TRAIN_CLIENTS,\n",
    "            min_available_clients=cfg.NUM_TRAIN_CLIENTS,\n",
    "            evaluate_fn=evaluate_function,\n",
    "            initial_parameters=get_initial_parameters(cfg.MODEL_NAME)\n",
    "\n",
    "        )\n",
    "        print(f\"Using FedAvg strategy with {cfg.MODEL_NAME} model.\")\n",
    "    return strategy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bc0e13",
   "metadata": {},
   "source": [
    "#### External Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3219b1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================================================================\n",
    "#  DATA Distribution\n",
    "# ==============================================================================\n",
    "\n",
    "ied1b_train_files=[col for col in modbus.dataset[\"benign_dataset_dir\"] if col.find(\"ied1b\")!=-1][:]\n",
    "ied1a_train_files=[col for col in modbus.dataset[\"benign_dataset_dir\"] if col.find(\"ied1a\")!=-1][:]\n",
    "ied4c_train_files=[col for col in modbus.dataset[\"benign_dataset_dir\"] if col.find(\"ied4c\")!=-1][:]\n",
    "cent_agent_test_files=[col for col in modbus.dataset[\"benign_dataset_dir\"] if col.find(\"central-agent\")!=-1][:]\n",
    "test_files=[col for col in modbus.dataset[\"attack_dataset_dir\"][\"external\"] if col.find(\"ied1a\")!=-1][:]\n",
    "random.seed(42)\n",
    "val_files = []\n",
    "\n",
    "for list_files in [ied1b_train_files,ied1a_train_files,ied4c_train_files]: \n",
    "    random.shuffle(list_files)\n",
    "    val_files += list_files[-2:]\n",
    "TRAIN_CLIENT_DATA_MAPPING = {\n",
    "    0: ied1b_train_files[:-2],\n",
    "    1: ied1a_train_files[:-2],\n",
    "    2: ied4c_train_files[:-2],\n",
    "    3: cent_agent_test_files,\n",
    "}\n",
    "\n",
    "SERVER_EVALUATION_DATA_MAPPING = {\n",
    "    0: val_files,\n",
    "    1: test_files\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8580f738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " ['dataset/ModbusDataset/attack/external/ied1a/ied1a-network-capture/ready/veth4edc015-0-labeled.csv'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ied1b_train_files),len(TRAIN_CLIENT_DATA_MAPPING[0]),len(val_files),len(test_files),len(val_files),test_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69c2c487",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================================================================\n",
    "#  CONFIGURATION: TWEAK  FEDERATED LEARNING EXPERIMENT\n",
    "# ==============================================================================\n",
    "class Config:\n",
    "    \"\"\"Global configuration class for the federated learning experiment.\"\"\"\n",
    "    # --- FL Parameters ---\n",
    "    NUM_TRAIN_CLIENTS = 4\n",
    "    NUM_ROUNDS = 5\n",
    "    LOCAL_EPOCHS = 6\n",
    "    BATCH_SIZE = 64\n",
    "    LEARNING_RATE = 5e-6\n",
    "    WEIGHT_DECAY = 1e-4\n",
    "    # --- Strategy Selection ---\n",
    "    # Choose from \"FED_AVG\", \"FED_PROX\"\n",
    "    STRATEGY = \"FED_AVG\" \n",
    "    PROXIMAL_MU = 0.1 # Proximal term for FedProx\n",
    "    # --- Model Selection ---\n",
    "    # Choose from \"AE\" (Autoencoder) or \"VAE\" (Variational Autoencoder) or \"AdverserialAutoencoder\"\n",
    "    MODEL_NAME = \"AE\"\n",
    "    INPUT_DIM = 76\n",
    "    # --- Anomaly Detection ---\n",
    "    SHUFFLE_FILES=  True\n",
    "# Instantiate the configuration\n",
    "cfg = Config()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "635dab53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded scalers for 'network-wide'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n",
      "\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n",
      "\n",
      "\t\t$ flwr new  # Create a new Flower app from a template\n",
      "\n",
      "\t\t$ flwr run  # Run the Flower app in Simulation Mode\n",
      "\n",
      "\tUsing `start_simulation()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=5, no round_timeout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "Using FedAvg strategy with AE model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-19 03:05:27,384\tINFO worker.py:1771 -- Started a local Ray instance.\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'accelerator_type:G': 1.0, 'node:__internal_head__': 1.0, 'node:172.27.10.149': 1.0, 'CPU': 4.0, 'memory': 5312792987.0, 'object_store_memory': 2656396492.0, 'GPU': 1.0}\n",
      "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 4, 'num_gpus': 0.25}\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 1 actors\n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 0 ---\n",
      "-----------mse_loss mean :  17.2971 std: 1.2517\n",
      "Val: Accuracy: 0.1758  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 17.683918378085338, {1: 'k= 1 ,Test : Accuracy: 0.7553 Recall : 0.1989 FDR: 0.2041  F1-score: 0.3183 ', 3: 'k= 3 ,Test : Accuracy: 0.7353 Recall : 0.0783 FDR: 0.0028  F1-score: 0.1452 '}\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 18.55\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 116430, 1: 9002})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 1837, 1: 28822, 2: 1, 3: 1, 4: 1, 5: 2, 6: 22, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.7553 Recall : 0.1989 FDR: 0.2041  F1-score: 0.3183 \n",
      " K: 3 K-SIGMA Threshold : ---thr 21.05\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 122605, 1: 2827})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 8, 1: 33161, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7353 Recall : 0.0783 FDR: 0.0028  F1-score: 0.1452 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m /home/hamid_rd3/labeling/FLBased-ICS-NIDS-main/modbus.py:4: DeprecationWarning: \n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m (to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m but was not found to be installed on your system.\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m If this would cause problems for you,\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m   import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 47.40 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 7.2898\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 45.71 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.3945\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 43.80 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0520\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 46.87 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0215\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 44.90 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0115\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 45.98 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0086\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 30.70 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 9.7899\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 28.19 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.2479\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 30.14 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0077\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 29.39 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0063\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 30.50 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0058\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 31.80 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0049\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 1.02 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 14.3722\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 0.85 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 14.1403\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 0.75 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 13.8809\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 0.78 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 13.5828\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 0.83 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 13.2593\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 0.89 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 12.9032\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 52.27 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 6.5341\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 48.32 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.2284\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 52.93 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0369\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 56.54 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0139\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 53.29 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 55.71 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0065\n",
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 1 ---\n",
      "-----------mse_loss mean :  1.0142 std: 1.8592\n",
      "Val: Accuracy: 0.8598  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (1, 1.3123269729813765, {1: 'k= 1 ,Test : Accuracy: 0.6876 Recall : 0.0806 FDR: 0.6766  F1-score: 0.1291 ', 3: 'k= 3 ,Test : Accuracy: 0.7107 Recall : 0.0802 FDR: 0.5222  F1-score: 0.1373 '}, 810.8188390980004)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 2.873\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 116452, 1: 8980})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6076, 1: 33076, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.6876 Recall : 0.0806 FDR: 0.6766  F1-score: 0.1291 \n",
      " K: 3 K-SIGMA Threshold : ---thr 6.592\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 119387, 1: 6045})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 3157, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7107 Recall : 0.0802 FDR: 0.5222  F1-score: 0.1373 \n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 1.13 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 2.2397\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 1.26 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 1.7217\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 0.77 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 1.3590\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 1.18 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 1.1153\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 0.74 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.9533\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 0.74 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.8438\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 51.95 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0667\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 54.43 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0070\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 53.28 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0056\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 51.19 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0050\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 52.95 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0045\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 52.36 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0042\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 45.60 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0804\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 44.54 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0086\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 44.81 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0070\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 44.08 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0060\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 47.58 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0051\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 45.63 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0045\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 30.14 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0051\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 29.65 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0015\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 28.31 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0009\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 28.84 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0007\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 29.13 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 2 ---\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 30.90 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0006\n",
      "-----------mse_loss mean :  0.7481 std: 1.5452\n",
      "Val: Accuracy: 0.8682  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (2, 1.2198267786529753, {1: 'k= 1 ,Test : Accuracy: 0.8659 Recall : 0.7042 FDR: 0.1954  F1-score: 0.7510 ', 3: 'k= 3 ,Test : Accuracy: 0.7107 Recall : 0.0802 FDR: 0.5224  F1-score: 0.1373 '}, 1613.0008086840007)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 2.293\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 93912, 1: 31520})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6160, 1: 10634, 3: 1, 4: 1, 5: 2, 6: 16, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.8659 Recall : 0.7042 FDR: 0.1954  F1-score: 0.7510 \n",
      " K: 3 K-SIGMA Threshold : ---thr 5.384\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 119385, 1: 6047})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 3159, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7107 Recall : 0.0802 FDR: 0.5224  F1-score: 0.1373 \n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 56.67 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0350\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 54.37 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0047\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 56.49 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0041\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 56.68 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0038\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 52.14 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0035\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 54.34 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0033\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 47.06 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0410\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 43.11 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0055\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 48.58 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0046\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 43.73 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0041\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 41.01 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0038\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 44.73 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0036\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 29.70 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0027\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 27.43 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0006\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 26.42 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0005\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 29.44 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0005\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 26.73 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0005\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 27.24 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0005\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 0.77 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 1.7347\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 0.77 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 1.1192\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 0.77 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.7513\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 0.78 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.5846\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 0.79 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.5143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 3 ---\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 0.78 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.4787\n",
      "-----------mse_loss mean :  0.7112 std: 1.6287\n",
      "Val: Accuracy: 0.8686  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (3, 1.2047836427307226, {1: 'k= 1 ,Test : Accuracy: 0.8659 Recall : 0.7041 FDR: 0.1955  F1-score: 0.7510 ', 3: 'k= 3 ,Test : Accuracy: 0.7107 Recall : 0.0802 FDR: 0.5223  F1-score: 0.1373 '}, 2407.797428791)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 2.34\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 93912, 1: 31520})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6161, 1: 10635, 3: 1, 4: 1, 5: 2, 6: 16, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.8659 Recall : 0.7041 FDR: 0.1955  F1-score: 0.7510 \n",
      " K: 3 K-SIGMA Threshold : ---thr 5.597\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 119386, 1: 6046})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 3158, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7107 Recall : 0.0802 FDR: 0.5223  F1-score: 0.1373 \n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 27.05 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0019\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 28.17 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0005\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 26.69 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 26.68 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 26.43 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 27.22 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 48.63 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0329\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 45.80 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0038\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 45.69 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0034\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 46.63 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0031\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 45.35 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0030\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 45.60 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0029\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 0.82 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 1.7088\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 2.07 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 1.0856\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 0.78 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.6887\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 0.79 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.5160\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 0.85 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.4496\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 0.81 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.4203\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 41.15 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0397\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 39.90 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0042\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 40.18 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0036\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 40.69 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0034\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 40.62 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 4 ---\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 41.09 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0032\n",
      "-----------mse_loss mean :  0.6935 std: 1.6027\n",
      "Val: Accuracy: 0.8686  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (4, 1.1944146031315772, {1: 'k= 1 ,Test : Accuracy: 0.8659 Recall : 0.7041 FDR: 0.1957  F1-score: 0.7509 ', 3: 'k= 3 ,Test : Accuracy: 0.7107 Recall : 0.0802 FDR: 0.5223  F1-score: 0.1373 '}, 3120.5346355479996)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 2.296\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 93904, 1: 31528})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6169, 1: 10635, 3: 1, 4: 1, 5: 2, 6: 16, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.8659 Recall : 0.7041 FDR: 0.1957  F1-score: 0.7509 \n",
      " K: 3 K-SIGMA Threshold : ---thr 5.502\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 119386, 1: 6046})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 3158, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7107 Recall : 0.0802 FDR: 0.5223  F1-score: 0.1373 \n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 43.57 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0372\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 41.52 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0037\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 41.46 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0033\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 41.08 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0032\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 41.64 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0031\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 41.41 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0030\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 0.79 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 1.6909\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 0.81 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 1.0606\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 0.79 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.6564\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 0.86 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.4841\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 0.79 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.4217\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 0.78 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.3952\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 45.43 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0324\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 46.38 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0034\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 46.92 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0030\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 46.76 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0029\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 46.72 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0028\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 45.93 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0028\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 26.70 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0016\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 26.13 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 26.23 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 26.85 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 27.51 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 5 ---\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train : time 26.99 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=34128)\u001b[0m Train Loss: 0.0004\n",
      "-----------mse_loss mean :  0.6844 std: 1.5719\n",
      "Val: Accuracy: 0.8686  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (5, 1.187656210137764, {1: 'k= 1 ,Test : Accuracy: 0.8658 Recall : 0.7042 FDR: 0.1959  F1-score: 0.7508 ', 3: 'k= 3 ,Test : Accuracy: 0.7107 Recall : 0.0802 FDR: 0.5223  F1-score: 0.1373 '}, 3836.0523890839995)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 5 round(s) in 3836.05s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, centralized):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 0: 17.683918378085338\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 1.3123269729813765\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 1.2198267786529753\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 1.2047836427307226\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 4: 1.1944146031315772\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 5: 1.187656210137764\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, centralized):\n",
      "\u001b[92mINFO \u001b[0m:      \t{1: [(0,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.7553 Recall : 0.1989 FDR: 0.2041  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.3183 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (1,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.6876 Recall : 0.0806 FDR: 0.6766  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1291 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (2,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.8659 Recall : 0.7042 FDR: 0.1954  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.7510 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (3,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.8659 Recall : 0.7041 FDR: 0.1955  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.7510 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (4,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.8659 Recall : 0.7041 FDR: 0.1957  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.7509 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (5,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.8658 Recall : 0.7042 FDR: 0.1959  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.7508 ')],\n",
      "\u001b[92mINFO \u001b[0m:      \t 3: [(0,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7353 Recall : 0.0783 FDR: 0.0028  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1452 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (1,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7107 Recall : 0.0802 FDR: 0.5222  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1373 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (2,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7107 Recall : 0.0802 FDR: 0.5224  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1373 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (3,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7107 Recall : 0.0802 FDR: 0.5223  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1373 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (4,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7107 Recall : 0.0802 FDR: 0.5223  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1373 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (5,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7107 Recall : 0.0802 FDR: 0.5223  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1373 ')]}\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 2.256\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 93893, 1: 31539})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6178, 1: 10633, 3: 1, 4: 1, 5: 2, 6: 16, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.8658 Recall : 0.7042 FDR: 0.1959  F1-score: 0.7508 \n",
      " K: 3 K-SIGMA Threshold : ---thr 5.4\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 119386, 1: 6046})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 3158, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7107 Recall : 0.0802 FDR: 0.5223  F1-score: 0.1373 \n",
      "Federated learning simulation finished.\n"
     ]
    }
   ],
   "source": [
    "loaded_scalers = load_scalers(\"fitted_scalers\")\n",
    "\n",
    "strategy=set_server_strategy()\n",
    "\n",
    "history = fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=cfg.NUM_TRAIN_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=cfg.NUM_ROUNDS),\n",
    "    strategy=strategy,\n",
    "    client_resources={\"num_cpus\": 4, \"num_gpus\": 1/cfg.NUM_TRAIN_CLIENTS} if DEVICE.type == \"cuda\" else {\"num_cpus\": 4},\n",
    ")\n",
    "print(\"Federated learning simulation finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa5f6d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n",
      "\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n",
      "\n",
      "\t\t$ flwr new  # Create a new Flower app from a template\n",
      "\n",
      "\t\t$ flwr run  # Run the Flower app in Simulation Mode\n",
      "\n",
      "\tUsing `start_simulation()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=5, no round_timeout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "Using FedProx strategy.\n",
      "Starting federated learning simulation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-19 04:09:52,423\tINFO worker.py:1771 -- Started a local Ray instance.\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'accelerator_type:G': 1.0, 'node:__internal_head__': 1.0, 'node:172.27.10.149': 1.0, 'CPU': 4.0, 'object_store_memory': 2499013017.0, 'memory': 4998026036.0, 'GPU': 1.0}\n",
      "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 4, 'num_gpus': 0.25}\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 1 actors\n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 0 ---\n",
      "-----------mse_loss mean :  17.0171 std: 1.1466\n",
      "Val: Accuracy: 0.1758  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 17.429796622871358, {1: 'k= 1 ,Test : Accuracy: 0.7552 Recall : 0.2056 FDR: 0.2202  F1-score: 0.3255 ', 3: 'k= 3 ,Test : Accuracy: 0.7358 Recall : 0.0802 FDR: 0.0028  F1-score: 0.1484 '}\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 18.16\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 115935, 1: 9497})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2091, 1: 28587, 2: 1, 5: 1, 6: 19, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.7552 Recall : 0.2056 FDR: 0.2202  F1-score: 0.3255 \n",
      " K: 3 K-SIGMA Threshold : ---thr 20.46\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 122536, 1: 2896})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 8, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7358 Recall : 0.0802 FDR: 0.0028  F1-score: 0.1484 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m /home/hamid_rd3/labeling/FLBased-ICS-NIDS-main/modbus.py:4: DeprecationWarning: \n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m (to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m but was not found to be installed on your system.\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m If this would cause problems for you,\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m   import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 0.99 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 13.9353\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 0.76 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 13.7694\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 0.76 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 13.5751\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 0.75 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 13.3405\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 0.71 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 13.0580\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 0.75 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 12.7241\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 50.81 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 5.6319\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 48.09 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.1376\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 46.05 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0363\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 46.97 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0160\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 47.49 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0090\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 47.49 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0071\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 41.46 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 6.3388\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 41.17 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.2587\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 41.13 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0475\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 42.02 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0232\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 41.70 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0126\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 40.89 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0090\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 26.86 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 9.2836\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 27.55 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.1611\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 27.14 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0073\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 27.09 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0063\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 27.52 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 1 ---\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 27.17 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0048\n",
      "-----------mse_loss mean :  1.1629 std: 1.8153\n",
      "Val: Accuracy: 0.5563  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (1, 1.4607347008737803, {1: 'k= 1 ,Test : Accuracy: 0.6875 Recall : 0.0806 FDR: 0.6770  F1-score: 0.1291 ', 3: 'k= 3 ,Test : Accuracy: 0.7149 Recall : 0.0802 FDR: 0.4766  F1-score: 0.1391 '}, 729.6528542150008)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 2.978\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 116442, 1: 8990})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6086, 1: 33076, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.6875 Recall : 0.0806 FDR: 0.6770  F1-score: 0.1291 \n",
      " K: 3 K-SIGMA Threshold : ---thr 6.609\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 119914, 1: 5518})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2630, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7149 Recall : 0.0802 FDR: 0.4766  F1-score: 0.1391 \n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 27.57 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0072\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 27.32 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0038\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 27.43 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0026\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 27.34 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0011\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 27.84 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0007\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 27.03 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0006\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 46.70 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0794\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 47.68 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0079\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 47.68 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0065\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 46.69 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0057\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 47.27 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0052\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 47.38 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0046\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 41.73 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0898\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 41.79 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0094\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 41.85 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0076\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 40.83 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0063\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 41.01 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0055\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 41.78 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0049\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 0.77 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 1.9464\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 0.80 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 1.5669\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 0.80 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 1.3096\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 0.77 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 1.1293\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 0.79 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 1.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 2 ---\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 0.76 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.9105\n",
      "-----------mse_loss mean :  0.7053 std: 1.3334\n",
      "Val: Accuracy: 0.7363  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (2, 1.2181432220246826, {1: 'k= 1 ,Test : Accuracy: 0.8713 Recall : 0.7216 FDR: 0.1904  F1-score: 0.7631 ', 3: 'k= 3 ,Test : Accuracy: 0.7107 Recall : 0.0802 FDR: 0.5224  F1-score: 0.1373 '}, 1453.7703845659998)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 2.039\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 93328, 1: 32104})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6114, 1: 10016, 5: 1, 6: 8}\n",
      "k= 1 ,Test : Accuracy: 0.8713 Recall : 0.7216 FDR: 0.1904  F1-score: 0.7631 \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.705\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 119385, 1: 6047})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 3159, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7107 Recall : 0.0802 FDR: 0.5224  F1-score: 0.1373 \n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 26.40 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0036\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 27.25 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0018\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 27.22 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0006\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 27.43 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0005\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 26.96 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0005\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 26.61 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0005\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 40.45 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0387\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 40.53 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0054\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 41.22 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0045\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 40.95 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0040\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 40.56 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0037\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 40.84 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0034\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 47.43 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0333\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 46.63 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0047\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 47.77 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0040\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 46.32 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0036\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 46.26 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0033\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 46.83 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0031\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 0.84 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 1.3587\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 0.81 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.9013\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 0.79 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.7809\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 0.82 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.5901\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 0.78 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.5485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 3 ---\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 0.75 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.5222\n",
      "-----------mse_loss mean :  0.6993 std: 1.4781\n",
      "Val: Accuracy: 0.8686  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (3, 1.212109948019644, {1: 'k= 1 ,Test : Accuracy: 0.8695 Recall : 0.7169 FDR: 0.1930  F1-score: 0.7593 ', 3: 'k= 3 ,Test : Accuracy: 0.7107 Recall : 0.0802 FDR: 0.5224  F1-score: 0.1373 '}, 2168.046382519)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 2.177\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 93441, 1: 31991})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6173, 1: 10176, 3: 1, 4: 1, 5: 2, 6: 16, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.8695 Recall : 0.7169 FDR: 0.1930  F1-score: 0.7593 \n",
      " K: 3 K-SIGMA Threshold : ---thr 5.134\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 119385, 1: 6047})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 3159, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7107 Recall : 0.0802 FDR: 0.5224  F1-score: 0.1373 \n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 0.83 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 1.6256\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 0.78 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 1.0185\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 0.79 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.6473\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 0.84 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.4963\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 0.87 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.4430\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 0.79 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.4181\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 26.74 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0023\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 26.99 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0005\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 27.46 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 26.98 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 27.00 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 26.46 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 40.14 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0372\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 40.85 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0040\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 41.57 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0035\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 40.01 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0032\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 41.43 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0031\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 40.42 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0030\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 47.03 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0321\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 47.57 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0037\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 46.44 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0031\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 46.06 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0029\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 46.56 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 4 ---\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 47.39 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0027\n",
      "-----------mse_loss mean :  0.7036 std: 1.5761\n",
      "Val: Accuracy: 0.8687  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (4, 1.2126703861454813, {1: 'k= 1 ,Test : Accuracy: 0.8658 Recall : 0.7042 FDR: 0.1958  F1-score: 0.7509 ', 3: 'k= 3 ,Test : Accuracy: 0.7107 Recall : 0.0802 FDR: 0.5223  F1-score: 0.1373 '}, 2882.2340830430003)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 2.28\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 93898, 1: 31534})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6174, 1: 10634, 3: 1, 4: 1, 5: 2, 6: 16, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.8658 Recall : 0.7042 FDR: 0.1958  F1-score: 0.7509 \n",
      " K: 3 K-SIGMA Threshold : ---thr 5.432\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 119386, 1: 6046})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 3158, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7107 Recall : 0.0802 FDR: 0.5223  F1-score: 0.1373 \n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 28.02 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0017\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 27.53 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 26.79 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 26.59 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 26.45 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 27.74 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 46.67 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0328\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 45.60 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0032\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 45.36 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0028\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 46.43 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0027\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 45.98 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0026\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 46.83 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0025\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 40.23 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0376\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 40.17 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0036\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 41.04 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0031\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 40.24 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0030\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 41.10 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0029\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 40.98 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.0028\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 0.78 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 1.6331\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 0.76 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 1.0092\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 0.76 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.6201\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 0.75 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.4657\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 0.78 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.4131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 5 ---\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train : time 0.76 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=55095)\u001b[0m Train Loss: 0.3895\n",
      "-----------mse_loss mean :  0.7081 std: 1.6124\n",
      "Val: Accuracy: 0.8687  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (5, 1.2157158609844378, {1: 'k= 1 ,Test : Accuracy: 0.8661 Recall : 0.7041 FDR: 0.1950  F1-score: 0.7512 ', 3: 'k= 3 ,Test : Accuracy: 0.7107 Recall : 0.0802 FDR: 0.5223  F1-score: 0.1373 '}, 3592.424329331001)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 5 round(s) in 3592.43s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, centralized):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 0: 17.429796622871358\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 1.4607347008737803\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 1.2181432220246826\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 1.212109948019644\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 4: 1.2126703861454813\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 5: 1.2157158609844378\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, centralized):\n",
      "\u001b[92mINFO \u001b[0m:      \t{1: [(0,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.7552 Recall : 0.2056 FDR: 0.2202  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.3255 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (1,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.6875 Recall : 0.0806 FDR: 0.6770  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1291 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (2,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.8713 Recall : 0.7216 FDR: 0.1904  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.7631 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (3,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.8695 Recall : 0.7169 FDR: 0.1930  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.7593 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (4,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.8658 Recall : 0.7042 FDR: 0.1958  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.7509 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (5,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.8661 Recall : 0.7041 FDR: 0.1950  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.7512 ')],\n",
      "\u001b[92mINFO \u001b[0m:      \t 3: [(0,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7358 Recall : 0.0802 FDR: 0.0028  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1484 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (1,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7149 Recall : 0.0802 FDR: 0.4766  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1391 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (2,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7107 Recall : 0.0802 FDR: 0.5224  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1373 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (3,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7107 Recall : 0.0802 FDR: 0.5224  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1373 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (4,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7107 Recall : 0.0802 FDR: 0.5223  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1373 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (5,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7107 Recall : 0.0802 FDR: 0.5223  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1373 ')]}\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 2.321\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 93929, 1: 31503})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6144, 1: 10635, 3: 1, 4: 1, 5: 2, 6: 16, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.8661 Recall : 0.7041 FDR: 0.1950  F1-score: 0.7512 \n",
      " K: 3 K-SIGMA Threshold : ---thr 5.545\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 119386, 1: 6046})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 3158, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7107 Recall : 0.0802 FDR: 0.5223  F1-score: 0.1373 \n",
      "Federated learning simulation finished.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Instantiate the configuration\n",
    "cfg.STRATEGY=\"FED_PROX\"\n",
    "strategy=set_server_strategy()\n",
    "\n",
    "# --- Start the Simulation ---\n",
    "print(\"Starting federated learning simulation...\")\n",
    "history = fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=cfg.NUM_TRAIN_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=cfg.NUM_ROUNDS),\n",
    "    strategy=strategy,\n",
    "    client_resources={\"num_cpus\": 4, \"num_gpus\": 1/cfg.NUM_TRAIN_CLIENTS} if DEVICE.type == \"cuda\" else {\"num_cpus\": 4},\n",
    ")\n",
    "print(\"Federated learning simulation finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cb200f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n",
      "\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n",
      "\n",
      "\t\t$ flwr new  # Create a new Flower app from a template\n",
      "\n",
      "\t\t$ flwr run  # Run the Flower app in Simulation Mode\n",
      "\n",
      "\tUsing `start_simulation()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=5, no round_timeout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Variational Autoencoder (VAE) \n",
      "Using FedAvg strategy with VAE model.\n",
      "Starting federated learning simulation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-19 11:49:28,747\tINFO worker.py:1771 -- Started a local Ray instance.\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'accelerator_type:G': 1.0, 'node:__internal_head__': 1.0, 'node:172.27.10.149': 1.0, 'CPU': 4.0, 'memory': 4968510260.0, 'object_store_memory': 2484255129.0, 'GPU': 1.0}\n",
      "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 4, 'num_gpus': 0.25}\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 1 actors\n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Variational Autoencoder (VAE) \n",
      "--- Running Evaluation for Server round 0 ---\n",
      "-----------mse_loss mean :  17.3787 std: 1.3158\n",
      "Val: Accuracy: 0.3893  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 17.95997632183175, {1: 'k= 1 ,Test : Accuracy: 0.6667 Recall : 0.3488 FDR: 0.5937  F1-score: 0.3753 ', 3: 'k= 3 ,Test : Accuracy: 0.7302 Recall : 0.0617 FDR: 0.0190  F1-score: 0.1160 '}\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 18.69\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 94517, 1: 30915})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 18354, 1: 23431, 2: 1, 5: 1, 6: 20, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.6667 Recall : 0.3488 FDR: 0.5937  F1-score: 0.3753 \n",
      " K: 3 K-SIGMA Threshold : ---thr 21.33\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 123168, 1: 2264})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 43, 1: 33759, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7302 Recall : 0.0617 FDR: 0.0190  F1-score: 0.1160 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m /home/hamid_rd3/labeling/FLBased-ICS-NIDS-main/modbus.py:4: DeprecationWarning: \n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m (to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m but was not found to be installed on your system.\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m If this would cause problems for you,\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m   import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train : time 49.13 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train Loss: 0.3940\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train : time 41.60 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train Loss: 0.0082\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train : time 47.62 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train Loss: 0.0072\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train : time 48.89 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train Loss: 0.0072\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train : time 49.72 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train Loss: 0.0072\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train : time 49.00 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train Loss: 0.0072\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train : time 1.30 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train Loss: 9.7322\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train : time 1.21 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train Loss: 3.0435\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train : time 1.24 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train Loss: 2.3218\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train : time 1.36 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train Loss: 2.2058\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train : time 1.21 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train Loss: 2.1682\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train : time 1.17 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train Loss: 2.1454\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train : time 61.64 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train Loss: 2.1494\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train : time 74.15 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train Loss: 1.5117\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train : time 60.49 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train Loss: 1.4638\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train : time 61.51 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train Loss: 1.4549\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train : time 64.55 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train Loss: 1.4524\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train : time 71.72 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train Loss: 1.4492\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train : time 75.28 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train Loss: 2.0498\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train : time 76.76 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train Loss: 1.4874\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train : time 75.39 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train Loss: 1.4514\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train : time 74.65 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train Loss: 1.4470\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train : time 75.41 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train Loss: 1.4434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Variational Autoencoder (VAE) \n",
      "--- Running Evaluation for Server round 1 ---\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train : time 80.55 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train Loss: 1.4406\n",
      "-----------mse_loss mean :  2.1925 std: 2.7500\n",
      "Val: Accuracy: 0.6831  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (1, 2.340798699693858, {1: 'k= 1 ,Test : Accuracy: 0.6315 Recall : 0.1697 FDR: 0.7275  F1-score: 0.2091 ', 3: 'k= 3 ,Test : Accuracy: 0.7147 Recall : 0.0136 FDR: 0.3480  F1-score: 0.0266 '}, 1184.9336028059988)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 4.942\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 103009, 1: 22423})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 16312, 1: 29872, 3: 1, 4: 1, 5: 2, 6: 27, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.6315 Recall : 0.1697 FDR: 0.7275  F1-score: 0.2091 \n",
      " K: 3 K-SIGMA Threshold : ---thr 10.44\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 124682, 1: 750})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 261, 1: 35489, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7147 Recall : 0.0136 FDR: 0.3480  F1-score: 0.0266 \n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train : time 42.56 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train Loss: 0.0224\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train : time 44.92 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train Loss: 0.0072\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train : time 44.20 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train Loss: 0.0072\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train : time 40.78 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train Loss: 0.0072\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train : time 39.74 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train Loss: 0.0072\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train : time 43.40 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Train Loss: 0.0072\n",
      "\u001b[36m(ClientAppActor pid=144945)\u001b[0m Using Variational Autoencoder (VAE) \n"
     ]
    }
   ],
   "source": [
    "# Instantiate the configuration\n",
    "cfg.STRATEGY=\"FED_AVG\"\n",
    "cfg.MODEL_NAME=\"VAE\"\n",
    "cfg.LEARNING_RATE=1e-4\n",
    "strategy=set_server_strategy()\n",
    "\n",
    "# --- Start the Simulation ---\n",
    "print(\"Starting federated learning simulation...\")\n",
    "history = fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=cfg.NUM_TRAIN_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=cfg.NUM_ROUNDS),\n",
    "    strategy=strategy,\n",
    "    client_resources={\"num_cpus\": 4, \"num_gpus\": 1/cfg.NUM_TRAIN_CLIENTS} if DEVICE.type == \"cuda\" else {\"num_cpus\": 4},\n",
    ")\n",
    "print(\"Federated learning simulation finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b129e9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n",
      "\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n",
      "\n",
      "\t\t$ flwr new  # Create a new Flower app from a template\n",
      "\n",
      "\t\t$ flwr run  # Run the Flower app in Simulation Mode\n",
      "\n",
      "\tUsing `start_simulation()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=5, no round_timeout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Variational Autoencoder (VAE) \n",
      "Using FedProx strategy.\n",
      "Starting federated learning simulation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-19 06:33:58,518\tINFO worker.py:1771 -- Started a local Ray instance.\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'accelerator_type:G': 1.0, 'node:__internal_head__': 1.0, 'node:172.27.10.149': 1.0, 'CPU': 4.0, 'memory': 4974339687.0, 'object_store_memory': 2487169843.0, 'GPU': 1.0}\n",
      "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 4, 'num_gpus': 0.25}\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 1 actors\n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Variational Autoencoder (VAE) \n",
      "--- Running Evaluation for Server round 0 ---\n",
      "-----------mse_loss mean :  17.5264 std: 1.3967\n",
      "Val: Accuracy: 0.3374  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 17.9617741086804, {1: 'k= 1 ,Test : Accuracy: 0.7126 Recall : 0.2428 FDR: 0.5011  F1-score: 0.3267 ', 3: 'k= 3 ,Test : Accuracy: 0.7299 Recall : 0.0595 FDR: 0.0056  F1-score: 0.1123 '}\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 18.92\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 107901, 1: 17531})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 8785, 1: 27246, 2: 1, 3: 1, 5: 1, 6: 19, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.7126 Recall : 0.2428 FDR: 0.5011  F1-score: 0.3267 \n",
      " K: 3 K-SIGMA Threshold : ---thr 21.72\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 123277, 1: 2155})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 12, 1: 33837, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7299 Recall : 0.0595 FDR: 0.0056  F1-score: 0.1123 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m /home/hamid_rd3/labeling/FLBased-ICS-NIDS-main/modbus.py:4: DeprecationWarning: \n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m (to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m but was not found to be installed on your system.\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m If this would cause problems for you,\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m   import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 56.39 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 16.6742\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 54.48 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 12.5681\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 55.17 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 8.0639\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 54.15 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 4.2634\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 56.07 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.0001\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 56.49 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 0.9922\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 1.74 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 15.3243\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 1.67 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 15.2025\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 1.65 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 15.0819\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 1.61 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 14.9628\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 1.65 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 14.8509\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 1.65 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 14.7409\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 94.42 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 14.9884\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 96.88 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 8.8846\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 94.05 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 4.6468\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 96.35 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 3.3925\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 95.70 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 3.2042\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 94.51 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 3.1596\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 84.58 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 15.3591\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 80.76 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 9.9820\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 84.09 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 5.5567\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 83.62 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 3.6878\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 82.26 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 3.2753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Variational Autoencoder (VAE) \n",
      "--- Running Evaluation for Server round 1 ---\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 83.37 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 3.1980\n",
      "-----------mse_loss mean :  2.5232 std: 2.1351\n",
      "Val: Accuracy: 0.5864  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (1, 2.307689126379233, {1: 'k= 1 ,Test : Accuracy: 0.6453 Recall : 0.0802 FDR: 0.7973  F1-score: 0.1149 ', 3: 'k= 3 ,Test : Accuracy: 0.7069 Recall : 0.0033 FDR: 0.8803  F1-score: 0.0064 '}, 1441.1795395670015)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 4.658\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 111182, 1: 14250})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 11362, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.6453 Recall : 0.0802 FDR: 0.7973  F1-score: 0.1149 \n",
      " K: 3 K-SIGMA Threshold : ---thr 8.929\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 124446, 1: 986})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 868, 1: 35860, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7069 Recall : 0.0033 FDR: 0.8803  F1-score: 0.0064 \n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 1.63 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 7.1982\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 1.72 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 7.1200\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 1.91 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 7.0513\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 1.68 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 6.9802\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 1.65 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 6.9067\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 1.59 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 6.8357\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 83.77 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.8030\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 84.13 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.7486\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 82.94 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.7435\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 83.91 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.7414\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 82.83 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.7397\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 84.44 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.7387\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 53.51 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 0.5065\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 54.98 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 0.2095\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 53.70 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 0.1550\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 55.68 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 0.1405\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 52.54 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 0.1353\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 54.93 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 0.1333\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 95.00 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.7820\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 94.78 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.7341\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 97.41 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.7291\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 94.79 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.7273\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 95.69 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.7263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Variational Autoencoder (VAE) \n",
      "--- Running Evaluation for Server round 2 ---\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 96.43 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.7248\n",
      "-----------mse_loss mean :  2.4834 std: 2.2404\n",
      "Val: Accuracy: 0.5838  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (2, 2.249124027361439, {1: 'k= 1 ,Test : Accuracy: 0.6436 Recall : 0.0802 FDR: 0.8004  F1-score: 0.1144 ', 3: 'k= 3 ,Test : Accuracy: 0.7070 Recall : 0.0032 FDR: 0.8796  F1-score: 0.0063 '}, 2878.7669868440025)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 4.724\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 110962, 1: 14470})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 11582, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.6436 Recall : 0.0802 FDR: 0.8004  F1-score: 0.1144 \n",
      " K: 3 K-SIGMA Threshold : ---thr 9.205\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 124460, 1: 972})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 855, 1: 35861, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7070 Recall : 0.0032 FDR: 0.8796  F1-score: 0.0063 \n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 53.67 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 0.4079\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 55.34 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 0.1701\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 52.78 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 0.1290\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 54.68 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 0.1171\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 55.32 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 0.1122\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 53.75 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 0.1096\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 1.74 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 7.3449\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 1.74 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 7.2784\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 1.62 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 7.2013\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 1.62 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 7.1353\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 1.73 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 7.0740\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 1.69 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 7.0157\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 83.74 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.7590\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 83.51 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.7068\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 84.53 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.7037\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 82.90 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.7019\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 83.08 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.7002\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 83.08 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.6989\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 95.86 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.7359\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 95.60 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.6921\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 95.47 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.6882\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 96.54 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.6873\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 96.58 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.6871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Variational Autoencoder (VAE) \n",
      "--- Running Evaluation for Server round 3 ---\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 94.01 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.6859\n",
      "-----------mse_loss mean :  2.4708 std: 2.2550\n",
      "Val: Accuracy: 0.5836  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (3, 2.2344569667230054, {1: 'k= 1 ,Test : Accuracy: 0.6416 Recall : 0.0802 FDR: 0.8038  F1-score: 0.1139 ', 3: 'k= 3 ,Test : Accuracy: 0.7071 Recall : 0.0032 FDR: 0.8783  F1-score: 0.0063 '}, 4314.609747707)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 4.726\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 110715, 1: 14717})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 11829, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.6416 Recall : 0.0802 FDR: 0.8038  F1-score: 0.1139 \n",
      " K: 3 K-SIGMA Threshold : ---thr 9.236\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 124471, 1: 961})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 844, 1: 35861, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7071 Recall : 0.0032 FDR: 0.8783  F1-score: 0.0063 \n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 1.80 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 7.3820\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 1.66 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 7.3149\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 1.71 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 7.2402\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 1.77 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 7.1757\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 1.83 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 7.1073\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 1.86 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 7.0511\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 82.79 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.7450\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 84.09 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.6917\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 81.46 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.6891\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 85.00 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.6866\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 82.40 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.6858\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 83.79 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.6851\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 96.41 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.7213\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 97.51 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.6775\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 95.32 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.6753\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 97.47 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.6731\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 97.45 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.6716\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 96.04 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.6709\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 56.21 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 0.3893\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 54.67 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 0.1616\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 55.81 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 0.1230\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 55.86 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 0.1117\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 54.16 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 0.1063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Variational Autoencoder (VAE) \n",
      "--- Running Evaluation for Server round 4 ---\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 55.77 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 0.1034\n",
      "-----------mse_loss mean :  2.4655 std: 2.2706\n",
      "Val: Accuracy: 0.5843  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (4, 2.2303476684578096, {1: 'k= 1 ,Test : Accuracy: 0.6383 Recall : 0.0802 FDR: 0.8092  F1-score: 0.1129 ', 3: 'k= 3 ,Test : Accuracy: 0.7074 Recall : 0.0032 FDR: 0.8731  F1-score: 0.0063 '}, 5763.319144224002)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 4.736\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 110298, 1: 15134})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 12246, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.6383 Recall : 0.0802 FDR: 0.8092  F1-score: 0.1129 \n",
      " K: 3 K-SIGMA Threshold : ---thr 9.277\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 124510, 1: 922})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 805, 1: 35861, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7074 Recall : 0.0032 FDR: 0.8731  F1-score: 0.0063 \n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 1.70 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 7.3969\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 2.07 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 7.3316\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 1.76 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 7.2651\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 1.85 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 7.1932\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 1.73 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 7.1374\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 1.83 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 7.0670\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 95.33 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.7119\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 95.86 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.6670\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 94.90 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.6641\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 96.90 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.6625\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 96.67 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.6607\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 93.73 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.6601\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 85.60 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.7354\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 80.94 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.6819\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 85.56 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.6783\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 83.61 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.6760\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 83.96 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.6753\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 81.70 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 2.6732\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Using Variational Autoencoder (VAE) \n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 56.16 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 0.3748\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 54.49 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 0.1563\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 53.49 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 0.1199\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 57.56 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 0.1088\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 54.26 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 0.1034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Variational Autoencoder (VAE) \n",
      "--- Running Evaluation for Server round 5 ---\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train : time 54.10 s Epoch 6\n",
      "\u001b[36m(ClientAppActor pid=87520)\u001b[0m Train Loss: 0.1003\n",
      "-----------mse_loss mean :  2.4442 std: 2.2568\n",
      "Val: Accuracy: 0.5836  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (5, 2.21790990337394, {1: 'k= 1 ,Test : Accuracy: 0.6393 Recall : 0.0802 FDR: 0.8075  F1-score: 0.1132 ', 3: 'k= 3 ,Test : Accuracy: 0.7070 Recall : 0.0032 FDR: 0.8791  F1-score: 0.0063 '}, 7204.026053035002)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 5 round(s) in 7204.03s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, centralized):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 0: 17.9617741086804\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 2.307689126379233\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 2.249124027361439\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 2.2344569667230054\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 4: 2.2303476684578096\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 5: 2.21790990337394\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, centralized):\n",
      "\u001b[92mINFO \u001b[0m:      \t{1: [(0,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.7126 Recall : 0.2428 FDR: 0.5011  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.3267 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (1,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.6453 Recall : 0.0802 FDR: 0.7973  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1149 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (2,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.6436 Recall : 0.0802 FDR: 0.8004  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1144 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (3,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.6416 Recall : 0.0802 FDR: 0.8038  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1139 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (4,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.6383 Recall : 0.0802 FDR: 0.8092  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1129 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (5,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.6393 Recall : 0.0802 FDR: 0.8075  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1132 ')],\n",
      "\u001b[92mINFO \u001b[0m:      \t 3: [(0,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7299 Recall : 0.0595 FDR: 0.0056  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1123 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (1,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7069 Recall : 0.0033 FDR: 0.8803  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.0064 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (2,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7070 Recall : 0.0032 FDR: 0.8796  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.0063 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (3,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7071 Recall : 0.0032 FDR: 0.8783  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.0063 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (4,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7074 Recall : 0.0032 FDR: 0.8731  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.0063 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (5,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7070 Recall : 0.0032 FDR: 0.8791  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.0063 ')]}\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 4.701\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 110428, 1: 15004})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 12116, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.6393 Recall : 0.0802 FDR: 0.8075  F1-score: 0.1132 \n",
      " K: 3 K-SIGMA Threshold : ---thr 9.214\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 124464, 1: 968})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 851, 1: 35861, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7070 Recall : 0.0032 FDR: 0.8791  F1-score: 0.0063 \n",
      "Federated learning simulation finished.\n"
     ]
    }
   ],
   "source": [
    "cfg.STRATEGY=\"FED_PROX\"\n",
    "strategy=set_server_strategy()\n",
    "\n",
    "print(\"Starting federated learning simulation...\")\n",
    "history = fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=cfg.NUM_TRAIN_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=cfg.NUM_ROUNDS),\n",
    "    strategy=strategy,\n",
    "    client_resources={\"num_cpus\": 4, \"num_gpus\": 1/cfg.NUM_TRAIN_CLIENTS} if DEVICE.type == \"cuda\" else {\"num_cpus\": 4},\n",
    ")\n",
    "print(\"Federated learning simulation finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fad8408",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown model name: AAE. Choose 'AE' or 'VAE' or 'AdverserialAutoencoder'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m cfg\u001b[38;5;241m.\u001b[39mMODEL_NAME\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAAE\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m cfg\u001b[38;5;241m.\u001b[39mLEARNING_RATE\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m\n\u001b[0;32m----> 5\u001b[0m strategy\u001b[38;5;241m=\u001b[39m\u001b[43mset_server_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# --- Start the Simulation ---\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting federated learning simulation...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 195\u001b[0m, in \u001b[0;36mset_server_strategy\u001b[0;34m()\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing FedProx strategy.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     strategy \u001b[38;5;241m=\u001b[39m fl\u001b[38;5;241m.\u001b[39mserver\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mFedAvg(\n\u001b[1;32m    191\u001b[0m         fraction_fit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, fraction_evaluate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m,\n\u001b[1;32m    192\u001b[0m         min_fit_clients\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mNUM_TRAIN_CLIENTS,\n\u001b[1;32m    193\u001b[0m         min_available_clients\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mNUM_TRAIN_CLIENTS,\n\u001b[1;32m    194\u001b[0m         evaluate_fn\u001b[38;5;241m=\u001b[39mevaluate_function,\n\u001b[0;32m--> 195\u001b[0m         initial_parameters\u001b[38;5;241m=\u001b[39m\u001b[43mget_initial_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMODEL_NAME\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m \n\u001b[1;32m    197\u001b[0m     )\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing FedAvg strategy with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg\u001b[38;5;241m.\u001b[39mMODEL_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m model.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m strategy\n",
      "Cell \u001b[0;32mIn[8], line 136\u001b[0m, in \u001b[0;36mget_initial_parameters\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_initial_parameters\u001b[39m(model_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    131\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m    Initializes the model weights using Xavier uniform distribution\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m    and returns them as a Flower Parameters object.\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m     temp_model \u001b[38;5;241m=\u001b[39m \u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m temp_model\u001b[38;5;241m.\u001b[39mparameters():\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m param\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "Cell \u001b[0;32mIn[8], line 174\u001b[0m, in \u001b[0;36mget_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m AdverserialAutoencoder(input_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m76\u001b[39m)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown model name: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg\u001b[38;5;241m.\u001b[39mMODEL_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Choose \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAE\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVAE\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdverserialAutoencoder\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown model name: AAE. Choose 'AE' or 'VAE' or 'AdverserialAutoencoder'."
     ]
    }
   ],
   "source": [
    "# Instantiate the configuration\n",
    "cfg.STRATEGY=\"FED_AVG\"\n",
    "cfg.MODEL_NAME=\"AdverserialAutoencoder\"\n",
    "cfg.LEARNING_RATE=1e-4\n",
    "strategy=set_server_strategy()\n",
    "\n",
    "# --- Start the Simulation ---\n",
    "print(\"Starting federated learning simulation...\")\n",
    "history = fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=cfg.NUM_TRAIN_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=cfg.NUM_ROUNDS),\n",
    "    strategy=strategy,\n",
    "    client_resources={\"num_cpus\": 4, \"num_gpus\": 1/cfg.NUM_TRAIN_CLIENTS} if DEVICE.type == \"cuda\" else {\"num_cpus\": 4},\n",
    ")\n",
    "print(\"Federated learning simulation finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055eb90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the configuration\n",
    "cfg.STRATEGY=\"FED_PROX\"\n",
    "cfg.MODEL_NAME=\"AAE\"\n",
    "cfg.LEARNING_RATE=1e-4\n",
    "strategy=set_server_strategy()\n",
    "\n",
    "# --- Start the Simulation ---\n",
    "print(\"Starting federated learning simulation...\")\n",
    "history = fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=cfg.NUM_TRAIN_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=cfg.NUM_ROUNDS),\n",
    "    strategy=strategy,\n",
    "    client_resources={\"num_cpus\": 4, \"num_gpus\": 1/cfg.NUM_TRAIN_CLIENTS} if DEVICE.type == \"cuda\" else {\"num_cpus\": 4},\n",
    ")\n",
    "print(\"Federated learning simulation finished.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7758849,
     "sourceId": 12309500,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 250292947,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "vnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
