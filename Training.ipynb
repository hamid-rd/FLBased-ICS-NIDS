{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d32826f1-1369-4eb5-a21b-0e6e548cded3",
   "metadata": {},
   "source": [
    "### Download and make the dataset ready in Kaggle \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26c2ad5c-f43a-4b40-a647-ecc58c71ff16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T16:17:38.693282Z",
     "iopub.status.busy": "2025-07-13T16:17:38.692671Z",
     "iopub.status.idle": "2025-07-13T16:20:31.990912Z",
     "shell.execute_reply": "2025-07-13T16:20:31.990108Z",
     "shell.execute_reply.started": "2025-07-13T16:17:38.693248Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# ## uncomment if The zip file of the dataset isn't downloaded,extraced \n",
    "# !pip install gdown\n",
    "# Copy the link. The file ID is the long string of characters between d/ and /view.\n",
    "#For example, in the URL https://drive.google.com/file/d/1aBcDeFgHiJkLmNoPqRsTuVwXyZ/view?usp=sharing, \n",
    "#the file ID is 1aBcDeFgHiJkLmNoPqRsTuVwXyZ\n",
    "# !mkdir /kaggle/tmp\n",
    "# !gdown  1pzXpA5Cz0DJmjRsLxlqRNnJq-kOUvojb -O /kaggle/tmp/Labeled_CICMODBUS2023.zip\n",
    "# !unzip /kaggle/tmp/Labeled_CICMODBUS2023.zip -d /kaggle/working/\n",
    "\n",
    "# # ## uncomment if the python modules (modbus.py,utils.py ,...) not cloned  and added to the path \n",
    "\n",
    "# !git clone https://github.com/hamid-rd/FLBased-ICS-NIDS.git\n",
    "# import sys\n",
    "# # Add the repository folder to the Python path\n",
    "# repo_path = '/kaggle/working/FLBased-ICS-NIDS'\n",
    "# repo_input_path = '/kaggle/input/training/FLBased-ICS-NIDS'\n",
    "# dataset_path = '/kaggle/input/training/'\n",
    "\n",
    "# for path in {repo_path,repo_input_path,dataset_path}:\n",
    "#     if path not in sys.path:\n",
    "#         sys.path.append(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "601bb537-782e-4266-b619-48cdad4fe6a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T16:25:34.078617Z",
     "iopub.status.busy": "2025-07-13T16:25:34.077721Z",
     "iopub.status.idle": "2025-07-13T16:25:34.430103Z",
     "shell.execute_reply": "2025-07-13T16:25:34.429493Z",
     "shell.execute_reply.started": "2025-07-13T16:25:34.078584Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The CIC Modbus Dataset contains network (pcap) captures and attack logs from a simulated substation network.\n",
      "                The dataset is categorized into two groups: an attack dataset and a benign dataset\n",
      "                The attack dataset includes network traffic captures that simulate various types of Modbus protocol attacks in a substation environment.\n",
      "                The attacks are reconnaissance, query flooding, loading payloads, delay response, modify length parameters, false data injection, stacking Modbus frames, brute force write and baseline replay.\n",
      "                These attacks are based of some techniques in the MITRE ICS ATT&CK framework.\n",
      "                On the other hand, the benign dataset consists of normal network traffic captures representing legitimate Modbus communication within the substation network.\n",
      "                The purpose of this dataset is to facilitate research, analysis, and development of intrusion detection systems, anomaly detection algorithms and other security mechanisms for substation networks using the Modbus protocol.\n",
      "                https://www.unb.ca/cic/datasets/modbus-2023.html\n",
      "                In my custom PyTorch Dataset class,\n",
      "                I utilize the Enhanced CICflowMeter and the Attack logs correlation to extract and label sequential data flows,\n",
      "                preparing them for batch processing with the DataLoader, which is crucial for AI model training.\n",
      "                https://github.com/hamid-rd/FLBased-ICS-NIDS/tree/main\n",
      "\n",
      "                \n",
      "csv files  in the dataset directory founded with the filter:  ready\n",
      "{\n",
      "    \"total_dataset_num\": 170,\n",
      "    \"benign_dataset_num\": 62,\n",
      "    \"attack_dataset_num\": {\n",
      "        \"total_num\": 108,\n",
      "        \"external_num\": 8,\n",
      "        \"compromised-ied_num\": 43,\n",
      "        \"compromised-scada_num\": 57\n",
      "    },\n",
      "    \"attack_logs_num\": {\n",
      "        \"total_num\": 0,\n",
      "        \"external_num\": [],\n",
      "        \"compromised-ied_num\": 0,\n",
      "        \"compromised-scada_num\": 0\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# To test if every thing is okay (modbus.py class and correct number of founded csv files )\n",
    "from modbus import ModbusDataset,ModbusFlowStream\n",
    "\n",
    "# dataset_directory = \"/kaggle/working/ModbusDataset\" \n",
    "# dataset_directory = \"/kaggle/input/training/ModbusDataset\" \n",
    "dataset_directory = \"dataset\" \n",
    "\n",
    "modbus = ModbusDataset(dataset_directory,\"ready\")\n",
    "modbus.summary_print()\n",
    "\n",
    "# Don't forget to save version in kaggle (to save outputs written on the disk (/kaggle/working/))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d238262",
   "metadata": {},
   "source": [
    "### Unsupervised Autoencoder training  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2c01e06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T16:25:38.158958Z",
     "iopub.status.busy": "2025-07-13T16:25:38.158509Z",
     "iopub.status.idle": "2025-07-13T16:25:38.167563Z",
     "shell.execute_reply": "2025-07-13T16:25:38.166807Z",
     "shell.execute_reply.started": "2025-07-13T16:25:38.158938Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np # For standard deviation calculation\n",
    "from modbus import ModbusDataset,ModbusFlowStream\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix,recall_score\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "from utils import load_scalers\n",
    "from random import SystemRandom\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import torch.nn.init as init\n",
    "\n",
    "\n",
    "def compute_threshold(mse_values,k=1):\n",
    "\n",
    "    \"\"\"\n",
    "    K-SIGMA\n",
    "    Computes the anomaly detection threshold (for marking sample as Intrusion if the IS was greater )\n",
    "    based on the mean and standard deviation of Mean Squared Error (MSE) values.\n",
    "    Formula: thr = mean(MSE) + std(MSE)\n",
    "    Args:\n",
    "    mse_values (torch.Tensor or list/np.array): A tensor or list of MSE values\n",
    "\n",
    "                            obtained from the validation set.\n",
    "    Returns:\n",
    "    float: The calculated threshold.\n",
    "    float: The calculated std.\n",
    "\n",
    "    \"\"\"\n",
    "    if not isinstance(mse_values, torch.Tensor):\n",
    "        mse_values = torch.tensor(mse_values, dtype=torch.float32)\n",
    "    if mse_values.numel() == 0:\n",
    "        return 0.0\n",
    "    mean_mse = torch.mean(mse_values)\n",
    "    std_mse = torch.std(mse_values)\n",
    "    print(\"-----------mse_loss mean : \",f\"{mean_mse.item():.4f}\",\"std:\",f\"{std_mse.item():.4f}\")\n",
    "    threshold = mean_mse + k*std_mse\n",
    "    return threshold.item(),std_mse.item()\n",
    "\n",
    "def vae_loss_function(recon_x, x, mu, logvar,beta =1):\n",
    "    \"\"\"\n",
    "    VAE loss function.\n",
    "    \"\"\"\n",
    "    BCE = nn.functional.mse_loss(recon_x, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return (BCE + beta*KLD)\n",
    "\n",
    "def _init_weights( module):\n",
    "    ## for one layer apply Xavier Initialization\n",
    "    if isinstance(module, nn.Linear):\n",
    "        init.xavier_normal_(module.weight)\n",
    "        if module.bias is not None:\n",
    "            init.zeros_(module.bias)\n",
    "    return module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9478520",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T16:25:42.807302Z",
     "iopub.status.busy": "2025-07-13T16:25:42.807033Z",
     "iopub.status.idle": "2025-07-13T16:25:42.941019Z",
     "shell.execute_reply": "2025-07-13T16:25:42.940221Z",
     "shell.execute_reply.started": "2025-07-13T16:25:42.807283Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The CIC Modbus Dataset contains network (pcap) captures and attack logs from a simulated substation network.\n",
      "                The dataset is categorized into two groups: an attack dataset and a benign dataset\n",
      "                The attack dataset includes network traffic captures that simulate various types of Modbus protocol attacks in a substation environment.\n",
      "                The attacks are reconnaissance, query flooding, loading payloads, delay response, modify length parameters, false data injection, stacking Modbus frames, brute force write and baseline replay.\n",
      "                These attacks are based of some techniques in the MITRE ICS ATT&CK framework.\n",
      "                On the other hand, the benign dataset consists of normal network traffic captures representing legitimate Modbus communication within the substation network.\n",
      "                The purpose of this dataset is to facilitate research, analysis, and development of intrusion detection systems, anomaly detection algorithms and other security mechanisms for substation networks using the Modbus protocol.\n",
      "                https://www.unb.ca/cic/datasets/modbus-2023.html\n",
      "                In my custom PyTorch Dataset class,\n",
      "                I utilize the Enhanced CICflowMeter and the Attack logs correlation to extract and label sequential data flows,\n",
      "                preparing them for batch processing with the DataLoader, which is crucial for AI model training.\n",
      "                https://github.com/hamid-rd/FLBased-ICS-NIDS/tree/main\n",
      "\n",
      "                \n",
      "csv files  in the dataset directory founded with the filter:  ready\n",
      "{\n",
      "    \"total_dataset_num\": 170,\n",
      "    \"benign_dataset_num\": 62,\n",
      "    \"attack_dataset_num\": {\n",
      "        \"total_num\": 108,\n",
      "        \"external_num\": 8,\n",
      "        \"compromised-ied_num\": 43,\n",
      "        \"compromised-scada_num\": 57\n",
      "    },\n",
      "    \"attack_logs_num\": {\n",
      "        \"total_num\": 0,\n",
      "        \"external_num\": [],\n",
      "        \"compromised-ied_num\": 0,\n",
      "        \"compromised-scada_num\": 0\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# dataset_directory = \"/kaggle/input/training/ModbusDataset\" # change this to the folder contain benign and attack subdirs\n",
    "dataset_directory = \"dataset\" \n",
    "modbus = ModbusDataset(dataset_directory,\"ready\")\n",
    "modbus.summary_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dede4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# AutoEncoder (AE)\n",
    "class AE(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder: (89-64-32)\n",
    "    Decoder: (32-64-89)\n",
    "    \"\"\"\n",
    "    def __init__(self,input_dim=89):\n",
    "        super(AE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        x_recon = self.decoder(z)\n",
    "        return x_recon\n",
    "\n",
    "\n",
    "# Variational AutoEncoder (VAE)\n",
    "class VAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder: (89-64-64-32 for mu and log_var)\n",
    "    Decoder: (32-64-64-89)\n",
    "    return x_recon, mu, logvar\n",
    "    \"\"\"\n",
    "    def __init__(self,input_dim=89):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(64, 32)\n",
    "        self.fc_logvar = nn.Linear(64, 32)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, input_dim),\n",
    "            nn.Sigmoid()\n",
    "                    )\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu = self.fc_mu(h)\n",
    "        logvar = self.fc_logvar(h)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_recon = self.decoder(z)\n",
    "        return x_recon, mu, logvar\n",
    "\n",
    "    \n",
    "class AAE_Encoder(nn.Module):\n",
    "    def __init__(self,input_dim=76):\n",
    "        \"\"\"\n",
    "        Encoder(Generator):(89-16-4-2)\n",
    "        \"\"\"\n",
    "        super(AAE_Encoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 16),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(16, 4),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(4, 2))\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "class AAE_Decoder(nn.Module):\n",
    "    def __init__(self,input_dim=76):\n",
    "        super(AAE_Decoder, self).__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2, 4),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(4, 16),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(16, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.decoder(x)\n",
    "class AAE_Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AAE_Discriminator, self).__init__()\n",
    "        # corrected to 2-16-4-1\n",
    "        self.discriminator = nn.Sequential(\n",
    "            nn.Linear(2, 16),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(16, 4),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(4, 1), \n",
    "            nn.Sigmoid()\n",
    "        )    \n",
    "    def forward(self, x):\n",
    "        return self.discriminator(x)\n",
    " \n",
    "class AdversarialAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AdversarialAutoencoder, self).__init__()\n",
    "        self.encoder = AAE_Encoder()\n",
    "        self.decoder = AAE_Decoder()\n",
    "        self.discriminator = AAE_Discriminator()\n",
    "    def forward(self, x):\n",
    "        fake_z = self.encoder(x)\n",
    "        x_recon = self.decoder(fake_z)\n",
    "        return fake_z,x_recon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2d2e0ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T08:02:58.408647Z",
     "iopub.status.busy": "2025-07-13T08:02:58.407931Z",
     "iopub.status.idle": "2025-07-13T08:02:58.430831Z",
     "shell.execute_reply": "2025-07-13T08:02:58.430062Z",
     "shell.execute_reply.started": "2025-07-13T08:02:58.408625Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def train_eval(model,train_dataloader,val_dataloader,test_dataloader,learning_rates= [5e-6,1e-7,5e-5,1e-5,1e-6],\n",
    "               weight_decays=[1e-5,1e-4,1e-7],shuffle_files=True,num_epochs=20,eval_epoch=4,criterion_method=\"mse\", k_range=[1,3],train_model=True):\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model=model.to(device)\n",
    "    if criterion_method==\"bce\":\n",
    "        criterion = nn.BCELoss(reduction='sum').to(device)\n",
    "        eval_criterion = nn.BCELoss(reduction='none').to(device)\n",
    "    else: #mse\n",
    "        criterion = nn.MSELoss(reduction='sum').to(device)\n",
    "        eval_criterion = nn.MSELoss(reduction='none').to(device)\n",
    "    best_f1=0 #to save best version of the model during test\n",
    "    best_recall=0 #to save best version of the model during test\n",
    "\n",
    "    for lr, wd in itertools.product(learning_rates, weight_decays):\n",
    "        if model._get_name()==\"AdversarialAutoencoder\":\n",
    "            adversarial_criterion= nn.BCELoss(reduction=\"sum\")\n",
    "            optimizer_D = optim.SGD(model.discriminator.parameters(), lr=lr, weight_decay=wd)\n",
    "            optimizer_G =  optim.SGD(list(model.encoder.parameters()) + list(model.decoder.parameters()), lr=lr, weight_decay=wd)\n",
    "        else:\n",
    "            AE_optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "            ### new code\n",
    "            # AE_optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "        print(f\"\\n==================  lr={lr}, wd={wd} ==================\")\n",
    "        if train_model==True:\n",
    "            model.apply(_init_weights)\n",
    "        for epoch in range(num_epochs):\n",
    "            if train_model==True:\n",
    "                time_1 = time.time()\n",
    "                model.train()\n",
    "                train_loss = 0\n",
    "                ## for AAE\n",
    "                Discriminator_loss = 0\n",
    "                if shuffle_files:\n",
    "                    sys_rand = SystemRandom()\n",
    "                    sys_rand.shuffle(train_dataloader.dataset.csv_files)\n",
    "                for sequences, labels in train_dataloader:\n",
    "                    sequences=sequences.squeeze().to(device)\n",
    "                    if labels.sum()!=0:\n",
    "                        continue\n",
    "                    if model._get_name()==\"AdversarialAutoencoder\":\n",
    "                        target_ones= torch.ones(sequences.size(0), 1,device=device,dtype=torch.float)\n",
    "                        target_zeros= torch.zeros(sequences.size(0), 1,device=device,dtype=torch.float)\n",
    "                        random_latent = torch.randn(sequences.size(0), 2, device=device)\n",
    "                        optimizer_G.zero_grad()\n",
    "                        fake_z,decoded_seq = model(sequences)\n",
    "                        G_loss = 0.001*adversarial_criterion(model.discriminator(fake_z),target_ones ) + 0.999*criterion(decoded_seq, sequences)\n",
    "                        G_loss.backward()\n",
    "                        optimizer_G.step()\n",
    "                        # 2) discriminator loss\n",
    "                        optimizer_D.zero_grad()\n",
    "                        real_loss = adversarial_criterion(model.discriminator(random_latent), target_ones)\n",
    "                        fake_loss = adversarial_criterion(model.discriminator(fake_z.detach()),  target_zeros)\n",
    "                        D_loss = 0.5*(real_loss + fake_loss)\n",
    "                        D_loss.backward()\n",
    "                        optimizer_D.step()\n",
    "                        train_loss+=G_loss.item()\n",
    "                        Discriminator_loss+=D_loss.item()   \n",
    "                    else:\n",
    "                        AE_optimizer.zero_grad()\n",
    "                        if model._get_name()==\"AE\":\n",
    "                            recon = model(sequences)\n",
    "                            loss = criterion(recon, sequences) / sequences.size(0)\n",
    "                        elif model._get_name()==\"VAE\" or model._get_name()==\"GRUVAE\":\n",
    "                            recon, mu, logvar = model(sequences)\n",
    "                            loss = vae_loss_function(recon, sequences, mu, logvar) /sequences.size(0)\n",
    "                        loss.backward()\n",
    "                        AE_optimizer.step()\n",
    "                        train_loss += loss.item()\n",
    "                print(f\"Train : time {(time.time()-time_1):.2f} s\",\n",
    "                f\"Epoch {epoch+1}\")\n",
    "                if model._get_name()==\"AdversarialAutoencoder\":\n",
    "                    print(f\"Generator Loss: {train_loss / len(train_dataloader):.4f}\",\n",
    "                        f\"Discriminator Loss: {Discriminator_loss / len(train_dataloader):.4f}\")\n",
    "                else:\n",
    "                    print(f\"Train Loss: {train_loss / len(train_dataloader):.4f}\")\n",
    "            # Evaluate part\n",
    "            if (epoch + 1) % eval_epoch == 0:\n",
    "                model.eval() \n",
    "                all_val_losses = []\n",
    "                all_val_labels = []\n",
    "                print(f\"--- Running Evaluation for Epoch {epoch+1} lr ={lr} wd {wd} ---\")\n",
    "                with torch.no_grad():\n",
    "                    for sequences, labels in val_dataloader:\n",
    "                        sequences = sequences.squeeze().to(device) \n",
    "                        if labels.sum()!=0:\n",
    "                            continue\n",
    "                        if criterion_method==\"bce\":\n",
    "                            ## may test features be greater than 1 after scaling \n",
    "                            sequences=torch.clamp(sequences, min=0.0, max=1.0)      \n",
    "                        if model._get_name()==\"AE\":\n",
    "                            recon = model(sequences)\n",
    "                        elif model._get_name()==\"VAE\" or model._get_name()==\"GRUVAE\" :\n",
    "                            recon, _, _ = model(sequences)\n",
    "                        elif model._get_name()==\"AdversarialAutoencoder\":\n",
    "                            _,recon= model(sequences)\n",
    "                        val_loss = eval_criterion(recon, sequences)\n",
    "                        if val_loss.dim() > 1:\n",
    "                            val_loss = val_loss\n",
    "                        else:\n",
    "                            val_loss = val_loss.unsqueeze(dim=0)\n",
    "                            labels = labels.unsqueeze(dim=0)\n",
    "                        if val_loss.dim()==3:\n",
    "                            ##GRU : mean of window\n",
    "                            val_loss = val_loss.mean(dim=1)\n",
    "                        val_loss = val_loss.sum(dim=1)\n",
    "                        all_val_losses.extend(val_loss.cpu().numpy())\n",
    "                        all_val_labels.extend(labels.flatten().cpu().numpy())     \n",
    "                threshold_1,std_mse = compute_threshold(all_val_losses,k=0)\n",
    "\n",
    "                all_val_losses = np.array(all_val_losses).squeeze()  \n",
    "                all_val_labels = np.array(all_val_labels).squeeze()  \n",
    "                # If intrusion score > threshold, predict 1 (intrusion), else 0 (benign)\n",
    "                # For FDR, get True Positives (TP) and False Positives (FP)\n",
    "                \n",
    "                predictions = (all_val_losses > threshold_1).astype(int)\n",
    "\n",
    "                accuracy = accuracy_score(all_val_labels, predictions)\n",
    "                print(f\"Val: Accuracy: {accuracy:.4f}  \")\n",
    "                model.eval() \n",
    "                all_test_losses = []\n",
    "                all_test_labels = []\n",
    "                with torch.no_grad():\n",
    "                    for sequences, labels in test_dataloader:\n",
    "                        sequences = sequences.squeeze().to(device)\n",
    "                        labels = labels.squeeze().to(device)\n",
    "                        if criterion_method==\"bce\":\n",
    "                            ## may test features be greater than 1 after scaling \n",
    "                            sequences=torch.clamp(sequences, min=0.0, max=1.0)\n",
    "                        if model._get_name()==\"AE\":\n",
    "                            recon = model(sequences)\n",
    "                        elif model._get_name()==\"VAE\"  or model._get_name()==\"GRUVAE\":\n",
    "                            recon, mu, logvar = model(sequences)\n",
    "                        elif model._get_name()==\"AdversarialAutoencoder\":\n",
    "                            _,recon= model(sequences)\n",
    "\n",
    "                        intrusion_scores = eval_criterion(recon, sequences)\n",
    "                        if intrusion_scores.dim() > 1:\n",
    "                            intrusion_scores = intrusion_scores\n",
    "                        else:\n",
    "                            intrusion_scores = intrusion_scores.unsqueeze(dim=0)\n",
    "                            labels = labels.unsqueeze(dim=0)\n",
    "                        if intrusion_scores.dim()==3:\n",
    "                            ##GRU : mean of window\n",
    "                            intrusion_scores = intrusion_scores.mean(dim=1)\n",
    "                        intrusion_scores = intrusion_scores.sum(dim=1)\n",
    "                        all_test_losses.extend(intrusion_scores.cpu().numpy())\n",
    "                        all_test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "                all_test_losses = np.array(all_test_losses)\n",
    "                all_test_labels = np.array(all_test_labels)\n",
    "                temp_best_recall =best_recall\n",
    "                temp_best_f1 =best_f1\n",
    "\n",
    "                for k in k_range:\n",
    "                    threshold=threshold_1+k*std_mse\n",
    "                    print(f\" K: {k} K-SIGMA Threshold : ---thr {threshold:.4}\")\n",
    "                    predictions = (all_test_losses > threshold).astype(int)\n",
    "                    binary_test_labels = (all_test_labels != 0).astype(int)\n",
    "\n",
    "                    # Find the indices where the prediction was incorrect\n",
    "                    misclassified_indices = np.where(binary_test_labels != predictions)[0]\n",
    "\n",
    "                    # Get the original labels for those misclassified instances\n",
    "                    misclassified_original_labels = all_test_labels[misclassified_indices]\n",
    "\n",
    "                    # To get a summary count of which labels were misclassified\n",
    "                    print(Counter(predictions),Counter(binary_test_labels))\n",
    "                    print(f\"Counts of  labels: {dict(sorted(Counter(all_test_labels).items()))}\")\n",
    "                    print(f\"Counts of misclassified original labels: {dict(sorted(Counter(misclassified_original_labels).items()))}\")\n",
    "                    accuracy = accuracy_score(binary_test_labels, predictions)\n",
    "                    f1 = f1_score(binary_test_labels, predictions, zero_division=0)\n",
    "                    recall = recall_score(binary_test_labels, predictions,zero_division=0)\n",
    "                    _, fp, _, tp = confusion_matrix(binary_test_labels, predictions, labels=[0, 1]).ravel()\n",
    "                    # FDR = FP / (FP + TP) \n",
    "                    if (fp + tp) == 0:\n",
    "                        fdr = 0.0 \n",
    "                    else:\n",
    "                        fdr = fp / (fp + tp)\n",
    "                    print(f\"Test : Accuracy: {accuracy:.4f} Recall : {recall:.4f} FDR: {fdr:.4f}  F1-score: {f1:.4f}  \")\n",
    "                    !mkdir best_models -p\n",
    "                    if f1>best_f1 :\n",
    "                        best_f1=f1\n",
    "                    if recall>best_recall:\n",
    "                        best_recall=recall\n",
    "                if (best_recall>temp_best_recall or best_f1 > temp_best_f1):\n",
    "                    if train_model==True:\n",
    "                        save_path =\"best_models/\"+model._get_name()+\"_f1_\"+f\"{best_f1:.2f}\" +\"_recall_\"+f\"{best_recall:.2f}\" +\"_.pth\"\n",
    "                        torch.save(model.state_dict(),save_path)\n",
    "                        print(\"model\",model._get_name(),\"is saved in\" ,save_path )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfeeeaf",
   "metadata": {},
   "source": [
    "#### Centralized : external scenario -> ied1a node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db440aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ied1b comp ied attack ->\n",
      " test:  1 ['dataset/ModbusDataset/attack/external/ied1a/ied1a-network-capture/ready/veth4edc015-0-labeled.csv']\n",
      "----------- Network-wide number of csv files -> \n",
      " ----------- train : 19 ['dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-21-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-16-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-27-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-18-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-25-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-28-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-31-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-17-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-29-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-26-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-14-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-19-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-32-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-22-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-15-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-24-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-30-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-20-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-23-labeled.csv'] \n",
      " -------- valid: 8 ['dataset/ModbusDataset/benign/ied1a/ied1a-network-capture/ready/veth4edc015-normal-6-labeled.csv', 'dataset/ModbusDataset/benign/ied1a/ied1a-network-capture/ready/veth4edc015-normal-8-labeled.csv', 'dataset/ModbusDataset/benign/ied1a/ied1a-network-capture/ready/veth4edc015-normal-11-labeled.csv', 'dataset/ModbusDataset/benign/ied1a/ied1a-network-capture/ready/veth4edc015-normal-7-labeled.csv', 'dataset/ModbusDataset/benign/ied1a/ied1a-network-capture/ready/veth4edc015-normal-5-labeled.csv', 'dataset/ModbusDataset/benign/ied1a/ied1a-network-capture/ready/veth4edc015-normal-10-labeled.csv', 'dataset/ModbusDataset/benign/ied1a/ied1a-network-capture/ready/veth4edc015-normal-9-labeled.csv', 'dataset/ModbusDataset/benign/ied1a/ied1a-network-capture/ready/veth4edc015-normal-4-labeled.csv']\n"
     ]
    }
   ],
   "source": [
    "# train_files=[col for col in modbus.dataset[\"benign_dataset_dir\"] if col.find(\"network-wide\")!=-1]\n",
    "train_files=[col for col in modbus.dataset[\"benign_dataset_dir\"] if col.find(\"network-wide\")!=-1][:]\n",
    "val_files = [col for col in modbus.dataset[\"benign_dataset_dir\"] if col.find(\"ied1a\")!=-1][:]\n",
    "test_files=[col for col in modbus.dataset[\"attack_dataset_dir\"][\"external\"] if col.find(\"ied1a\")!=-1]\n",
    "sys_rand = SystemRandom()\n",
    "\n",
    "sys_rand.shuffle(train_files)\n",
    "sys_rand.shuffle(val_files)\n",
    "sys_rand.shuffle(test_files)\n",
    "\n",
    "\n",
    "print(\"ied1b comp ied attack ->\\n test: \",len(test_files),test_files)\n",
    "print(\"----------- Network-wide number of csv files -> \\n ----------- train :\",len(train_files),train_files,\"\\n -------- valid:\",len(val_files),val_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb2505cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded scalers for 'network-wide'\n"
     ]
    }
   ],
   "source": [
    "### Try The Copy-on-Write (CoW) technique, share the same single copy of the dataset in memory with multiple forked workers from the main process\n",
    "# Ensure to have enough memory for saving large tensors in the ram \n",
    "###### else use chunk_size =1 and read the files iteratively\n",
    "\n",
    "use_cow=False\n",
    "window_size=1\n",
    "loaded_scalers=load_scalers('fitted_scalers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eac4698b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T08:12:06.828444Z",
     "iopub.status.busy": "2025-07-13T08:12:06.827779Z",
     "iopub.status.idle": "2025-07-13T08:12:07.034947Z",
     "shell.execute_reply": "2025-07-13T08:12:07.034115Z",
     "shell.execute_reply.started": "2025-07-13T08:12:06.828415Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# This cell Initializes and returns train, validation, and test dataloaders.\n",
    "\n",
    "# This function supports two strategies for data loading:\n",
    "# 1. Copy-on-Write (use_cow=True): Loads the entire dataset into RAM. This is fast\n",
    "#     but memory-intensive. It allows multiple worker processes to share the same\n",
    "#     dataset copy in memory, which is efficient for multiprocessing.\n",
    "# 2. Iterative (use_cow=False): Reads data from files in small chunks. This is\n",
    "#     slower but uses significantly less memory, suitable for very large datasets\n",
    "#     that don't fit in RAM.\n",
    "\n",
    "#     train_files (list): List of file paths for the training dataset.\n",
    "#     val_files (list): List of file paths for the validation dataset.\n",
    "#     test_files (list): List of file paths for the test dataset.\n",
    "#     window_size (int): The size of the sliding window for sequence data.\n",
    "#     use_cow (bool, optional): If True, uses the Copy-on-Write strategy. \n",
    "#                                 Defaults to True.\n",
    "\n",
    "#      return        (train_dataloader, val_dataloader, test_dataloader)\n",
    "\n",
    "if use_cow==True:\n",
    "    large_chunk_size = modbus.dataset[\"metadata\"][\"founded_files_num\"][\"total_dataset_num\"]\n",
    "\n",
    "    dataset_configs = {\n",
    "        \"train\": {\"files\": train_files},\n",
    "        \"val\": {\"files\": val_files},\n",
    "        \"test\": {\"files\": test_files},\n",
    "    }\n",
    "    datasets = {}\n",
    "    ae_datasets = {}\n",
    "\n",
    "    print(\"Cow Processing datasets...\")\n",
    "\n",
    "    for name, config in dataset_configs.items():\n",
    "        print(f\"  - Creating '{name}' dataset...\")\n",
    "        \n",
    "        # 1. Create the primary ModbusFlowStream dataset\n",
    "        datasets[name] = ModbusFlowStream(\n",
    "            shuffle=False,\n",
    "            chunk_size=large_chunk_size,\n",
    "            batch_size=1,\n",
    "            csv_files=config[\"files\"],\n",
    "            scalers=loaded_scalers['network-wide']['min_max_scalers'],\n",
    "            window_size=window_size\n",
    "        )\n",
    "        \n",
    "        # 2. Call __getitem__(0) once to load the entire dataset chunk into memory\n",
    "        datasets[name].__getitem__(0)\n",
    "        \n",
    "        # used for specific AE training/evaluation without re-reading files.\n",
    "        ae_datasets[name] = ModbusFlowStream(\n",
    "            shuffle=False,  # AE data is typically processed in order\n",
    "            chunk_size=large_chunk_size,\n",
    "            batch_size=1,\n",
    "            csv_files=[],  # No CSV files needed as we copy the data directly\n",
    "            scalers=None,   # Data is already scaled from the original dataset\n",
    "            window_size=window_size\n",
    "        )\n",
    "        \n",
    "        # 4. Manually copy the loaded data and properties to the AE dataset\n",
    "\n",
    "        ae_datasets[name].current_chunk_data =  datasets[name].current_chunk_data\n",
    "        ae_datasets[name].current_len_chunk_data =  datasets[name].current_len_chunk_data\n",
    "        ae_datasets[name].current_chunk_labels =  datasets[name].current_chunk_labels\n",
    "        ae_datasets[name].total_batches =  datasets[name].total_batches\n",
    "        \n",
    "        print(f\"  - Finished '{name}' dataset.\")\n",
    "    train_dataloader=DataLoader(ae_datasets['train'],batch_size=64,shuffle=True,num_workers=4,persistent_workers=True,prefetch_factor=2,pin_memory=True)\n",
    "    val_dataloader=DataLoader(ae_datasets['val'],batch_size=64,shuffle=False,num_workers=4,persistent_workers=True,prefetch_factor=2,pin_memory=True)\n",
    "    test_dataloader=DataLoader(ae_datasets['test'],batch_size=64,shuffle=False,num_workers=4,persistent_workers=True,prefetch_factor=2,pin_memory=True)\n",
    "\n",
    "else :\n",
    "    train_dataloader=DataLoader(ModbusFlowStream( \n",
    "        shuffle=True,chunk_size=1,batch_size=64,csv_files=train_files,scalers=loaded_scalers['network-wide']['min_max_scalers'],window_size=window_size\n",
    "    ),  batch_size=1,shuffle=False)\n",
    "    val_dataloader=DataLoader(ModbusFlowStream( \n",
    "        shuffle=False,chunk_size=1,batch_size=64,csv_files=val_files,scalers=loaded_scalers['network-wide']['min_max_scalers'],window_size=window_size\n",
    "    ),batch_size=1,shuffle=False)\n",
    "    test_dataloader=DataLoader(ModbusFlowStream(shuffle=False,chunk_size=1,batch_size=64,csv_files=test_files,scalers=loaded_scalers['network-wide']['min_max_scalers'],window_size=window_size),\n",
    "                               batch_size=1,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69406aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44111 19158 1960\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataloader),len(val_dataloader),len(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e82123e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================  lr=5e-05, wd=0.0001 ==================\n",
      "Train : time 163.55 s Epoch 1\n",
      "Train Loss: 0.2204\n",
      "--- Running Evaluation for Epoch 1 lr =5e-05 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0031 std: 0.0626\n",
      "Val: Accuracy: 0.9751  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.06569\n",
      "Counter({1: 65686, 0: 59746}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29808, 1: 137}\n",
      "Test : Accuracy: 0.7613 Recall : 0.9962 FDR: 0.4538  F1-score: 0.7056  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.1908\n",
      "Counter({1: 65565, 0: 59867}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29715, 1: 165}\n",
      "Test : Accuracy: 0.7618 Recall : 0.9954 FDR: 0.4532  F1-score: 0.7058  \n",
      "model AE is saved in best_models/AE_f1_0.71_recall_1.00_.pth\n",
      "Train : time 174.78 s Epoch 2\n",
      "Train Loss: 0.0026\n",
      "--- Running Evaluation for Epoch 2 lr =5e-05 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0026 std: 0.0561\n",
      "Val: Accuracy: 0.9753  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.05864\n",
      "Counter({1: 65711, 0: 59721}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29812, 1: 116}\n",
      "Test : Accuracy: 0.7614 Recall : 0.9968 FDR: 0.4537  F1-score: 0.7058  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.1708\n",
      "Counter({1: 65561, 0: 59871}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29711, 1: 165}\n",
      "Test : Accuracy: 0.7618 Recall : 0.9954 FDR: 0.4532  F1-score: 0.7059  \n",
      "model AE is saved in best_models/AE_f1_0.71_recall_1.00_.pth\n",
      "Train : time 171.34 s Epoch 3\n",
      "Train Loss: 0.0025\n",
      "--- Running Evaluation for Epoch 3 lr =5e-05 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0025 std: 0.0556\n",
      "Val: Accuracy: 0.9753  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.05811\n",
      "Counter({1: 65710, 0: 59722}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29811, 1: 116}\n",
      "Test : Accuracy: 0.7614 Recall : 0.9968 FDR: 0.4537  F1-score: 0.7058  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.1694\n",
      "Counter({1: 65558, 0: 59874}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29708, 1: 165}\n",
      "Test : Accuracy: 0.7618 Recall : 0.9954 FDR: 0.4532  F1-score: 0.7059  \n",
      "model AE is saved in best_models/AE_f1_0.71_recall_1.00_.pth\n",
      "Train : time 177.66 s Epoch 4\n",
      "Train Loss: 0.0024\n",
      "--- Running Evaluation for Epoch 4 lr =5e-05 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0024 std: 0.0552\n",
      "Val: Accuracy: 0.9754  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.05764\n",
      "Counter({1: 65712, 0: 59720}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29813, 1: 116}\n",
      "Test : Accuracy: 0.7614 Recall : 0.9968 FDR: 0.4537  F1-score: 0.7058  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.1681\n",
      "Counter({1: 65554, 0: 59878}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29704, 1: 165}\n",
      "Test : Accuracy: 0.7619 Recall : 0.9954 FDR: 0.4531  F1-score: 0.7059  \n",
      "model AE is saved in best_models/AE_f1_0.71_recall_1.00_.pth\n",
      "Train : time 171.83 s Epoch 5\n",
      "Train Loss: 0.0024\n",
      "--- Running Evaluation for Epoch 5 lr =5e-05 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0024 std: 0.0551\n",
      "Val: Accuracy: 0.9755  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.05744\n",
      "Counter({1: 65711, 0: 59721}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29812, 1: 116}\n",
      "Test : Accuracy: 0.7614 Recall : 0.9968 FDR: 0.4537  F1-score: 0.7058  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.1676\n",
      "Counter({1: 65552, 0: 59880}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29702, 1: 165}\n",
      "Test : Accuracy: 0.7619 Recall : 0.9954 FDR: 0.4531  F1-score: 0.7059  \n",
      "model AE is saved in best_models/AE_f1_0.71_recall_1.00_.pth\n",
      "Train : time 182.10 s Epoch 6\n",
      "Train Loss: 0.0024\n",
      "--- Running Evaluation for Epoch 6 lr =5e-05 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0024 std: 0.0551\n",
      "Val: Accuracy: 0.9754  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.05741\n",
      "Counter({1: 65703, 0: 59729}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29804, 1: 116}\n",
      "Test : Accuracy: 0.7615 Recall : 0.9968 FDR: 0.4536  F1-score: 0.7059  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.1675\n",
      "Counter({1: 65554, 0: 59878}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29704, 1: 165}\n",
      "Test : Accuracy: 0.7619 Recall : 0.9954 FDR: 0.4531  F1-score: 0.7059  \n",
      "\n",
      "==================  lr=0.0001, wd=0.0001 ==================\n",
      "Train : time 179.37 s Epoch 1\n",
      "Train Loss: 0.1122\n",
      "--- Running Evaluation for Epoch 1 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0026 std: 0.0541\n",
      "Val: Accuracy: 0.9753  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.05669\n",
      "Counter({1: 65673, 0: 59759}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29812, 1: 154}\n",
      "Test : Accuracy: 0.7611 Recall : 0.9957 FDR: 0.4539  F1-score: 0.7053  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.1648\n",
      "Counter({1: 65580, 0: 59852}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29730, 1: 165}\n",
      "Test : Accuracy: 0.7617 Recall : 0.9954 FDR: 0.4533  F1-score: 0.7057  \n",
      "Train : time 162.05 s Epoch 2\n",
      "Train Loss: 0.0019\n",
      "--- Running Evaluation for Epoch 2 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0023 std: 0.0511\n",
      "Val: Accuracy: 0.9754  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.05343\n",
      "Counter({1: 65672, 0: 59760}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29811, 1: 154}\n",
      "Test : Accuracy: 0.7611 Recall : 0.9957 FDR: 0.4539  F1-score: 0.7053  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.1556\n",
      "Counter({1: 65584, 0: 59848}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29734, 1: 165}\n",
      "Test : Accuracy: 0.7616 Recall : 0.9954 FDR: 0.4534  F1-score: 0.7057  \n",
      "Train : time 161.43 s Epoch 3\n",
      "Train Loss: 0.0017\n",
      "--- Running Evaluation for Epoch 3 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0022 std: 0.0487\n",
      "Val: Accuracy: 0.9754  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.05093\n",
      "Counter({1: 65688, 0: 59744}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29820, 1: 147}\n",
      "Test : Accuracy: 0.7611 Recall : 0.9959 FDR: 0.4540  F1-score: 0.7053  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.1483\n",
      "Counter({1: 65582, 0: 59850}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29732, 1: 165}\n",
      "Test : Accuracy: 0.7616 Recall : 0.9954 FDR: 0.4534  F1-score: 0.7057  \n",
      "Train : time 163.25 s Epoch 4\n",
      "Train Loss: 0.0017\n",
      "--- Running Evaluation for Epoch 4 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0022 std: 0.0468\n",
      "Val: Accuracy: 0.9691  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.04908\n",
      "Counter({1: 65693, 0: 59739}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29824, 1: 146}\n",
      "Test : Accuracy: 0.7611 Recall : 0.9959 FDR: 0.4540  F1-score: 0.7053  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.1428\n",
      "Counter({1: 65578, 0: 59854}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29728, 1: 165}\n",
      "Test : Accuracy: 0.7617 Recall : 0.9954 FDR: 0.4533  F1-score: 0.7058  \n",
      "Train : time 160.82 s Epoch 5\n",
      "Train Loss: 0.0016\n",
      "--- Running Evaluation for Epoch 5 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0022 std: 0.0466\n",
      "Val: Accuracy: 0.9755  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.04876\n",
      "Counter({1: 65695, 0: 59737}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29824, 1: 144}\n",
      "Test : Accuracy: 0.7611 Recall : 0.9960 FDR: 0.4540  F1-score: 0.7054  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.1419\n",
      "Counter({1: 65574, 0: 59858}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29724, 1: 165}\n",
      "Test : Accuracy: 0.7617 Recall : 0.9954 FDR: 0.4533  F1-score: 0.7058  \n",
      "Train : time 161.55 s Epoch 6\n",
      "Train Loss: 0.0016\n",
      "--- Running Evaluation for Epoch 6 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0021 std: 0.0450\n",
      "Val: Accuracy: 0.9754  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.04719\n",
      "Counter({1: 65698, 0: 59734}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29822, 1: 139}\n",
      "Test : Accuracy: 0.7611 Recall : 0.9961 FDR: 0.4539  F1-score: 0.7054  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.1373\n",
      "Counter({1: 65584, 0: 59848}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29734, 1: 165}\n",
      "Test : Accuracy: 0.7616 Recall : 0.9954 FDR: 0.4534  F1-score: 0.7057  \n",
      "\n",
      "==================  lr=1e-05, wd=0.0001 ==================\n",
      "Train : time 161.90 s Epoch 1\n",
      "Train Loss: 1.0142\n",
      "--- Running Evaluation for Epoch 1 lr =1e-05 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0083 std: 0.1267\n",
      "Val: Accuracy: 0.9544  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.135\n",
      "Counter({1: 65648, 0: 59784}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29794, 1: 161}\n",
      "Test : Accuracy: 0.7612 Recall : 0.9955 FDR: 0.4538  F1-score: 0.7054  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.3885\n",
      "Counter({0: 99255, 1: 26177}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 184, 1: 10014, 6: 8}\n",
      "Test : Accuracy: 0.9186 Recall : 0.7217 FDR: 0.0070  F1-score: 0.8359  \n",
      "model AE is saved in best_models/AE_f1_0.84_recall_1.00_.pth\n",
      "Train : time 161.67 s Epoch 2\n",
      "Train Loss: 0.0046\n",
      "--- Running Evaluation for Epoch 2 lr =1e-05 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0051 std: 0.1041\n",
      "Val: Accuracy: 0.9645  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.1091\n",
      "Counter({1: 65624, 0: 59808}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29772, 1: 163}\n",
      "Test : Accuracy: 0.7613 Recall : 0.9955 FDR: 0.4537  F1-score: 0.7055  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.3173\n",
      "Counter({0: 63776, 1: 61656}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 27154, 1: 1513}\n",
      "Test : Accuracy: 0.7715 Recall : 0.9580 FDR: 0.4404  F1-score: 0.7065  \n",
      "Train : time 162.36 s Epoch 3\n",
      "Train Loss: 0.0035\n",
      "--- Running Evaluation for Epoch 3 lr =1e-05 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0044 std: 0.0941\n",
      "Val: Accuracy: 0.9753  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.09849\n",
      "Counter({1: 65628, 0: 59804}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29772, 1: 159}\n",
      "Test : Accuracy: 0.7614 Recall : 0.9956 FDR: 0.4536  F1-score: 0.7055  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.2867\n",
      "Counter({1: 65530, 0: 59902}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29683, 1: 168}\n",
      "Test : Accuracy: 0.7620 Recall : 0.9953 FDR: 0.4530  F1-score: 0.7060  \n",
      "Train : time 162.12 s Epoch 4\n",
      "Train Loss: 0.0032\n",
      "--- Running Evaluation for Epoch 4 lr =1e-05 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0039 std: 0.0811\n",
      "Val: Accuracy: 0.9755  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.08498\n",
      "Counter({1: 65647, 0: 59785}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29785, 1: 153}\n",
      "Test : Accuracy: 0.7613 Recall : 0.9958 FDR: 0.4537  F1-score: 0.7055  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.2472\n",
      "Counter({1: 65544, 0: 59888}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29695, 1: 166}\n",
      "Test : Accuracy: 0.7619 Recall : 0.9954 FDR: 0.4531  F1-score: 0.7060  \n",
      "Train : time 161.58 s Epoch 5\n",
      "Train Loss: 0.0029\n",
      "--- Running Evaluation for Epoch 5 lr =1e-05 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0033 std: 0.0686\n",
      "Val: Accuracy: 0.9755  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.07192\n",
      "Counter({1: 65665, 0: 59767}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29794, 1: 144}\n",
      "Test : Accuracy: 0.7613 Recall : 0.9960 FDR: 0.4537  F1-score: 0.7056  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.2091\n",
      "Counter({1: 65568, 0: 59864}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29718, 1: 165}\n",
      "Test : Accuracy: 0.7618 Recall : 0.9954 FDR: 0.4532  F1-score: 0.7058  \n",
      "Train : time 162.15 s Epoch 6\n",
      "Train Loss: 0.0027\n",
      "--- Running Evaluation for Epoch 6 lr =1e-05 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0030 std: 0.0614\n",
      "Val: Accuracy: 0.9754  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.0644\n",
      "Counter({1: 65683, 0: 59749}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29802, 1: 134}\n",
      "Test : Accuracy: 0.7613 Recall : 0.9963 FDR: 0.4537  F1-score: 0.7056  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.1873\n",
      "Counter({1: 65574, 0: 59858}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29724, 1: 165}\n",
      "Test : Accuracy: 0.7617 Recall : 0.9954 FDR: 0.4533  F1-score: 0.7058  \n",
      "\n",
      "==================  lr=1e-06, wd=0.0001 ==================\n",
      "Train : time 161.77 s Epoch 1\n",
      "Train Loss: 10.1483\n",
      "--- Running Evaluation for Epoch 1 lr =1e-06 wd 0.0001 ---\n",
      "-----------mse_loss mean :  3.2309 std: 1.6270\n",
      "Val: Accuracy: 0.4993  \n",
      " K: 1 K-SIGMA Threshold : ---thr 4.858\n",
      "Counter({0: 118057, 1: 7375}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 4487, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.7001 Recall : 0.0802 FDR: 0.6084  F1-score: 0.1331  \n",
      " K: 3 K-SIGMA Threshold : ---thr 8.112\n",
      "Counter({0: 123544, 1: 1888}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 1618, 1: 35708, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Test : Accuracy: 0.7021 Recall : 0.0075 FDR: 0.8570  F1-score: 0.0142  \n",
      "Train : time 162.11 s Epoch 2\n",
      "Train Loss: 1.5494\n",
      "--- Running Evaluation for Epoch 2 lr =1e-06 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.8414 std: 1.4347\n",
      "Val: Accuracy: 0.8450  \n",
      " K: 1 K-SIGMA Threshold : ---thr 2.276\n",
      "Counter({0: 116201, 1: 9231}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6327, 1: 33076, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.6856 Recall : 0.0806 FDR: 0.6854  F1-score: 0.1284  \n",
      " K: 3 K-SIGMA Threshold : ---thr 5.145\n",
      "Counter({0: 120194, 1: 5238}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2350, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.7172 Recall : 0.0802 FDR: 0.4486  F1-score: 0.1400  \n",
      "Train : time 162.57 s Epoch 3\n",
      "Train Loss: 0.3442\n",
      "--- Running Evaluation for Epoch 3 lr =1e-06 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.1821 std: 0.4975\n",
      "Val: Accuracy: 0.7249  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.6796\n",
      "Counter({0: 96750, 1: 28682}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2689, 1: 10014, 6: 8}\n",
      "Test : Accuracy: 0.8987 Recall : 0.7217 FDR: 0.0938  F1-score: 0.8035  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.675\n",
      "Counter({0: 99104, 1: 26328}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 336, 1: 10014, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.9174 Recall : 0.7217 FDR: 0.0128  F1-score: 0.8338  \n",
      "Train : time 161.78 s Epoch 4\n",
      "Train Loss: 0.0902\n",
      "--- Running Evaluation for Epoch 4 lr =1e-06 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0743 std: 0.3823\n",
      "Val: Accuracy: 0.8269  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.4566\n",
      "Counter({0: 99088, 1: 26344}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 351, 1: 10014, 6: 8}\n",
      "Test : Accuracy: 0.9173 Recall : 0.7217 FDR: 0.0133  F1-score: 0.8337  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.221\n",
      "Counter({0: 99090, 1: 26342}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 350, 1: 10014, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.9173 Recall : 0.7217 FDR: 0.0133  F1-score: 0.8337  \n",
      "Train : time 162.60 s Epoch 5\n",
      "Train Loss: 0.0541\n",
      "--- Running Evaluation for Epoch 5 lr =1e-06 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0438 std: 0.2805\n",
      "Val: Accuracy: 0.9093  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.3243\n",
      "Counter({1: 65730, 0: 59702}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29881, 1: 166}\n",
      "Test : Accuracy: 0.7605 Recall : 0.9954 FDR: 0.4546  F1-score: 0.7047  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.8852\n",
      "Counter({0: 99090, 1: 26342}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 350, 1: 10014, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.9173 Recall : 0.7217 FDR: 0.0133  F1-score: 0.8337  \n",
      "Train : time 162.11 s Epoch 6\n",
      "Train Loss: 0.0352\n",
      "--- Running Evaluation for Epoch 6 lr =1e-06 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0268 std: 0.2090\n",
      "Val: Accuracy: 0.9380  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.2358\n",
      "Counter({1: 65737, 0: 59695}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29884, 1: 162}\n",
      "Test : Accuracy: 0.7605 Recall : 0.9955 FDR: 0.4546  F1-score: 0.7047  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.6538\n",
      "Counter({0: 99088, 1: 26344}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 351, 1: 10014, 6: 8}\n",
      "Test : Accuracy: 0.9173 Recall : 0.7217 FDR: 0.0133  F1-score: 0.8337  \n"
     ]
    }
   ],
   "source": [
    "# train_eval(AE_model,AE_train_dataloader,AE_val_dataloader,AE_test_dataloader,shuffle_files=True,num_epochs=20,eval_epoch=1,criterion_method=\"bce\",learning_rates=[5e-4],weight_decays=[0])\n",
    "AE_model = AE(input_dim=76)\n",
    "train_eval(AE_model,train_dataloader,val_dataloader,test_dataloader,shuffle_files=False,num_epochs=6,eval_epoch=1,criterion_method=\"mse\",learning_rates=[5e-5,1e-4,1e-5,1e-6],weight_decays=[1e-4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29df511f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================  lr=0.01, wd=0.0001 ==================\n",
      "Train : time 214.81 s Epoch 1\n",
      "Train Loss: 1.3880\n",
      "--- Running Evaluation for Epoch 1 lr =0.01 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.5267 std: 1.3753\n",
      "Val: Accuracy: 0.8128  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.902\n",
      "Counter({0: 94388, 1: 31044}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 4751, 1: 9713, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8846 Recall : 0.7301 FDR: 0.1530  F1-score: 0.7842  \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.653\n",
      "Counter({0: 119349, 1: 6083}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2430, 1: 32327, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.7226 Recall : 0.1014 FDR: 0.3995  F1-score: 0.1735  \n",
      "model VAE is saved in best_models/VAE_f1_0.78_recall_0.73_.pth\n",
      "Train : time 213.60 s Epoch 2\n",
      "Train Loss: 1.3741\n",
      "--- Running Evaluation for Epoch 2 lr =0.01 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.3784 std: 1.0960\n",
      "Val: Accuracy: 0.8162  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.474\n",
      "Counter({0: 95378, 1: 30054}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 3847, 1: 9800, 5: 1, 6: 7}\n",
      "Test : Accuracy: 0.8911 Recall : 0.7277 FDR: 0.1280  F1-score: 0.7933  \n",
      " K: 3 K-SIGMA Threshold : ---thr 3.666\n",
      "Counter({0: 120423, 1: 5009}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 1649, 1: 32621, 2: 1, 3: 1, 4: 1, 5: 2, 6: 28, 7: 1}\n",
      "Test : Accuracy: 0.7265 Recall : 0.0933 FDR: 0.3292  F1-score: 0.1638  \n",
      "model VAE is saved in best_models/VAE_f1_0.79_recall_0.73_.pth\n",
      "Train : time 204.72 s Epoch 3\n",
      "Train Loss: 1.3734\n",
      "--- Running Evaluation for Epoch 3 lr =0.01 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.4957 std: 1.2378\n",
      "Val: Accuracy: 0.7918  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.733\n",
      "Counter({0: 94250, 1: 31182}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 4874, 1: 9698, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8838 Recall : 0.7305 FDR: 0.1563  F1-score: 0.7830  \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.209\n",
      "Counter({0: 119626, 1: 5806}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2167, 1: 32341, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.7246 Recall : 0.1010 FDR: 0.3732  F1-score: 0.1740  \n",
      "model VAE is saved in best_models/VAE_f1_0.79_recall_0.73_.pth\n",
      "Train : time 207.81 s Epoch 4\n",
      "Train Loss: 1.3721\n",
      "--- Running Evaluation for Epoch 4 lr =0.01 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.5366 std: 1.4410\n",
      "Val: Accuracy: 0.8199  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.978\n",
      "Counter({0: 94077, 1: 31355}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 4964, 1: 9615, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8837 Recall : 0.7328 FDR: 0.1583  F1-score: 0.7835  \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.859\n",
      "Counter({0: 119161, 1: 6271}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2601, 1: 32310, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.7214 Recall : 0.1019 FDR: 0.4148  F1-score: 0.1736  \n",
      "model VAE is saved in best_models/VAE_f1_0.79_recall_0.73_.pth\n",
      "Train : time 207.30 s Epoch 5\n",
      "Train Loss: 1.3720\n",
      "--- Running Evaluation for Epoch 5 lr =0.01 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.5561 std: 1.4035\n",
      "Val: Accuracy: 0.8107  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.96\n",
      "Counter({0: 93454, 1: 31978}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5527, 1: 9557, 5: 1, 6: 6}\n",
      "Test : Accuracy: 0.8797 Recall : 0.7344 FDR: 0.1728  F1-score: 0.7781  \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.766\n",
      "Counter({0: 118787, 1: 6645}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2781, 1: 32118, 2: 1, 3: 1, 4: 1, 5: 2, 6: 27, 7: 1}\n",
      "Test : Accuracy: 0.7215 Recall : 0.1073 FDR: 0.4185  F1-score: 0.1812  \n",
      "model VAE is saved in best_models/VAE_f1_0.79_recall_0.73_.pth\n",
      "Train : time 210.59 s Epoch 6\n",
      "Train Loss: 1.3759\n",
      "--- Running Evaluation for Epoch 6 lr =0.01 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.5801 std: 1.4476\n",
      "Val: Accuracy: 0.8111  \n",
      " K: 1 K-SIGMA Threshold : ---thr 2.028\n",
      "Counter({0: 93899, 1: 31533}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5169, 1: 9643, 5: 1, 6: 7}\n",
      "Test : Accuracy: 0.8818 Recall : 0.7320 FDR: 0.1639  F1-score: 0.7806  \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.923\n",
      "Counter({0: 119143, 1: 6289}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2545, 1: 32237, 2: 1, 3: 1, 4: 1, 5: 2, 6: 28, 7: 1}\n",
      "Test : Accuracy: 0.7224 Recall : 0.1040 FDR: 0.4047  F1-score: 0.1770  \n",
      "\n",
      "==================  lr=0.001, wd=0.0001 ==================\n",
      "Train : time 201.18 s Epoch 1\n",
      "Train Loss: 1.3844\n",
      "--- Running Evaluation for Epoch 1 lr =0.001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.5234 std: 1.4359\n",
      "Val: Accuracy: 0.8247  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.959\n",
      "Counter({0: 93702, 1: 31730}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5197, 1: 9476, 5: 1, 6: 5}\n",
      "Test : Accuracy: 0.8830 Recall : 0.7367 FDR: 0.1638  F1-score: 0.7833  \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.831\n",
      "Counter({0: 116875, 1: 8557}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2887, 1: 30313, 2: 1, 3: 1, 4: 1, 5: 2, 6: 26, 7: 1}\n",
      "Test : Accuracy: 0.7351 Recall : 0.1574 FDR: 0.3374  F1-score: 0.2544  \n",
      "model VAE is saved in best_models/VAE_f1_0.79_recall_0.74_.pth\n",
      "Train : time 202.13 s Epoch 2\n",
      "Train Loss: 1.3367\n",
      "--- Running Evaluation for Epoch 2 lr =0.001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.4915 std: 1.2705\n",
      "Val: Accuracy: 0.8023  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.762\n",
      "Counter({0: 92951, 1: 32481}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5798, 1: 9324, 5: 1, 6: 7}\n",
      "Test : Accuracy: 0.8794 Recall : 0.7409 FDR: 0.1785  F1-score: 0.7791  \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.303\n",
      "Counter({0: 116470, 1: 8962}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2816, 1: 29839, 2: 1, 3: 1, 4: 1, 5: 2, 6: 25}\n",
      "Test : Accuracy: 0.7394 Recall : 0.1707 FDR: 0.3142  F1-score: 0.2733  \n",
      "model VAE is saved in best_models/VAE_f1_0.79_recall_0.74_.pth\n",
      "Train : time 214.40 s Epoch 3\n",
      "Train Loss: 1.3349\n",
      "--- Running Evaluation for Epoch 3 lr =0.001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.4413 std: 1.2113\n",
      "Val: Accuracy: 0.8112  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.653\n",
      "Counter({0: 94588, 1: 30844}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 4502, 1: 9664, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8870 Recall : 0.7314 FDR: 0.1460  F1-score: 0.7880  \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.075\n",
      "Counter({0: 118018, 1: 7414}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2034, 1: 30602, 2: 1, 3: 1, 4: 1, 5: 2, 6: 27, 7: 1}\n",
      "Test : Accuracy: 0.7395 Recall : 0.1494 FDR: 0.2743  F1-score: 0.2478  \n",
      "Train : time 208.56 s Epoch 4\n",
      "Train Loss: 1.3323\n",
      "--- Running Evaluation for Epoch 4 lr =0.001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.4396 std: 1.2035\n",
      "Val: Accuracy: 0.8136  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.643\n",
      "Counter({0: 94184, 1: 31248}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 4878, 1: 9636, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8842 Recall : 0.7322 FDR: 0.1561  F1-score: 0.7841  \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.05\n",
      "Counter({0: 117387, 1: 8045}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2241, 1: 30178, 2: 1, 3: 1, 4: 1, 5: 2, 6: 27, 7: 1}\n",
      "Test : Accuracy: 0.7413 Recall : 0.1612 FDR: 0.2786  F1-score: 0.2635  \n",
      "Train : time 214.48 s Epoch 5\n",
      "Train Loss: 1.3323\n",
      "--- Running Evaluation for Epoch 5 lr =0.001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.4618 std: 1.2407\n",
      "Val: Accuracy: 0.8073  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.703\n",
      "Counter({0: 94585, 1: 30847}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 4545, 1: 9704, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8863 Recall : 0.7303 FDR: 0.1473  F1-score: 0.7868  \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.184\n",
      "Counter({0: 114950, 1: 10482}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2052, 1: 27558, 2: 1, 3: 1, 4: 1, 5: 1, 6: 22, 7: 1}\n",
      "Test : Accuracy: 0.7637 Recall : 0.2341 FDR: 0.1958  F1-score: 0.3626  \n",
      "Train : time 203.56 s Epoch 6\n",
      "Train Loss: 1.3300\n",
      "--- Running Evaluation for Epoch 6 lr =0.001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.4515 std: 1.2477\n",
      "Val: Accuracy: 0.8083  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.699\n",
      "Counter({0: 94645, 1: 30787}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 4498, 1: 9717, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8866 Recall : 0.7299 FDR: 0.1461  F1-score: 0.7871  \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.195\n",
      "Counter({0: 117295, 1: 8137}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2049, 1: 29895, 2: 1, 3: 1, 4: 1, 5: 2, 6: 26, 7: 1}\n",
      "Test : Accuracy: 0.7451 Recall : 0.1690 FDR: 0.2518  F1-score: 0.2758  \n",
      "\n",
      "==================  lr=0.0001, wd=0.0001 ==================\n",
      "Train : time 208.30 s Epoch 1\n",
      "Train Loss: 1.6629\n",
      "--- Running Evaluation for Epoch 1 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.5126 std: 1.2397\n",
      "Val: Accuracy: 0.7923  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.752\n",
      "Counter({0: 92331, 1: 33101}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6436, 1: 9341, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8741 Recall : 0.7404 FDR: 0.1944  F1-score: 0.7716  \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.232\n",
      "Counter({0: 116853, 1: 8579}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2701, 1: 30103, 2: 1, 3: 1, 4: 1, 5: 2, 6: 28, 7: 1}\n",
      "Test : Accuracy: 0.7382 Recall : 0.1632 FDR: 0.3148  F1-score: 0.2636  \n",
      "Train : time 212.61 s Epoch 2\n",
      "Train Loss: 1.3564\n",
      "--- Running Evaluation for Epoch 2 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.4601 std: 1.1599\n",
      "Val: Accuracy: 0.7882  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.62\n",
      "Counter({0: 93022, 1: 32410}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5794, 1: 9391, 5: 1, 6: 7}\n",
      "Test : Accuracy: 0.8789 Recall : 0.7390 FDR: 0.1788  F1-score: 0.7780  \n",
      " K: 3 K-SIGMA Threshold : ---thr 3.94\n",
      "Counter({0: 117637, 1: 7795}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2459, 1: 30646, 2: 1, 3: 1, 4: 1, 5: 2, 6: 27, 7: 1}\n",
      "Test : Accuracy: 0.7358 Recall : 0.1482 FDR: 0.3155  F1-score: 0.2436  \n",
      "Train : time 209.88 s Epoch 3\n",
      "Train Loss: 1.3410\n",
      "--- Running Evaluation for Epoch 3 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.4890 std: 1.2726\n",
      "Val: Accuracy: 0.7989  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.762\n",
      "Counter({0: 93565, 1: 31867}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5313, 1: 9453, 5: 1, 6: 7}\n",
      "Test : Accuracy: 0.8822 Recall : 0.7373 FDR: 0.1667  F1-score: 0.7824  \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.307\n",
      "Counter({0: 117509, 1: 7923}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2602, 1: 30663, 2: 1, 3: 1, 4: 1, 5: 2, 6: 25, 7: 1}\n",
      "Test : Accuracy: 0.7345 Recall : 0.1477 FDR: 0.3284  F1-score: 0.2422  \n",
      "Train : time 216.86 s Epoch 4\n",
      "Train Loss: 1.3330\n",
      "--- Running Evaluation for Epoch 4 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.4776 std: 1.2604\n",
      "Val: Accuracy: 0.8059  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.738\n",
      "Counter({0: 93224, 1: 32208}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5607, 1: 9406, 5: 1, 6: 7}\n",
      "Test : Accuracy: 0.8802 Recall : 0.7386 FDR: 0.1741  F1-score: 0.7798  \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.259\n",
      "Counter({0: 115562, 1: 9870}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2770, 1: 28884, 2: 1, 3: 1, 4: 1, 5: 2, 6: 25, 7: 1}\n",
      "Test : Accuracy: 0.7474 Recall : 0.1971 FDR: 0.2806  F1-score: 0.3095  \n",
      "Train : time 220.11 s Epoch 5\n",
      "Train Loss: 1.3298\n",
      "--- Running Evaluation for Epoch 5 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.4700 std: 1.2589\n",
      "Val: Accuracy: 0.8037  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.729\n",
      "Counter({0: 93975, 1: 31457}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5008, 1: 9558, 5: 1, 6: 7}\n",
      "Test : Accuracy: 0.8838 Recall : 0.7344 FDR: 0.1592  F1-score: 0.7840  \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.247\n",
      "Counter({0: 116662, 1: 8770}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2429, 1: 29642, 2: 1, 3: 1, 4: 1, 5: 2, 6: 26, 7: 1}\n",
      "Test : Accuracy: 0.7441 Recall : 0.1761 FDR: 0.2770  F1-score: 0.2832  \n",
      "Train : time 212.34 s Epoch 6\n",
      "Train Loss: 1.3284\n",
      "--- Running Evaluation for Epoch 6 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.4627 std: 1.1898\n",
      "Val: Accuracy: 0.7938  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.652\n",
      "Counter({0: 93585, 1: 31847}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5349, 1: 9508, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8815 Recall : 0.7357 FDR: 0.1680  F1-score: 0.7809  \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.032\n",
      "Counter({0: 116379, 1: 9053}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2486, 1: 29416, 2: 1, 3: 1, 4: 1, 5: 2, 6: 26, 7: 1}\n",
      "Test : Accuracy: 0.7454 Recall : 0.1823 FDR: 0.2746  F1-score: 0.2914  \n"
     ]
    }
   ],
   "source": [
    "VAE_model = VAE(input_dim=76)\n",
    "train_eval(VAE_model,train_dataloader,val_dataloader,test_dataloader,shuffle_files=False,num_epochs=6,eval_epoch=1,criterion_method=\"mse\",learning_rates=[1e-2,1e-3,1e-4],weight_decays=[1e-4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea756ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================  lr=0.01, wd=1e-05 ==================\n",
      "Train : time 219.01 s Epoch 1\n",
      "Train Loss: 1.5069\n",
      "--- Running Evaluation for Epoch 1 lr =0.01 wd 1e-05 ---\n",
      "-----------mse_loss mean :  1.1421 std: 2.1842\n",
      "Val: Accuracy: 0.8135  \n",
      " K: 0 K-SIGMA Threshold : ---thr 1.142\n",
      "Counter({0: 87765, 1: 37667}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 11401, 1: 9740, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8314 Recall : 0.7293 FDR: 0.3027  F1-score: 0.7130  \n",
      " K: 1 K-SIGMA Threshold : ---thr 3.326\n",
      "Counter({0: 113934, 1: 11498}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 8073, 1: 32555, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.6758 Recall : 0.0951 FDR: 0.7021  F1-score: 0.1442  \n",
      " K: 3 K-SIGMA Threshold : ---thr 7.695\n",
      "Counter({0: 120569, 1: 4863}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2059, 1: 33176, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.7188 Recall : 0.0779 FDR: 0.4234  F1-score: 0.1372  \n",
      "model VAE is saved in best_models/VAE_f1_0.71_recall_0.73_.pth\n",
      "Train : time 220.23 s Epoch 2\n",
      "Train Loss: 1.5914\n",
      "--- Running Evaluation for Epoch 2 lr =0.01 wd 1e-05 ---\n",
      "-----------mse_loss mean :  1.0722 std: 2.0689\n",
      "Val: Accuracy: 0.8325  \n",
      " K: 0 K-SIGMA Threshold : ---thr 1.072\n",
      "Counter({0: 88719, 1: 36713}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 10386, 1: 9679, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8400 Recall : 0.7310 FDR: 0.2829  F1-score: 0.7240  \n",
      " K: 1 K-SIGMA Threshold : ---thr 3.141\n",
      "Counter({0: 114065, 1: 11367}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 7825, 1: 32438, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.6787 Recall : 0.0983 FDR: 0.6884  F1-score: 0.1495  \n",
      " K: 3 K-SIGMA Threshold : ---thr 7.279\n",
      "Counter({0: 120213, 1: 5219}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2255, 1: 33016, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.7185 Recall : 0.0823 FDR: 0.4321  F1-score: 0.1438  \n",
      "model VAE is saved in best_models/VAE_f1_0.72_recall_0.73_.pth\n",
      "Train : time 211.51 s Epoch 3\n",
      "Train Loss: 1.5916\n",
      "--- Running Evaluation for Epoch 3 lr =0.01 wd 1e-05 ---\n",
      "-----------mse_loss mean :  1.0979 std: 2.0933\n",
      "Val: Accuracy: 0.8189  \n",
      " K: 0 K-SIGMA Threshold : ---thr 1.098\n",
      "Counter({0: 87702, 1: 37730}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 11387, 1: 9663, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8321 Recall : 0.7314 FDR: 0.3018  F1-score: 0.7144  \n",
      " K: 1 K-SIGMA Threshold : ---thr 3.191\n",
      "Counter({0: 113979, 1: 11453}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 8019, 1: 32546, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.6763 Recall : 0.0953 FDR: 0.7002  F1-score: 0.1447  \n",
      " K: 3 K-SIGMA Threshold : ---thr 7.378\n",
      "Counter({0: 120388, 1: 5044}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2114, 1: 33050, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.7194 Recall : 0.0814 FDR: 0.4191  F1-score: 0.1427  \n",
      "model VAE is saved in best_models/VAE_f1_0.72_recall_0.73_.pth\n",
      "Train : time 217.71 s Epoch 4\n",
      "Train Loss: 1.5912\n",
      "--- Running Evaluation for Epoch 4 lr =0.01 wd 1e-05 ---\n",
      "-----------mse_loss mean :  1.1288 std: 2.2768\n",
      "Val: Accuracy: 0.8233  \n",
      " K: 0 K-SIGMA Threshold : ---thr 1.129\n",
      "Counter({0: 88009, 1: 37423}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 11084, 1: 9667, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8345 Recall : 0.7313 FDR: 0.2962  F1-score: 0.7173  \n",
      " K: 1 K-SIGMA Threshold : ---thr 3.406\n",
      "Counter({0: 113957, 1: 11475}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 7921, 1: 32427, 2: 1, 3: 1, 4: 1, 5: 2, 6: 28, 7: 1}\n",
      "Test : Accuracy: 0.6781 Recall : 0.0987 FDR: 0.6903  F1-score: 0.1497  \n",
      " K: 3 K-SIGMA Threshold : ---thr 7.959\n",
      "Counter({0: 120578, 1: 4854}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2156, 1: 33283, 2: 1, 3: 1, 4: 1, 5: 2, 6: 28, 7: 1}\n",
      "Test : Accuracy: 0.7172 Recall : 0.0749 FDR: 0.4442  F1-score: 0.1320  \n",
      "Train : time 221.20 s Epoch 5\n",
      "Train Loss: 1.5915\n",
      "--- Running Evaluation for Epoch 5 lr =0.01 wd 1e-05 ---\n",
      "-----------mse_loss mean :  1.0588 std: 2.1450\n",
      "Val: Accuracy: 0.8275  \n",
      " K: 0 K-SIGMA Threshold : ---thr 1.059\n",
      "Counter({0: 88443, 1: 36989}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 10645, 1: 9662, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8380 Recall : 0.7315 FDR: 0.2878  F1-score: 0.7217  \n",
      " K: 1 K-SIGMA Threshold : ---thr 3.204\n",
      "Counter({0: 114377, 1: 11055}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 7599, 1: 32525, 2: 1, 3: 1, 4: 1, 5: 2, 6: 28, 7: 1}\n",
      "Test : Accuracy: 0.6798 Recall : 0.0960 FDR: 0.6874  F1-score: 0.1468  \n",
      " K: 3 K-SIGMA Threshold : ---thr 7.494\n",
      "Counter({0: 120455, 1: 4977}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2081, 1: 33084, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.7194 Recall : 0.0804 FDR: 0.4181  F1-score: 0.1413  \n",
      "model VAE is saved in best_models/VAE_f1_0.72_recall_0.73_.pth\n",
      "Train : time 224.08 s Epoch 6\n",
      "Train Loss: 1.5918\n",
      "--- Running Evaluation for Epoch 6 lr =0.01 wd 1e-05 ---\n",
      "-----------mse_loss mean :  1.1323 std: 2.1209\n",
      "Val: Accuracy: 0.8241  \n",
      " K: 0 K-SIGMA Threshold : ---thr 1.132\n",
      "Counter({0: 87994, 1: 37438}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 11034, 1: 9602, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8354 Recall : 0.7331 FDR: 0.2947  F1-score: 0.7189  \n",
      " K: 1 K-SIGMA Threshold : ---thr 3.253\n",
      "Counter({0: 113784, 1: 11648}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 8031, 1: 32363, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.6777 Recall : 0.1004 FDR: 0.6895  F1-score: 0.1518  \n",
      " K: 3 K-SIGMA Threshold : ---thr 7.495\n",
      "Counter({0: 120230, 1: 5202}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2247, 1: 33025, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.7185 Recall : 0.0820 FDR: 0.4319  F1-score: 0.1434  \n",
      "model VAE is saved in best_models/VAE_f1_0.72_recall_0.73_.pth\n",
      "\n",
      "==================  lr=0.001, wd=1e-05 ==================\n",
      "Train : time 214.88 s Epoch 1\n",
      "Train Loss: 1.3838\n",
      "--- Running Evaluation for Epoch 1 lr =0.001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.4839 std: 1.2300\n",
      "Val: Accuracy: 0.7991  \n",
      " K: 0 K-SIGMA Threshold : ---thr 0.4839\n",
      "Counter({0: 65078, 1: 60354}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 32086, 1: 7739, 6: 8}\n",
      "Test : Accuracy: 0.6824 Recall : 0.7849 FDR: 0.5316  F1-score: 0.5867  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.714\n",
      "Counter({0: 94069, 1: 31363}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 4982, 1: 9625, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8835 Recall : 0.7325 FDR: 0.1588  F1-score: 0.7831  \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.174\n",
      "Counter({0: 115508, 1: 9924}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2108, 1: 28168, 2: 1, 3: 1, 4: 1, 5: 2, 6: 26}\n",
      "Test : Accuracy: 0.7584 Recall : 0.2170 FDR: 0.2124  F1-score: 0.3403  \n",
      "model VAE is saved in best_models/VAE_f1_0.78_recall_0.78_.pth\n",
      "Train : time 213.59 s Epoch 2\n",
      "Train Loss: 1.3368\n",
      "--- Running Evaluation for Epoch 2 lr =0.001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.4961 std: 1.2799\n",
      "Val: Accuracy: 0.8061  \n",
      " K: 0 K-SIGMA Threshold : ---thr 0.4961\n",
      "Counter({0: 80616, 1: 44816}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 16405, 1: 7597, 6: 7}\n",
      "Test : Accuracy: 0.8086 Recall : 0.7889 FDR: 0.3661  F1-score: 0.7030  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.776\n",
      "Counter({0: 93438, 1: 31994}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5403, 1: 9416, 5: 1, 6: 7}\n",
      "Test : Accuracy: 0.8818 Recall : 0.7383 FDR: 0.1689  F1-score: 0.7820  \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.336\n",
      "Counter({0: 110454, 1: 14978}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2858, 1: 23865, 2: 1, 3: 1, 4: 1, 5: 2, 6: 24, 7: 1}\n",
      "Test : Accuracy: 0.7867 Recall : 0.3365 FDR: 0.1908  F1-score: 0.4754  \n",
      "model VAE is saved in best_models/VAE_f1_0.78_recall_0.79_.pth\n",
      "Train : time 220.05 s Epoch 3\n",
      "Train Loss: 1.3330\n",
      "--- Running Evaluation for Epoch 3 lr =0.001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.4967 std: 1.3043\n",
      "Val: Accuracy: 0.8066  \n",
      " K: 0 K-SIGMA Threshold : ---thr 0.4967\n",
      "Counter({0: 80469, 1: 44963}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 16810, 1: 7854, 6: 8}\n",
      "Test : Accuracy: 0.8033 Recall : 0.7817 FDR: 0.3739  F1-score: 0.6953  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.801\n",
      "Counter({0: 93686, 1: 31746}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5312, 1: 9572, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8813 Recall : 0.7340 FDR: 0.1673  F1-score: 0.7802  \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.409\n",
      "Counter({0: 114298, 1: 11134}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2617, 1: 27469, 2: 1, 3: 1, 5: 2, 6: 24, 7: 1}\n",
      "Test : Accuracy: 0.7599 Recall : 0.2365 FDR: 0.2350  F1-score: 0.3613  \n",
      "Train : time 222.62 s Epoch 4\n",
      "Train Loss: 1.3312\n",
      "--- Running Evaluation for Epoch 4 lr =0.001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.4527 std: 1.2202\n",
      "Val: Accuracy: 0.8063  \n",
      " K: 0 K-SIGMA Threshold : ---thr 0.4527\n",
      "Counter({1: 67430, 0: 58002}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 39177, 1: 7755, 6: 7}\n",
      "Test : Accuracy: 0.6258 Recall : 0.7845 FDR: 0.5810  F1-score: 0.5462  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.673\n",
      "Counter({0: 94231, 1: 31201}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 4868, 1: 9673, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8840 Recall : 0.7312 FDR: 0.1560  F1-score: 0.7835  \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.113\n",
      "Counter({0: 114212, 1: 11220}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2327, 1: 27091, 2: 1, 4: 1, 5: 1, 6: 27, 7: 1}\n",
      "Test : Accuracy: 0.7652 Recall : 0.2469 FDR: 0.2074  F1-score: 0.3765  \n",
      "model VAE is saved in best_models/VAE_f1_0.78_recall_0.79_.pth\n",
      "Train : time 218.29 s Epoch 5\n",
      "Train Loss: 1.3299\n",
      "--- Running Evaluation for Epoch 5 lr =0.001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.4914 std: 1.3105\n",
      "Val: Accuracy: 0.8079  \n",
      " K: 0 K-SIGMA Threshold : ---thr 0.4914\n",
      "Counter({0: 74790, 1: 50642}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 22401, 1: 7766, 6: 8}\n",
      "Test : Accuracy: 0.7594 Recall : 0.7841 FDR: 0.4423  F1-score: 0.6518  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.802\n",
      "Counter({0: 94038, 1: 31394}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 4982, 1: 9594, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8837 Recall : 0.7334 FDR: 0.1587  F1-score: 0.7836  \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.423\n",
      "Counter({0: 116360, 1: 9072}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2476, 1: 29385, 2: 1, 3: 1, 4: 1, 5: 2, 6: 28, 7: 1}\n",
      "Test : Accuracy: 0.7457 Recall : 0.1831 FDR: 0.2729  F1-score: 0.2926  \n",
      "model VAE is saved in best_models/VAE_f1_0.78_recall_0.79_.pth\n",
      "Train : time 210.89 s Epoch 6\n",
      "Train Loss: 1.3287\n",
      "--- Running Evaluation for Epoch 6 lr =0.001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.4699 std: 1.2638\n",
      "Val: Accuracy: 0.8044  \n",
      " K: 0 K-SIGMA Threshold : ---thr 0.4699\n",
      "Counter({1: 67250, 0: 58182}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 39117, 1: 7874, 6: 8}\n",
      "Test : Accuracy: 0.6253 Recall : 0.7811 FDR: 0.5817  F1-score: 0.5449  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.734\n",
      "Counter({0: 94739, 1: 30693}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 4409, 1: 9722, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8873 Recall : 0.7298 FDR: 0.1436  F1-score: 0.7880  \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.261\n",
      "Counter({0: 119744, 1: 5688}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2209, 1: 32501, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.7230 Recall : 0.0966 FDR: 0.3884  F1-score: 0.1668  \n",
      "model VAE is saved in best_models/VAE_f1_0.79_recall_0.79_.pth\n",
      "\n",
      "==================  lr=0.0001, wd=1e-05 ==================\n",
      "Train : time 213.55 s Epoch 1\n",
      "Train Loss: 1.6114\n",
      "--- Running Evaluation for Epoch 1 lr =0.0001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.5460 std: 1.3061\n",
      "Val: Accuracy: 0.7901  \n",
      " K: 0 K-SIGMA Threshold : ---thr 0.546\n",
      "Counter({0: 80701, 1: 44731}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 16465, 1: 7741, 6: 8}\n",
      "Test : Accuracy: 0.8070 Recall : 0.7848 FDR: 0.3681  F1-score: 0.7001  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.852\n",
      "Counter({0: 92768, 1: 32664}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5970, 1: 9312, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8781 Recall : 0.7412 FDR: 0.1828  F1-score: 0.7774  \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.464\n",
      "Counter({0: 116725, 1: 8707}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2368, 1: 29643, 2: 1, 3: 1, 4: 1, 5: 2, 6: 27, 7: 1}\n",
      "Test : Accuracy: 0.7445 Recall : 0.1760 FDR: 0.2720  F1-score: 0.2835  \n",
      "Train : time 218.92 s Epoch 2\n",
      "Train Loss: 1.3548\n",
      "--- Running Evaluation for Epoch 2 lr =0.0001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.4922 std: 1.2653\n",
      "Val: Accuracy: 0.7957  \n",
      " K: 0 K-SIGMA Threshold : ---thr 0.4922\n",
      "Counter({0: 68582, 1: 56850}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 28064, 1: 7221, 6: 8}\n",
      "Test : Accuracy: 0.7186 Recall : 0.7993 FDR: 0.4936  F1-score: 0.6200  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.757\n",
      "Counter({0: 93223, 1: 32209}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5553, 1: 9350, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8811 Recall : 0.7401 FDR: 0.1724  F1-score: 0.7814  \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.288\n",
      "Counter({0: 115876, 1: 9556}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2610, 1: 29038, 2: 1, 3: 1, 4: 1, 5: 2, 6: 25, 7: 1}\n",
      "Test : Accuracy: 0.7474 Recall : 0.1929 FDR: 0.2731  F1-score: 0.3048  \n",
      "model VAE is saved in best_models/VAE_f1_0.79_recall_0.80_.pth\n",
      "Train : time 210.02 s Epoch 3\n",
      "Train Loss: 1.3383\n",
      "--- Running Evaluation for Epoch 3 lr =0.0001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.4318 std: 1.1756\n",
      "Val: Accuracy: 0.8023  \n",
      " K: 0 K-SIGMA Threshold : ---thr 0.4318\n",
      "Counter({1: 68510, 0: 56922}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 39420, 1: 6917, 6: 8}\n",
      "Test : Accuracy: 0.6305 Recall : 0.8077 FDR: 0.5754  F1-score: 0.5566  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.607\n",
      "Counter({0: 93867, 1: 31565}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 4989, 1: 9430, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8850 Recall : 0.7379 FDR: 0.1581  F1-score: 0.7865  \n",
      " K: 3 K-SIGMA Threshold : ---thr 3.959\n",
      "Counter({0: 116838, 1: 8594}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2296, 1: 29683, 2: 1, 3: 1, 4: 1, 5: 2, 6: 28, 7: 1}\n",
      "Test : Accuracy: 0.7448 Recall : 0.1749 FDR: 0.2672  F1-score: 0.2824  \n",
      "model VAE is saved in best_models/VAE_f1_0.79_recall_0.81_.pth\n",
      "Train : time 214.64 s Epoch 4\n",
      "Train Loss: 1.3308\n",
      "--- Running Evaluation for Epoch 4 lr =0.0001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.4999 std: 1.2979\n",
      "Val: Accuracy: 0.8038  \n",
      " K: 0 K-SIGMA Threshold : ---thr 0.4999\n",
      "Counter({0: 76581, 1: 48851}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 20367, 1: 7523, 6: 8}\n",
      "Test : Accuracy: 0.7776 Recall : 0.7909 FDR: 0.4169  F1-score: 0.6713  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.798\n",
      "Counter({0: 93462, 1: 31970}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5314, 1: 9350, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8830 Recall : 0.7401 FDR: 0.1662  F1-score: 0.7842  \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.394\n",
      "Counter({0: 116135, 1: 9297}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2651, 1: 29337, 2: 1, 3: 1, 4: 1, 5: 2, 6: 27}\n",
      "Test : Accuracy: 0.7447 Recall : 0.1845 FDR: 0.2851  F1-score: 0.2933  \n",
      "Train : time 215.15 s Epoch 5\n",
      "Train Loss: 1.3285\n",
      "--- Running Evaluation for Epoch 5 lr =0.0001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.4388 std: 1.1805\n",
      "Val: Accuracy: 0.8053  \n",
      " K: 0 K-SIGMA Threshold : ---thr 0.4388\n",
      "Counter({1: 67498, 0: 57934}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 38999, 1: 7508, 6: 8}\n",
      "Test : Accuracy: 0.6292 Recall : 0.7913 FDR: 0.5778  F1-score: 0.5506  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.619\n",
      "Counter({0: 94378, 1: 31054}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 4564, 1: 9516, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8877 Recall : 0.7355 FDR: 0.1470  F1-score: 0.7899  \n",
      " K: 3 K-SIGMA Threshold : ---thr 3.98\n",
      "Counter({0: 117964, 1: 7468}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2079, 1: 30593, 2: 1, 3: 1, 4: 1, 5: 2, 6: 27, 7: 1}\n",
      "Test : Accuracy: 0.7393 Recall : 0.1496 FDR: 0.2784  F1-score: 0.2479  \n",
      "model VAE is saved in best_models/VAE_f1_0.79_recall_0.81_.pth\n",
      "Train : time 222.71 s Epoch 6\n",
      "Train Loss: 1.3280\n",
      "--- Running Evaluation for Epoch 6 lr =0.0001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.4660 std: 1.2850\n",
      "Val: Accuracy: 0.8112  \n",
      " K: 0 K-SIGMA Threshold : ---thr 0.466\n",
      "Counter({1: 67061, 0: 58371}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 38757, 1: 7704, 6: 7}\n",
      "Test : Accuracy: 0.6295 Recall : 0.7859 FDR: 0.5779  F1-score: 0.5492  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.751\n",
      "Counter({0: 94089, 1: 31343}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 4875, 1: 9538, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8850 Recall : 0.7349 FDR: 0.1555  F1-score: 0.7859  \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.321\n",
      "Counter({0: 117625, 1: 7807}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2504, 1: 30681, 2: 1, 3: 1, 4: 1, 5: 2, 6: 25, 7: 1}\n",
      "Test : Accuracy: 0.7352 Recall : 0.1472 FDR: 0.3207  F1-score: 0.2420  \n"
     ]
    }
   ],
   "source": [
    "VAE_model = VAE(input_dim=76)\n",
    "train_eval(VAE_model,train_dataloader,val_dataloader,test_dataloader,shuffle_files=False,num_epochs=6,eval_epoch=1,criterion_method=\"mse\",learning_rates=[1e-2,1e-3,1e-4],weight_decays=[1e-5],k_range=[0,1,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54635226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================  lr=0.01, wd=0.0001 ==================\n",
      "Train : time 267.13 s Epoch 1\n",
      "Generator Loss: 491.9236 Discriminator Loss: 0.3799\n",
      "--- Running Evaluation for Epoch 1 lr =0.01 wd 0.0001 ---\n",
      "-----------mse_loss mean :  6.6088 std: 3.8604\n",
      "Val: Accuracy: 0.3866  \n",
      " K: 1 K-SIGMA Threshold : ---thr 10.47\n",
      "Counter({0: 117814, 1: 7618}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 4729, 1: 33091, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.6982 Recall : 0.0802 FDR: 0.6208  F1-score: 0.1324  \n",
      " K: 3 K-SIGMA Threshold : ---thr 18.19\n",
      "Counter({0: 125314, 1: 118}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 1, 1: 35861, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Test : Accuracy: 0.7138 Recall : 0.0032 FDR: 0.0085  F1-score: 0.0065  \n",
      "model AdversarialAutoencoder is saved in best_models/AdversarialAutoencoder_f1_0.01_recall_0.08_.pth\n",
      "Train : time 266.93 s Epoch 2\n",
      "Generator Loss: 485.4757 Discriminator Loss: 0.0003\n",
      "--- Running Evaluation for Epoch 2 lr =0.01 wd 0.0001 ---\n",
      "-----------mse_loss mean :  6.6088 std: 3.8604\n",
      "Val: Accuracy: 0.3866  \n",
      " K: 1 K-SIGMA Threshold : ---thr 10.47\n",
      "Counter({0: 117814, 1: 7618}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 4729, 1: 33091, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.6982 Recall : 0.0802 FDR: 0.6208  F1-score: 0.1324  \n",
      " K: 3 K-SIGMA Threshold : ---thr 18.19\n",
      "Counter({0: 125314, 1: 118}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 1, 1: 35861, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Test : Accuracy: 0.7138 Recall : 0.0032 FDR: 0.0085  F1-score: 0.0065  \n",
      "Train : time 266.49 s Epoch 3\n",
      "Generator Loss: 485.5684 Discriminator Loss: 0.0001\n",
      "--- Running Evaluation for Epoch 3 lr =0.01 wd 0.0001 ---\n",
      "-----------mse_loss mean :  6.6088 std: 3.8604\n",
      "Val: Accuracy: 0.3866  \n",
      " K: 1 K-SIGMA Threshold : ---thr 10.47\n",
      "Counter({0: 117814, 1: 7618}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 4729, 1: 33091, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.6982 Recall : 0.0802 FDR: 0.6208  F1-score: 0.1324  \n",
      " K: 3 K-SIGMA Threshold : ---thr 18.19\n",
      "Counter({0: 125314, 1: 118}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 1, 1: 35861, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Test : Accuracy: 0.7138 Recall : 0.0032 FDR: 0.0085  F1-score: 0.0065  \n",
      "Train : time 268.82 s Epoch 4\n",
      "Generator Loss: 485.5682 Discriminator Loss: 0.0001\n",
      "--- Running Evaluation for Epoch 4 lr =0.01 wd 0.0001 ---\n",
      "-----------mse_loss mean :  6.6088 std: 3.8604\n",
      "Val: Accuracy: 0.3866  \n",
      " K: 1 K-SIGMA Threshold : ---thr 10.47\n",
      "Counter({0: 117814, 1: 7618}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 4729, 1: 33091, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.6982 Recall : 0.0802 FDR: 0.6208  F1-score: 0.1324  \n",
      " K: 3 K-SIGMA Threshold : ---thr 18.19\n",
      "Counter({0: 125314, 1: 118}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 1, 1: 35861, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Test : Accuracy: 0.7138 Recall : 0.0032 FDR: 0.0085  F1-score: 0.0065  \n",
      "Train : time 267.98 s Epoch 5\n",
      "Generator Loss: 485.4134 Discriminator Loss: 0.0001\n",
      "--- Running Evaluation for Epoch 5 lr =0.01 wd 0.0001 ---\n",
      "-----------mse_loss mean :  6.6088 std: 3.8604\n",
      "Val: Accuracy: 0.3866  \n",
      " K: 1 K-SIGMA Threshold : ---thr 10.47\n",
      "Counter({0: 117814, 1: 7618}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 4729, 1: 33091, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.6982 Recall : 0.0802 FDR: 0.6208  F1-score: 0.1324  \n",
      " K: 3 K-SIGMA Threshold : ---thr 18.19\n",
      "Counter({0: 125314, 1: 118}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 1, 1: 35861, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Test : Accuracy: 0.7138 Recall : 0.0032 FDR: 0.0085  F1-score: 0.0065  \n",
      "Train : time 268.42 s Epoch 6\n",
      "Generator Loss: 484.8974 Discriminator Loss: 0.0001\n",
      "--- Running Evaluation for Epoch 6 lr =0.01 wd 0.0001 ---\n",
      "-----------mse_loss mean :  6.6088 std: 3.8604\n",
      "Val: Accuracy: 0.3866  \n",
      " K: 1 K-SIGMA Threshold : ---thr 10.47\n",
      "Counter({0: 117814, 1: 7618}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 4729, 1: 33091, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.6982 Recall : 0.0802 FDR: 0.6208  F1-score: 0.1324  \n",
      " K: 3 K-SIGMA Threshold : ---thr 18.19\n",
      "Counter({0: 125314, 1: 118}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 1, 1: 35861, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Test : Accuracy: 0.7138 Recall : 0.0032 FDR: 0.0085  F1-score: 0.0065  \n",
      "\n",
      "==================  lr=0.001, wd=0.0001 ==================\n",
      "Train : time 266.66 s Epoch 1\n",
      "Generator Loss: 3.1654 Discriminator Loss: 10.2019\n",
      "--- Running Evaluation for Epoch 1 lr =0.001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0108 std: 0.1407\n",
      "Val: Accuracy: 0.9618  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.1514\n",
      "Counter({1: 65734, 0: 59698}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29884, 1: 165}\n",
      "Test : Accuracy: 0.7604 Recall : 0.9954 FDR: 0.4546  F1-score: 0.7047  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.4328\n",
      "Counter({0: 99239, 1: 26193}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 200, 1: 10014, 6: 8}\n",
      "Test : Accuracy: 0.9185 Recall : 0.7217 FDR: 0.0076  F1-score: 0.8357  \n",
      "model AdversarialAutoencoder is saved in best_models/AdversarialAutoencoder_f1_0.84_recall_1.00_.pth\n",
      "Train : time 267.77 s Epoch 2\n",
      "Generator Loss: 0.8580 Discriminator Loss: 8.3709\n",
      "--- Running Evaluation for Epoch 2 lr =0.001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0098 std: 0.1202\n",
      "Val: Accuracy: 0.9186  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.1301\n",
      "Counter({1: 65692, 0: 59740}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29842, 1: 165}\n",
      "Test : Accuracy: 0.7608 Recall : 0.9954 FDR: 0.4543  F1-score: 0.7050  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.3705\n",
      "Counter({0: 98862, 1: 26570}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 182, 1: 9619, 6: 8}\n",
      "Test : Accuracy: 0.9218 Recall : 0.7327 FDR: 0.0068  F1-score: 0.8433  \n",
      "model AdversarialAutoencoder is saved in best_models/AdversarialAutoencoder_f1_0.84_recall_1.00_.pth\n",
      "Train : time 275.52 s Epoch 3\n",
      "Generator Loss: 0.6960 Discriminator Loss: 9.5130\n",
      "--- Running Evaluation for Epoch 3 lr =0.001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0070 std: 0.1163\n",
      "Val: Accuracy: 0.9589  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.1233\n",
      "Counter({1: 65719, 0: 59713}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29869, 1: 165}\n",
      "Test : Accuracy: 0.7606 Recall : 0.9954 FDR: 0.4545  F1-score: 0.7048  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.3559\n",
      "Counter({0: 97333, 1: 28099}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 194, 1: 8102, 6: 8}\n",
      "Test : Accuracy: 0.9338 Recall : 0.7748 FDR: 0.0069  F1-score: 0.8705  \n",
      "model AdversarialAutoencoder is saved in best_models/AdversarialAutoencoder_f1_0.87_recall_1.00_.pth\n",
      "Train : time 268.60 s Epoch 4\n",
      "Generator Loss: 0.5717 Discriminator Loss: 11.5459\n",
      "--- Running Evaluation for Epoch 4 lr =0.001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0059 std: 0.1123\n",
      "Val: Accuracy: 0.9358  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.1182\n",
      "Counter({1: 65668, 0: 59764}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29818, 1: 165}\n",
      "Test : Accuracy: 0.7610 Recall : 0.9954 FDR: 0.4541  F1-score: 0.7051  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.3428\n",
      "Counter({0: 76242, 1: 49190}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 21360, 1: 8177, 6: 8}\n",
      "Test : Accuracy: 0.7645 Recall : 0.7727 FDR: 0.4342  F1-score: 0.6532  \n",
      "Train : time 267.18 s Epoch 5\n",
      "Generator Loss: 0.5787 Discriminator Loss: 10.8131\n",
      "--- Running Evaluation for Epoch 5 lr =0.001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0058 std: 0.1113\n",
      "Val: Accuracy: 0.9553  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.1171\n",
      "Counter({1: 65643, 0: 59789}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29793, 1: 165}\n",
      "Test : Accuracy: 0.7612 Recall : 0.9954 FDR: 0.4539  F1-score: 0.7053  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.3398\n",
      "Counter({0: 97742, 1: 27690}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 188, 1: 8505, 6: 8}\n",
      "Test : Accuracy: 0.9306 Recall : 0.7636 FDR: 0.0068  F1-score: 0.8634  \n",
      "Train : time 267.83 s Epoch 6\n",
      "Generator Loss: 1.7347 Discriminator Loss: 22.7155\n",
      "--- Running Evaluation for Epoch 6 lr =0.001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0163 std: 0.1244\n",
      "Val: Accuracy: 0.8915  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.1406\n",
      "Counter({1: 67524, 0: 57908}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 31674, 1: 165}\n",
      "Test : Accuracy: 0.7462 Recall : 0.9954 FDR: 0.4691  F1-score: 0.6925  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.3894\n",
      "Counter({0: 97424, 1: 28008}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 181, 1: 8180, 6: 8}\n",
      "Test : Accuracy: 0.9333 Recall : 0.7727 FDR: 0.0065  F1-score: 0.8693  \n",
      "\n",
      "==================  lr=0.0001, wd=0.0001 ==================\n",
      "Train : time 267.07 s Epoch 1\n",
      "Generator Loss: 48.1480 Discriminator Loss: 3.2173\n",
      "--- Running Evaluation for Epoch 1 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.8232 std: 2.1164\n",
      "Val: Accuracy: 0.8333  \n",
      " K: 1 K-SIGMA Threshold : ---thr 2.94\n",
      "Counter({0: 116492, 1: 8940}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6036, 1: 33076, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.6879 Recall : 0.0806 FDR: 0.6752  F1-score: 0.1292  \n",
      " K: 3 K-SIGMA Threshold : ---thr 7.173\n",
      "Counter({0: 120253, 1: 5179}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2304, 1: 33103, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Test : Accuracy: 0.7174 Recall : 0.0798 FDR: 0.4449  F1-score: 0.1396  \n",
      "Train : time 267.92 s Epoch 2\n",
      "Generator Loss: 37.6486 Discriminator Loss: 0.7104\n",
      "--- Running Evaluation for Epoch 2 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.5837 std: 1.4865\n",
      "Val: Accuracy: 0.8333  \n",
      " K: 1 K-SIGMA Threshold : ---thr 2.07\n",
      "Counter({0: 93324, 1: 32108}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6116, 1: 10014, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8713 Recall : 0.7217 FDR: 0.1905  F1-score: 0.7631  \n",
      " K: 3 K-SIGMA Threshold : ---thr 5.043\n",
      "Counter({0: 120417, 1: 5015}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2127, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.7189 Recall : 0.0802 FDR: 0.4241  F1-score: 0.1408  \n",
      "Train : time 266.72 s Epoch 3\n",
      "Generator Loss: 27.0534 Discriminator Loss: 0.6192\n",
      "--- Running Evaluation for Epoch 3 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.4912 std: 1.2596\n",
      "Val: Accuracy: 0.8333  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.751\n",
      "Counter({0: 93518, 1: 31914}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5922, 1: 10014, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8729 Recall : 0.7217 FDR: 0.1856  F1-score: 0.7653  \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.27\n",
      "Counter({0: 120421, 1: 5011}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2123, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.7190 Recall : 0.0802 FDR: 0.4237  F1-score: 0.1408  \n",
      "Train : time 267.52 s Epoch 4\n",
      "Generator Loss: 21.3178 Discriminator Loss: 0.6024\n",
      "--- Running Evaluation for Epoch 4 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.4208 std: 1.0797\n",
      "Val: Accuracy: 0.8340  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.5\n",
      "Counter({0: 93522, 1: 31910}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5918, 1: 10014, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8729 Recall : 0.7217 FDR: 0.1855  F1-score: 0.7653  \n",
      " K: 3 K-SIGMA Threshold : ---thr 3.66\n",
      "Counter({0: 120398, 1: 5034}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2146, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.7188 Recall : 0.0802 FDR: 0.4263  F1-score: 0.1407  \n",
      "Train : time 267.51 s Epoch 5\n",
      "Generator Loss: 21.1457 Discriminator Loss: 0.6184\n",
      "--- Running Evaluation for Epoch 5 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.4189 std: 1.0788\n",
      "Val: Accuracy: 0.8348  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.498\n",
      "Counter({0: 93531, 1: 31901}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5909, 1: 10014, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8730 Recall : 0.7217 FDR: 0.1852  F1-score: 0.7654  \n",
      " K: 3 K-SIGMA Threshold : ---thr 3.655\n",
      "Counter({0: 120401, 1: 5031}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2143, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.7188 Recall : 0.0802 FDR: 0.4260  F1-score: 0.1407  \n",
      "Train : time 266.90 s Epoch 6\n",
      "Generator Loss: 21.0620 Discriminator Loss: 0.6443\n",
      "--- Running Evaluation for Epoch 6 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.4180 std: 1.0772\n",
      "Val: Accuracy: 0.8353  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.495\n",
      "Counter({0: 93534, 1: 31898}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5906, 1: 10014, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8730 Recall : 0.7217 FDR: 0.1852  F1-score: 0.7654  \n",
      " K: 3 K-SIGMA Threshold : ---thr 3.65\n",
      "Counter({0: 120402, 1: 5030}) Counter({0: 89417, 1: 36015})\n",
      "Counts of  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2142, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.7188 Recall : 0.0802 FDR: 0.4258  F1-score: 0.1407  \n"
     ]
    }
   ],
   "source": [
    "AAE_model = AdversarialAutoencoder()\n",
    "train_eval(AAE_model,train_dataloader,val_dataloader,test_dataloader,shuffle_files=False,num_epochs=6,eval_epoch=1,criterion_method=\"mse\",learning_rates=[1e-2,1e-3,1e-4],weight_decays=[1e-4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b21a73a",
   "metadata": {},
   "source": [
    "#### Trained model evaluation on the compromised-ied and compromised scada scenarios \n",
    "\n",
    "No exact labeling for the comp ied scenario results in low performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "19349642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Trained_AE_model=AE(input_dim=76)\n",
    "Trained_AE_model.load_state_dict(torch.load(\"./best_models/AE_f1_0.84_recall_1.00_.pth\"))\n",
    "Trained_VAE_model=VAE(input_dim=76)\n",
    "Trained_VAE_model.load_state_dict(torch.load(\"./best_models/VAE_f1_0.79_recall_0.81_.pth\"))\n",
    "Trained_AAE_model=AdversarialAutoencoder()\n",
    "Trained_AAE_model.load_state_dict(torch.load(\"./best_models/AdversarialAutoencoder_f1_0.87_recall_1.00_.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d3d7e62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scenario : compromised-scada node ied1b\n",
      "----------- benign valid files: 7 ['dataset/ModbusDataset/benign/ied1b/ied1b-network-capture/ready/vethd9e14c0-normal-6-labeled.csv', 'dataset/ModbusDataset/benign/ied1b/ied1b-network-capture/ready/vethd9e14c0-normal-9-labeled.csv', 'dataset/ModbusDataset/benign/ied1b/ied1b-network-capture/ready/vethd9e14c0-normal-8-labeled.csv', 'dataset/ModbusDataset/benign/ied1b/ied1b-network-capture/ready/vethd9e14c0-normal-5-labeled.csv', 'dataset/ModbusDataset/benign/ied1b/ied1b-network-capture/ready/vethd9e14c0-normal-7-labeled.csv', 'dataset/ModbusDataset/benign/ied1b/ied1b-network-capture/ready/vethd9e14c0-normal-4-labeled.csv', 'dataset/ModbusDataset/benign/ied1b/ied1b-network-capture/ready/vethd9e14c0-normal-10-labeled.csv']\n",
      "----------compromised-scada attack  test files :  8 ['dataset/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-1-labeled.csv', 'dataset/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-0-labeled.csv', 'dataset/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-3-labeled.csv', 'dataset/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-2-labeled.csv', 'dataset/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-6-labeled.csv', 'dataset/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-4-labeled.csv', 'dataset/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-5-labeled.csv', 'dataset/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-7-labeled.csv']\n",
      "********** VAE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.1894 std: 0.8939\n",
      "Val: Accuracy: 0.9647  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.083\n",
      "Counter({0: 635368, 1: 237905}) Counter({0: 701716, 1: 171557})\n",
      "Counts of  labels: {0: 701716, 1: 170342, 2: 263, 3: 182, 4: 208, 5: 197, 6: 158, 7: 207}\n",
      "Counts of misclassified original labels: {0: 98079, 1: 31318, 2: 47, 3: 69, 4: 32, 5: 8, 6: 60, 7: 197}\n",
      "Test : Accuracy: 0.8514 Recall : 0.8150 FDR: 0.4123  F1-score: 0.6830  \n",
      " K: 3 K-SIGMA Threshold : ---thr 2.871\n",
      "Counter({0: 838208, 1: 35065}) Counter({0: 701716, 1: 171557})\n",
      "Counts of  labels: {0: 701716, 1: 170342, 2: 263, 3: 182, 4: 208, 5: 197, 6: 158, 7: 207}\n",
      "Counts of misclassified original labels: {0: 21832, 1: 157221, 2: 246, 3: 173, 4: 191, 5: 151, 6: 145, 7: 197}\n",
      "Test : Accuracy: 0.7937 Recall : 0.0771 FDR: 0.6226  F1-score: 0.1281  \n",
      "********** AdversarialAutoencoder **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0037 std: 0.1117\n",
      "Val: Accuracy: 0.9991  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.1153\n",
      "Counter({0: 649791, 1: 223482}) Counter({0: 701708, 1: 171565})\n",
      "Counts of  labels: {0: 701708, 1: 170345, 2: 268, 3: 182, 4: 208, 5: 197, 6: 158, 7: 207}\n",
      "Counts of misclassified original labels: {0: 82599, 1: 30475, 2: 47, 3: 69, 4: 27, 5: 2, 6: 61, 7: 1}\n",
      "Test : Accuracy: 0.8703 Recall : 0.8212 FDR: 0.3696  F1-score: 0.7132  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.3387\n",
      "Counter({0: 652906, 1: 220367}) Counter({0: 701708, 1: 171565})\n",
      "Counts of  labels: {0: 701708, 1: 170345, 2: 268, 3: 182, 4: 208, 5: 197, 6: 158, 7: 207}\n",
      "Counts of misclassified original labels: {0: 81467, 1: 32241, 2: 47, 3: 72, 4: 33, 5: 2, 6: 63, 7: 207}\n",
      "Test : Accuracy: 0.8693 Recall : 0.8096 FDR: 0.3697  F1-score: 0.7088  \n",
      "********** AE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0067 std: 0.1255\n",
      "Val: Accuracy: 0.9955  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.1322\n",
      "Counter({0: 649798, 1: 223475}) Counter({0: 701716, 1: 171557})\n",
      "Counts of  labels: {0: 701716, 1: 170342, 2: 263, 3: 182, 4: 208, 5: 197, 6: 158, 7: 207}\n",
      "Counts of misclassified original labels: {0: 82599, 1: 30474, 2: 47, 3: 69, 4: 27, 5: 2, 6: 61, 7: 1}\n",
      "Test : Accuracy: 0.8703 Recall : 0.8212 FDR: 0.3696  F1-score: 0.7132  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.3831\n",
      "Counter({0: 652913, 1: 220360}) Counter({0: 701716, 1: 171557})\n",
      "Counts of  labels: {0: 701716, 1: 170342, 2: 263, 3: 182, 4: 208, 5: 197, 6: 158, 7: 207}\n",
      "Counts of misclassified original labels: {0: 81467, 1: 32240, 2: 47, 3: 72, 4: 33, 5: 2, 6: 63, 7: 207}\n",
      "Test : Accuracy: 0.8693 Recall : 0.8096 FDR: 0.3697  F1-score: 0.7088  \n",
      "scenario : compromised-ied node ied1b\n",
      "----------- benign valid files: 7 ['dataset/ModbusDataset/benign/ied1b/ied1b-network-capture/ready/vethd9e14c0-normal-7-labeled.csv', 'dataset/ModbusDataset/benign/ied1b/ied1b-network-capture/ready/vethd9e14c0-normal-10-labeled.csv', 'dataset/ModbusDataset/benign/ied1b/ied1b-network-capture/ready/vethd9e14c0-normal-9-labeled.csv', 'dataset/ModbusDataset/benign/ied1b/ied1b-network-capture/ready/vethd9e14c0-normal-5-labeled.csv', 'dataset/ModbusDataset/benign/ied1b/ied1b-network-capture/ready/vethd9e14c0-normal-8-labeled.csv', 'dataset/ModbusDataset/benign/ied1b/ied1b-network-capture/ready/vethd9e14c0-normal-6-labeled.csv', 'dataset/ModbusDataset/benign/ied1b/ied1b-network-capture/ready/vethd9e14c0-normal-4-labeled.csv']\n",
      "----------compromised-ied attack  test files :  6 ['dataset/ModbusDataset/attack/compromised-ied/ied1b/ied1b-network-captures/ready/vethc76bd3f-2-labeled.csv', 'dataset/ModbusDataset/attack/compromised-ied/ied1b/ied1b-network-captures/ready/vethc76bd3f-3-labeled.csv', 'dataset/ModbusDataset/attack/compromised-ied/ied1b/ied1b-network-captures/ready/vethc76bd3f-0-labeled.csv', 'dataset/ModbusDataset/attack/compromised-ied/ied1b/ied1b-network-captures/ready/vethc76bd3f-1-labeled.csv', 'dataset/ModbusDataset/attack/compromised-ied/ied1b/ied1b-network-captures/ready/vethc76bd3f-4-labeled.csv', 'dataset/ModbusDataset/attack/compromised-ied/ied1b/ied1b-network-captures/ready/vethc76bd3f-5-labeled.csv']\n",
      "********** VAE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.1885 std: 0.8908\n",
      "Val: Accuracy: 0.9651  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.079\n",
      "Counter({0: 527608, 1: 131688}) Counter({0: 658934, 1: 362})\n",
      "Counts of  labels: {0: 658934, 2: 66, 3: 78, 4: 52, 5: 62, 7: 60, 8: 44}\n",
      "Counts of misclassified original labels: {0: 131591, 2: 52, 3: 60, 4: 44, 5: 32, 7: 42, 8: 35}\n",
      "Test : Accuracy: 0.8000 Recall : 0.2680 FDR: 0.9993  F1-score: 0.0015  \n",
      " K: 3 K-SIGMA Threshold : ---thr 2.861\n",
      "Counter({0: 638353, 1: 20943}) Counter({0: 658934, 1: 362})\n",
      "Counts of  labels: {0: 658934, 2: 66, 3: 78, 4: 52, 5: 62, 7: 60, 8: 44}\n",
      "Counts of misclassified original labels: {0: 20923, 2: 66, 3: 74, 4: 48, 5: 54, 7: 58, 8: 42}\n",
      "Test : Accuracy: 0.9677 Recall : 0.0552 FDR: 0.9990  F1-score: 0.0019  \n",
      "********** AdversarialAutoencoder **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0037 std: 0.1117\n",
      "Val: Accuracy: 0.9991  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.1153\n",
      "Counter({0: 657228, 1: 2068}) Counter({0: 658934, 1: 362})\n",
      "Counts of  labels: {0: 658934, 2: 66, 3: 78, 4: 52, 5: 62, 7: 60, 8: 44}\n",
      "Counts of misclassified original labels: {0: 2057, 2: 66, 3: 78, 4: 52, 5: 51, 7: 60, 8: 44}\n",
      "Test : Accuracy: 0.9963 Recall : 0.0304 FDR: 0.9947  F1-score: 0.0091  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.3387\n",
      "Counter({0: 657267, 1: 2029}) Counter({0: 658934, 1: 362})\n",
      "Counts of  labels: {0: 658934, 2: 66, 3: 78, 4: 52, 5: 62, 7: 60, 8: 44}\n",
      "Counts of misclassified original labels: {0: 2018, 2: 66, 3: 78, 4: 52, 5: 51, 7: 60, 8: 44}\n",
      "Test : Accuracy: 0.9964 Recall : 0.0304 FDR: 0.9946  F1-score: 0.0092  \n",
      "********** AE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0067 std: 0.1255\n",
      "Val: Accuracy: 0.9955  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.1322\n",
      "Counter({0: 657231, 1: 2065}) Counter({0: 658934, 1: 362})\n",
      "Counts of  labels: {0: 658934, 2: 66, 3: 78, 4: 52, 5: 62, 7: 60, 8: 44}\n",
      "Counts of misclassified original labels: {0: 2054, 2: 66, 3: 78, 4: 52, 5: 51, 7: 60, 8: 44}\n",
      "Test : Accuracy: 0.9964 Recall : 0.0304 FDR: 0.9947  F1-score: 0.0091  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.3831\n",
      "Counter({0: 657749, 1: 1547}) Counter({0: 658934, 1: 362})\n",
      "Counts of  labels: {0: 658934, 2: 66, 3: 78, 4: 52, 5: 62, 7: 60, 8: 44}\n",
      "Counts of misclassified original labels: {0: 1536, 2: 66, 3: 78, 4: 52, 5: 51, 7: 60, 8: 44}\n",
      "Test : Accuracy: 0.9971 Recall : 0.0304 FDR: 0.9929  F1-score: 0.0115  \n"
     ]
    }
   ],
   "source": [
    "for scenario in {\"compromised-scada\",\"compromised-ied\"}:\n",
    "    print(\"scenario :\",scenario,\"node ied1b\")\n",
    "    val_files = [col for col in modbus.dataset[\"benign_dataset_dir\"] if col.find(\"ied1b\")!=-1][:]\n",
    "    test_files= [col for col in modbus.dataset[\"attack_dataset_dir\"][scenario] if col.find(\"ied1b\")!=-1]\n",
    "    #\n",
    "    sys_rand = SystemRandom()\n",
    "    sys_rand.shuffle(val_files)\n",
    "    sys_rand.shuffle(test_files)\n",
    "    print(\"----------- benign valid files:\",len(val_files),val_files)\n",
    "    print(f\"----------{scenario} attack  test files : \",len(test_files),test_files)\n",
    "    val_dataloader=DataLoader(ModbusFlowStream(\n",
    "                shuffle=False,\n",
    "                chunk_size=100,\n",
    "                batch_size=64,\n",
    "                csv_files=val_files,\n",
    "                scalers=loaded_scalers['network-wide']['min_max_scalers'],\n",
    "            ),batch_size=1,shuffle=False)\n",
    "    test_dataloader=DataLoader(ModbusFlowStream(\n",
    "                shuffle=False,\n",
    "                chunk_size=100,\n",
    "                batch_size=64,\n",
    "                csv_files=test_files,\n",
    "                scalers=loaded_scalers['network-wide']['min_max_scalers'],\n",
    "            ),batch_size=1,shuffle=False)\n",
    "    for trained_model in {Trained_AE_model,Trained_VAE_model,Trained_AAE_model}:\n",
    "        print(\"*\"*10,trained_model._get_name(),10*\"*\")\n",
    "        train_eval(trained_model,None,val_dataloader,test_dataloader,shuffle_files=False,num_epochs=1,eval_epoch=1,criterion_method=\"mse\",train_model=False,learning_rates=[0],weight_decays=[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e10197",
   "metadata": {},
   "source": [
    "### FedAvg - non iid distribution (ip based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f948763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 1. SETUP: INSTALL LIBRARIES AND IMPORT DEPENDENCIES\n",
    "# ==============================================================================\n",
    "# In a Kaggle notebook, run this cell first to install the necessary libraries.\n",
    "!pip install -q flwr[simulation] torch torchvision pandas scikit-learn matplotlib seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc049d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import flwr as fl\n",
    "from collections import OrderedDict\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import seaborn as sns\n",
    "import os \n",
    "from flwr.common import Context # Make sure this import is added\n",
    "\n",
    "# Suppress warning messages for a cleaner output\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "# Set a seed for reproducibility\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "#global device\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on {DEVICE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69c2c487",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================================================================\n",
    "# 2. CONFIGURATION: TWEAK  FEDERATED LEARNING EXPERIMENT\n",
    "# ==============================================================================\n",
    "class Config:\n",
    "    \"\"\"Global configuration class for the federated learning experiment.\"\"\"\n",
    "    # --- FL Parameters ---\n",
    "    NUM_TRAIN_CLIENTS = 4\n",
    "    NUM_ROUNDS = 10\n",
    "    LOCAL_EPOCHS = 5\n",
    "    BATCH_SIZE = 64\n",
    "    LEARNING_RATE = 5e-5\n",
    "    WEIGHT_DECAY = 1e-4\n",
    "    # --- Strategy Selection ---\n",
    "    # Choose from \"FED_AVG\", \"FED_PROX\"\n",
    "    STRATEGY = \"FED_AVG\" \n",
    "    PROXIMAL_MU = 0.1 # Proximal term for FedProx\n",
    "    # --- Model Selection ---\n",
    "    # Choose from \"AE\" (Autoencoder) or \"VAE\" (Variational Autoencoder) or \"AdverserialAutoencoder\"\n",
    "    MODEL_NAME = \"AE\"\n",
    "    INPUT_DIM = 76\n",
    "    # --- Anomaly Detection ---\n",
    "    # ANOMALY_THRESHOLD is calculated dynamically in the evaluation function.\n",
    "    EVAL_DATA_FILES = [\"data_9.csv\", \"data_10.csv\"]\n",
    "    SHUFFLE_FILES=  True\n",
    "# Instantiate the configuration\n",
    "cfg = Config()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2873163a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================================================================\n",
    "# 3. DATA Distribution\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "ied1b_train_files=[col for col in modbus.dataset[\"benign_dataset_dir\"] if col.find(\"ied1b\")!=-1]\n",
    "ied1a_train_files=[col for col in modbus.dataset[\"benign_dataset_dir\"] if col.find(\"ied1a\")!=-1]\n",
    "ied4c_train_files=[col for col in modbus.dataset[\"benign_dataset_dir\"] if col.find(\"ied4c\")!=-1]\n",
    "scada_train_files=[col for col in modbus.dataset[\"benign_dataset_dir\"] if col.find(\"scada-hmi\")!=-1]\n",
    "cent_agent_train_files=[col for col in modbus.dataset[\"benign_dataset_dir\"] if col.find(\"central-agent\")!=-1]\n",
    "\n",
    "TRAIN_CLIENT_DATA_MAPPING = {\n",
    "    0: ied1b_train_files,\n",
    "    1: ied1a_train_files,\n",
    "    2: ied4c_train_files,\n",
    "    3: scada_train_files,\n",
    "    4: cent_agent_train_files,\n",
    "}\n",
    "\n",
    "SERVER_EVALUATION_DATA_MAPPING = {\n",
    "    0: val_files,\n",
    "    1: test_files \n",
    "}\n",
    "\n",
    "def load_data(id: int, node = \"client\" ):\n",
    "    \"\"\"Loads the data for a specific training client.\"\"\"\n",
    "    if node == \"client\":\n",
    "        file_list = TRAIN_CLIENT_DATA_MAPPING[id]\n",
    "        shuffle=cfg.SHUFFLE_FILES\n",
    "    else: # server\n",
    "        file_list = SERVER_EVALUATION_DATA_MAPPING[id]\n",
    "        shuffle = False\n",
    "\n",
    "    train_loader=DataLoader(ModbusFlowStream(\n",
    "            shuffle=shuffle,\n",
    "            chunk_size=1,\n",
    "            batch_size=cfg.BATCH_SIZE ,\n",
    "            csv_files=file_list,\n",
    "            scalers=loaded_scalers['network-wide']['min_max_scalers'],\n",
    "        ),batch_size=1,shuffle=False)\n",
    "    return train_loader\n",
    "def get_model():\n",
    "    \"\"\"Returns the model specified in the config.\"\"\"\n",
    "    if cfg.MODEL_NAME == \"VAE\":\n",
    "        print(f\"Using Variational Autoencoder (VAE) \")\n",
    "        return VAE(input_dim=cfg.INPUT_DIM)\n",
    "    elif cfg.MODEL_NAME == \"AE\":\n",
    "        print(f\"Using Autoencoder (AE) \")\n",
    "        return AE(input_dim=cfg.INPUT_DIM)\n",
    "    elif cfg.MODEL_NAME ==\"AdverserialAutoencoder\":\n",
    "        print(f\"Using Adverserial Autoencoder (AAE) \")\n",
    "        return AdverserialAutoencoder(input_dim=76)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model name: {cfg.MODEL_NAME}. Choose 'AE' or 'VAE' or 'AdverserialAutoencoder'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30addecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================================================================\n",
    "# 5. FEDERATED LEARNING CLIENT: FlowerClient\n",
    "# ==============================================================================\n",
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    \"\"\"Flower client for training.\"\"\"\n",
    "    def __init__(self, cid, model, trainloader):\n",
    "        self.cid = cid\n",
    "        self.model = model\n",
    "        self.train_dataloader = trainloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n",
    "\n",
    "    def set_parameters(self, parameters):\n",
    "        params_dict = zip(self.model.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "        self.model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        model =self.model\n",
    "        lr = cfg.LEARNING_RATE\n",
    "        wd= cfg.WEIGHT_DECAY\n",
    "        \n",
    "        criterion = nn.MSELoss(reduction='sum').to(DEVICE)\n",
    "        if model._get_name()==\"AdversarialAutoencoder\":\n",
    "            adversarial_criterion= nn.BCELoss(reduction=\"sum\")\n",
    "            optimizer_D = optim.Adam(model.discriminator.parameters(), lr=lr, weight_decay=wd)\n",
    "            optimizer_G =  optim.Adam(list(model.encoder.parameters()) + list(model.decoder.parameters()), lr=lr, weight_decay=wd)\n",
    "        else:\n",
    "            AE_optimizer = optim.Adam(model.parameters(), lr=lr,weight_decay=wd)\n",
    "\n",
    "        if cfg.STRATEGY == \"FED_PROX\":\n",
    "            global_params = [torch.tensor(p, device=DEVICE) for p in parameters]\n",
    "\n",
    "        for epoch in range(cfg.LOCAL_EPOCHS):\n",
    "                time_1 = time.time()\n",
    "                model.train()\n",
    "                train_loss = 0\n",
    "                ## for AAE\n",
    "                Discriminator_loss = 0\n",
    "                if cfg.SHUFFLE_FILES:\n",
    "                    sys_rand = SystemRandom()\n",
    "                    sys_rand.shuffle(self.train_dataloader.dataset.csv_files)\n",
    "                for sequences, _ in self.train_dataloader:\n",
    "                    sequences=sequences.squeeze().to(DEVICE)\n",
    "                    if model._get_name()==\"AdversarialAutoencoder\":\n",
    "                        target_ones= torch.ones(sequences.size(0), 1,device=DEVICE,dtype=torch.float)\n",
    "                        target_zeros= torch.zeros(sequences.size(0), 1,device=DEVICE,dtype=torch.float)\n",
    "                        random_latent = torch.randn(sequences.size(0), 2, device=DEVICE)\n",
    "                        optimizer_G.zero_grad()\n",
    "                        fake_z,decoded_seq = model(sequences)\n",
    "                        G_loss = 0.001*adversarial_criterion(model.discriminator(fake_z),target_ones ) + 0.999*criterion(decoded_seq, sequences)\n",
    "                        G_loss.backward()\n",
    "                        optimizer_G.step()\n",
    "                        # 2) discriminator loss\n",
    "                        optimizer_D.zero_grad()\n",
    "                        real_loss = adversarial_criterion(model.discriminator(random_latent), target_ones)\n",
    "                        fake_loss = adversarial_criterion(model.discriminator(fake_z.detach()),  target_zeros)\n",
    "                        D_loss =  0.001*0.5*(real_loss + fake_loss)\n",
    "                        D_loss.backward()\n",
    "                        optimizer_D.step()\n",
    "                        train_loss+=G_loss.item()\n",
    "                        Discriminator_loss+=D_loss.item()   \n",
    "                    else:\n",
    "                        AE_optimizer.zero_grad()\n",
    "                        if model._get_name()==\"AE\":\n",
    "                            recon = model(sequences)\n",
    "                            loss = criterion(recon, sequences) / sequences.size(0)\n",
    "                        elif model._get_name()==\"VAE\" or model._get_name()==\"GRUVAE\":\n",
    "                            recon, mu, logvar = model(sequences)\n",
    "                            loss = vae_loss_function(recon, sequences, mu, logvar) /sequences.size(0)\n",
    "                            if cfg.STRATEGY == \"FED_PROX\":\n",
    "                                proximal_term = 0.0\n",
    "                                for local_w, global_w in zip(model.parameters(), global_params):\n",
    "                                    proximal_term += (local_w - global_w).norm(2)\n",
    "                                loss += (cfg.PROXIMAL_MU / 2) * proximal_term\n",
    "                        loss.backward()\n",
    "                        AE_optimizer.step()\n",
    "                        train_loss += loss.item()\n",
    "                print(f\"Train : time {(time.time()-time_1):.2f} s\",\n",
    "                f\"Epoch {epoch+1}\")\n",
    "                if model._get_name()==\"AdversarialAutoencoder\":\n",
    "                    print(f\"Generator Loss: {train_loss / len(self.train_dataloader):.4f}\",\n",
    "                        f\"Discriminator Loss: {Discriminator_loss / len(self.train_dataloader):.4f}\")\n",
    "                else:\n",
    "                    print(f\"Train Loss: {train_loss / len(self.train_dataloader):.4f}\")\n",
    "        return self.get_parameters(config={}), len(self.trainloader.dataset), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        return 0.0, 0, {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5903afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flower.common import ndarrays_to_parameters, parameters_to_ndarrays\n",
    "\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 6. SERVER-SIDE LOGIC AND SIMULATION START\n",
    "# ==============================================================================\n",
    "def client_fn(context: Context) -> FlowerClient:\n",
    "    \"\"\"Create a Flower client instance for a given client ID.\"\"\"\n",
    "    # The client's ID is retrieved from the context.\n",
    "    client_id = int(context.node_config[\"partition-id\"])\n",
    "    model = get_model().to(DEVICE)\n",
    "    trainloader = load_data(client_id)\n",
    "    return FlowerClient(client_id, model, trainloader).to_client()\n",
    "\n",
    "def get_evaluate_fn():\n",
    "    \"\"\"Return an evaluation function for server-side evaluation.\"\"\"\n",
    "    val_dataloader = load_data(0)\n",
    "    test_dataloader = load_data(1)\n",
    "    eval_criterion = nn.MSELoss(reduction='none').to(DEVICE)\n",
    "\n",
    "    def evaluate(\n",
    "        server_round: int,\n",
    "        parameters: fl.common.NDArrays,\n",
    "        config: Dict[str, fl.common.Scalar],\n",
    "    ) -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:\n",
    "        model = get_model() # Use the get_model function\n",
    "        params_dict = zip(model.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "        model.load_state_dict(state_dict, strict=True)\n",
    "        model.to(DEVICE)\n",
    "        model.eval()\n",
    "        # Evaluate part\n",
    "        all_val_losses = []\n",
    "        all_val_labels = []\n",
    "        print(f\"--- Running Evaluation for Server round {server_round} ---\")\n",
    "        with torch.no_grad():\n",
    "            for sequences, labels in val_dataloader:\n",
    "                sequences = sequences.squeeze().to(DEVICE) \n",
    "                if labels.sum()!=0:\n",
    "                    continue\n",
    "                if model._get_name()==\"AE\":\n",
    "                    recon = model(sequences)\n",
    "                elif model._get_name()==\"VAE\" or model._get_name()==\"GRUVAE\" :\n",
    "                    recon, _, _ = model(sequences)\n",
    "                elif model._get_name()==\"AdversarialAutoencoder\":\n",
    "                    _,recon= model(sequences)\n",
    "                val_loss = eval_criterion(recon, sequences)\n",
    "                if val_loss.dim() > 1:\n",
    "                    val_loss = val_loss\n",
    "                else:\n",
    "                    val_loss = val_loss.unsqueeze(dim=0)\n",
    "                    labels = labels.unsqueeze(dim=0)\n",
    "                if val_loss.dim()==3:\n",
    "                    ##GRU : mean of window\n",
    "                    val_loss = val_loss.mean(dim=1)\n",
    "                val_loss = val_loss.sum(dim=1)\n",
    "                all_val_losses.extend(val_loss.cpu().numpy())\n",
    "                all_val_labels.extend(labels.flatten().cpu().numpy())     \n",
    "        threshold_1,std_mse = compute_threshold(all_val_losses,k=0)\n",
    "\n",
    "        all_val_losses = np.array(all_val_losses).squeeze()  \n",
    "        all_val_labels = np.array(all_val_labels).squeeze()  \n",
    "        # If intrusion score > threshold, predict 1 (intrusion), else 0 (benign)\n",
    "        # For FDR, get True Positives (TP) and False Positives (FP)\n",
    "        \n",
    "        predictions = (all_val_losses > threshold_1).astype(int)\n",
    "\n",
    "        accuracy = accuracy_score(all_val_labels, predictions)\n",
    "        print(f\"Val: Accuracy: {accuracy:.4f}  \")\n",
    "        model.eval() \n",
    "\n",
    "        all_test_losses = []\n",
    "        all_test_labels = []\n",
    "        with torch.no_grad():\n",
    "            for sequences, labels in test_dataloader:\n",
    "                sequences = sequences.squeeze().to(DEVICE)\n",
    "                labels = labels.squeeze().to(DEVICE)\n",
    "                if model._get_name()==\"AE\":\n",
    "                    recon = model(sequences)\n",
    "                elif model._get_name()==\"VAE\"  or model._get_name()==\"GRUVAE\":\n",
    "                    recon, mu, logvar = model(sequences)\n",
    "                elif model._get_name()==\"AdversarialAutoencoder\":\n",
    "                    _,recon= model(sequences)\n",
    "\n",
    "                intrusion_scores = eval_criterion(recon, sequences)\n",
    "                if intrusion_scores.dim() > 1:\n",
    "                    intrusion_scores = intrusion_scores\n",
    "                else:\n",
    "                    intrusion_scores = intrusion_scores.unsqueeze(dim=0)\n",
    "                    labels = labels.unsqueeze(dim=0)\n",
    "                if intrusion_scores.dim()==3:\n",
    "                    ##GRU : mean of window\n",
    "                    intrusion_scores = intrusion_scores.mean(dim=1)\n",
    "                intrusion_scores = intrusion_scores.sum(dim=1)\n",
    "                all_test_losses.extend(intrusion_scores.cpu().numpy())\n",
    "                all_test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        all_test_losses = np.array(all_test_losses)\n",
    "        all_test_labels = np.array(all_test_labels)\n",
    "        test_result = {}\n",
    "        for k in {1,3}:\n",
    "            threshold=threshold_1+k*std_mse\n",
    "            print(f\" K: {k} K-SIGMA Threshold : ---thr {threshold:.4}\")\n",
    "            predictions = (all_test_losses > threshold).astype(int)\n",
    "            binary_test_labels = (all_test_labels != 0).astype(int)\n",
    "\n",
    "            # Find the indices where the prediction was incorrect\n",
    "            misclassified_indices = np.where(binary_test_labels != predictions)[0]\n",
    "\n",
    "            # Get the original labels for those misclassified instances\n",
    "            misclassified_original_labels = all_test_labels[misclassified_indices]\n",
    "\n",
    "            # To get a summary count of which labels were misclassified\n",
    "            print(Counter(predictions),Counter(binary_test_labels))\n",
    "            print(f\"Counts of  labels: {dict(sorted(Counter(all_test_labels).items()))}\")\n",
    "            print(f\"Counts of misclassified original labels: {dict(sorted(Counter(misclassified_original_labels).items()))}\")\n",
    "            accuracy = accuracy_score(binary_test_labels, predictions)\n",
    "            f1 = f1_score(binary_test_labels, predictions, zero_division=0)\n",
    "            recall = recall_score(binary_test_labels, predictions,zero_division=0)\n",
    "            _, fp, _, tp = confusion_matrix(binary_test_labels, predictions, labels=[0, 1]).ravel()\n",
    "            # FDR = FP / (FP + TP) \n",
    "            if (fp + tp) == 0:\n",
    "                fdr = 0.0 \n",
    "            else:\n",
    "                fdr = fp / (fp + tp)\n",
    "            test_result[k] = f\"k= {k} ,Test : Accuracy: {accuracy:.4f} Recall : {recall:.4f} FDR: {fdr:.4f}  F1-score: {f1:.4f} \"\n",
    "            print(test_result[k])\n",
    "        return np.sum(all_test_losses)/len(all_test_losses),test_result\n",
    "    return evaluate\n",
    "\n",
    "def get_initial_parameters(model: torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Initializes the model weights using Xavier uniform distribution\n",
    "    and returns them as a Flower Parameters object.\n",
    "    \"\"\"\n",
    "    temp_model = model()\n",
    "    \n",
    "    for param in temp_model.parameters():\n",
    "        if param.dim() > 1:\n",
    "            nn.init.xavier_uniform_(param)\n",
    "            \n",
    "    ndarrays = [val.cpu().numpy() for _, val in temp_model.state_dict().items()]\n",
    "    return ndarrays_to_parameters(ndarrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635dab53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n",
      "\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n",
      "\n",
      "\t\t$ flwr new  # Create a new Flower app from a template\n",
      "\n",
      "\t\t$ flwr run  # Run the Flower app in Simulation Mode\n",
      "\n",
      "\tUsing `start_simulation()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=10, no round_timeout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using FedAvg strategy with AE model.\n",
      "Starting federated learning simulation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-17 13:33:32,745\tINFO worker.py:1771 -- Started a local Ray instance.\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'accelerator_type:G': 1.0, 'node:__internal_head__': 1.0, 'node:172.27.10.149': 1.0, 'CPU': 4.0, 'memory': 6197892711.0, 'object_store_memory': 3098946355.0, 'GPU': 1.0}\n",
      "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 4, 'num_gpus': 0.25}\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 1 actors\n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
      "\u001b[36m(ClientAppActor pid=119723)\u001b[0m /home/hamid_rd3/labeling/FLBased-ICS-NIDS-main/modbus.py:4: DeprecationWarning: \n",
      "\u001b[36m(ClientAppActor pid=119723)\u001b[0m Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "\u001b[36m(ClientAppActor pid=119723)\u001b[0m (to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "\u001b[36m(ClientAppActor pid=119723)\u001b[0m but was not found to be installed on your system.\n",
      "\u001b[36m(ClientAppActor pid=119723)\u001b[0m If this would cause problems for you,\n",
      "\u001b[36m(ClientAppActor pid=119723)\u001b[0m please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "\u001b[36m(ClientAppActor pid=119723)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=119723)\u001b[0m   import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=119723)\u001b[0m Using Autoencoder (AE) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 0 ---\n",
      "-----------mse_loss mean :  17.2565 std: 0.0250\n",
      "Val: Accuracy: 0.5170  \n",
      " K: 1 K-SIGMA Threshold : ---thr 17.28\n",
      "Counter({0: 710557, 1: 515282}) Counter({0: 1225839})\n",
      "Counts of  labels: {0: 1225839}\n",
      "Counts of misclassified original labels: {0: 515282}\n",
      "k= 1 ,Test : Accuracy: 0.5796 Recall : 0.0000 FDR: 1.0000  F1-score: 0.0000 \n",
      " K: 3 K-SIGMA Threshold : ---thr 17.33\n",
      "Counter({0: 912970, 1: 312869}) Counter({0: 1225839})\n",
      "Counts of  labels: {0: 1225839}\n",
      "Counts of misclassified original labels: {0: 312869}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 16.642735302107372, {1: 'k= 1 ,Test : Accuracy: 0.5796 Recall : 0.0000 FDR: 1.0000  F1-score: 0.0000 ', 3: 'k= 3 ,Test : Accuracy: 0.7448 Recall : 0.0000 FDR: 1.0000  F1-score: 0.0000 '}\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 3 ,Test : Accuracy: 0.7448 Recall : 0.0000 FDR: 1.0000  F1-score: 0.0000 \n",
      "\u001b[36m(ClientAppActor pid=119723)\u001b[0m Using Autoencoder (AE) \n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "# --- Select the Federation Strategy ---\n",
    "evaluate_function = get_evaluate_fn()\n",
    "\n",
    "if cfg.STRATEGY == \"FED_PROX\":\n",
    "    strategy = fl.server.strategy.FedProx(\n",
    "        fraction_fit=1.0, fraction_evaluate=0.0,\n",
    "        min_fit_clients=cfg.NUM_TRAIN_CLIENTS,\n",
    "        min_available_clients=cfg.NUM_TRAIN_CLIENTS,\n",
    "        evaluate_fn=evaluate_function,\n",
    "        proximal_mu=cfg.PROXIMAL_MU,\n",
    "        initial_parameters=get_initial_parameters(cf)\n",
    "    )\n",
    "    print(\"Using FedProx strategy.\")\n",
    "else:\n",
    "    strategy = fl.server.strategy.FedAvg(\n",
    "        fraction_fit=1.0, fraction_evaluate=0.0,\n",
    "        min_fit_clients=cfg.NUM_TRAIN_CLIENTS,\n",
    "        min_available_clients=cfg.NUM_TRAIN_CLIENTS,\n",
    "        evaluate_fn=evaluate_function,\n",
    "    )\n",
    "    print(f\"Using FedAvg strategy with {cfg.MODEL_NAME} model.\")\n",
    "\n",
    "# --- Start the Simulation ---\n",
    "print(\"Starting federated learning simulation...\")\n",
    "history = fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=cfg.NUM_TRAIN_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=cfg.NUM_ROUNDS),\n",
    "    strategy=strategy,\n",
    "    client_resources={\"num_cpus\": 4, \"num_gpus\": 1/cfg.NUM_TRAIN_CLIENTS} if DEVICE.type == \"cuda\" else {\"num_cpus\": 4},\n",
    ")\n",
    "print(\"Federated learning simulation finished.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7758849,
     "sourceId": 12309500,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 250292947,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "vnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
