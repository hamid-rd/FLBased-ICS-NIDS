{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d238262",
   "metadata": {},
   "source": [
    "### Unsupervised GRU-VAE training  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2c01e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np # For standard deviation calculation\n",
    "from modbus import ModbusDataset,ModbusFlowStream\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix,recall_score\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "import os \n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import random\n",
    "from utils import load_scalers\n",
    "from random import SystemRandom\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import torch.nn.init as init\n",
    "\n",
    "\n",
    "def compute_threshold(mse_values):\n",
    "    \"\"\"\n",
    "    Computes the anomaly detection threshold (for marking sample as Intrusion if the IS was greater )\n",
    "    based on the mean and standard deviation of Mean Squared Error (MSE) values.\n",
    "    Formula: thr = mean(MSE) + std(MSE)\n",
    "\n",
    "    Args:\n",
    "        mse_values (torch.Tensor or list/np.array): A tensor or list of MSE values\n",
    "                                                    obtained from the validation set.\n",
    "\n",
    "    Returns:\n",
    "        float: The calculated threshold.\n",
    "    \"\"\"\n",
    "    if not isinstance(mse_values, torch.Tensor):\n",
    "        mse_values = torch.tensor(mse_values, dtype=torch.float32)\n",
    "\n",
    "    if mse_values.numel() == 0:\n",
    "        return 0.0 \n",
    "    mean_mse = torch.mean(mse_values)\n",
    "    std_mse = torch.std(mse_values)\n",
    "\n",
    "    threshold = mean_mse + std_mse\n",
    "    return threshold.item() \n",
    "\n",
    "def vae_loss_function(recon_x, x, mu, logvar,beta =1):\n",
    "    \"\"\"\n",
    "    VAE loss function.\n",
    "    \"\"\"\n",
    "    BCE = nn.functional.mse_loss(recon_x, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return (BCE + beta*KLD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9478520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The CIC Modbus Dataset contains network (pcap) captures and attack logs from a simulated substation network.\n",
      "                The dataset is categorized into two groups: an attack dataset and a benign dataset\n",
      "                The attack dataset includes network traffic captures that simulate various types of Modbus protocol attacks in a substation environment.\n",
      "                The attacks are reconnaissance, query flooding, loading payloads, delay response, modify length parameters, false data injection, stacking Modbus frames, brute force write and baseline replay.\n",
      "                These attacks are based of some techniques in the MITRE ICS ATT&CK framework.\n",
      "                On the other hand, the benign dataset consists of normal network traffic captures representing legitimate Modbus communication within the substation network.\n",
      "                The purpose of this dataset is to facilitate research, analysis, and development of intrusion detection systems, anomaly detection algorithms and other security mechanisms for substation networks using the Modbus protocol.\n",
      "                https://www.unb.ca/cic/datasets/modbus-2023.html\n",
      "                In my custom PyTorch Dataset class,\n",
      "                I utilize the Enhanced CICflowMeter and the Attack logs correlation to extract and label sequential data flows,\n",
      "                preparing them for batch processing with the DataLoader, which is crucial for AI model training.\n",
      "                https://github.com/hamid-rd/FLBased-ICS-NIDS/tree/main\n",
      "\n",
      "                \n",
      "csv files  in the dataset directory founded with the filter:  ready\n",
      "{\n",
      "    \"total_dataset_num\": 170,\n",
      "    \"benign_dataset_num\": 62,\n",
      "    \"attack_dataset_num\": {\n",
      "        \"total_num\": 108,\n",
      "        \"external_num\": 8,\n",
      "        \"compromised-ied_num\": 43,\n",
      "        \"compromised-scada_num\": 57\n",
      "    },\n",
      "    \"attack_logs_num\": {\n",
      "        \"total_num\": 0,\n",
      "        \"external_num\": [],\n",
      "        \"compromised-ied_num\": 0,\n",
      "        \"compromised-scada_num\": 0\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "dataset_directory = \"./dataset\" # change this to the folder contain benign and attack subdirs\n",
    "modbus = ModbusDataset(dataset_directory,\"ready\")\n",
    "modbus.summary_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "510ea189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_weights( module):\n",
    "    if isinstance(module, nn.Linear):\n",
    "        #Xavier Initialization\n",
    "        init.xavier_normal_(module.weight)\n",
    "        if module.bias is not None:\n",
    "            init.zeros_(module.bias)\n",
    "    return module\n",
    "# AutoEncoder (AE)\n",
    "class AE(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder: (89-64-32)\n",
    "    Decoder: (32-64-89)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(AE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(89, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 89),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        x_recon = self.decoder(z)\n",
    "        return x_recon\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "74fb743d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.1040,  0.0537, -0.0960,  ..., -0.1059,  0.0405,  0.0280],\n",
      "        [-0.0164,  0.0952, -0.0784,  ...,  0.0404,  0.0534,  0.0173],\n",
      "        [-0.0385,  0.0915,  0.0383,  ...,  0.0031, -0.0315, -0.0096],\n",
      "        ...,\n",
      "        [ 0.1002, -0.0972, -0.0732,  ..., -0.0014,  0.0039, -0.0452],\n",
      "        [-0.0682,  0.0007, -0.0890,  ...,  0.0590, -0.0071, -0.0748],\n",
      "        [ 0.0239,  0.1055,  0.0341,  ..., -0.0421,  0.0008,  0.1047]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1040,  0.0537, -0.0960,  ..., -0.1059,  0.0405,  0.0280],\n",
      "        [-0.0164,  0.0952, -0.0784,  ...,  0.0404,  0.0534,  0.0173],\n",
      "        [-0.0385,  0.0915,  0.0383,  ...,  0.0031, -0.0315, -0.0096],\n",
      "        ...,\n",
      "        [ 0.1002, -0.0972, -0.0732,  ..., -0.0014,  0.0039, -0.0452],\n",
      "        [-0.0682,  0.0007, -0.0890,  ...,  0.0590, -0.0071, -0.0748],\n",
      "        [ 0.0239,  0.1055,  0.0341,  ..., -0.0421,  0.0008,  0.1047]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0686,  0.0836, -0.0466,  ...,  0.0031,  0.0578, -0.0419],\n",
      "        [-0.0607, -0.0072, -0.1243,  ..., -0.0258,  0.0110, -0.0085],\n",
      "        [ 0.1819, -0.1079,  0.0496,  ..., -0.1680,  0.1653, -0.1968],\n",
      "        ...,\n",
      "        [ 0.0494,  0.0496, -0.0251,  ..., -0.1232, -0.1470,  0.0172],\n",
      "        [ 0.0020,  0.0323,  0.0822,  ...,  0.0855,  0.1923, -0.2587],\n",
      "        [-0.1034,  0.0446, -0.0216,  ..., -0.0136,  0.0220, -0.1080]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0785,  0.0442,  0.2202,  ..., -0.0545, -0.1306, -0.0869],\n",
      "        [-0.0546,  0.0293, -0.0444,  ..., -0.3096,  0.1633, -0.0184],\n",
      "        [ 0.0126,  0.0858, -0.0166,  ..., -0.0531,  0.0193, -0.0250],\n",
      "        ...,\n",
      "        [-0.0642, -0.0066, -0.0012,  ...,  0.0511,  0.0477, -0.1798],\n",
      "        [ 0.0580,  0.0268, -0.0023,  ..., -0.1341,  0.1284,  0.0848],\n",
      "        [-0.2614,  0.0860,  0.1729,  ..., -0.2849, -0.1150, -0.0361]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "a = AE()\n",
    "first_iterator = list(a.parameters())\n",
    "print(first_iterator[0])\n",
    "print(first_iterator[0])\n",
    "\n",
    "a.apply(_init_weights)\n",
    "first_iterator = list(a.parameters())\n",
    "print(first_iterator[0])\n",
    "a.apply(_init_weights)\n",
    "print(first_iterator[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "310d2f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ied1b comp ied attack ->\n",
      " test:  4 ['./dataset/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-6-labeled.csv', './dataset/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-3-labeled.csv', './dataset/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-4-labeled.csv', './dataset/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-1-labeled.csv']\n",
      "network-wide number of csv files ->\n",
      " train : 15 ['./dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-23-labeled.csv', './dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-17-labeled.csv', './dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-14-labeled.csv', './dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-28-labeled.csv', './dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-19-labeled.csv', './dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-15-labeled.csv', './dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-20-labeled.csv', './dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-26-labeled.csv', './dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-25-labeled.csv', './dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-22-labeled.csv', './dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-21-labeled.csv', './dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-16-labeled.csv', './dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-18-labeled.csv', './dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-29-labeled.csv', './dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-32-labeled.csv'] \n",
      " valid: 4 ['./dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-31-labeled.csv', './dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-30-labeled.csv', './dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-27-labeled.csv', './dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-24-labeled.csv']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "csv_files=[col for col in modbus.dataset[\"benign_dataset_dir\"] if col.find(\"network-wide\")!=-1]\n",
    "sys_rand = SystemRandom()\n",
    "sys_rand.shuffle(csv_files)\n",
    "train_files,val_files = train_test_split(csv_files,test_size=0.2,shuffle=True)\n",
    "test_files=[col for col in modbus.dataset[\"attack_dataset_dir\"][\"compromised-scada\"] if col.find(\"ied1b\")!=-1][0:4]\n",
    "print(\"ied1b comp ied attack ->\\n test: \",len(test_files),test_files)\n",
    "print(\"network-wide number of csv files ->\\n train :\",len(train_files),train_files,\"\\n valid:\",len(val_files),val_files)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eac4698b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded scalers for 'network-wide'\n"
     ]
    }
   ],
   "source": [
    "loaded_scalers = load_scalers(\"fitted_scalers\")\n",
    "AE_train_dataset=ModbusFlowStream( \n",
    "    shuffle=True,chunk_size=1,batch_size=64,csv_files=train_files,scalers=loaded_scalers['network-wide']['min_max_scalers'],window_size=1\n",
    ")\n",
    "AE_train_dataloader=DataLoader(AE_train_dataset,batch_size=1,shuffle=False)\n",
    "AE_val_dataloader=DataLoader(ModbusFlowStream( \n",
    "    shuffle=False,chunk_size=1,batch_size=64,csv_files=val_files,scalers=loaded_scalers['network-wide']['min_max_scalers'],window_size=1\n",
    "),batch_size=1,shuffle=False)\n",
    "AE_test_dataloader=DataLoader(ModbusFlowStream(shuffle=False,chunk_size=1,batch_size=64,csv_files=test_files,scalers=loaded_scalers['network-wide']['min_max_scalers'],window_size=1),batch_size=1,shuffle=False)\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "AE_model = AE().to(device)\n",
    "lr = 0.01\n",
    "wd= 1e-4\n",
    "shuffle_files =True\n",
    "AE_optimizer = optim.Adam(AE_model.parameters(), lr=lr, weight_decay=wd)\n",
    "criterion = nn.MSELoss(reduction='sum').to(device)\n",
    "eval_criterion = nn.MSELoss(reduction='none').to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2d2e0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_eval(model,train_dataloader,val_dataloader,test_dataloader,learning_rates= [0.01, 0.001, 1e-4, 1e-5],\n",
    "               weight_decays=[1e-4, 1e-5, 1e-6],shuffle_files=True,epochs=2):\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    criterion = nn.MSELoss(reduction='sum').to(device)\n",
    "    eval_criterion = nn.MSELoss(reduction='none').to(device)\n",
    "    for lr, wd in itertools.product(learning_rates, weight_decays):\n",
    "        print(f\"\\n================== Evaluate lr={lr}, wd={wd} ==================\")\n",
    "        model.apply(_init_weights)\n",
    "        AE_optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "        for epoch in range(epochs):\n",
    "            time_1 = time.time()\n",
    "            train_loss = 0\n",
    "            model.train()\n",
    "            if shuffle_files:\n",
    "                sys_rand = SystemRandom()\n",
    "                sys_rand.shuffle(AE_train_dataset.file_order_indices)\n",
    "            for sequences, _ in train_dataloader:\n",
    "                sequences=sequences.squeeze().to(device)\n",
    "                AE_optimizer.zero_grad()\n",
    "\n",
    "                if model._get_name()==\"AE\":\n",
    "                    recon = model(sequences)\n",
    "                    loss = criterion(recon, sequences) / sequences.size(0)\n",
    "                elif model._get_name()==\"VAE\":\n",
    "                    recon, mu, logvar = model(sequences)\n",
    "                    loss = vae_loss_function(recon, sequences, mu, logvar)\n",
    "                loss.backward()\n",
    "                AE_optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "            print(f\"Train : time {(time.time()-time_1):.4f}\",f\"Epoch {epoch}\", f\"Train Loss: {train_loss / len(train_dataloader):.4f}\")\n",
    "            # Evaluate part\n",
    "            if (epoch + 1) % 1 == 0:\n",
    "                model.eval() \n",
    "                all_val_losses = []\n",
    "                all_val_labels = []\n",
    "                print(f\"\\n--- Running Evaluation for Epoch {epoch+1} lr ={lr} wd {wd} ---\")\n",
    "                with torch.no_grad():\n",
    "                    for sequences, labels in val_dataloader:\n",
    "                        sequences = sequences.squeeze().to(device)\n",
    "                                \n",
    "                        if model._get_name()==\"AE\":\n",
    "                            recon = model(sequences)\n",
    "                        elif model._get_name()==\"VAE\":\n",
    "                            recon, mu, logvar = model(sequences)\n",
    "                        val_loss = eval_criterion(recon, sequences)\n",
    "                        if val_loss.dim() > 1:\n",
    "                            intrusion_scores = val_loss.mean(dim=1)\n",
    "                        else:\n",
    "                            intrusion_scores = val_loss.unsqueeze(dim=0).mean(dim=1)\n",
    "                        intrusion_scores = val_loss.mean(dim=1)\n",
    "                        all_val_losses.extend(intrusion_scores.cpu().numpy())\n",
    "                        all_val_labels.extend(labels.flatten().cpu().numpy())            \n",
    "                threshold = compute_threshold(all_val_losses)\n",
    "                print(f\"Computed Threshold: {threshold:.4f}\")\n",
    "                all_val_losses = np.array(all_val_losses).squeeze()  \n",
    "                all_val_labels = np.array(all_val_labels).squeeze()  \n",
    "                # If intrusion score > threshold, predict 1 (intrusion), else 0 (benign)\n",
    "                # For FDR, get True Positives (TP) and False Positives (FP)\n",
    "                predictions = (all_val_losses > threshold).astype(int)\n",
    "                accuracy = accuracy_score(all_val_labels, predictions)\n",
    "                print(f\"Val: Accuracy: {accuracy:.4f}  \")\n",
    "                threshold=0.0023\n",
    "                model.eval() \n",
    "                all_test_losses = []\n",
    "                all_test_labels = []\n",
    "                with torch.no_grad():\n",
    "                    for sequences, labels in test_dataloader:\n",
    "                        sequences = sequences.squeeze().to(device)\n",
    "                        if model._get_name()==\"AE\":\n",
    "                            recon = model(sequences)\n",
    "                        elif model._get_name()==\"VAE\":\n",
    "                            recon, mu, logvar = model(sequences)\n",
    "                        test_loss = eval_criterion(recon, sequences)\n",
    "                        if test_loss.dim() > 1:\n",
    "                            intrusion_scores = test_loss.mean(dim=1)\n",
    "                        else:\n",
    "                            intrusion_scores = test_loss.unsqueeze(dim=0).mean(dim=1)\n",
    "                        all_test_losses.extend(intrusion_scores.cpu().numpy())\n",
    "                        all_test_labels.extend(labels.flatten().cpu().numpy())            \n",
    "                all_test_losses = np.array(all_test_losses)\n",
    "                all_test_labels = np.array(all_test_labels) \n",
    "                predictions = (all_test_losses > threshold).astype(int)\n",
    "                binary_test_labels = (all_test_labels != 0).astype(int)\n",
    "                accuracy = accuracy_score(binary_test_labels, predictions)\n",
    "                f1 = f1_score(binary_test_labels, predictions, zero_division=0)\n",
    "                recall = recall_score(binary_test_labels, predictions,zero_division=0)\n",
    "                tn, fp, fn, tp = confusion_matrix(binary_test_labels, predictions, labels=[0, 1]).ravel()\n",
    "                # FDR = FP / (FP + TP) \n",
    "                if (fp + tp) == 0:\n",
    "                    fdr = 0.0 \n",
    "                else:\n",
    "                    fdr = fp / (fp + tp)\n",
    "                print(f\"Test : Accuracy: {accuracy:.4f} Recall : {recall:.4f} FDR: {fdr:.4f}  F1-score: {f1:.4f}  \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "aa71c4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================== Evaluate lr=0.01, wd=0.0001 ==================\n",
      "Train : time 109.1824 Epoch 0 Train Loss: 0.1841\n",
      "\n",
      "--- Running Evaluation for Epoch 1 lr =0.01 wd 0.0001 ---\n",
      "Computed Threshold: 0.0011\n",
      "Val: Accuracy: 0.9950  \n",
      "Test : Accuracy: 0.8894 Recall : 0.8442 FDR: 0.2954  F1-score: 0.7681  \n",
      "Train : time 106.1758 Epoch 1 Train Loss: 0.0068\n",
      "\n",
      "--- Running Evaluation for Epoch 2 lr =0.01 wd 0.0001 ---\n",
      "Computed Threshold: 0.0009\n",
      "Val: Accuracy: 0.9949  \n",
      "Test : Accuracy: 0.8894 Recall : 0.8442 FDR: 0.2954  F1-score: 0.7681  \n",
      "\n",
      "================== Evaluate lr=0.01, wd=1e-05 ==================\n",
      "Train : time 100.7914 Epoch 0 Train Loss: 0.1683\n",
      "\n",
      "--- Running Evaluation for Epoch 1 lr =0.01 wd 1e-05 ---\n",
      "Computed Threshold: 0.0016\n",
      "Val: Accuracy: 0.9954  \n",
      "Test : Accuracy: 0.8894 Recall : 0.8443 FDR: 0.2954  F1-score: 0.7681  \n",
      "Train : time 99.9983 Epoch 1 Train Loss: 0.0079\n",
      "\n",
      "--- Running Evaluation for Epoch 2 lr =0.01 wd 1e-05 ---\n",
      "Computed Threshold: 0.0012\n",
      "Val: Accuracy: 0.9955  \n",
      "Test : Accuracy: 0.7855 Recall : 0.0608 FDR: 0.4451  F1-score: 0.1095  \n",
      "\n",
      "================== Evaluate lr=0.01, wd=1e-06 ==================\n",
      "Train : time 99.4093 Epoch 0 Train Loss: 0.2716\n",
      "\n",
      "--- Running Evaluation for Epoch 1 lr =0.01 wd 1e-06 ---\n",
      "Computed Threshold: 0.0015\n",
      "Val: Accuracy: 0.9956  \n",
      "Test : Accuracy: 0.7855 Recall : 0.0607 FDR: 0.4451  F1-score: 0.1095  \n",
      "Train : time 99.9659 Epoch 1 Train Loss: 0.0180\n",
      "\n",
      "--- Running Evaluation for Epoch 2 lr =0.01 wd 1e-06 ---\n",
      "Computed Threshold: 0.0034\n",
      "Val: Accuracy: 0.9956  \n",
      "Test : Accuracy: 0.8894 Recall : 0.8443 FDR: 0.2954  F1-score: 0.7682  \n",
      "\n",
      "================== Evaluate lr=0.001, wd=0.0001 ==================\n",
      "Train : time 99.2148 Epoch 0 Train Loss: 0.1038\n",
      "\n",
      "--- Running Evaluation for Epoch 1 lr =0.001 wd 0.0001 ---\n",
      "Computed Threshold: 0.0006\n",
      "Val: Accuracy: 0.9955  \n",
      "Test : Accuracy: 0.7855 Recall : 0.0607 FDR: 0.4450  F1-score: 0.1094  \n",
      "Train : time 102.1952 Epoch 1 Train Loss: 0.0021\n",
      "\n",
      "--- Running Evaluation for Epoch 2 lr =0.001 wd 0.0001 ---\n",
      "Computed Threshold: 0.0007\n",
      "Val: Accuracy: 0.9953  \n",
      "Test : Accuracy: 0.7855 Recall : 0.0607 FDR: 0.4450  F1-score: 0.1094  \n",
      "\n",
      "================== Evaluate lr=0.001, wd=1e-05 ==================\n",
      "Train : time 100.2355 Epoch 0 Train Loss: 0.2166\n",
      "\n",
      "--- Running Evaluation for Epoch 1 lr =0.001 wd 1e-05 ---\n",
      "Computed Threshold: 0.0005\n",
      "Val: Accuracy: 0.9957  \n",
      "Test : Accuracy: 0.7841 Recall : 0.0500 FDR: 0.4720  F1-score: 0.0914  \n",
      "Train : time 99.3218 Epoch 1 Train Loss: 0.0016\n",
      "\n",
      "--- Running Evaluation for Epoch 2 lr =0.001 wd 1e-05 ---\n",
      "Computed Threshold: 0.0004\n",
      "Val: Accuracy: 0.9957  \n",
      "Test : Accuracy: 0.7812 Recall : 0.0126 FDR: 0.6211  F1-score: 0.0244  \n",
      "\n",
      "================== Evaluate lr=0.001, wd=1e-06 ==================\n",
      "Train : time 99.1567 Epoch 0 Train Loss: 0.1542\n",
      "\n",
      "--- Running Evaluation for Epoch 1 lr =0.001 wd 1e-06 ---\n",
      "Computed Threshold: 0.0007\n",
      "Val: Accuracy: 0.9951  \n",
      "Test : Accuracy: 0.7841 Recall : 0.0501 FDR: 0.4719  F1-score: 0.0915  \n",
      "Train : time 99.8882 Epoch 1 Train Loss: 0.0042\n",
      "\n",
      "--- Running Evaluation for Epoch 2 lr =0.001 wd 1e-06 ---\n",
      "Computed Threshold: 0.0007\n",
      "Val: Accuracy: 0.9944  \n",
      "Test : Accuracy: 0.7841 Recall : 0.0500 FDR: 0.4720  F1-score: 0.0914  \n",
      "\n",
      "================== Evaluate lr=0.0001, wd=0.0001 ==================\n",
      "Train : time 98.8413 Epoch 0 Train Loss: 0.7397\n",
      "\n",
      "--- Running Evaluation for Epoch 1 lr =0.0001 wd 0.0001 ---\n",
      "Computed Threshold: 0.0010\n",
      "Val: Accuracy: 0.9938  \n",
      "Test : Accuracy: 0.7850 Recall : 0.0446 FDR: 0.4381  F1-score: 0.0826  \n",
      "Train : time 99.2594 Epoch 1 Train Loss: 0.0042\n",
      "\n",
      "--- Running Evaluation for Epoch 2 lr =0.0001 wd 0.0001 ---\n",
      "Computed Threshold: 0.0006\n",
      "Val: Accuracy: 0.9956  \n",
      "Test : Accuracy: 0.7825 Recall : 0.0312 FDR: 0.5131  F1-score: 0.0587  \n",
      "\n",
      "================== Evaluate lr=0.0001, wd=1e-05 ==================\n",
      "Train : time 100.1437 Epoch 0 Train Loss: 0.1919\n",
      "\n",
      "--- Running Evaluation for Epoch 1 lr =0.0001 wd 1e-05 ---\n",
      "Computed Threshold: 0.0005\n",
      "Val: Accuracy: 0.9956  \n",
      "Test : Accuracy: 0.7841 Recall : 0.0501 FDR: 0.4719  F1-score: 0.0914  \n",
      "Train : time 99.3982 Epoch 1 Train Loss: 0.0023\n",
      "\n",
      "--- Running Evaluation for Epoch 2 lr =0.0001 wd 1e-05 ---\n",
      "Computed Threshold: 0.0004\n",
      "Val: Accuracy: 0.9957  \n",
      "Test : Accuracy: 0.7810 Recall : 0.0206 FDR: 0.5891  F1-score: 0.0392  \n",
      "\n",
      "================== Evaluate lr=0.0001, wd=1e-06 ==================\n",
      "Train : time 99.3635 Epoch 0 Train Loss: 1.9065\n",
      "\n",
      "--- Running Evaluation for Epoch 1 lr =0.0001 wd 1e-06 ---\n",
      "Computed Threshold: 0.0263\n",
      "Val: Accuracy: 0.9996  \n",
      "Test : Accuracy: 0.2171 Recall : 1.0000 FDR: 0.7829  F1-score: 0.3567  \n",
      "Train : time 98.7849 Epoch 1 Train Loss: 0.9250\n",
      "\n",
      "--- Running Evaluation for Epoch 2 lr =0.0001 wd 1e-06 ---\n",
      "Computed Threshold: 0.0131\n",
      "Val: Accuracy: 0.9992  \n",
      "Test : Accuracy: 0.2171 Recall : 1.0000 FDR: 0.7829  F1-score: 0.3567  \n",
      "\n",
      "================== Evaluate lr=1e-05, wd=0.0001 ==================\n",
      "Train : time 100.2900 Epoch 0 Train Loss: 1.2076\n",
      "\n",
      "--- Running Evaluation for Epoch 1 lr =1e-05 wd 0.0001 ---\n",
      "Computed Threshold: 0.0179\n",
      "Val: Accuracy: 0.9050  \n",
      "Test : Accuracy: 0.2171 Recall : 1.0000 FDR: 0.7829  F1-score: 0.3567  \n",
      "Train : time 100.9512 Epoch 1 Train Loss: 0.2413\n",
      "\n",
      "--- Running Evaluation for Epoch 2 lr =1e-05 wd 0.0001 ---\n",
      "Computed Threshold: 0.0030\n",
      "Val: Accuracy: 0.9175  \n",
      "Test : Accuracy: 0.8894 Recall : 0.8442 FDR: 0.2954  F1-score: 0.7681  \n",
      "\n",
      "================== Evaluate lr=1e-05, wd=1e-05 ==================\n",
      "Train : time 100.6645 Epoch 0 Train Loss: 1.0808\n",
      "\n",
      "--- Running Evaluation for Epoch 1 lr =1e-05 wd 1e-05 ---\n",
      "Computed Threshold: 0.0167\n",
      "Val: Accuracy: 0.7430  \n",
      "Test : Accuracy: 0.8894 Recall : 0.8443 FDR: 0.2954  F1-score: 0.7681  \n",
      "Train : time 99.2972 Epoch 1 Train Loss: 0.5416\n",
      "\n",
      "--- Running Evaluation for Epoch 2 lr =1e-05 wd 1e-05 ---\n",
      "Computed Threshold: 0.0018\n",
      "Val: Accuracy: 0.8941  \n",
      "Test : Accuracy: 0.8894 Recall : 0.8442 FDR: 0.2954  F1-score: 0.7681  \n",
      "\n",
      "================== Evaluate lr=1e-05, wd=1e-06 ==================\n",
      "Train : time 99.3311 Epoch 0 Train Loss: 2.4865\n",
      "\n",
      "--- Running Evaluation for Epoch 1 lr =1e-05 wd 1e-06 ---\n",
      "Computed Threshold: 0.0346\n",
      "Val: Accuracy: 0.9170  \n",
      "Test : Accuracy: 0.2171 Recall : 1.0000 FDR: 0.7829  F1-score: 0.3567  \n",
      "Train : time 98.6569 Epoch 1 Train Loss: 1.9573\n",
      "\n",
      "--- Running Evaluation for Epoch 2 lr =1e-05 wd 1e-06 ---\n",
      "Computed Threshold: 0.0279\n",
      "Val: Accuracy: 0.9134  \n",
      "Test : Accuracy: 0.2171 Recall : 1.0000 FDR: 0.7829  F1-score: 0.3567  \n"
     ]
    }
   ],
   "source": [
    "train_eval(AE_model,AE_train_dataloader,AE_val_dataloader,AE_test_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c7f4d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Variational AutoEncoder (VAE)\n",
    "class VAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder: (89-64-64-32 for mu and log_var)\n",
    "    Decoder: (32-64-64-89)\n",
    "    return x_recon, mu, logvar\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(89, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(64, 32)\n",
    "        self.fc_logvar = nn.Linear(64, 32)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 89),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu = self.fc_mu(h)\n",
    "        logvar = self.fc_logvar(h)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_recon = self.decoder(z)\n",
    "        return x_recon, mu, logvar\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6081d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================== Evaluate lr=0.01, wd=0.0001 ==================\n",
      "Train : time 141.5818 Epoch 0 Train Loss: 97.8765\n",
      "\n",
      "--- Running Evaluation for Epoch 1 lr =0.01 wd 0.0001 ---\n",
      "Computed Threshold: 0.0206\n",
      "Val: Accuracy: 0.9378  \n",
      "Test : Accuracy: 0.8535 Recall : 0.8524 FDR: 0.3822  F1-score: 0.7164  \n",
      "Train : time 139.1011 Epoch 1 Train Loss: 93.5440\n",
      "\n",
      "--- Running Evaluation for Epoch 2 lr =0.01 wd 0.0001 ---\n",
      "Computed Threshold: 0.0382\n",
      "Val: Accuracy: 0.8970  \n",
      "Test : Accuracy: 0.8366 Recall : 0.8565 FDR: 0.4156  F1-score: 0.6948  \n",
      "\n",
      "================== Evaluate lr=0.01, wd=1e-05 ==================\n",
      "Train : time 135.4118 Epoch 0 Train Loss: 102.8192\n",
      "\n",
      "--- Running Evaluation for Epoch 1 lr =0.01 wd 1e-05 ---\n",
      "Computed Threshold: 0.0314\n",
      "Val: Accuracy: 0.8984  \n",
      "Test : Accuracy: 0.2174 Recall : 0.9999 FDR: 0.7829  F1-score: 0.3568  \n",
      "Train : time 134.7249 Epoch 1 Train Loss: 102.6428\n",
      "\n",
      "--- Running Evaluation for Epoch 2 lr =0.01 wd 1e-05 ---\n",
      "Computed Threshold: 0.0322\n",
      "Val: Accuracy: 0.8927  \n",
      "Test : Accuracy: 0.2171 Recall : 1.0000 FDR: 0.7829  F1-score: 0.3567  \n",
      "\n",
      "================== Evaluate lr=0.01, wd=1e-06 ==================\n",
      "Train : time 134.4829 Epoch 0 Train Loss: 104.2518\n",
      "\n",
      "--- Running Evaluation for Epoch 1 lr =0.01 wd 1e-06 ---\n",
      "Computed Threshold: 0.0177\n",
      "Val: Accuracy: 0.9337  \n",
      "Test : Accuracy: 0.8099 Recall : 0.8636 FDR: 0.4612  F1-score: 0.6636  \n",
      "Train : time 136.0765 Epoch 1 Train Loss: 90.2909\n",
      "\n",
      "--- Running Evaluation for Epoch 2 lr =0.01 wd 1e-06 ---\n",
      "Computed Threshold: 0.0343\n",
      "Val: Accuracy: 0.8991  \n",
      "Test : Accuracy: 0.8530 Recall : 0.8530 FDR: 0.3832  F1-score: 0.7159  \n",
      "\n",
      "================== Evaluate lr=0.001, wd=0.0001 ==================\n",
      "Train : time 136.5938 Epoch 0 Train Loss: 95.5846\n",
      "\n",
      "--- Running Evaluation for Epoch 1 lr =0.001 wd 0.0001 ---\n",
      "Computed Threshold: 0.0196\n",
      "Val: Accuracy: 0.9336  \n",
      "Test : Accuracy: 0.8549 Recall : 0.8525 FDR: 0.3793  F1-score: 0.7184  \n",
      "Train : time 140.2261 Epoch 1 Train Loss: 85.7759\n",
      "\n",
      "--- Running Evaluation for Epoch 2 lr =0.001 wd 0.0001 ---\n",
      "Computed Threshold: 0.0192\n",
      "Val: Accuracy: 0.9459  \n",
      "Test : Accuracy: 0.8641 Recall : 0.8503 FDR: 0.3589  F1-score: 0.7310  \n",
      "\n",
      "================== Evaluate lr=0.001, wd=1e-05 ==================\n",
      "Train : time 138.3106 Epoch 0 Train Loss: 93.6457\n",
      "\n",
      "--- Running Evaluation for Epoch 1 lr =0.001 wd 1e-05 ---\n",
      "Computed Threshold: 0.0212\n",
      "Val: Accuracy: 0.9177  \n",
      "Test : Accuracy: 0.8457 Recall : 0.8543 FDR: 0.3981  F1-score: 0.7062  \n",
      "Train : time 134.6083 Epoch 1 Train Loss: 86.1772\n",
      "\n",
      "--- Running Evaluation for Epoch 2 lr =0.001 wd 1e-05 ---\n",
      "Computed Threshold: 0.0187\n",
      "Val: Accuracy: 0.9421  \n",
      "Test : Accuracy: 0.8573 Recall : 0.8521 FDR: 0.3742  F1-score: 0.7216  \n",
      "\n",
      "================== Evaluate lr=0.001, wd=1e-06 ==================\n",
      "Train : time 136.1477 Epoch 0 Train Loss: 99.5214\n",
      "\n",
      "--- Running Evaluation for Epoch 1 lr =0.001 wd 1e-06 ---\n",
      "Computed Threshold: 0.0192\n",
      "Val: Accuracy: 0.9012  \n",
      "Test : Accuracy: 0.8543 Recall : 0.8526 FDR: 0.3806  F1-score: 0.7175  \n",
      "Train : time 135.3940 Epoch 1 Train Loss: 88.1068\n",
      "\n",
      "--- Running Evaluation for Epoch 2 lr =0.001 wd 1e-06 ---\n",
      "Computed Threshold: 0.0194\n",
      "Val: Accuracy: 0.9470  \n",
      "Test : Accuracy: 0.8604 Recall : 0.8510 FDR: 0.3674  F1-score: 0.7257  \n",
      "\n",
      "================== Evaluate lr=0.0001, wd=0.0001 ==================\n",
      "Train : time 135.7181 Epoch 0 Train Loss: 103.1032\n",
      "\n",
      "--- Running Evaluation for Epoch 1 lr =0.0001 wd 0.0001 ---\n",
      "Computed Threshold: 0.0177\n",
      "Val: Accuracy: 0.9241  \n",
      "Test : Accuracy: 0.8526 Recall : 0.8531 FDR: 0.3841  F1-score: 0.7154  \n",
      "Train : time 136.3915 Epoch 1 Train Loss: 87.1517\n",
      "\n",
      "--- Running Evaluation for Epoch 2 lr =0.0001 wd 0.0001 ---\n",
      "Computed Threshold: 0.0186\n",
      "Val: Accuracy: 0.9370  \n",
      "Test : Accuracy: 0.8594 Recall : 0.8512 FDR: 0.3696  F1-score: 0.7244  \n",
      "\n",
      "================== Evaluate lr=0.0001, wd=1e-05 ==================\n",
      "Train : time 136.6951 Epoch 0 Train Loss: 105.1742\n",
      "\n",
      "--- Running Evaluation for Epoch 1 lr =0.0001 wd 1e-05 ---\n",
      "Computed Threshold: 0.0181\n",
      "Val: Accuracy: 0.9300  \n",
      "Test : Accuracy: 0.8505 Recall : 0.8536 FDR: 0.3885  F1-score: 0.7125  \n",
      "Train : time 134.5713 Epoch 1 Train Loss: 86.9760\n",
      "\n",
      "--- Running Evaluation for Epoch 2 lr =0.0001 wd 1e-05 ---\n",
      "Computed Threshold: 0.0185\n",
      "Val: Accuracy: 0.9335  \n",
      "Test : Accuracy: 0.8570 Recall : 0.8521 FDR: 0.3749  F1-score: 0.7212  \n",
      "\n",
      "================== Evaluate lr=0.0001, wd=1e-06 ==================\n",
      "Train : time 136.1035 Epoch 0 Train Loss: 106.1062\n",
      "\n",
      "--- Running Evaluation for Epoch 1 lr =0.0001 wd 1e-06 ---\n",
      "Computed Threshold: 0.0194\n",
      "Val: Accuracy: 0.9186  \n",
      "Test : Accuracy: 0.8510 Recall : 0.8530 FDR: 0.3874  F1-score: 0.7131  \n",
      "Train : time 135.7051 Epoch 1 Train Loss: 89.3941\n",
      "\n",
      "--- Running Evaluation for Epoch 2 lr =0.0001 wd 1e-06 ---\n",
      "Computed Threshold: 0.0198\n",
      "Val: Accuracy: 0.9342  \n",
      "Test : Accuracy: 0.8613 Recall : 0.8507 FDR: 0.3652  F1-score: 0.7271  \n",
      "\n",
      "================== Evaluate lr=1e-05, wd=0.0001 ==================\n",
      "Train : time 136.9625 Epoch 0 Train Loss: 171.3044\n",
      "\n",
      "--- Running Evaluation for Epoch 1 lr =1e-05 wd 0.0001 ---\n",
      "Computed Threshold: 0.0417\n",
      "Val: Accuracy: 0.8669  \n",
      "Test : Accuracy: 0.3565 Recall : 0.9690 FDR: 0.7517  F1-score: 0.3953  \n",
      "Train : time 134.8269 Epoch 1 Train Loss: 121.9192\n",
      "\n",
      "--- Running Evaluation for Epoch 2 lr =1e-05 wd 0.0001 ---\n",
      "Computed Threshold: 0.0276\n",
      "Val: Accuracy: 0.8930  \n",
      "Test : Accuracy: 0.6191 Recall : 0.9077 FDR: 0.6468  F1-score: 0.5085  \n",
      "\n",
      "================== Evaluate lr=1e-05, wd=1e-05 ==================\n",
      "Train : time 148.1193 Epoch 0 Train Loss: 168.1857\n",
      "\n",
      "--- Running Evaluation for Epoch 1 lr =1e-05 wd 1e-05 ---\n",
      "Computed Threshold: 0.0438\n",
      "Val: Accuracy: 0.8706  \n",
      "Test : Accuracy: 0.4983 Recall : 0.9369 FDR: 0.7058  F1-score: 0.4478  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "VAE_model = VAE().to(device=device)\n",
    "train_eval(VAE_model,AE_train_dataloader,AE_val_dataloader,AE_test_dataloader)\n",
    "\n",
    "\n",
    "# for epoch in range(3):\n",
    "#     time_1 = time.time()\n",
    "#     train_loss = 0\n",
    "#     AE_model.train()\n",
    "#     if shuffle_files:\n",
    "#         sys_rand = SystemRandom()\n",
    "#         sys_rand.shuffle(AE_dataset.file_order_indices)\n",
    "#     for sequences, _ in AE_dataloader:\n",
    "#         sequences = sequences.squeeze().to(device)\n",
    "#         VAE_optimizer.zero_grad()\n",
    "#         recon, mu, logvar = VAE_model(sequences)\n",
    "#         loss = vae_loss_function(recon, sequences, mu, logvar)\n",
    "#         loss.backward()\n",
    "#         VAE_optimizer.step()\n",
    "#         train_loss += loss.item()\n",
    "#     print(\"time\",time.time()-time_1,f\"Epoch {epoch}, Train Loss: {train_loss / len(AE_dataloader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48a5bd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AAE_Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Encoder(Generator):(89-16-4-2)\n",
    "        \"\"\"\n",
    "        super(AAE_Encoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(89, 16),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(16, 4),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(4, 2))\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "class AAE_Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AAE_Decoder, self).__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2, 4),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(4, 16),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(16, 89),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.decoder(x)\n",
    "class AAE_Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AAE_Discriminator, self).__init__()\n",
    "        self.discriminator = nn.Sequential(\n",
    "            nn.Linear(2, 16),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(16, 4),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(4, 2), # Output for binary classification (real/fake)\n",
    "            nn.Sigmoid()\n",
    "        )    \n",
    "    def forward(self, x):\n",
    "        return self.discriminator(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ea5785d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "aae_encoder = AAE_Encoder()\n",
    "aae_decoder = AAE_Decoder()\n",
    "aae_discriminator = AAE_Discriminator()\n",
    "aae_encoder.to(device)\n",
    "aae_decoder.to(device)\n",
    "aae_discriminator.to(device)\n",
    "optimizer_G = optim.Adam(list(aae_encoder.parameters()) + list(aae_decoder.parameters()), lr=1e-4)\n",
    "optimizer_D = optim.Adam(aae_discriminator.parameters(), lr=1e-4)\n",
    "adversarial_loss = nn.BCELoss(reduction=\"sum\")\n",
    "reconstruction_loss = nn.MSELoss(reduction=\"sum\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f371a05",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aae_encoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> 3\u001b[0m     \u001b[43maae_encoder\u001b[49m\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      4\u001b[0m     aae_decoder\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      5\u001b[0m     aae_discriminator\u001b[38;5;241m.\u001b[39mtrain()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'aae_encoder' is not defined"
     ]
    }
   ],
   "source": [
    "num_epochs=5\n",
    "for epoch in range(num_epochs):\n",
    "    aae_encoder.train()\n",
    "    aae_decoder.train()\n",
    "    aae_discriminator.train()\n",
    "    if shuffle_files:\n",
    "        sys_rand = SystemRandom()\n",
    "        sys_rand.shuffle(AE_dataset.file_order_indices)\n",
    "    for sequences,_ in AE_dataloader:\n",
    "        sequences=sequences.squeeze().to(device)\n",
    "        # 1) reconstruction + generator loss\n",
    "        optimizer_G.zero_grad()\n",
    "        fake_z = aae_encoder(sequences)\n",
    "        decoded_seq = aae_decoder(fake_z)\n",
    "        G_loss = 0.001*adversarial_loss(aae_discriminator(fake_z),  torch.ones(sequences.size(0), 2,device=device)) + 0.999*reconstruction_loss(decoded_seq, sequences)\n",
    "        G_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        # 2) discriminator loss\n",
    "        optimizer_D.zero_grad()\n",
    "        real_loss = adversarial_loss(aae_discriminator(torch.randn(sequences.size(0), 2, device=device)),  torch.ones(sequences.size(0), 2,device=device))\n",
    "        fake_loss = adversarial_loss(aae_discriminator(fake_z.detach()),  torch.zeros(sequences.size(0), 2,device=device))\n",
    "        D_loss = 0.5*(real_loss + fake_loss)\n",
    "        D_loss.backward()\n",
    "        optimizer_D.step()\n",
    "    # print loss\n",
    "    print(\n",
    "            \"[Epoch %d/%d] [G loss: %f] [D loss: %f]\"\n",
    "            % (epoch, num_epochs, G_loss.item(), D_loss.item())\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3698c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU-VAE\n",
    "class GRUVAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Gated Recurrent Unit : num_layers=2, hidden_size=256, dropout=0.01,window size (seq_len)= 40\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=89, hidden_dim=256, latent_dim=32, num_layers=2, dropout=0.01):\n",
    "        super(GRUVAE, self).__init__()\n",
    "        self.encoder_gru = nn.GRU(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_z_to_hidden = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.decoder_gru = nn.GRU(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc_out = nn.Linear(hidden_dim, input_dim)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, seq_len, input_dim=89]\n",
    "        _, hidden = self.encoder_gru(x) \n",
    "        h = hidden[-1]  # [batch_size, hidden_dim]\n",
    "        mu = self.fc_mu(h)  \n",
    "        logvar = self.fc_logvar(h)  \n",
    "        z = self.reparameterize(mu, logvar)  # [batch_size, latent_dim]\n",
    "        # repeat and feed latent z as input trick\n",
    "        h0 = self.fc_z_to_hidden(z).unsqueeze(0).repeat(self.encoder_gru.num_layers, 1, 1)  # [num_layers, batch_size, hidden_dim]\n",
    "        # Initialize decoder input with zeros \n",
    "        decoder_input = torch.zeros_like(x)\n",
    "        output, _ = self.decoder_gru(decoder_input, h0)  # [batch_size, seq_len, hidden_dim]\n",
    "        x_recon = self.fc_out(output)  # [batch_size, seq_len, input_dim]\n",
    "        return x_recon, mu, logvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "799e51d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded scalers for 'network-wide'\n"
     ]
    }
   ],
   "source": [
    "loaded_scalers = load_scalers(\"fitted_scalers\")\n",
    "RNN_dataset=ModbusFlowStream( \n",
    "    shuffle=False,chunk_size=1,batch_size=64,csv_files=modbus.dataset[\"benign_dataset_dir\"][0:2],\n",
    "    scalers=loaded_scalers['network-wide']['min_max_scalers'],window_size=30\n",
    ")\n",
    "RNN_dataloadder=DataLoader(RNN_dataset,batch_size=1,shuffle=False)\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "GRU_VAE_model = GRUVAE().to(device)\n",
    "lr = 0.01\n",
    "wd= 1e-4\n",
    "shuffle_files =True\n",
    "GRU_VAE_optimizer = optim.Adam(GRU_VAE_model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97bb352b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 103.30588173866272 Epoch 0, Train Loss: 127700652.60516566\n",
      "time 95.60702395439148 Epoch 1, Train Loss: 70232281.69612122\n",
      "time 94.19640827178955 Epoch 2, Train Loss: 3457994.1813964844\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):\n",
    "    time_1 = time.time()\n",
    "    train_loss = 0\n",
    "    GRU_VAE_model.train()\n",
    "    if shuffle_files:\n",
    "        sys_rand = SystemRandom()\n",
    "        sys_rand.shuffle(RNN_dataset.file_order_indices)\n",
    "    for sequences, _ in RNN_dataloadder:\n",
    "        sequences = sequences.squeeze().to(device)\n",
    "        GRU_VAE_optimizer.zero_grad()\n",
    "        recon, mu, logvar = GRU_VAE_model(sequences)\n",
    "        loss = vae_loss_function(recon, sequences, mu, logvar)/sequences.size(0)\n",
    "        loss.backward()\n",
    "        GRU_VAE_optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    print(\"time\",time.time()-time_1,f\"Epoch {epoch}, Train Loss: {train_loss/len(RNN_dataloadder)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
