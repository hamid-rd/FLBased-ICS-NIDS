{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d32826f1-1369-4eb5-a21b-0e6e548cded3",
   "metadata": {},
   "source": [
    "### Download and make the dataset ready in Kaggle \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26c2ad5c-f43a-4b40-a647-ecc58c71ff16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T16:17:38.693282Z",
     "iopub.status.busy": "2025-07-13T16:17:38.692671Z",
     "iopub.status.idle": "2025-07-13T16:20:31.990912Z",
     "shell.execute_reply": "2025-07-13T16:20:31.990108Z",
     "shell.execute_reply.started": "2025-07-13T16:17:38.693248Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# ## uncomment if The zip file of the dataset isn't downloaded,extraced \n",
    "# !pip install gdown\n",
    "# Copy the link. The file ID is the long string of characters between d/ and /view.\n",
    "#For example, in the URL https://drive.google.com/file/d/1aBcDeFgHiJkLmNoPqRsTuVwXyZ/view?usp=sharing, \n",
    "#the file ID is 1aBcDeFgHiJkLmNoPqRsTuVwXyZ\n",
    "# !mkdir /kaggle/tmp\n",
    "# !gdown  1pzXpA5Cz0DJmjRsLxlqRNnJq-kOUvojb -O /kaggle/tmp/Labeled_CICMODBUS2023.zip\n",
    "# !unzip /kaggle/tmp/Labeled_CICMODBUS2023.zip -d /kaggle/working/\n",
    "\n",
    "# # ## uncomment if the python modules (modbus.py,utils.py ,...) not cloned  and added to the path \n",
    "\n",
    "# !git clone https://github.com/hamid-rd/FLBased-ICS-NIDS.git\n",
    "# import sys\n",
    "# # Add the repository folder to the Python path\n",
    "# repo_path = '/kaggle/working/FLBased-ICS-NIDS'\n",
    "# repo_input_path = '/kaggle/input/training/FLBased-ICS-NIDS'\n",
    "# dataset_path = '/kaggle/input/training/'\n",
    "\n",
    "# for path in {repo_path,repo_input_path,dataset_path}:\n",
    "#     if path not in sys.path:\n",
    "#         sys.path.append(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "601bb537-782e-4266-b619-48cdad4fe6a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T16:25:34.078617Z",
     "iopub.status.busy": "2025-07-13T16:25:34.077721Z",
     "iopub.status.idle": "2025-07-13T16:25:34.430103Z",
     "shell.execute_reply": "2025-07-13T16:25:34.429493Z",
     "shell.execute_reply.started": "2025-07-13T16:25:34.078584Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The CIC Modbus Dataset contains network (pcap) captures and attack logs from a simulated substation network.\n",
      "                The dataset is categorized into two groups: an attack dataset and a benign dataset\n",
      "                The attack dataset includes network traffic captures that simulate various types of Modbus protocol attacks in a substation environment.\n",
      "                The attacks are reconnaissance, query flooding, loading payloads, delay response, modify length parameters, false data injection, stacking Modbus frames, brute force write and baseline replay.\n",
      "                These attacks are based of some techniques in the MITRE ICS ATT&CK framework.\n",
      "                On the other hand, the benign dataset consists of normal network traffic captures representing legitimate Modbus communication within the substation network.\n",
      "                The purpose of this dataset is to facilitate research, analysis, and development of intrusion detection systems, anomaly detection algorithms and other security mechanisms for substation networks using the Modbus protocol.\n",
      "                https://www.unb.ca/cic/datasets/modbus-2023.html\n",
      "                In my custom PyTorch Dataset class,\n",
      "                I utilize the Enhanced CICflowMeter and the Attack logs correlation to extract and label sequential data flows,\n",
      "                preparing them for batch processing with the DataLoader, which is crucial for AI model training.\n",
      "                https://github.com/hamid-rd/FLBased-ICS-NIDS/tree/main\n",
      "\n",
      "                \n",
      "csv files  in the dataset directory founded with the filter:  ready\n",
      "{\n",
      "    \"total_dataset_num\": 170,\n",
      "    \"benign_dataset_num\": 62,\n",
      "    \"attack_dataset_num\": {\n",
      "        \"total_num\": 108,\n",
      "        \"external_num\": 8,\n",
      "        \"compromised-ied_num\": 43,\n",
      "        \"compromised-scada_num\": 57\n",
      "    },\n",
      "    \"attack_logs_num\": {\n",
      "        \"total_num\": 0,\n",
      "        \"external_num\": [],\n",
      "        \"compromised-ied_num\": 0,\n",
      "        \"compromised-scada_num\": 0\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# To test if every thing is okay (modbus.py class and correct number of founded csv files )\n",
    "from modbus import ModbusDataset,ModbusFlowStream\n",
    "\n",
    "# dataset_directory = \"/kaggle/working/ModbusDataset\" \n",
    "# dataset_directory = \"/kaggle/input/training/ModbusDataset\" \n",
    "dataset_directory = \"dataset\" \n",
    "\n",
    "modbus = ModbusDataset(dataset_directory,\"ready\")\n",
    "modbus.summary_print()\n",
    "\n",
    "# Don't forget to save version in kaggle (to save outputs written on the disk (/kaggle/working/))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d238262",
   "metadata": {},
   "source": [
    "### Unsupervised Autoencoder training  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2c01e06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T16:25:38.158958Z",
     "iopub.status.busy": "2025-07-13T16:25:38.158509Z",
     "iopub.status.idle": "2025-07-13T16:25:38.167563Z",
     "shell.execute_reply": "2025-07-13T16:25:38.166807Z",
     "shell.execute_reply.started": "2025-07-13T16:25:38.158938Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np # For standard deviation calculation\n",
    "from modbus import ModbusDataset,ModbusFlowStream\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix,recall_score\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "from utils import load_scalers\n",
    "import random\n",
    "from random import SystemRandom\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import torch.nn.init as init\n",
    "from collections import Counter\n",
    "\n",
    "def compute_threshold(mse_values,k=1):\n",
    "\n",
    "    \"\"\"\n",
    "    K-SIGMA\n",
    "    Computes the anomaly detection threshold (for marking sample as Intrusion if the IS was greater )\n",
    "    based on the mean and standard deviation of Mean Squared Error (MSE) values.\n",
    "    Formula: thr = mean(MSE) + std(MSE)\n",
    "    Args:\n",
    "    mse_values (torch.Tensor or list/np.array): A tensor or list of MSE values\n",
    "\n",
    "                            obtained from the validation set.\n",
    "    Returns:\n",
    "    float: The calculated threshold.\n",
    "    float: The calculated std.\n",
    "\n",
    "    \"\"\"\n",
    "    if not isinstance(mse_values, torch.Tensor):\n",
    "        mse_values = torch.tensor(mse_values, dtype=torch.float32)\n",
    "    if mse_values.numel() == 0:\n",
    "        return 0.0\n",
    "    mean_mse = torch.mean(mse_values)\n",
    "    std_mse = torch.std(mse_values)\n",
    "    print(\"-----------mse_loss mean : \",f\"{mean_mse.item():.4f}\",\"std:\",f\"{std_mse.item():.4f}\")\n",
    "    threshold = mean_mse + k*std_mse\n",
    "    return threshold.item(),std_mse.item()\n",
    "\n",
    "def vae_loss_function(recon_x, x, mu, logvar,beta=0.05):\n",
    "    \"\"\"\n",
    "    VAE loss function.\n",
    "    \"\"\"\n",
    "    #equivalent to BCE loss\n",
    "    BCE = nn.functional.mse_loss(recon_x, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    # print(BCE.item(),KLD.item())\n",
    "    return (BCE + beta*KLD)\n",
    "\n",
    "def _init_weights( module):\n",
    "    ## for one layer apply Xavier Initialization\n",
    "    if isinstance(module, nn.Linear):\n",
    "        init.xavier_normal_(module.weight)\n",
    "        if module.bias is not None:\n",
    "            init.zeros_(module.bias)\n",
    "    return module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9478520",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T16:25:42.807302Z",
     "iopub.status.busy": "2025-07-13T16:25:42.807033Z",
     "iopub.status.idle": "2025-07-13T16:25:42.941019Z",
     "shell.execute_reply": "2025-07-13T16:25:42.940221Z",
     "shell.execute_reply.started": "2025-07-13T16:25:42.807283Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The CIC Modbus Dataset contains network (pcap) captures and attack logs from a simulated substation network.\n",
      "                The dataset is categorized into two groups: an attack dataset and a benign dataset\n",
      "                The attack dataset includes network traffic captures that simulate various types of Modbus protocol attacks in a substation environment.\n",
      "                The attacks are reconnaissance, query flooding, loading payloads, delay response, modify length parameters, false data injection, stacking Modbus frames, brute force write and baseline replay.\n",
      "                These attacks are based of some techniques in the MITRE ICS ATT&CK framework.\n",
      "                On the other hand, the benign dataset consists of normal network traffic captures representing legitimate Modbus communication within the substation network.\n",
      "                The purpose of this dataset is to facilitate research, analysis, and development of intrusion detection systems, anomaly detection algorithms and other security mechanisms for substation networks using the Modbus protocol.\n",
      "                https://www.unb.ca/cic/datasets/modbus-2023.html\n",
      "                In my custom PyTorch Dataset class,\n",
      "                I utilize the Enhanced CICflowMeter and the Attack logs correlation to extract and label sequential data flows,\n",
      "                preparing them for batch processing with the DataLoader, which is crucial for AI model training.\n",
      "                https://github.com/hamid-rd/FLBased-ICS-NIDS/tree/main\n",
      "\n",
      "                \n",
      "csv files  in the dataset directory founded with the filter:  ready\n",
      "{\n",
      "    \"total_dataset_num\": 170,\n",
      "    \"benign_dataset_num\": 62,\n",
      "    \"attack_dataset_num\": {\n",
      "        \"total_num\": 108,\n",
      "        \"external_num\": 8,\n",
      "        \"compromised-ied_num\": 43,\n",
      "        \"compromised-scada_num\": 57\n",
      "    },\n",
      "    \"attack_logs_num\": {\n",
      "        \"total_num\": 34,\n",
      "        \"external_num\": [\n",
      "            \"./ModbusDataset/attack/external/external-attacker/attacker logs/02-01-2023/02-01-2023-1.csv\",\n",
      "            \"./ModbusDataset/attack/external/external-attacker/attacker logs/12-29-2022/12-29-2022-1.csv\",\n",
      "            \"./ModbusDataset/attack/external/external-attacker/attacker logs/01-17-2023/01-17-2023-1.csv\",\n",
      "            \"./ModbusDataset/attack/external/external-attacker/attacker logs/01-02-2023/01-02-2023-1.csv\",\n",
      "            \"./ModbusDataset/attack/external/external-attacker/attacker logs/12-30-2022/12-30-2022-1.csv\",\n",
      "            \"./ModbusDataset/attack/external/external-attacker/attacker logs/01-01-2023/01-01-2023-1.csv\"\n",
      "        ],\n",
      "        \"compromised-ied_num\": 7,\n",
      "        \"compromised-scada_num\": 21\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# dataset_directory = \"/kaggle/input/training/ModbusDataset\" # change this to the folder contain benign and attack subdirs\n",
    "# dataset_directory = \"dataset\" \n",
    "dataset_directory = \"./ModbusDataset/\" \n",
    "\n",
    "modbus = ModbusDataset(dataset_directory,\"ready\")\n",
    "modbus.summary_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dede4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# AutoEncoder (AE)\n",
    "class AE(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder: (76-32-16-4-2)\n",
    "    Decoder: (2-4-16-32-76)\n",
    "    \"\"\"\n",
    "    def __init__(self,input_dim=76):\n",
    "        super(AE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        x_recon = self.decoder(z)\n",
    "        return x_recon\n",
    "\n",
    "\n",
    "# Variational AutoEncoder (VAE)\n",
    "class VAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder: (76-16-4-2 for mu and log_var)\n",
    "    Decoder: (2-4-16-76)\n",
    "    return x_recon, mu, logvar\n",
    "    \"\"\"\n",
    "    def __init__(self,input_dim=76):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 4),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(4, 2)\n",
    "        self.fc_logvar = nn.Linear(4, 2)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, input_dim),\n",
    "            nn.Sigmoid()\n",
    "                    )\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu = self.fc_mu(h)\n",
    "        logvar = self.fc_logvar(h)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_recon = self.decoder(z)\n",
    "        return x_recon, mu, logvar\n",
    "\n",
    "    \n",
    "class AAE_Encoder(nn.Module):\n",
    "    def __init__(self,input_dim=76):\n",
    "        \"\"\"\n",
    "        Encoder(Generator):(76-16-4-2)\n",
    "        \"\"\"\n",
    "        super(AAE_Encoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 16),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(16, 4),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(4, 2))\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "class AAE_Decoder(nn.Module):\n",
    "    def __init__(self,input_dim=76):\n",
    "        super(AAE_Decoder, self).__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2, 4),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(4, 16),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(16, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.decoder(x)\n",
    "class AAE_Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AAE_Discriminator, self).__init__()\n",
    "        # corrected to 2-16-4-1\n",
    "        self.discriminator = nn.Sequential(\n",
    "            nn.Linear(2, 16),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(16, 4),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(4, 1), \n",
    "            nn.Sigmoid()\n",
    "        )    \n",
    "    def forward(self, x):\n",
    "        return self.discriminator(x)\n",
    " \n",
    "class AdversarialAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AdversarialAutoencoder, self).__init__()\n",
    "        self.encoder = AAE_Encoder()\n",
    "        self.decoder = AAE_Decoder()\n",
    "        self.discriminator = AAE_Discriminator()\n",
    "    def forward(self, x):\n",
    "        fake_z = self.encoder(x)\n",
    "        x_recon = self.decoder(fake_z)\n",
    "        return fake_z,x_recon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79e46753",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class InMemoryDataset(Dataset):\n",
    "    \"\"\"A simple dataset that serves data from pre-loaded tensors.\"\"\"\n",
    "    def __init__(self, data, labels):\n",
    "        # This dataset holds references to the data, which should already be in shared memory.\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436b79f1",
   "metadata": {},
   "source": [
    "### Part a: Centralized learning \n",
    "\n",
    "##### You can go from here right to the FL part\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "602895d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataloader(load_all_chunks=True):\n",
    "\n",
    "    ## must be called after that the global train_files,val_files and test_files plus loades scalers are initilized\n",
    "    ## return train, valid and test dataloaders\n",
    "    if load_all_chunks==True:\n",
    "        large_chunk_size = modbus.dataset[\"metadata\"][\"founded_files_num\"][\"total_dataset_num\"]\n",
    "\n",
    "        dataset_configs = {\n",
    "            \"train\": {\"files\": train_files},\n",
    "            \"val\": {\"files\": val_files},\n",
    "            \"test\": {\"files\": test_files},\n",
    "        }\n",
    "        datasets = {}\n",
    "        ae_datasets = {}\n",
    "        dataloaders = {}\n",
    "\n",
    "        print(\"Cow Processing datasets...\")\n",
    "\n",
    "        for name, config in dataset_configs.items():\n",
    "            print(f\"  - Creating '{name}' dataset...\")\n",
    "            \n",
    "            # 1. Create the primary ModbusFlowStream dataset\n",
    "            datasets[name] = ModbusFlowStream(\n",
    "                shuffle=False,\n",
    "                chunk_size=large_chunk_size,\n",
    "                batch_size=1,\n",
    "                csv_files=config[\"files\"],\n",
    "                scalers=loaded_scalers['network-wide']['min_max_scalers'],\n",
    "                window_size=window_size\n",
    "            )\n",
    "            \n",
    "            # 2. Call __getitem__(0) once to load the entire dataset chunk into memory\n",
    "            datasets[name].__getitem__(0)\n",
    "\n",
    "            # 2. Extract the raw tensors\n",
    "            all_data = datasets[name].current_chunk_data\n",
    "            all_labels = datasets[name].current_chunk_labels\n",
    "            \n",
    "            # all_data.share_memory_()\n",
    "            # all_labels.share_memory_()\n",
    "            \n",
    "            # 4. Create an instance of our SIMPLE dataset using the SHARED tensors.\n",
    "            shared_dataset = InMemoryDataset(all_data, all_labels)\n",
    "\n",
    "            # 5. Create the DataLoader from the simple dataset. This will work correctly with workers.\n",
    "            if name==\"train\":\n",
    "                shuffle_samples =True\n",
    "            else:\n",
    "                shuffle_samples =False\n",
    "            # dataloaders[name] = DataLoader(\n",
    "            #     shared_dataset,\n",
    "            #     batch_size=64,\n",
    "            #     shuffle=shuffle_samples,\n",
    "            #     num_workers=4\n",
    "            #     persistent_workers=True,\n",
    "            #     pin_memory=True\n",
    "            # )\n",
    "            dataloaders[name] = DataLoader(\n",
    "                shared_dataset,\n",
    "                batch_size=64,\n",
    "                shuffle=shuffle_samples,\n",
    "                num_workers=0, # You can now use multiple workers effectively.\n",
    "                persistent_workers=False,\n",
    "                pin_memory=False\n",
    "            )\n",
    "                    \n",
    "            \n",
    "            print(f\"  - Finished '{name}' dataset.\")\n",
    "        train_dataloader = dataloaders['train']\n",
    "        val_dataloader = dataloaders['val']\n",
    "        test_dataloader = dataloaders['test']\n",
    "\n",
    "    else :\n",
    "        train_dataloader=DataLoader(ModbusFlowStream( \n",
    "            shuffle=True,chunk_size=1,batch_size=64,csv_files=train_files,scalers=loaded_scalers['network-wide']['min_max_scalers'],window_size=window_size\n",
    "        ),  batch_size=1,shuffle=False)\n",
    "        val_dataloader=DataLoader(ModbusFlowStream( \n",
    "            shuffle=False,chunk_size=1,batch_size=64,csv_files=val_files,scalers=loaded_scalers['network-wide']['min_max_scalers'],window_size=window_size\n",
    "        ),batch_size=1,shuffle=False)\n",
    "        test_dataloader=DataLoader(ModbusFlowStream(shuffle=False,chunk_size=1,batch_size=64,csv_files=test_files,scalers=loaded_scalers['network-wide']['min_max_scalers'],window_size=window_size),\n",
    "                                    batch_size=1,shuffle=False)\n",
    "    return train_dataloader,val_dataloader,test_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a2d2e0ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T08:02:58.408647Z",
     "iopub.status.busy": "2025-07-13T08:02:58.407931Z",
     "iopub.status.idle": "2025-07-13T08:02:58.430831Z",
     "shell.execute_reply": "2025-07-13T08:02:58.430062Z",
     "shell.execute_reply.started": "2025-07-13T08:02:58.408625Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_eval(model,train_dataloader,val_dataloader,test_dataloader,learning_rates= [5e-6,1e-7,5e-5,1e-5,1e-6],\n",
    "               weight_decays=[1e-5,1e-4,1e-7],shuffle_files=True,num_epochs=20,eval_epoch=4,criterion_method=\"mse\", k_range=[1,3],train_model=True):\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model=model.to(device)\n",
    "    if criterion_method==\"bce\":\n",
    "        criterion = nn.BCELoss(reduction='sum').to(device)\n",
    "        eval_criterion = nn.BCELoss(reduction='none').to(device)\n",
    "    else: #mse\n",
    "        criterion = nn.MSELoss(reduction='sum').to(device)\n",
    "        eval_criterion = nn.MSELoss(reduction='none').to(device)\n",
    "\n",
    "    for lr, wd in itertools.product(learning_rates, weight_decays):\n",
    "        if model._get_name()==\"AdversarialAutoencoder\":\n",
    "            adversarial_criterion= nn.BCELoss(reduction=\"sum\")\n",
    "            optimizer_D = optim.Adam(model.discriminator.parameters(), lr=lr, weight_decay=wd)\n",
    "            optimizer_G =  optim.Adam(list(model.encoder.parameters()) + list(model.decoder.parameters()), lr=lr, weight_decay=wd)\n",
    "        else:\n",
    "            AE_optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "            ### new code\n",
    "            # AE_optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "        print(f\"\\n==================  lr={lr}, wd={wd} ==================\")\n",
    "        if train_model==True:\n",
    "            model.apply(_init_weights)\n",
    "        for epoch in range(num_epochs):\n",
    "            if train_model==True:\n",
    "                time_1 = time.time()\n",
    "                model.train()\n",
    "                train_loss = 0\n",
    "                ## for AAE\n",
    "                Discriminator_loss = 0\n",
    "                for sequences, labels in train_dataloader:\n",
    "                    sequences=sequences.squeeze().to(device)\n",
    "                    if labels.sum()!=0:\n",
    "                        continue\n",
    "                    if model._get_name()==\"AdversarialAutoencoder\":\n",
    "                        # 1) generator loss\n",
    "\n",
    "                        target_ones= torch.ones(sequences.size(0), 1,device=device,dtype=torch.float)\n",
    "                        target_zeros= torch.zeros(sequences.size(0), 1,device=device,dtype=torch.float)\n",
    "                        random_latent = torch.randn(sequences.size(0), 2, device=device)\n",
    "                        optimizer_G.zero_grad()\n",
    "                        fake_z,decoded_seq = model(sequences)\n",
    "                        G_loss = 0.001*adversarial_criterion(model.discriminator(fake_z),target_ones ) + 0.999*criterion(decoded_seq, sequences)\n",
    "                        G_loss.backward()\n",
    "                        optimizer_G.step()\n",
    "                        # 2) discriminator loss\n",
    "                        optimizer_D.zero_grad()\n",
    "                        real_loss = adversarial_criterion(model.discriminator(random_latent), target_ones)\n",
    "                        fake_loss = adversarial_criterion(model.discriminator(fake_z.detach()),  target_zeros)\n",
    "                        D_loss = 0.5*(real_loss + fake_loss)\n",
    "                        D_loss.backward()\n",
    "                        optimizer_D.step()\n",
    "                        train_loss+=G_loss.item()\n",
    "                        Discriminator_loss+=D_loss.item()   \n",
    "                    else:\n",
    "                        AE_optimizer.zero_grad()\n",
    "                        if model._get_name()==\"AE\":\n",
    "                            recon = model(sequences)\n",
    "                            loss = criterion(recon, sequences) / sequences.size(0)\n",
    "                        elif model._get_name()==\"VAE\" :\n",
    "                            recon, mu, logvar = model(sequences)\n",
    "                            loss = vae_loss_function(recon, sequences, mu, logvar) /sequences.size(0)\n",
    "                        loss.backward()\n",
    "                        AE_optimizer.step()\n",
    "                        train_loss += loss.item()\n",
    "                print(f\"Train : time {(time.time()-time_1):.2f} s\",\n",
    "                f\"Epoch {epoch+1}\")\n",
    "                if model._get_name()==\"AdversarialAutoencoder\":\n",
    "                    print(f\"Generator Loss: {train_loss / len(train_dataloader):.4f}\",\n",
    "                        f\"Discriminator Loss: {Discriminator_loss / len(train_dataloader):.4f}\")\n",
    "                else:\n",
    "                    print(f\"Train Loss: {train_loss / len(train_dataloader):.4f}\")\n",
    "            # Evaluate part\n",
    "            if (epoch + 1) % eval_epoch == 0:\n",
    "                model.eval() \n",
    "                all_val_losses = []\n",
    "                all_val_labels = []\n",
    "                print(f\"--- Running Evaluation for Epoch {epoch+1} lr ={lr} wd {wd} ---\")\n",
    "                with torch.no_grad():\n",
    "                    for sequences, labels in val_dataloader:\n",
    "                        sequences = sequences.squeeze().to(device) \n",
    "                        if criterion_method==\"bce\":\n",
    "                            ## may test features be greater than 1 after scaling \n",
    "                            sequences=torch.clamp(sequences, min=0.0, max=1.0)      \n",
    "                        if model._get_name()==\"AE\":\n",
    "                            recon = model(sequences)\n",
    "                        elif model._get_name()==\"VAE\" :\n",
    "                            recon, _, _ = model(sequences)\n",
    "                        elif model._get_name()==\"AdversarialAutoencoder\":\n",
    "                            _,recon= model(sequences)\n",
    "                        val_loss = eval_criterion(recon, sequences)\n",
    "                        if val_loss.dim() > 1:\n",
    "                            val_loss = val_loss\n",
    "                        else:\n",
    "                            val_loss = val_loss.unsqueeze(dim=0)\n",
    "                            labels = labels.unsqueeze(dim=0)\n",
    "                        val_loss = val_loss.sum(dim=1)\n",
    "                        all_val_losses.extend(val_loss.cpu().numpy())\n",
    "                        all_val_labels.extend(labels.flatten().cpu().numpy())\n",
    "                threshold_1,std_mse = compute_threshold(all_val_losses,k=0)\n",
    "\n",
    "                all_val_losses = np.array(all_val_losses).squeeze()  \n",
    "                all_val_labels = np.array(all_val_labels).squeeze()  \n",
    "                # If intrusion score > threshold, predict 1 (intrusion), else 0 (benign)\n",
    "                # For FDR, get True Positives (TP) and False Positives (FP)\n",
    "                \n",
    "                predictions = (all_val_losses > threshold_1).astype(int)\n",
    "\n",
    "                accuracy = accuracy_score(all_val_labels, predictions)\n",
    "                print(f\"Val: Accuracy: {accuracy:.4f}  \")\n",
    "                model.eval() \n",
    "                all_test_losses = []\n",
    "                all_test_labels = []\n",
    "                with torch.no_grad():\n",
    "                    for sequences, labels in test_dataloader:\n",
    "                        sequences = sequences.squeeze().to(device)\n",
    "                        labels = labels.squeeze().to(device)\n",
    "                        if criterion_method==\"bce\":\n",
    "                            ## may test features be greater than 1 after scaling \n",
    "                            sequences=torch.clamp(sequences, min=0.0, max=1.0)\n",
    "                        if model._get_name()==\"AE\":\n",
    "                            recon = model(sequences)\n",
    "                        elif model._get_name()==\"VAE\"  :\n",
    "                            recon, mu, logvar = model(sequences)\n",
    "                        elif model._get_name()==\"AdversarialAutoencoder\":\n",
    "                            _,recon= model(sequences)\n",
    "\n",
    "                        intrusion_scores = eval_criterion(recon, sequences)\n",
    "                        if intrusion_scores.dim() > 1:\n",
    "                            intrusion_scores = intrusion_scores\n",
    "                        else:\n",
    "                            intrusion_scores = intrusion_scores.unsqueeze(dim=0)\n",
    "                            labels = labels.unsqueeze(dim=0)\n",
    "                        if intrusion_scores.dim()==3:\n",
    "                            ##GRU : mean of window\n",
    "                            intrusion_scores = intrusion_scores.mean(dim=1)\n",
    "                        intrusion_scores = intrusion_scores.sum(dim=1)\n",
    "                        all_test_losses.extend(intrusion_scores.cpu().numpy())\n",
    "                        all_test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "                all_test_losses = np.array(all_test_losses)\n",
    "                all_test_labels = np.array(all_test_labels)\n",
    "                for k in k_range:\n",
    "                    threshold=threshold_1+k*std_mse\n",
    "                    print(f\" K: {k} K-SIGMA Threshold : ---thr {threshold:.4}\")\n",
    "                    predictions = (all_test_losses > threshold).astype(int)\n",
    "                    binary_test_labels = (all_test_labels != 0).astype(int)\n",
    "\n",
    "                    # Find the indices where the prediction was incorrect\n",
    "                    misclassified_indices = np.where(binary_test_labels != predictions)[0]\n",
    "\n",
    "                    # Get the original labels for those misclassified instances\n",
    "                    misclassified_original_labels = all_test_labels[misclassified_indices]\n",
    "\n",
    "                    # To get a summary count of which labels were misclassified\n",
    "                    print(\"Counts of : original binary labels\",Counter(binary_test_labels),\"predicted binary labels\",Counter(predictions))\n",
    "                    print(f\"Counts of  original  labels: {dict(sorted(Counter(all_test_labels).items()))}\")\n",
    "                    print(f\"Counts of misclassified original labels: {dict(sorted(Counter(misclassified_original_labels).items()))}\")\n",
    "                    accuracy = accuracy_score(binary_test_labels, predictions)\n",
    "                    f1 = f1_score(binary_test_labels, predictions, zero_division=0)\n",
    "                    recall = recall_score(binary_test_labels, predictions,zero_division=0)\n",
    "                    _, fp, _, tp = confusion_matrix(binary_test_labels, predictions, labels=[0, 1]).ravel()\n",
    "                    # FDR = FP / (FP + TP) \n",
    "                    if (fp + tp) == 0:\n",
    "                        fdr = 0.0 \n",
    "                    else:\n",
    "                        fdr = fp / (fp + tp)\n",
    "                    print(f\"Test : Accuracy: {accuracy:.4f} Recall : {recall:.4f} FDR: {fdr:.4f}  F1-score: {f1:.4f}  \")\n",
    "                    !mkdir best_center_models -p\n",
    "                    if train_model:\n",
    "                        save_path =\"best_center_models/\"+model._get_name()+\"_f1_\"+f\"{f1:.4f}\" +\"_recall_\"+f\"{recall:.4f}\" +\"_.pth\"\n",
    "                        torch.save(model.state_dict(),save_path)\n",
    "                        print(\"model\",model._get_name(),\"is saved in\" ,save_path )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eca3b99",
   "metadata": {},
   "source": [
    "#### Train on network-wdie\n",
    "#### evaluate on comrpomised-scada IED node ied1b during centralized training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db440aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded scalers for 'network-wide'\n",
      "ied1b comp ied attack ->\n",
      " test:  2 ['./ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-7-labeled.csv', './ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-3-labeled.csv']\n",
      "----------- Network-wide number of csv files -> \n",
      " ----------- train : 16 ['./ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-27-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-29-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-20-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-19-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-15-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-14-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-28-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-31-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-16-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-30-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-32-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-24-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-25-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-26-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-23-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-21-labeled.csv'] \n",
      " -------- valid: 3 ['./ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-26-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-23-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-21-labeled.csv']\n"
     ]
    }
   ],
   "source": [
    "train_files=[col for col in modbus.dataset[\"benign_dataset_dir\"] if col.find(\"network-wide\")!=-1][:]\n",
    "test_files= [col for col in modbus.dataset[\"attack_dataset_dir\"][\"compromised-scada\"] if col.find(\"ied1b\")!=-1]\n",
    "\n",
    "\n",
    "### missed attack logs files for the day 21 for ied1b which can reduce the accuracy.\n",
    "test_files.remove(dataset_directory+\"attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-6-labeled.csv\")\n",
    "# test_files.remove(dataset_directory+\"/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-6-labeled.csv\")\n",
    "SEED=20\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "random.shuffle(train_files)\n",
    "random.shuffle(test_files)\n",
    "\n",
    "train_files = train_files[:-3]\n",
    "val_files = train_files[-3:]\n",
    "test_files = test_files[:2]\n",
    "loaded_scalers=load_scalers(\"fitted_scalers\")\n",
    "print(\"ied1b comp ied attack ->\\n test: \",len(test_files),test_files)\n",
    "print(\"----------- Network-wide number of csv files -> \\n ----------- train :\",len(train_files),train_files,\"\\n -------- valid:\",len(val_files),val_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac4698b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T08:12:06.828444Z",
     "iopub.status.busy": "2025-07-13T08:12:06.827779Z",
     "iopub.status.idle": "2025-07-13T08:12:07.034947Z",
     "shell.execute_reply": "2025-07-13T08:12:07.034115Z",
     "shell.execute_reply.started": "2025-07-13T08:12:06.828415Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def make_dataloader(load_all_chunks=True):\n",
    "\n",
    "    ## must be called if global train_files,val_files and test_files plus loades scalers are initilized\n",
    "    ## return train, valid and test dataloaders\n",
    "    if load_all_chunks:\n",
    "        large_chunk_size = modbus.dataset[\"metadata\"][\"founded_files_num\"][\"total_dataset_num\"]\n",
    "\n",
    "        dataset_configs = {\n",
    "            \"train\": {\"files\": train_files},\n",
    "            \"val\": {\"files\": val_files},\n",
    "            \"test\": {\"files\": test_files},\n",
    "        }\n",
    "        datasets = {}\n",
    "        ae_datasets = {}\n",
    "        dataloaders = {}\n",
    "\n",
    "        print(\"Cow Processing datasets...\")\n",
    "\n",
    "        for name, config in dataset_configs.items():\n",
    "            print(f\"  - Creating '{name}' dataset...\")\n",
    "            \n",
    "            # 1. Create the primary ModbusFlowStream dataset\n",
    "            datasets[name] = ModbusFlowStream(\n",
    "                shuffle=False,\n",
    "                chunk_size=large_chunk_size,\n",
    "                batch_size=1,\n",
    "                csv_files=config[\"files\"],\n",
    "                scalers=loaded_scalers['network-wide']['min_max_scalers'],\n",
    "                window_size=window_size\n",
    "            )\n",
    "            \n",
    "            # 2. Call __getitem__(0) once to load the entire dataset chunk into memory\n",
    "            datasets[name].__getitem__(0)\n",
    "\n",
    "            # 2. Extract the raw tensors\n",
    "            all_data = datasets[name].current_chunk_data\n",
    "            all_labels = datasets[name].current_chunk_labels\n",
    "            \n",
    "            # all_data.share_memory_()\n",
    "            # all_labels.share_memory_()\n",
    "            \n",
    "            # 4. Create an instance of our SIMPLE dataset using the SHARED tensors.\n",
    "            shared_dataset = InMemoryDataset(all_data, all_labels)\n",
    "\n",
    "            # 5. Create the DataLoader from the simple dataset. This will work correctly with workers.\n",
    "            if name==\"train\":\n",
    "                shuffle_samples =True\n",
    "            else:\n",
    "                shuffle_samples =False\n",
    "            # dataloaders[name] = DataLoader(\n",
    "            #     shared_dataset,\n",
    "            #     batch_size=64,\n",
    "            #     shuffle=shuffle_samples,\n",
    "            #     num_workers=4\n",
    "            #     persistent_workers=True,\n",
    "            #     pin_memory=True\n",
    "            # )\n",
    "            dataloaders[name] = DataLoader(\n",
    "                shared_dataset,\n",
    "                batch_size=64,\n",
    "                shuffle=shuffle_samples,\n",
    "                num_workers=0, # You can now use multiple workers effectively.\n",
    "                persistent_workers=False,\n",
    "                pin_memory=False\n",
    "            )\n",
    "                    \n",
    "            \n",
    "            print(f\"  - Finished '{name}' dataset.\")\n",
    "        train_dataloader = dataloaders['train']\n",
    "        val_dataloader = dataloaders['val']\n",
    "        test_dataloader = dataloaders['test']\n",
    "\n",
    "    else :\n",
    "        train_dataloader=DataLoader(ModbusFlowStream( \n",
    "            shuffle=True,chunk_size=1,batch_size=64,csv_files=train_files,scalers=loaded_scalers['network-wide']['min_max_scalers'],window_size=window_size\n",
    "        ),  batch_size=1,shuffle=False)\n",
    "        val_dataloader=DataLoader(ModbusFlowStream( \n",
    "            shuffle=False,chunk_size=1,batch_size=64,csv_files=val_files,scalers=loaded_scalers['network-wide']['min_max_scalers'],window_size=window_size\n",
    "        ),batch_size=1,shuffle=False)\n",
    "        test_dataloader=DataLoader(ModbusFlowStream(shuffle=False,chunk_size=1,batch_size=64,csv_files=test_files,scalers=loaded_scalers['network-wide']['min_max_scalers'],window_size=window_size),\n",
    "                                    batch_size=1,shuffle=False)\n",
    "    return train_dataloader,val_dataloader,test_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c8fb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader,val_dataloader,test_dataloader= make_dataloader(load_all_chunks=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "97026967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.09274983406067\n"
     ]
    }
   ],
   "source": [
    "t_1=time.time()\n",
    "for seq,label in train_dataloader:\n",
    "     pass\n",
    "print(time.time()-t_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "69406aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36920 7193 2174\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataloader),len(val_dataloader),len(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e82123e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================  lr=0.01, wd=0.0001 ==================\n",
      "Train : time 164.74 s Epoch 1\n",
      "Train Loss: 0.0511\n",
      "Train : time 177.71 s Epoch 2\n",
      "Train Loss: 0.0156\n",
      "--- Running Evaluation for Epoch 2 lr =0.01 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0093 std: 0.1554\n",
      "Val: Accuracy: 0.9101  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.1647\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 102696, 1: 36354})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 94, 1: 5260, 2: 14, 3: 15, 4: 4, 5: 1, 6: 10}\n",
      "Test : Accuracy: 0.9612 Recall : 0.8724 FDR: 0.0026  F1-score: 0.9307  \n",
      "model AE is saved in best_models/AE_f1_0.93_recall_0.87_.pth\n",
      " K: 3 K-SIGMA Threshold : ---thr 0.4756\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 103018, 1: 36032})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 93, 1: 5552, 2: 14, 3: 16, 4: 4, 5: 1, 6: 10, 7: 28}\n",
      "Test : Accuracy: 0.9589 Recall : 0.8647 FDR: 0.0026  F1-score: 0.9263  \n",
      "model AE is saved in best_models/AE_f1_0.93_recall_0.86_.pth\n",
      "\n",
      "==================  lr=0.01, wd=1e-05 ==================\n",
      "Train : time 178.04 s Epoch 1\n",
      "Train Loss: 2.4584\n",
      "Train : time 171.56 s Epoch 2\n",
      "Train Loss: 2.4511\n",
      "--- Running Evaluation for Epoch 2 lr =0.01 wd 1e-05 ---\n",
      "-----------mse_loss mean :  2.4606 std: 1.8546\n",
      "Val: Accuracy: 0.6062  \n",
      " K: 1 K-SIGMA Threshold : ---thr 4.315\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 138733, 1: 317})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 84, 1: 41076, 2: 59, 3: 40, 4: 55, 5: 37, 6: 36, 7: 28}\n",
      "Test : Accuracy: 0.7022 Recall : 0.0056 FDR: 0.2650  F1-score: 0.0111  \n",
      " K: 3 K-SIGMA Threshold : ---thr 8.024\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 139022, 1: 28})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 28, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Test : Accuracy: 0.7009 Recall : 0.0000 FDR: 1.0000  F1-score: 0.0000  \n",
      "\n",
      "==================  lr=0.001, wd=0.0001 ==================\n",
      "Train : time 166.50 s Epoch 1\n",
      "Train Loss: 0.6129\n",
      "Train : time 153.68 s Epoch 2\n",
      "Train Loss: 0.5173\n",
      "--- Running Evaluation for Epoch 2 lr =0.001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.5096 std: 1.5885\n",
      "Val: Accuracy: 0.8721  \n",
      " K: 1 K-SIGMA Threshold : ---thr 2.098\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 103104, 1: 35946})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 34, 1: 5577, 2: 14, 3: 16, 4: 4, 5: 3, 6: 10, 7: 28}\n",
      "Test : Accuracy: 0.9591 Recall : 0.8640 FDR: 0.0009  F1-score: 0.9266  \n",
      " K: 3 K-SIGMA Threshold : ---thr 5.275\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 138817, 1: 233})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {1: 41076, 2: 59, 3: 40, 4: 55, 5: 37, 6: 36, 7: 28}\n",
      "Test : Accuracy: 0.7028 Recall : 0.0056 FDR: 0.0000  F1-score: 0.0111  \n",
      "\n",
      "==================  lr=0.001, wd=1e-05 ==================\n",
      "Train : time 252.75 s Epoch 1\n",
      "Train Loss: 0.0467\n",
      "Train : time 184.46 s Epoch 2\n",
      "Train Loss: 0.0053\n",
      "--- Running Evaluation for Epoch 2 lr =0.001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.0039 std: 0.0915\n",
      "Val: Accuracy: 0.9698  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.09543\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 102696, 1: 36354})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 94, 1: 5260, 2: 14, 3: 15, 4: 4, 5: 1, 6: 10}\n",
      "Test : Accuracy: 0.9612 Recall : 0.8724 FDR: 0.0026  F1-score: 0.9307  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.2785\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 102699, 1: 36351})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 94, 1: 5263, 2: 14, 3: 15, 4: 4, 5: 1, 6: 10}\n",
      "Test : Accuracy: 0.9612 Recall : 0.8723 FDR: 0.0026  F1-score: 0.9307  \n",
      "\n",
      "==================  lr=0.0001, wd=0.0001 ==================\n",
      "Train : time 151.60 s Epoch 1\n",
      "Train Loss: 0.5153\n",
      "Train : time 166.29 s Epoch 2\n",
      "Train Loss: 0.1308\n",
      "--- Running Evaluation for Epoch 2 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0933 std: 0.3970\n",
      "Val: Accuracy: 0.9193  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.4903\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 103018, 1: 36032})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 93, 1: 5552, 2: 14, 3: 16, 4: 4, 5: 1, 6: 10, 7: 28}\n",
      "Test : Accuracy: 0.9589 Recall : 0.8647 FDR: 0.0026  F1-score: 0.9263  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.284\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 103033, 1: 36017})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 92, 1: 5564, 2: 14, 3: 16, 4: 4, 5: 3, 6: 10, 7: 28}\n",
      "Test : Accuracy: 0.9588 Recall : 0.8643 FDR: 0.0026  F1-score: 0.9261  \n",
      "\n",
      "==================  lr=0.0001, wd=1e-05 ==================\n",
      "Train : time 165.19 s Epoch 1\n",
      "Train Loss: 5.4972\n",
      "Train : time 152.08 s Epoch 2\n",
      "Train Loss: 2.4568\n",
      "--- Running Evaluation for Epoch 2 lr =0.0001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  2.4584 std: 1.9250\n",
      "Val: Accuracy: 0.6062  \n",
      " K: 1 K-SIGMA Threshold : ---thr 4.383\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 138733, 1: 317})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 84, 1: 41076, 2: 59, 3: 40, 4: 55, 5: 37, 6: 36, 7: 28}\n",
      "Test : Accuracy: 0.7022 Recall : 0.0056 FDR: 0.2650  F1-score: 0.0111  \n",
      " K: 3 K-SIGMA Threshold : ---thr 8.233\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 139022, 1: 28})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 28, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Test : Accuracy: 0.7009 Recall : 0.0000 FDR: 1.0000  F1-score: 0.0000  \n",
      "\n",
      "==================  lr=1e-05, wd=0.0001 ==================\n",
      "Train : time 153.99 s Epoch 1\n",
      "Train Loss: 3.3753\n",
      "Train : time 161.76 s Epoch 2\n",
      "Train Loss: 0.4425\n",
      "--- Running Evaluation for Epoch 2 lr =1e-05 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.2281 std: 0.7813\n",
      "Val: Accuracy: 0.8676  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.009\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 103033, 1: 36017})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 92, 1: 5564, 2: 14, 3: 16, 4: 4, 5: 3, 6: 10, 7: 28}\n",
      "Test : Accuracy: 0.9588 Recall : 0.8643 FDR: 0.0026  F1-score: 0.9261  \n",
      " K: 3 K-SIGMA Threshold : ---thr 2.572\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 138667, 1: 383})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 86, 1: 41064, 2: 59, 3: 40, 4: 27, 5: 13, 6: 36, 7: 28}\n",
      "Test : Accuracy: 0.7026 Recall : 0.0071 FDR: 0.2245  F1-score: 0.0142  \n",
      "\n",
      "==================  lr=1e-05, wd=1e-05 ==================\n",
      "Train : time 173.96 s Epoch 1\n",
      "Train Loss: 3.1448\n",
      "Train : time 157.81 s Epoch 2\n",
      "Train Loss: 0.4104\n",
      "--- Running Evaluation for Epoch 2 lr =1e-05 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.2407 std: 0.8241\n",
      "Val: Accuracy: 0.8674  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.065\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 103033, 1: 36017})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 92, 1: 5564, 2: 14, 3: 16, 4: 4, 5: 3, 6: 10, 7: 28}\n",
      "Test : Accuracy: 0.9588 Recall : 0.8643 FDR: 0.0026  F1-score: 0.9261  \n",
      " K: 3 K-SIGMA Threshold : ---thr 2.713\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 138697, 1: 353})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 85, 1: 41076, 2: 59, 3: 40, 4: 27, 5: 30, 6: 36, 7: 28}\n",
      "Test : Accuracy: 0.7024 Recall : 0.0064 FDR: 0.2408  F1-score: 0.0128  \n"
     ]
    }
   ],
   "source": [
    "AE_model = AE(input_dim=76)\n",
    "train_eval(AE_model,train_dataloader,val_dataloader,test_dataloader,shuffle_files=True,num_epochs=2,eval_epoch=2,criterion_method=\"mse\",learning_rates=[1e-2,1e-3,1e-4,1e-5],weight_decays=[1e-4,1e-5],k_range=[1,3])\n",
    "# --- Running Evaluation for Epoch 6 lr =0.001 wd 1e-05 ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ca63c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ea756ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================  lr=0.01, wd=0.001 ==================\n",
      "Train : time 165.62 s Epoch 1\n",
      "Train Loss: 0.2089\n",
      "Train : time 184.23 s Epoch 2\n",
      "Train Loss: 0.1849\n",
      "--- Running Evaluation for Epoch 2 lr =0.01 wd 0.001 ---\n",
      "-----------mse_loss mean :  0.0732 std: 0.4997\n",
      "Val: Accuracy: 0.8659  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.5729\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 102985, 1: 36065})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 102, 1: 5530, 2: 14, 3: 16, 4: 4, 5: 1, 6: 10, 7: 26}\n",
      "Test : Accuracy: 0.9590 Recall : 0.8652 FDR: 0.0028  F1-score: 0.9265  \n",
      "model VAE is saved in best_models/VAE_f1_0.93_recall_0.87_.pth\n",
      " K: 3 K-SIGMA Threshold : ---thr 1.572\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 103032, 1: 36018})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 93, 1: 5564, 2: 14, 3: 16, 4: 4, 5: 3, 6: 10, 7: 28}\n",
      "Test : Accuracy: 0.9588 Recall : 0.8643 FDR: 0.0026  F1-score: 0.9261  \n",
      "model VAE is saved in best_models/VAE_f1_0.93_recall_0.86_.pth\n",
      "\n",
      "==================  lr=0.01, wd=0.0001 ==================\n",
      "Train : time 188.93 s Epoch 1\n",
      "Train Loss: 0.1842\n",
      "Train : time 170.62 s Epoch 2\n",
      "Train Loss: 0.1610\n",
      "--- Running Evaluation for Epoch 2 lr =0.01 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0586 std: 0.3152\n",
      "Val: Accuracy: 0.8239  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.3738\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 101489, 1: 37561})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 1313, 1: 5262, 2: 14, 3: 16, 4: 4, 5: 1, 6: 10, 7: 9}\n",
      "Test : Accuracy: 0.9523 Recall : 0.8721 FDR: 0.0350  F1-score: 0.9162  \n",
      "model VAE is saved in best_models/VAE_f1_0.92_recall_0.87_.pth\n",
      " K: 3 K-SIGMA Threshold : ---thr 1.004\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 102803, 1: 36247})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 286, 1: 5528, 2: 14, 3: 16, 4: 4, 5: 3, 6: 10, 7: 28}\n",
      "Test : Accuracy: 0.9576 Recall : 0.8652 FDR: 0.0079  F1-score: 0.9243  \n",
      "model VAE is saved in best_models/VAE_f1_0.92_recall_0.87_.pth\n",
      "\n",
      "==================  lr=0.001, wd=0.001 ==================\n",
      "Train : time 166.37 s Epoch 1\n",
      "Train Loss: 0.2522\n",
      "Train : time 163.68 s Epoch 2\n",
      "Train Loss: 0.1756\n",
      "--- Running Evaluation for Epoch 2 lr =0.001 wd 0.001 ---\n",
      "-----------mse_loss mean :  0.0565 std: 0.2311\n",
      "Val: Accuracy: 0.8161  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.2876\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 102214, 1: 36836})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 552, 1: 5236, 2: 14, 3: 15, 4: 4, 5: 1, 6: 10}\n",
      "Test : Accuracy: 0.9581 Recall : 0.8730 FDR: 0.0150  F1-score: 0.9256  \n",
      "model VAE is saved in best_models/VAE_f1_0.93_recall_0.87_.pth\n",
      " K: 3 K-SIGMA Threshold : ---thr 0.7497\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 102911, 1: 36139})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 207, 1: 5557, 2: 14, 3: 16, 4: 4, 5: 3, 6: 10, 7: 28}\n",
      "Test : Accuracy: 0.9580 Recall : 0.8645 FDR: 0.0057  F1-score: 0.9249  \n",
      "model VAE is saved in best_models/VAE_f1_0.92_recall_0.86_.pth\n",
      "\n",
      "==================  lr=0.001, wd=0.0001 ==================\n",
      "Train : time 166.28 s Epoch 1\n",
      "Train Loss: 0.5838\n",
      "Train : time 167.08 s Epoch 2\n",
      "Train Loss: 0.1607\n",
      "--- Running Evaluation for Epoch 2 lr =0.001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0279 std: 0.1585\n",
      "Val: Accuracy: 0.7928  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.1864\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 102327, 1: 36723})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 452, 1: 5250, 2: 13, 3: 15, 4: 4, 5: 1, 6: 10}\n",
      "Test : Accuracy: 0.9587 Recall : 0.8727 FDR: 0.0123  F1-score: 0.9266  \n",
      "model VAE is saved in best_models/VAE_f1_0.93_recall_0.87_.pth\n",
      " K: 3 K-SIGMA Threshold : ---thr 0.5034\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 102930, 1: 36120})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 163, 1: 5536, 2: 14, 3: 16, 4: 4, 5: 1, 6: 10, 7: 26}\n",
      "Test : Accuracy: 0.9585 Recall : 0.8651 FDR: 0.0045  F1-score: 0.9257  \n",
      "model VAE is saved in best_models/VAE_f1_0.93_recall_0.87_.pth\n",
      "\n",
      "==================  lr=0.0001, wd=0.001 ==================\n",
      "Train : time 175.71 s Epoch 1\n",
      "Train Loss: 0.8655\n",
      "Train : time 183.30 s Epoch 2\n",
      "Train Loss: 0.1900\n",
      "--- Running Evaluation for Epoch 2 lr =0.0001 wd 0.001 ---\n",
      "-----------mse_loss mean :  0.0729 std: 0.4357\n",
      "Val: Accuracy: 0.8804  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.5086\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 102776, 1: 36274})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 316, 1: 5534, 2: 14, 3: 15, 4: 4, 5: 1, 6: 10, 7: 28}\n",
      "Test : Accuracy: 0.9574 Recall : 0.8651 FDR: 0.0087  F1-score: 0.9239  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.38\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 102981, 1: 36069})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 142, 1: 5562, 2: 14, 3: 16, 4: 4, 5: 3, 6: 10, 7: 28}\n",
      "Test : Accuracy: 0.9584 Recall : 0.8644 FDR: 0.0039  F1-score: 0.9256  \n",
      "\n",
      "==================  lr=0.0001, wd=0.0001 ==================\n",
      "Train : time 169.46 s Epoch 1\n",
      "Train Loss: 0.7625\n",
      "Train : time 169.04 s Epoch 2\n",
      "Train Loss: 0.1811\n",
      "--- Running Evaluation for Epoch 2 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0726 std: 0.5199\n",
      "Val: Accuracy: 0.8965  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.5925\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 102602, 1: 36448})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 419, 1: 5466, 2: 14, 3: 16, 4: 4, 5: 1, 6: 10, 7: 24}\n",
      "Test : Accuracy: 0.9572 Recall : 0.8668 FDR: 0.0115  F1-score: 0.9237  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.632\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 102912, 1: 36138})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 178, 1: 5532, 2: 14, 3: 16, 4: 4, 5: 2, 6: 10, 7: 26}\n",
      "Test : Accuracy: 0.9584 Recall : 0.8652 FDR: 0.0049  F1-score: 0.9256  \n",
      "\n",
      "==================  lr=1e-05, wd=0.001 ==================\n",
      "Train : time 166.01 s Epoch 1\n",
      "Train Loss: 5.0073\n",
      "Train : time 174.91 s Epoch 2\n",
      "Train Loss: 0.5260\n",
      "--- Running Evaluation for Epoch 2 lr =1e-05 wd 0.001 ---\n",
      "-----------mse_loss mean :  0.2171 std: 0.5639\n",
      "Val: Accuracy: 0.8156  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.781\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 102988, 1: 36062})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 199, 1: 5628, 2: 14, 3: 16, 4: 4, 5: 3, 6: 10, 7: 26}\n",
      "Test : Accuracy: 0.9576 Recall : 0.8628 FDR: 0.0055  F1-score: 0.9240  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.909\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 106921, 1: 32129})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 104, 1: 9454, 2: 15, 3: 19, 4: 6, 5: 4, 6: 13, 7: 28}\n",
      "Test : Accuracy: 0.9307 Recall : 0.7705 FDR: 0.0032  F1-score: 0.8691  \n",
      "\n",
      "==================  lr=1e-05, wd=0.0001 ==================\n",
      "Train : time 164.80 s Epoch 1\n",
      "Train Loss: 6.6122\n",
      "Train : time 165.44 s Epoch 2\n",
      "Train Loss: 1.4314\n",
      "--- Running Evaluation for Epoch 2 lr =1e-05 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.5035 std: 1.1192\n",
      "Val: Accuracy: 0.8474  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.623\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 103026, 1: 36024})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 142, 1: 5607, 2: 14, 3: 16, 4: 4, 5: 3, 6: 10, 7: 28}\n",
      "Test : Accuracy: 0.9581 Recall : 0.8633 FDR: 0.0039  F1-score: 0.9249  \n",
      " K: 3 K-SIGMA Threshold : ---thr 3.861\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 138728, 1: 322})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 87, 1: 41075, 2: 59, 3: 40, 4: 55, 5: 36, 6: 36, 7: 28}\n",
      "Test : Accuracy: 0.7022 Recall : 0.0057 FDR: 0.2702  F1-score: 0.0112  \n"
     ]
    }
   ],
   "source": [
    "VAE_model = VAE(input_dim=76)\n",
    "train_eval(VAE_model,train_dataloader,val_dataloader,test_dataloader,shuffle_files=True,num_epochs=2,eval_epoch=2,criterion_method=\"mse\",learning_rates=[1e-2,1e-3,1e-4,1e-5],weight_decays=[1e-3,1e-4],k_range=[1,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eb02de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================  lr=0.001, wd=1e-05 ==================\n",
      "Train : time 165.04 s Epoch 1\n",
      "Train Loss: 0.3184\n",
      "Train : time 155.17 s Epoch 2\n",
      "Train Loss: 0.1613\n",
      "Train : time 158.38 s Epoch 3\n",
      "Train Loss: 0.1547\n",
      "Train : time 168.95 s Epoch 4\n",
      "Train Loss: 0.1528\n",
      "Train : time 163.59 s Epoch 5\n",
      "Train Loss: 0.1508\n",
      "--- Running Evaluation for Epoch 5 lr =0.001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.0367 std: 0.2408\n",
      "Val: Accuracy: 0.8536  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.2775\n",
      "Counts of : original binary labels Counter({0: 529457, 1: 220322}) predicted binary labels Counter({0: 555983, 1: 193796})\n",
      "Counts of  original  labels: {0: 529457, 1: 218884, 2: 317, 3: 236, 4: 243, 5: 240, 6: 170, 7: 232}\n",
      "Counts of misclassified original labels: {0: 13336, 1: 39597, 2: 57, 3: 95, 4: 42, 5: 2, 6: 68, 7: 1}\n",
      "Test : Accuracy: 0.9290 Recall : 0.8191 FDR: 0.0688  F1-score: 0.8715  \n",
      "model VAE is saved in best_models/VAE_f1_0.87_recall_0.82_.pth\n",
      "Train : time 168.75 s Epoch 6\n",
      "Train Loss: 0.1486\n",
      "Train : time 159.53 s Epoch 7\n",
      "Train Loss: 0.1466\n",
      "Train : time 159.93 s Epoch 8\n",
      "Train Loss: 0.1445\n",
      "Train : time 158.90 s Epoch 9\n",
      "Train Loss: 0.1418\n",
      "Train : time 164.31 s Epoch 10\n",
      "Train Loss: 0.1399\n",
      "--- Running Evaluation for Epoch 10 lr =0.001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.0349 std: 0.2490\n",
      "Val: Accuracy: 0.8459  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.2838\n",
      "Counts of : original binary labels Counter({0: 529457, 1: 220322}) predicted binary labels Counter({0: 558716, 1: 191063})\n",
      "Counts of  original  labels: {0: 529457, 1: 218884, 2: 317, 3: 236, 4: 243, 5: 240, 6: 170, 7: 232}\n",
      "Counts of misclassified original labels: {0: 10807, 1: 39799, 2: 58, 3: 96, 4: 42, 5: 2, 6: 68, 7: 1}\n",
      "Test : Accuracy: 0.9321 Recall : 0.8181 FDR: 0.0566  F1-score: 0.8763  \n",
      "model VAE is saved in best_models/VAE_f1_0.88_recall_0.82_.pth\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "54635226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================  lr=0.01, wd=0.001 ==================\n",
      "Train : time 260.97 s Epoch 1\n",
      "Generator Loss: 2.7325 Discriminator Loss: 25.2167\n",
      "Train : time 260.60 s Epoch 2\n",
      "Generator Loss: 0.8408 Discriminator Loss: 26.6410\n",
      "--- Running Evaluation for Epoch 2 lr =0.01 wd 0.001 ---\n",
      "-----------mse_loss mean :  0.0046 std: 0.0674\n",
      "Val: Accuracy: 0.9078  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.07198\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 102696, 1: 36354})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 94, 1: 5260, 2: 14, 3: 15, 4: 4, 5: 1, 6: 10}\n",
      "Test : Accuracy: 0.9612 Recall : 0.8724 FDR: 0.0026  F1-score: 0.9307  \n",
      "model AdversarialAutoencoder is saved in best_models/AdversarialAutoencoder_f1_0.93_recall_0.87_.pth\n",
      " K: 3 K-SIGMA Threshold : ---thr 0.2068\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 102696, 1: 36354})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 94, 1: 5260, 2: 14, 3: 15, 4: 4, 5: 1, 6: 10}\n",
      "Test : Accuracy: 0.9612 Recall : 0.8724 FDR: 0.0026  F1-score: 0.9307  \n",
      "model AdversarialAutoencoder is saved in best_models/AdversarialAutoencoder_f1_0.93_recall_0.87_.pth\n",
      "\n",
      "==================  lr=0.01, wd=0.0001 ==================\n",
      "Train : time 264.68 s Epoch 1\n",
      "Generator Loss: 1.2799 Discriminator Loss: 22.5400\n",
      "Train : time 259.20 s Epoch 2\n",
      "Generator Loss: 0.4998 Discriminator Loss: 26.5191\n",
      "--- Running Evaluation for Epoch 2 lr =0.01 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0051 std: 0.0661\n",
      "Val: Accuracy: 0.8826  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.07129\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 102719, 1: 36331})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 67, 1: 5260, 2: 14, 3: 15, 5: 1, 6: 10}\n",
      "Test : Accuracy: 0.9614 Recall : 0.8725 FDR: 0.0018  F1-score: 0.9311  \n",
      "model AdversarialAutoencoder is saved in best_models/AdversarialAutoencoder_f1_0.93_recall_0.87_.pth\n",
      " K: 3 K-SIGMA Threshold : ---thr 0.2036\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 102779, 1: 36271})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 11, 1: 5260, 2: 14, 3: 15, 4: 4, 5: 1, 6: 10}\n",
      "Test : Accuracy: 0.9618 Recall : 0.8724 FDR: 0.0003  F1-score: 0.9317  \n",
      "model AdversarialAutoencoder is saved in best_models/AdversarialAutoencoder_f1_0.93_recall_0.87_.pth\n",
      "\n",
      "==================  lr=0.001, wd=0.001 ==================\n",
      "Train : time 260.29 s Epoch 1\n",
      "Generator Loss: 9.1342 Discriminator Loss: 13.2783\n",
      "Train : time 260.57 s Epoch 2\n",
      "Generator Loss: 0.4133 Discriminator Loss: 18.0982\n",
      "--- Running Evaluation for Epoch 2 lr =0.001 wd 0.001 ---\n",
      "-----------mse_loss mean :  0.0028 std: 0.0658\n",
      "Val: Accuracy: 0.9755  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.06864\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 102696, 1: 36354})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 94, 1: 5260, 2: 14, 3: 15, 4: 4, 5: 1, 6: 10}\n",
      "Test : Accuracy: 0.9612 Recall : 0.8724 FDR: 0.0026  F1-score: 0.9307  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.2002\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 102696, 1: 36354})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 94, 1: 5260, 2: 14, 3: 15, 4: 4, 5: 1, 6: 10}\n",
      "Test : Accuracy: 0.9612 Recall : 0.8724 FDR: 0.0026  F1-score: 0.9307  \n",
      "\n",
      "==================  lr=0.001, wd=0.0001 ==================\n",
      "Train : time 292.07 s Epoch 1\n",
      "Generator Loss: 4.7865 Discriminator Loss: 12.0390\n",
      "Train : time 286.77 s Epoch 2\n",
      "Generator Loss: 0.7527 Discriminator Loss: 14.7540\n",
      "--- Running Evaluation for Epoch 2 lr =0.001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0084 std: 0.1414\n",
      "Val: Accuracy: 0.9738  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.1498\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 102696, 1: 36354})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 94, 1: 5260, 2: 14, 3: 15, 4: 4, 5: 1, 6: 10}\n",
      "Test : Accuracy: 0.9612 Recall : 0.8724 FDR: 0.0026  F1-score: 0.9307  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.4327\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 102706, 1: 36344})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 94, 1: 5270, 2: 14, 3: 15, 4: 4, 5: 1, 6: 10}\n",
      "Test : Accuracy: 0.9611 Recall : 0.8721 FDR: 0.0026  F1-score: 0.9306  \n",
      "\n",
      "==================  lr=0.0001, wd=0.001 ==================\n",
      "Train : time 286.40 s Epoch 1\n",
      "Generator Loss: 27.5954 Discriminator Loss: 10.3724\n",
      "Train : time 283.44 s Epoch 2\n",
      "Generator Loss: 0.7782 Discriminator Loss: 14.2462\n",
      "--- Running Evaluation for Epoch 2 lr =0.0001 wd 0.001 ---\n",
      "-----------mse_loss mean :  0.0064 std: 0.1363\n",
      "Val: Accuracy: 0.9300  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.1427\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 102696, 1: 36354})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 94, 1: 5260, 2: 14, 3: 15, 4: 4, 5: 1, 6: 10}\n",
      "Test : Accuracy: 0.9612 Recall : 0.8724 FDR: 0.0026  F1-score: 0.9307  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.4153\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 103018, 1: 36032})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 93, 1: 5552, 2: 14, 3: 16, 4: 4, 5: 1, 6: 10, 7: 28}\n",
      "Test : Accuracy: 0.9589 Recall : 0.8647 FDR: 0.0026  F1-score: 0.9263  \n",
      "\n",
      "==================  lr=0.0001, wd=0.0001 ==================\n",
      "Train : time 268.64 s Epoch 1\n",
      "Generator Loss: 65.0635 Discriminator Loss: 8.7646\n",
      "Train : time 262.92 s Epoch 2\n",
      "Generator Loss: 10.5829 Discriminator Loss: 6.4434\n",
      "--- Running Evaluation for Epoch 2 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.1523 std: 0.6022\n",
      "Val: Accuracy: 0.9102  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.7545\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 103031, 1: 36019})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 92, 1: 5564, 2: 14, 3: 16, 4: 4, 5: 1, 6: 10, 7: 28}\n",
      "Test : Accuracy: 0.9588 Recall : 0.8644 FDR: 0.0026  F1-score: 0.9262  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.959\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 138700, 1: 350})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 87, 1: 41064, 2: 59, 3: 40, 4: 50, 5: 24, 6: 36, 7: 28}\n",
      "Test : Accuracy: 0.7024 Recall : 0.0063 FDR: 0.2486  F1-score: 0.0125  \n",
      "\n",
      "==================  lr=1e-05, wd=0.001 ==================\n",
      "Train : time 263.54 s Epoch 1\n",
      "Generator Loss: 302.3294 Discriminator Loss: 16.6262\n",
      "Train : time 288.15 s Epoch 2\n",
      "Generator Loss: 70.8611 Discriminator Loss: 10.7389\n",
      "--- Running Evaluation for Epoch 2 lr =1e-05 wd 0.001 ---\n",
      "-----------mse_loss mean :  0.8029 std: 2.0147\n",
      "Val: Accuracy: 0.8629  \n",
      " K: 1 K-SIGMA Threshold : ---thr 2.818\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 138731, 1: 319})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 85, 1: 41076, 2: 59, 3: 40, 4: 55, 5: 36, 6: 36, 7: 28}\n",
      "Test : Accuracy: 0.7022 Recall : 0.0056 FDR: 0.2665  F1-score: 0.0112  \n",
      " K: 3 K-SIGMA Threshold : ---thr 6.847\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 139019, 1: 31})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 28, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 37, 6: 36, 7: 28}\n",
      "Test : Accuracy: 0.7009 Recall : 0.0001 FDR: 0.9032  F1-score: 0.0001  \n",
      "\n",
      "==================  lr=1e-05, wd=0.0001 ==================\n",
      "Train : time 261.87 s Epoch 1\n",
      "Generator Loss: 299.4895 Discriminator Loss: 25.2969\n",
      "Train : time 260.48 s Epoch 2\n",
      "Generator Loss: 74.1173 Discriminator Loss: 10.9795\n",
      "--- Running Evaluation for Epoch 2 lr =1e-05 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.8956 std: 2.0302\n",
      "Val: Accuracy: 0.8556  \n",
      " K: 1 K-SIGMA Threshold : ---thr 2.926\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 138731, 1: 319})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 85, 1: 41076, 2: 59, 3: 40, 4: 55, 5: 36, 6: 36, 7: 28}\n",
      "Test : Accuracy: 0.7022 Recall : 0.0056 FDR: 0.2665  F1-score: 0.0112  \n",
      " K: 3 K-SIGMA Threshold : ---thr 6.986\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 139019, 1: 31})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 28, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 37, 6: 36, 7: 28}\n",
      "Test : Accuracy: 0.7009 Recall : 0.0001 FDR: 0.9032  F1-score: 0.0001  \n"
     ]
    }
   ],
   "source": [
    "AAE_model = AdversarialAutoencoder()\n",
    "train_eval(AAE_model,train_dataloader,val_dataloader,test_dataloader,shuffle_files=True,num_epochs=2,eval_epoch=2,criterion_method=\"mse\",learning_rates=[1e-2,1e-3,1e-4,1e-5],weight_decays=[1e-3,1e-4],k_range=[1,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77de9ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================  lr=0.0001, wd=1e-06 ==================\n",
      "Train : time 266.33 s Epoch 1\n",
      "Generator Loss: 56.0338 Discriminator Loss: 6.7792\n",
      "Train : time 264.11 s Epoch 2\n",
      "Generator Loss: 9.7689 Discriminator Loss: 12.3131\n",
      "Train : time 263.87 s Epoch 3\n",
      "Generator Loss: 8.1489 Discriminator Loss: 10.4486\n",
      "Train : time 261.28 s Epoch 4\n",
      "Generator Loss: 6.0716 Discriminator Loss: 11.2788\n",
      "Train : time 256.96 s Epoch 5\n",
      "Generator Loss: 5.6057 Discriminator Loss: 10.5377\n",
      "--- Running Evaluation for Epoch 5 lr =0.0001 wd 1e-06 ---\n",
      "-----------mse_loss mean :  0.0837 std: 0.3804\n",
      "Val: Accuracy: 0.9290  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.4641\n",
      "Counts of : original binary labels Counter({0: 529457, 1: 220322}) predicted binary labels Counter({0: 561825, 1: 187954})\n",
      "Counts of  original  labels: {0: 529457, 1: 218884, 2: 317, 3: 236, 4: 243, 5: 240, 6: 170, 7: 232}\n",
      "Counts of misclassified original labels: {0: 7937, 1: 40041, 2: 58, 3: 96, 4: 39, 5: 2, 6: 68, 7: 1}\n",
      "Test : Accuracy: 0.9357 Recall : 0.8171 FDR: 0.0422  F1-score: 0.8818  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.225\n",
      "Counts of : original binary labels Counter({0: 529457, 1: 220322}) predicted binary labels Counter({0: 561829, 1: 187950})\n",
      "Counts of  original  labels: {0: 529457, 1: 218884, 2: 317, 3: 236, 4: 243, 5: 240, 6: 170, 7: 232}\n",
      "Counts of misclassified original labels: {0: 7936, 1: 40041, 2: 58, 3: 96, 4: 42, 5: 2, 6: 68, 7: 1}\n",
      "Test : Accuracy: 0.9357 Recall : 0.8170 FDR: 0.0422  F1-score: 0.8818  \n",
      "model AdversarialAutoencoder is saved in best_models/AdversarialAutoencoder_f1_0.88_recall_0.82_.pth\n",
      "Train : time 265.82 s Epoch 6\n",
      "Generator Loss: 5.5684 Discriminator Loss: 8.4417\n",
      "Train : time 258.36 s Epoch 7\n",
      "Generator Loss: 5.4602 Discriminator Loss: 12.5588\n",
      "Train : time 269.10 s Epoch 8\n",
      "Generator Loss: 5.4909 Discriminator Loss: 15.0568\n",
      "Train : time 280.94 s Epoch 9\n",
      "Generator Loss: 5.4308 Discriminator Loss: 18.7288\n",
      "Train : time 267.99 s Epoch 10\n",
      "Generator Loss: 5.3895 Discriminator Loss: 16.9664\n",
      "--- Running Evaluation for Epoch 10 lr =0.0001 wd 1e-06 ---\n",
      "-----------mse_loss mean :  0.0816 std: 0.3700\n",
      "Val: Accuracy: 0.9296  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.4515\n",
      "Counts of : original binary labels Counter({0: 529457, 1: 220322}) predicted binary labels Counter({0: 562060, 1: 187719})\n",
      "Counts of  original  labels: {0: 529457, 1: 218884, 2: 317, 3: 236, 4: 243, 5: 240, 6: 170, 7: 232}\n",
      "Counts of misclassified original labels: {0: 7935, 1: 40041, 2: 58, 3: 96, 4: 42, 5: 2, 6: 68, 7: 231}\n",
      "Test : Accuracy: 0.9354 Recall : 0.8160 FDR: 0.0423  F1-score: 0.8812  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.191\n",
      "Counts of : original binary labels Counter({0: 529457, 1: 220322}) predicted binary labels Counter({0: 610228, 1: 139551})\n",
      "Counts of  original  labels: {0: 529457, 1: 218884, 2: 317, 3: 236, 4: 243, 5: 240, 6: 170, 7: 232}\n",
      "Counts of misclassified original labels: {0: 6855, 1: 86816, 2: 102, 3: 197, 4: 111, 5: 73, 6: 95, 7: 232}\n",
      "Test : Accuracy: 0.8740 Recall : 0.6023 FDR: 0.0491  F1-score: 0.7375  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[85], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m AAE_model \u001b[38;5;241m=\u001b[39m AdversarialAutoencoder()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAAE_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mshuffle_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43meval_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mcriterion_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmse\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mlearning_rates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mweight_decays\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1e-6\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[72], line 47\u001b[0m, in \u001b[0;36mtrain_eval\u001b[0;34m(model, train_dataloader, val_dataloader, test_dataloader, learning_rates, weight_decays, shuffle_files, num_epochs, eval_epoch, criterion_method, k_range, train_model)\u001b[0m\n\u001b[1;32m     45\u001b[0m fake_z,decoded_seq \u001b[38;5;241m=\u001b[39m model(sequences)\n\u001b[1;32m     46\u001b[0m G_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.001\u001b[39m\u001b[38;5;241m*\u001b[39madversarial_criterion(model\u001b[38;5;241m.\u001b[39mdiscriminator(fake_z),target_ones ) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.999\u001b[39m\u001b[38;5;241m*\u001b[39mcriterion(decoded_seq, sequences)\n\u001b[0;32m---> 47\u001b[0m \u001b[43mG_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m optimizer_G\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# 2) discriminator loss\u001b[39;00m\n",
      "File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/torch/_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    647\u001b[0m     )\n\u001b[0;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/torch/autograd/__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/torch/autograd/graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8c8ddee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================  lr=0.001, wd=1e-05 ==================\n",
      "Train : time 157.69 s Epoch 1\n",
      "Train Loss: 0.3925\n",
      "Train : time 153.40 s Epoch 2\n",
      "Train Loss: 0.0358\n",
      "Train : time 152.62 s Epoch 3\n",
      "Train Loss: 0.0248\n",
      "Train : time 153.83 s Epoch 4\n",
      "Train Loss: 0.0219\n",
      "--- Running Evaluation for Epoch 4 lr =0.001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.0232 std: 0.3594\n",
      "Val: Accuracy: 0.9913  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.3826\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 103017, 1: 36033})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 93, 1: 5552, 2: 14, 3: 15, 4: 4, 5: 1, 6: 10, 7: 28}\n",
      "Test : Accuracy: 0.9589 Recall : 0.8647 FDR: 0.0026  F1-score: 0.9263  \n",
      "model AE is saved in best_center_models/AE_f1_0.9263_recall_0.8647_.pth\n",
      "Train : time 152.49 s Epoch 5\n",
      "Train Loss: 0.0216\n",
      "Train : time 157.49 s Epoch 6\n",
      "Train Loss: 0.0214\n",
      "Train : time 160.24 s Epoch 7\n",
      "Train Loss: 0.0209\n",
      "Train : time 151.94 s Epoch 8\n",
      "Train Loss: 0.0206\n",
      "--- Running Evaluation for Epoch 8 lr =0.001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.0222 std: 0.3556\n",
      "Val: Accuracy: 0.9920  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.3779\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 103018, 1: 36032})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 93, 1: 5552, 2: 14, 3: 16, 4: 4, 5: 1, 6: 10, 7: 28}\n",
      "Test : Accuracy: 0.9589 Recall : 0.8647 FDR: 0.0026  F1-score: 0.9263  \n",
      "model AE is saved in best_center_models/AE_f1_0.9263_recall_0.8647_.pth\n",
      "Train : time 150.98 s Epoch 9\n",
      "Train Loss: 0.0190\n",
      "Train : time 151.27 s Epoch 10\n",
      "Train Loss: 0.0166\n",
      "Train : time 150.30 s Epoch 11\n",
      "Train Loss: 0.0164\n",
      "Train : time 166.52 s Epoch 12\n",
      "Train Loss: 0.0163\n",
      "--- Running Evaluation for Epoch 12 lr =0.001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.0179 std: 0.2902\n",
      "Val: Accuracy: 0.9933  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.3081\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 103018, 1: 36032})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 93, 1: 5552, 2: 14, 3: 16, 4: 4, 5: 1, 6: 10, 7: 28}\n",
      "Test : Accuracy: 0.9589 Recall : 0.8647 FDR: 0.0026  F1-score: 0.9263  \n",
      "model AE is saved in best_center_models/AE_f1_0.9263_recall_0.8647_.pth\n",
      "Train : time 185.63 s Epoch 13\n",
      "Train Loss: 0.0161\n",
      "Train : time 183.92 s Epoch 14\n",
      "Train Loss: 0.0160\n",
      "Train : time 214.25 s Epoch 15\n",
      "Train Loss: 0.0159\n",
      "Train : time 196.49 s Epoch 16\n",
      "Train Loss: 0.0159\n",
      "--- Running Evaluation for Epoch 16 lr =0.001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.0176 std: 0.2892\n",
      "Val: Accuracy: 0.9933  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.3067\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 102984, 1: 36066})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 93, 1: 5525, 2: 14, 3: 16, 4: 4, 5: 1, 6: 10, 7: 21}\n",
      "Test : Accuracy: 0.9591 Recall : 0.8655 FDR: 0.0026  F1-score: 0.9268  \n",
      "model AE is saved in best_center_models/AE_f1_0.9268_recall_0.8655_.pth\n",
      "Train : time 193.83 s Epoch 17\n",
      "Train Loss: 0.0158\n",
      "Train : time 167.43 s Epoch 18\n",
      "Train Loss: 0.0158\n",
      "Train : time 197.43 s Epoch 19\n",
      "Train Loss: 0.0158\n",
      "Train : time 184.70 s Epoch 20\n",
      "Train Loss: 0.0157\n",
      "--- Running Evaluation for Epoch 20 lr =0.001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.0174 std: 0.2855\n",
      "Val: Accuracy: 0.9933  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.3029\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 103015, 1: 36035})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 93, 1: 5549, 2: 14, 3: 16, 4: 4, 5: 1, 6: 10, 7: 28}\n",
      "Test : Accuracy: 0.9589 Recall : 0.8647 FDR: 0.0026  F1-score: 0.9264  \n",
      "model AE is saved in best_center_models/AE_f1_0.9264_recall_0.8647_.pth\n"
     ]
    }
   ],
   "source": [
    "#lr=0.001, wd=1e-05 \n",
    "AE_model = AE(input_dim=76)\n",
    "train_eval(AE_model,train_dataloader,val_dataloader,test_dataloader,shuffle_files=True,num_epochs=20,eval_epoch=4,criterion_method=\"mse\",learning_rates=[1e-3],weight_decays=[1e-5],k_range=[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b96a2214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================  lr=0.0001, wd=0.0001 ==================\n",
      "Train : time 195.29 s Epoch 1\n",
      "Train Loss: 0.7271\n",
      "Train : time 188.97 s Epoch 2\n",
      "Train Loss: 0.1814\n",
      "Train : time 196.54 s Epoch 3\n",
      "Train Loss: 0.1734\n",
      "Train : time 204.82 s Epoch 4\n",
      "Train Loss: 0.1685\n",
      "--- Running Evaluation for Epoch 4 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0537 std: 0.2896\n",
      "Val: Accuracy: 0.8444  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.3433\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 102169, 1: 36881})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 711, 1: 5348, 2: 14, 3: 14, 4: 4, 5: 1, 6: 10, 7: 3}\n",
      "Test : Accuracy: 0.9561 Recall : 0.8702 FDR: 0.0193  F1-score: 0.9222  \n",
      "model VAE is saved in best_center_models/VAE_f1_0.9222_recall_0.8702_.pth\n",
      "Train : time 200.85 s Epoch 5\n",
      "Train Loss: 0.1655\n",
      "Train : time 177.86 s Epoch 6\n",
      "Train Loss: 0.1617\n",
      "Train : time 162.78 s Epoch 7\n",
      "Train Loss: 0.1580\n",
      "Train : time 166.06 s Epoch 8\n",
      "Train Loss: 0.1559\n",
      "--- Running Evaluation for Epoch 8 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0437 std: 0.2229\n",
      "Val: Accuracy: 0.8138  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.2666\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 101733, 1: 37317})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 996, 1: 5199, 2: 14, 3: 15, 4: 4, 5: 1, 6: 10}\n",
      "Test : Accuracy: 0.9551 Recall : 0.8739 FDR: 0.0267  F1-score: 0.9209  \n",
      "model VAE is saved in best_center_models/VAE_f1_0.9209_recall_0.8739_.pth\n",
      "Train : time 164.64 s Epoch 9\n",
      "Train Loss: 0.1537\n",
      "Train : time 167.24 s Epoch 10\n",
      "Train Loss: 0.1517\n",
      "Train : time 164.10 s Epoch 11\n",
      "Train Loss: 0.1505\n",
      "Train : time 166.60 s Epoch 12\n",
      "Train Loss: 0.1498\n",
      "--- Running Evaluation for Epoch 12 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0361 std: 0.1753\n",
      "Val: Accuracy: 0.8037  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.2114\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 101721, 1: 37329})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 1007, 1: 5199, 2: 14, 3: 14, 4: 4, 5: 1, 6: 10}\n",
      "Test : Accuracy: 0.9551 Recall : 0.8739 FDR: 0.0270  F1-score: 0.9208  \n",
      "model VAE is saved in best_center_models/VAE_f1_0.9208_recall_0.8739_.pth\n",
      "Train : time 166.92 s Epoch 13\n",
      "Train Loss: 0.1486\n",
      "Train : time 165.14 s Epoch 14\n",
      "Train Loss: 0.1466\n",
      "Train : time 164.43 s Epoch 15\n",
      "Train Loss: 0.1456\n",
      "Train : time 165.91 s Epoch 16\n",
      "Train Loss: 0.1449\n",
      "--- Running Evaluation for Epoch 16 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0321 std: 0.1612\n",
      "Val: Accuracy: 0.8001  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.1933\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 101758, 1: 37292})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 971, 1: 5200, 2: 14, 3: 14, 4: 4, 5: 1, 6: 10}\n",
      "Test : Accuracy: 0.9553 Recall : 0.8739 FDR: 0.0260  F1-score: 0.9212  \n",
      "model VAE is saved in best_center_models/VAE_f1_0.9212_recall_0.8739_.pth\n",
      "Train : time 167.85 s Epoch 17\n",
      "Train Loss: 0.1442\n",
      "Train : time 165.36 s Epoch 18\n",
      "Train Loss: 0.1437\n",
      "Train : time 164.41 s Epoch 19\n",
      "Train Loss: 0.1434\n",
      "Train : time 166.37 s Epoch 20\n",
      "Train Loss: 0.1430\n",
      "--- Running Evaluation for Epoch 20 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0321 std: 0.1713\n",
      "Val: Accuracy: 0.8045  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.2034\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 101884, 1: 37166})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 857, 1: 5211, 2: 14, 3: 15, 4: 4, 5: 1, 6: 10}\n",
      "Test : Accuracy: 0.9560 Recall : 0.8736 FDR: 0.0231  F1-score: 0.9224  \n",
      "model VAE is saved in best_center_models/VAE_f1_0.9224_recall_0.8736_.pth\n"
     ]
    }
   ],
   "source": [
    "#==================  lr=0.0001, wd=0.0001 ==================\n",
    "\n",
    "VAE_model = VAE(input_dim=76)\n",
    "train_eval(VAE_model,train_dataloader,val_dataloader,test_dataloader,shuffle_files=True,num_epochs=20,eval_epoch=4,criterion_method=\"mse\",learning_rates=[1e-4],weight_decays=[1e-4,],k_range=[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e00eca6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================  lr=0.01, wd=0.0001 ==================\n",
      "Train : time 258.46 s Epoch 1\n",
      "Generator Loss: 2.5820 Discriminator Loss: 23.0968\n",
      "Train : time 263.93 s Epoch 2\n",
      "Generator Loss: 1.0836 Discriminator Loss: 26.7439\n",
      "Train : time 260.17 s Epoch 3\n",
      "Generator Loss: 0.5757 Discriminator Loss: 32.0621\n",
      "Train : time 259.62 s Epoch 4\n",
      "Generator Loss: 1.3244 Discriminator Loss: 27.5940\n",
      "--- Running Evaluation for Epoch 4 lr =0.01 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0067 std: 0.0696\n",
      "Val: Accuracy: 0.8607  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.07626\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 102696, 1: 36354})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 94, 1: 5260, 2: 14, 3: 15, 4: 4, 5: 1, 6: 10}\n",
      "Test : Accuracy: 0.9612 Recall : 0.8724 FDR: 0.0026  F1-score: 0.9307  \n",
      "model AdversarialAutoencoder is saved in best_center_models/AdversarialAutoencoder_f1_0.9307_recall_0.8724_.pth\n",
      " K: 3 K-SIGMA Threshold : ---thr 0.2154\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 102697, 1: 36353})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 93, 1: 5260, 2: 14, 3: 15, 4: 4, 5: 1, 6: 10}\n",
      "Test : Accuracy: 0.9612 Recall : 0.8724 FDR: 0.0026  F1-score: 0.9307  \n",
      "model AdversarialAutoencoder is saved in best_center_models/AdversarialAutoencoder_f1_0.9307_recall_0.8724_.pth\n",
      "Train : time 261.93 s Epoch 5\n",
      "Generator Loss: 0.4218 Discriminator Loss: 29.8320\n",
      "Train : time 259.54 s Epoch 6\n",
      "Generator Loss: 0.4281 Discriminator Loss: 29.8482\n",
      "Train : time 274.09 s Epoch 7\n",
      "Generator Loss: 3.7527 Discriminator Loss: 90.9324\n",
      "Train : time 264.96 s Epoch 8\n",
      "Generator Loss: 0.4802 Discriminator Loss: 28.1880\n",
      "--- Running Evaluation for Epoch 8 lr =0.01 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0028 std: 0.0471\n",
      "Val: Accuracy: 0.9383  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.0499\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 102696, 1: 36354})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 94, 1: 5260, 2: 14, 3: 15, 4: 4, 5: 1, 6: 10}\n",
      "Test : Accuracy: 0.9612 Recall : 0.8724 FDR: 0.0026  F1-score: 0.9307  \n",
      "model AdversarialAutoencoder is saved in best_center_models/AdversarialAutoencoder_f1_0.9307_recall_0.8724_.pth\n",
      " K: 3 K-SIGMA Threshold : ---thr 0.1442\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 102697, 1: 36353})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 93, 1: 5260, 2: 14, 3: 15, 4: 4, 5: 1, 6: 10}\n",
      "Test : Accuracy: 0.9612 Recall : 0.8724 FDR: 0.0026  F1-score: 0.9307  \n",
      "model AdversarialAutoencoder is saved in best_center_models/AdversarialAutoencoder_f1_0.9307_recall_0.8724_.pth\n",
      "Train : time 263.18 s Epoch 9\n",
      "Generator Loss: 0.3780 Discriminator Loss: 28.9714\n",
      "Train : time 265.96 s Epoch 10\n",
      "Generator Loss: 0.3796 Discriminator Loss: 28.3467\n",
      "Train : time 263.32 s Epoch 11\n",
      "Generator Loss: 0.3695 Discriminator Loss: 27.9243\n",
      "Train : time 263.32 s Epoch 12\n",
      "Generator Loss: 1.3631 Discriminator Loss: 27.8087\n",
      "--- Running Evaluation for Epoch 12 lr =0.01 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.1652 std: 0.5505\n",
      "Val: Accuracy: 0.9169  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.7158\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 103117, 1: 35933})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 8, 1: 5564, 2: 14, 3: 16, 4: 4, 5: 3, 6: 10, 7: 28}\n",
      "Test : Accuracy: 0.9594 Recall : 0.8643 FDR: 0.0002  F1-score: 0.9271  \n",
      "model AdversarialAutoencoder is saved in best_center_models/AdversarialAutoencoder_f1_0.9271_recall_0.8643_.pth\n",
      " K: 3 K-SIGMA Threshold : ---thr 1.817\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 103117, 1: 35933})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 8, 1: 5564, 2: 14, 3: 16, 4: 4, 5: 3, 6: 10, 7: 28}\n",
      "Test : Accuracy: 0.9594 Recall : 0.8643 FDR: 0.0002  F1-score: 0.9271  \n",
      "model AdversarialAutoencoder is saved in best_center_models/AdversarialAutoencoder_f1_0.9271_recall_0.8643_.pth\n",
      "Train : time 263.85 s Epoch 13\n",
      "Generator Loss: 0.8763 Discriminator Loss: 124.4304\n",
      "Train : time 262.09 s Epoch 14\n",
      "Generator Loss: 0.4965 Discriminator Loss: 28.3297\n",
      "Train : time 262.66 s Epoch 15\n",
      "Generator Loss: 0.4882 Discriminator Loss: 30.3285\n",
      "Train : time 263.67 s Epoch 16\n",
      "Generator Loss: 0.3859 Discriminator Loss: 35.9983\n",
      "--- Running Evaluation for Epoch 16 lr =0.01 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0035 std: 0.0669\n",
      "Val: Accuracy: 0.9614  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.07038\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 102697, 1: 36353})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 93, 1: 5260, 2: 14, 3: 15, 4: 4, 5: 1, 6: 10}\n",
      "Test : Accuracy: 0.9612 Recall : 0.8724 FDR: 0.0026  F1-score: 0.9307  \n",
      "model AdversarialAutoencoder is saved in best_center_models/AdversarialAutoencoder_f1_0.9307_recall_0.8724_.pth\n",
      " K: 3 K-SIGMA Threshold : ---thr 0.2042\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 102697, 1: 36353})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 93, 1: 5260, 2: 14, 3: 15, 4: 4, 5: 1, 6: 10}\n",
      "Test : Accuracy: 0.9612 Recall : 0.8724 FDR: 0.0026  F1-score: 0.9307  \n",
      "model AdversarialAutoencoder is saved in best_center_models/AdversarialAutoencoder_f1_0.9307_recall_0.8724_.pth\n",
      "Train : time 264.79 s Epoch 17\n",
      "Generator Loss: 0.3639 Discriminator Loss: 32.5534\n",
      "Train : time 263.88 s Epoch 18\n",
      "Generator Loss: 0.3547 Discriminator Loss: 29.6391\n",
      "Train : time 262.28 s Epoch 19\n",
      "Generator Loss: 0.4275 Discriminator Loss: 28.6417\n",
      "Train : time 263.69 s Epoch 20\n",
      "Generator Loss: 0.3488 Discriminator Loss: 34.8351\n",
      "--- Running Evaluation for Epoch 20 lr =0.01 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0028 std: 0.0493\n",
      "Val: Accuracy: 0.9432  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.05213\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 102691, 1: 36359})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 95, 1: 5260, 2: 14, 3: 15, 5: 1, 6: 10}\n",
      "Test : Accuracy: 0.9612 Recall : 0.8725 FDR: 0.0026  F1-score: 0.9308  \n",
      "model AdversarialAutoencoder is saved in best_center_models/AdversarialAutoencoder_f1_0.9308_recall_0.8725_.pth\n",
      " K: 3 K-SIGMA Threshold : ---thr 0.1508\n",
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({0: 102779, 1: 36271})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 11, 1: 5260, 2: 14, 3: 15, 4: 4, 5: 1, 6: 10}\n",
      "Test : Accuracy: 0.9618 Recall : 0.8724 FDR: 0.0003  F1-score: 0.9317  \n",
      "model AdversarialAutoencoder is saved in best_center_models/AdversarialAutoencoder_f1_0.9317_recall_0.8724_.pth\n"
     ]
    }
   ],
   "source": [
    "# ==================  lr=0.01, wd=0.0001 ==================\n",
    "\n",
    "AAE_model = AdversarialAutoencoder()\n",
    "train_eval(AAE_model,train_dataloader,val_dataloader,test_dataloader,shuffle_files=True,num_epochs=20,eval_epoch=4,criterion_method=\"mse\",learning_rates=[1e-2],weight_decays=[1e-4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b21a73a",
   "metadata": {},
   "source": [
    "#### Evaluate pre-trained autoencoders  on the compromised-ied and compromised scada scenarios \n",
    "\n",
    "No exact labeling for the comp ied scenario results in low performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "19349642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Trained_AE_model=AE(input_dim=76)\n",
    "Trained_AE_model.load_state_dict(torch.load(\"./best_models/AE_f1_0.88_recall_0.81_.pth\"))\n",
    "Trained_VAE_model=VAE(input_dim=76)\n",
    "Trained_VAE_model.load_state_dict(torch.load(\"./best_models/VAE_f1_0.88_recall_0.82_.pth\"))\n",
    "Trained_AAE_model=AdversarialAutoencoder()\n",
    "Trained_AAE_model.load_state_dict(torch.load(\"./best_models/AdversarialAutoencoder_f1_0.88_recall_0.82_.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f29e2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The CIC Modbus Dataset contains network (pcap) captures and attack logs from a simulated substation network.\n",
      "                The dataset is categorized into two groups: an attack dataset and a benign dataset\n",
      "                The attack dataset includes network traffic captures that simulate various types of Modbus protocol attacks in a substation environment.\n",
      "                The attacks are reconnaissance, query flooding, loading payloads, delay response, modify length parameters, false data injection, stacking Modbus frames, brute force write and baseline replay.\n",
      "                These attacks are based of some techniques in the MITRE ICS ATT&CK framework.\n",
      "                On the other hand, the benign dataset consists of normal network traffic captures representing legitimate Modbus communication within the substation network.\n",
      "                The purpose of this dataset is to facilitate research, analysis, and development of intrusion detection systems, anomaly detection algorithms and other security mechanisms for substation networks using the Modbus protocol.\n",
      "                https://www.unb.ca/cic/datasets/modbus-2023.html\n",
      "                In my custom PyTorch Dataset class,\n",
      "                I utilize the Enhanced CICflowMeter and the Attack logs correlation to extract and label sequential data flows,\n",
      "                preparing them for batch processing with the DataLoader, which is crucial for AI model training.\n",
      "                https://github.com/hamid-rd/FLBased-ICS-NIDS/tree/main\n",
      "\n",
      "                \n",
      "csv files  in the dataset directory founded with the filter:  ready\n",
      "{\n",
      "    \"total_dataset_num\": 170,\n",
      "    \"benign_dataset_num\": 62,\n",
      "    \"attack_dataset_num\": {\n",
      "        \"total_num\": 108,\n",
      "        \"external_num\": 8,\n",
      "        \"compromised-ied_num\": 43,\n",
      "        \"compromised-scada_num\": 57\n",
      "    },\n",
      "    \"attack_logs_num\": {\n",
      "        \"total_num\": 34,\n",
      "        \"external_num\": [\n",
      "            \"./ModbusDataset/attack/external/external-attacker/attacker logs/02-01-2023/02-01-2023-1.csv\",\n",
      "            \"./ModbusDataset/attack/external/external-attacker/attacker logs/12-29-2022/12-29-2022-1.csv\",\n",
      "            \"./ModbusDataset/attack/external/external-attacker/attacker logs/01-17-2023/01-17-2023-1.csv\",\n",
      "            \"./ModbusDataset/attack/external/external-attacker/attacker logs/01-02-2023/01-02-2023-1.csv\",\n",
      "            \"./ModbusDataset/attack/external/external-attacker/attacker logs/12-30-2022/12-30-2022-1.csv\",\n",
      "            \"./ModbusDataset/attack/external/external-attacker/attacker logs/01-01-2023/01-01-2023-1.csv\"\n",
      "        ],\n",
      "        \"compromised-ied_num\": 7,\n",
      "        \"compromised-scada_num\": 21\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "dataset_directory = \"./ModbusDataset/\" \n",
    "\n",
    "modbus = ModbusDataset(dataset_directory,\"ready\")\n",
    "modbus.summary_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a5ea10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scenario : compromised-scada\n",
      "----------- benign valid files: 4 ['./ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-28-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-22-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-25-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-17-labeled.csv']\n",
      "----------compromised-scada attack  test files :  7 ['./ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-3-labeled.csv', './ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-4-labeled.csv', './ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-1-labeled.csv', './ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-7-labeled.csv', './ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-0-labeled.csv', './ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-5-labeled.csv', './ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-2-labeled.csv']\n",
      "********** AE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0066 std: 0.1111\n",
      "Val: Accuracy: 0.9929  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.1177\n",
      "Counts of : original binary labels Counter({0: 529457, 1: 220322}) predicted binary labels Counter({0: 562658, 1: 187121})\n",
      "Counts of  original  labels: {0: 529457, 1: 218884, 2: 317, 3: 236, 4: 243, 5: 240, 6: 170, 7: 232}\n",
      "Counts of misclassified original labels: {0: 7927, 1: 40869, 2: 58, 3: 96, 4: 32, 5: 2, 6: 70, 7: 1}\n",
      "Test : Accuracy: 0.9346 Recall : 0.8133 FDR: 0.0424  F1-score: 0.8796  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.34\n",
      "Counts of : original binary labels Counter({0: 529457, 1: 220322}) predicted binary labels Counter({0: 564535, 1: 185244})\n",
      "Counts of  original  labels: {0: 529457, 1: 218884, 2: 317, 3: 236, 4: 243, 5: 240, 6: 170, 7: 232}\n",
      "Counts of misclassified original labels: {0: 7891, 1: 42465, 2: 59, 3: 99, 4: 42, 5: 2, 6: 70, 7: 232}\n",
      "Test : Accuracy: 0.9322 Recall : 0.8050 FDR: 0.0426  F1-score: 0.8746  \n",
      "********** AdversarialAutoencoder **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0837 std: 0.3804\n",
      "Val: Accuracy: 0.9290  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.4641\n",
      "Counts of : original binary labels Counter({0: 529457, 1: 220322}) predicted binary labels Counter({0: 561825, 1: 187954})\n",
      "Counts of  original  labels: {0: 529457, 1: 218884, 2: 317, 3: 236, 4: 243, 5: 240, 6: 170, 7: 232}\n",
      "Counts of misclassified original labels: {0: 7937, 1: 40041, 2: 58, 3: 96, 4: 39, 5: 2, 6: 68, 7: 1}\n",
      "Test : Accuracy: 0.9357 Recall : 0.8171 FDR: 0.0422  F1-score: 0.8818  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.225\n",
      "Counts of : original binary labels Counter({0: 529457, 1: 220322}) predicted binary labels Counter({0: 561829, 1: 187950})\n",
      "Counts of  original  labels: {0: 529457, 1: 218884, 2: 317, 3: 236, 4: 243, 5: 240, 6: 170, 7: 232}\n",
      "Counts of misclassified original labels: {0: 7936, 1: 40041, 2: 58, 3: 96, 4: 42, 5: 2, 6: 68, 7: 1}\n",
      "Test : Accuracy: 0.9357 Recall : 0.8170 FDR: 0.0422  F1-score: 0.8818  \n",
      "********** VAE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0351 std: 0.2528\n",
      "Val: Accuracy: 0.8474  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.2879\n",
      "Counts of : original binary labels Counter({0: 529457, 1: 220322}) predicted binary labels Counter({0: 558587, 1: 191192})\n",
      "Counts of  original  labels: {0: 529457, 1: 218884, 2: 317, 3: 236, 4: 243, 5: 240, 6: 170, 7: 232}\n",
      "Counts of misclassified original labels: {0: 10927, 1: 39793, 2: 58, 3: 96, 4: 42, 5: 2, 6: 65, 7: 1}\n",
      "Test : Accuracy: 0.9320 Recall : 0.8182 FDR: 0.0572  F1-score: 0.8761  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.7934\n",
      "Counts of : original binary labels Counter({0: 529457, 1: 220322}) predicted binary labels Counter({0: 563164, 1: 186615})\n",
      "Counts of  original  labels: {0: 529457, 1: 218884, 2: 317, 3: 236, 4: 243, 5: 240, 6: 170, 7: 232}\n",
      "Counts of misclassified original labels: {0: 9180, 1: 42392, 2: 59, 3: 99, 4: 42, 5: 7, 6: 69, 7: 219}\n",
      "Test : Accuracy: 0.9306 Recall : 0.8053 FDR: 0.0492  F1-score: 0.8721  \n",
      "scenario : external\n",
      "----------- benign valid files: 4 ['./ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-28-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-22-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-25-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-17-labeled.csv']\n",
      "----------external attack  test files :  2 ['./ModbusDataset/attack/external/network-wide/ready/network-wide-normal-1-labeled.csv', './ModbusDataset/attack/external/network-wide/ready/network-wide-normal-0-labeled.csv']\n",
      "********** AE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0066 std: 0.1111\n",
      "Val: Accuracy: 0.9929  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.1177\n",
      "Counts of : original binary labels Counter({0: 156058, 1: 65271}) predicted binary labels Counter({0: 155929, 1: 65400})\n",
      "Counts of  original  labels: {0: 156058, 1: 65233, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 618, 1: 489}\n",
      "Test : Accuracy: 0.9950 Recall : 0.9925 FDR: 0.0094  F1-score: 0.9915  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.34\n",
      "Counts of : original binary labels Counter({0: 156058, 1: 65271}) predicted binary labels Counter({0: 194856, 1: 26473})\n",
      "Counts of  original  labels: {0: 156058, 1: 65233, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 509, 1: 39299, 6: 8}\n",
      "Test : Accuracy: 0.8201 Recall : 0.3978 FDR: 0.0192  F1-score: 0.5660  \n",
      "********** AdversarialAutoencoder **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0837 std: 0.3804\n",
      "Val: Accuracy: 0.9290  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.4641\n",
      "Counts of : original binary labels Counter({0: 156058, 1: 65271}) predicted binary labels Counter({0: 147639, 1: 73690})\n",
      "Counts of  original  labels: {0: 156058, 1: 65233, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 8587, 1: 168}\n",
      "Test : Accuracy: 0.9604 Recall : 0.9974 FDR: 0.1165  F1-score: 0.9370  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.225\n",
      "Counts of : original binary labels Counter({0: 156058, 1: 65271}) predicted binary labels Counter({0: 152012, 1: 69317})\n",
      "Counts of  original  labels: {0: 156058, 1: 65233, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 4214, 1: 168}\n",
      "Test : Accuracy: 0.9802 Recall : 0.9974 FDR: 0.0608  F1-score: 0.9674  \n",
      "********** VAE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0351 std: 0.2527\n",
      "Val: Accuracy: 0.8474  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.2878\n",
      "Counts of : original binary labels Counter({0: 156058, 1: 65271}) predicted binary labels Counter({0: 157278, 1: 64051})\n",
      "Counts of  original  labels: {0: 156058, 1: 65233, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 1786, 1: 3006}\n",
      "Test : Accuracy: 0.9783 Recall : 0.9539 FDR: 0.0279  F1-score: 0.9629  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.7933\n",
      "Counts of : original binary labels Counter({0: 156058, 1: 65271}) predicted binary labels Counter({0: 179006, 1: 42323})\n",
      "Counts of  original  labels: {0: 156058, 1: 65233, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 1120, 1: 24060, 5: 1, 6: 7}\n",
      "Test : Accuracy: 0.8862 Recall : 0.6313 FDR: 0.0265  F1-score: 0.7659  \n",
      "scenario : compromised-ied\n",
      "----------- benign valid files: 4 ['./ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-28-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-22-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-25-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-17-labeled.csv']\n",
      "----------compromised-ied attack  test files :  20 ['./ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-2-labeled.csv', './ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-10-labeled.csv', './ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-19-labeled.csv', './ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-17-labeled.csv', './ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-0-labeled.csv', './ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-9-labeled.csv', './ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-15-labeled.csv', './ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-3-labeled.csv', './ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-7-labeled.csv', './ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-14-labeled.csv', './ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-12-labeled.csv', './ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-18-labeled.csv', './ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-6-labeled.csv', './ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-16-labeled.csv', './ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-8-labeled.csv', './ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-1-labeled.csv', './ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-13-labeled.csv', './ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-4-labeled.csv', './ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-5-labeled.csv', './ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-11-labeled.csv']\n",
      "********** AE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0066 std: 0.1111\n",
      "Val: Accuracy: 0.9929  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.1177\n",
      "Counts of : original binary labels Counter({0: 2552713, 1: 356}) predicted binary labels Counter({0: 2525537, 1: 27532})\n",
      "Counts of  original  labels: {0: 2552713, 2: 64, 3: 78, 4: 51, 5: 61, 7: 59, 8: 43}\n",
      "Counts of misclassified original labels: {0: 27426, 2: 64, 3: 78, 4: 31, 7: 59, 8: 18}\n",
      "Test : Accuracy: 0.9892 Recall : 0.2978 FDR: 0.9961  F1-score: 0.0076  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.34\n",
      "Counts of : original binary labels Counter({0: 2552713, 1: 356}) predicted binary labels Counter({0: 2526004, 1: 27065})\n",
      "Counts of  original  labels: {0: 2552713, 2: 64, 3: 78, 4: 51, 5: 61, 7: 59, 8: 43}\n",
      "Counts of misclassified original labels: {0: 26987, 2: 64, 3: 78, 4: 51, 7: 59, 8: 26}\n",
      "Test : Accuracy: 0.9893 Recall : 0.2191 FDR: 0.9971  F1-score: 0.0057  \n",
      "********** AdversarialAutoencoder **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0837 std: 0.3804\n",
      "Val: Accuracy: 0.9290  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.4641\n",
      "Counts of : original binary labels Counter({0: 2552713, 1: 356}) predicted binary labels Counter({0: 2286313, 1: 266756})\n",
      "Counts of  original  labels: {0: 2552713, 2: 64, 3: 78, 4: 51, 5: 61, 7: 59, 8: 43}\n",
      "Counts of misclassified original labels: {0: 266588, 2: 45, 3: 54, 4: 37, 7: 38, 8: 14}\n",
      "Test : Accuracy: 0.8955 Recall : 0.4719 FDR: 0.9994  F1-score: 0.0013  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.225\n",
      "Counts of : original binary labels Counter({0: 2552713, 1: 356}) predicted binary labels Counter({0: 2424529, 1: 128540})\n",
      "Counts of  original  labels: {0: 2552713, 2: 64, 3: 78, 4: 51, 5: 61, 7: 59, 8: 43}\n",
      "Counts of misclassified original labels: {0: 128429, 2: 52, 3: 71, 4: 46, 7: 48, 8: 28}\n",
      "Test : Accuracy: 0.9496 Recall : 0.3118 FDR: 0.9991  F1-score: 0.0017  \n",
      "********** VAE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0350 std: 0.2533\n",
      "Val: Accuracy: 0.8475  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.2883\n",
      "Counts of : original binary labels Counter({0: 2552713, 1: 356}) predicted binary labels Counter({0: 2517130, 1: 35939})\n",
      "Counts of  original  labels: {0: 2552713, 2: 64, 3: 78, 4: 51, 5: 61, 7: 59, 8: 43}\n",
      "Counts of misclassified original labels: {0: 35859, 2: 63, 3: 78, 4: 51, 7: 59, 8: 25}\n",
      "Test : Accuracy: 0.9858 Recall : 0.2247 FDR: 0.9978  F1-score: 0.0044  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.7948\n",
      "Counts of : original binary labels Counter({0: 2552713, 1: 356}) predicted binary labels Counter({0: 2534193, 1: 18876})\n",
      "Counts of  original  labels: {0: 2552713, 2: 64, 3: 78, 4: 51, 5: 61, 7: 59, 8: 43}\n",
      "Counts of misclassified original labels: {0: 18805, 2: 63, 3: 78, 4: 51, 7: 59, 8: 34}\n",
      "Test : Accuracy: 0.9925 Recall : 0.1994 FDR: 0.9962  F1-score: 0.0074  \n"
     ]
    }
   ],
   "source": [
    "for scenario in {\"compromised-ied\",\"external\",\"compromised-scada\"}:\n",
    "    if scenario==\"compromised-scada\":\n",
    "        print(\"scenario :\",scenario)\n",
    "        test_files= [col for col in modbus.dataset[\"attack_dataset_dir\"][scenario] if col.find(\"ied1b\")!=-1]\n",
    "        ### missed attack logs for the day 21 for ied1b which can reduce the accuracy.\n",
    "        test_files.remove(dataset_directory+\"attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-6-labeled.csv\")    \n",
    "    elif scenario==\"compromised-ied\":\n",
    "        print(\"scenario :\",scenario)\n",
    "        test_files= [col for col in modbus.dataset[\"attack_dataset_dir\"][scenario] if col.find(\"trust-scada-hmi\")!=-1]\n",
    "    else:\n",
    "        print(\"scenario :\",scenario)\n",
    "        test_files= [col for col in modbus.dataset[\"attack_dataset_dir\"][scenario] if col.find(\"network-wide\")!=-1]        \n",
    "\n",
    "    print(\"----------- benign valid files:\",len(val_files),val_files)\n",
    "    print(f\"----------{scenario} attack  test files : \",len(test_files),test_files)\n",
    "    val_dataloader=DataLoader(ModbusFlowStream(\n",
    "                shuffle=False,\n",
    "                chunk_size=1,\n",
    "                batch_size=64,\n",
    "                csv_files=val_files,\n",
    "                scalers=loaded_scalers['network-wide']['min_max_scalers'],\n",
    "            ),batch_size=1,shuffle=False)\n",
    "    test_dataloader=DataLoader(ModbusFlowStream(\n",
    "                shuffle=False,\n",
    "                chunk_size=1,\n",
    "                batch_size=64,\n",
    "                csv_files=test_files,\n",
    "                scalers=loaded_scalers['network-wide']['min_max_scalers'],\n",
    "            ),batch_size=1,shuffle=False)\n",
    "    for trained_model in {Trained_AE_model,Trained_VAE_model,Trained_AAE_model}:\n",
    "        print(\"*\"*10,trained_model._get_name(),10*\"*\")\n",
    "        train_eval(trained_model,None,val_dataloader,test_dataloader,shuffle_files=False,num_epochs=1,eval_epoch=1,criterion_method=\"mse\",train_model=False,learning_rates=[0],weight_decays=[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d9f36972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compromised-scada\n",
      "exclude 51 ['./ModbusDataset/attack/compromised-scada/ied4c/ied4c-network-captures/ready/vethe685ac9-0-labeled.csv', './ModbusDataset/attack/compromised-scada/ied4c/ied4c-network-captures/ready/vethe685ac9-5-labeled.csv', './ModbusDataset/attack/compromised-scada/ied4c/ied4c-network-captures/ready/vethe685ac9-1-labeled.csv', './ModbusDataset/attack/compromised-scada/ied4c/ied4c-network-captures/ready/vethe685ac9-2-labeled.csv', './ModbusDataset/attack/compromised-scada/ied4c/ied4c-network-captures/ready/vethe685ac9-4-labeled.csv', './ModbusDataset/attack/compromised-scada/ied4c/ied4c-network-captures/ready/vethe685ac9-3-labeled.csv', './ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-6-labeled.csv', './ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-3-labeled.csv', './ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-4-labeled.csv', './ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-1-labeled.csv', './ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-7-labeled.csv', './ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-0-labeled.csv', './ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-5-labeled.csv', './ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-2-labeled.csv', './ModbusDataset/attack/compromised-scada/scada-hmi/scada-hmi-network-capture/ready/veth291ab9a-0-labeled.csv', './ModbusDataset/attack/compromised-scada/scada-hmi/scada-hmi-network-capture/ready/veth291ab9a-14-labeled.csv', './ModbusDataset/attack/compromised-scada/scada-hmi/scada-hmi-network-capture/ready/veth291ab9a-13-labeled.csv', './ModbusDataset/attack/compromised-scada/scada-hmi/scada-hmi-network-capture/ready/veth291ab9a-1-labeled.csv', './ModbusDataset/attack/compromised-scada/scada-hmi/scada-hmi-network-capture/ready/veth291ab9a-16-labeled.csv', './ModbusDataset/attack/compromised-scada/scada-hmi/scada-hmi-network-capture/ready/veth291ab9a-3-labeled.csv', './ModbusDataset/attack/compromised-scada/scada-hmi/scada-hmi-network-capture/ready/veth291ab9a-11-labeled.csv', './ModbusDataset/attack/compromised-scada/scada-hmi/scada-hmi-network-capture/ready/veth291ab9a-8-labeled.csv', './ModbusDataset/attack/compromised-scada/scada-hmi/scada-hmi-network-capture/ready/veth291ab9a-7-labeled.csv', './ModbusDataset/attack/compromised-scada/scada-hmi/scada-hmi-network-capture/ready/veth291ab9a-5-labeled.csv', './ModbusDataset/attack/compromised-scada/scada-hmi/scada-hmi-network-capture/ready/veth291ab9a-12-labeled.csv', './ModbusDataset/attack/compromised-scada/scada-hmi/scada-hmi-network-capture/ready/veth291ab9a-9-labeled.csv', './ModbusDataset/attack/compromised-scada/scada-hmi/scada-hmi-network-capture/ready/veth291ab9a-6-labeled.csv', './ModbusDataset/attack/compromised-scada/scada-hmi/scada-hmi-network-capture/ready/veth291ab9a-2-labeled.csv', './ModbusDataset/attack/compromised-scada/scada-hmi/scada-hmi-network-capture/ready/veth291ab9a-15-labeled.csv', './ModbusDataset/attack/compromised-scada/scada-hmi/scada-hmi-network-capture/ready/veth291ab9a-4-labeled.csv', './ModbusDataset/attack/compromised-scada/scada-hmi/scada-hmi-network-capture/ready/veth291ab9a-10-labeled.csv', './ModbusDataset/attack/compromised-scada/central-agent/central-agent-network-captures/ready/vethffb308b-1-labeled.csv', './ModbusDataset/attack/compromised-scada/central-agent/central-agent-network-captures/ready/vethffb308b-0-labeled.csv', './ModbusDataset/attack/compromised-scada/substation-wide-capture/ready/substation-14-labeled.csv', './ModbusDataset/attack/compromised-scada/substation-wide-capture/ready/substation-13-labeled.csv', './ModbusDataset/attack/compromised-scada/substation-wide-capture/ready/substation-15-labeled.csv', './ModbusDataset/attack/compromised-scada/substation-wide-capture/ready/substation-4-labeled.csv', './ModbusDataset/attack/compromised-scada/substation-wide-capture/ready/substation-10-labeled.csv', './ModbusDataset/attack/compromised-scada/substation-wide-capture/ready/substation-3-labeled.csv', './ModbusDataset/attack/compromised-scada/substation-wide-capture/ready/substation-17-labeled.csv', './ModbusDataset/attack/compromised-scada/substation-wide-capture/ready/substation-8-labeled.csv', './ModbusDataset/attack/compromised-scada/substation-wide-capture/ready/substation-5-labeled.csv', './ModbusDataset/attack/compromised-scada/substation-wide-capture/ready/substation-0-labeled.csv', './ModbusDataset/attack/compromised-scada/substation-wide-capture/ready/substation-11-labeled.csv', './ModbusDataset/attack/compromised-scada/substation-wide-capture/ready/substation-2-labeled.csv', './ModbusDataset/attack/compromised-scada/substation-wide-capture/ready/substation-9-labeled.csv', './ModbusDataset/attack/compromised-scada/substation-wide-capture/ready/substation-1-labeled.csv', './ModbusDataset/attack/compromised-scada/substation-wide-capture/ready/substation-6-labeled.csv', './ModbusDataset/attack/compromised-scada/substation-wide-capture/ready/substation-12-labeled.csv', './ModbusDataset/attack/compromised-scada/substation-wide-capture/ready/substation-7-labeled.csv', './ModbusDataset/attack/compromised-scada/substation-wide-capture/ready/substation-16-labeled.csv']\n",
      "filtered test files without ied1b 6 ['./ModbusDataset/attack/compromised-scada/ied1a/ied1a-network-captures/ready/veth3614724-3-labeled.csv', './ModbusDataset/attack/compromised-scada/ied1a/ied1a-network-captures/ready/veth3614724-4-labeled.csv', './ModbusDataset/attack/compromised-scada/ied1a/ied1a-network-captures/ready/veth3614724-0-labeled.csv', './ModbusDataset/attack/compromised-scada/ied1a/ied1a-network-captures/ready/veth3614724-1-labeled.csv', './ModbusDataset/attack/compromised-scada/ied1a/ied1a-network-captures/ready/veth3614724-2-labeled.csv', './ModbusDataset/attack/compromised-scada/ied1a/ied1a-network-captures/ready/veth3614724-5-labeled.csv']\n",
      "./ModbusDataset/attack/compromised-scada/ied1a/ied1a-network-captures/ready/veth3614724-3-labeled.csv\n",
      "********** AE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0049 std: 0.1301\n",
      "Val: Accuracy: 0.9906  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.1349\n",
      "Counts of : original binary labels Counter({0: 140850, 1: 16604}) predicted binary labels Counter({0: 127999, 1: 29455})\n",
      "Counts of  original  labels: {0: 140850, 1: 16419, 2: 40, 3: 32, 4: 32, 5: 27, 6: 32, 7: 22}\n",
      "Counts of misclassified original labels: {0: 12869, 1: 13, 3: 1, 6: 4}\n",
      "Test : Accuracy: 0.9182 Recall : 0.9989 FDR: 0.4369  F1-score: 0.7202  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.3951\n",
      "Counts of : original binary labels Counter({0: 140850, 1: 16604}) predicted binary labels Counter({0: 139986, 1: 17468})\n",
      "Counts of  original  labels: {0: 140850, 1: 16419, 2: 40, 3: 32, 4: 32, 5: 27, 6: 32, 7: 22}\n",
      "Counts of misclassified original labels: {0: 11616, 1: 10702, 2: 24, 3: 10, 4: 7, 6: 9}\n",
      "Test : Accuracy: 0.8579 Recall : 0.3524 FDR: 0.6650  F1-score: 0.3435  \n",
      "********** VAE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0324 std: 0.2272\n",
      "Val: Accuracy: 0.8431  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.2596\n",
      "Counts of : original binary labels Counter({0: 140850, 1: 16604}) predicted binary labels Counter({0: 127490, 1: 29964})\n",
      "Counts of  original  labels: {0: 140850, 1: 16419, 2: 40, 3: 32, 4: 32, 5: 27, 6: 32, 7: 22}\n",
      "Counts of misclassified original labels: {0: 13379, 1: 13, 3: 1, 4: 1, 6: 4}\n",
      "Test : Accuracy: 0.9149 Recall : 0.9989 FDR: 0.4465  F1-score: 0.7123  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.714\n",
      "Counts of : original binary labels Counter({0: 140850, 1: 16604}) predicted binary labels Counter({0: 146271, 1: 11183})\n",
      "Counts of  original  labels: {0: 140850, 1: 16419, 2: 40, 3: 32, 4: 32, 5: 27, 6: 32, 7: 22}\n",
      "Counts of misclassified original labels: {0: 11048, 1: 16343, 2: 32, 3: 20, 4: 23, 5: 4, 6: 26, 7: 21}\n",
      "Test : Accuracy: 0.8252 Recall : 0.0081 FDR: 0.9879  F1-score: 0.0097  \n",
      "********** AdversarialAutoencoder **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0056 std: 0.0996\n",
      "Val: Accuracy: 0.9444  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.1051\n",
      "Counts of : original binary labels Counter({0: 140850, 1: 16604}) predicted binary labels Counter({0: 127510, 1: 29944})\n",
      "Counts of  original  labels: {0: 140850, 1: 16419, 2: 40, 3: 32, 4: 32, 5: 27, 6: 32, 7: 22}\n",
      "Counts of misclassified original labels: {0: 13358, 1: 13, 3: 1, 6: 4}\n",
      "Test : Accuracy: 0.9150 Recall : 0.9989 FDR: 0.4461  F1-score: 0.7126  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.3043\n",
      "Counts of : original binary labels Counter({0: 140850, 1: 16604}) predicted binary labels Counter({0: 128477, 1: 28977})\n",
      "Counts of  original  labels: {0: 140850, 1: 16419, 2: 40, 3: 32, 4: 32, 5: 27, 6: 32, 7: 22}\n",
      "Counts of misclassified original labels: {0: 12407, 1: 13, 3: 1, 4: 1, 5: 15, 6: 4}\n",
      "Test : Accuracy: 0.9210 Recall : 0.9980 FDR: 0.4282  F1-score: 0.7271  \n",
      "./ModbusDataset/attack/compromised-scada/ied1a/ied1a-network-captures/ready/veth3614724-4-labeled.csv\n",
      "********** AE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0049 std: 0.1301\n",
      "Val: Accuracy: 0.9906  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.1349\n",
      "Counts of : original binary labels Counter({0: 167779}) predicted binary labels Counter({0: 161437, 1: 6342})\n",
      "Counts of  original  labels: {0: 167779}\n",
      "Counts of misclassified original labels: {0: 6342}\n",
      "Test : Accuracy: 0.9622 Recall : 0.0000 FDR: 1.0000  F1-score: 0.0000  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.3951\n",
      "Counts of : original binary labels Counter({0: 167779}) predicted binary labels Counter({0: 165855, 1: 1924})\n",
      "Counts of  original  labels: {0: 167779}\n",
      "Counts of misclassified original labels: {0: 1924}\n",
      "Test : Accuracy: 0.9885 Recall : 0.0000 FDR: 1.0000  F1-score: 0.0000  \n",
      "********** VAE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0322 std: 0.2244\n",
      "Val: Accuracy: 0.8422  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.2566\n",
      "Counts of : original binary labels Counter({0: 167779}) predicted binary labels Counter({0: 159737, 1: 8042})\n",
      "Counts of  original  labels: {0: 167779}\n",
      "Counts of misclassified original labels: {0: 8042}\n",
      "Test : Accuracy: 0.9521 Recall : 0.0000 FDR: 1.0000  F1-score: 0.0000  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.7054\n",
      "Counts of : original binary labels Counter({0: 167779}) predicted binary labels Counter({0: 165200, 1: 2579})\n",
      "Counts of  original  labels: {0: 167779}\n",
      "Counts of misclassified original labels: {0: 2579}\n",
      "Test : Accuracy: 0.9846 Recall : 0.0000 FDR: 1.0000  F1-score: 0.0000  \n",
      "********** AdversarialAutoencoder **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0056 std: 0.0996\n",
      "Val: Accuracy: 0.9444  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.1051\n",
      "Counts of : original binary labels Counter({0: 167779}) predicted binary labels Counter({0: 160943, 1: 6836})\n",
      "Counts of  original  labels: {0: 167779}\n",
      "Counts of misclassified original labels: {0: 6836}\n",
      "Test : Accuracy: 0.9593 Recall : 0.0000 FDR: 1.0000  F1-score: 0.0000  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.3043\n",
      "Counts of : original binary labels Counter({0: 167779}) predicted binary labels Counter({0: 161574, 1: 6205})\n",
      "Counts of  original  labels: {0: 167779}\n",
      "Counts of misclassified original labels: {0: 6205}\n",
      "Test : Accuracy: 0.9630 Recall : 0.0000 FDR: 1.0000  F1-score: 0.0000  \n",
      "./ModbusDataset/attack/compromised-scada/ied1a/ied1a-network-captures/ready/veth3614724-0-labeled.csv\n",
      "********** AE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0049 std: 0.1301\n",
      "Val: Accuracy: 0.9906  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.1349\n",
      "Counts of : original binary labels Counter({0: 95450, 1: 44470}) predicted binary labels Counter({0: 86648, 1: 53272})\n",
      "Counts of  original  labels: {0: 95450, 1: 44239, 2: 30, 3: 20, 4: 61, 5: 32, 6: 36, 7: 52}\n",
      "Counts of misclassified original labels: {0: 8846, 1: 38, 3: 1, 4: 1, 6: 4}\n",
      "Test : Accuracy: 0.9365 Recall : 0.9990 FDR: 0.1661  F1-score: 0.9090  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.3951\n",
      "Counts of : original binary labels Counter({0: 95450, 1: 44470}) predicted binary labels Counter({0: 101133, 1: 38787})\n",
      "Counts of  original  labels: {0: 95450, 1: 44239, 2: 30, 3: 20, 4: 61, 5: 32, 6: 36, 7: 52}\n",
      "Counts of misclassified original labels: {0: 8413, 1: 14028, 2: 22, 3: 5, 4: 25, 6: 16}\n",
      "Test : Accuracy: 0.8391 Recall : 0.6830 FDR: 0.2169  F1-score: 0.7296  \n",
      "********** VAE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0323 std: 0.2244\n",
      "Val: Accuracy: 0.8420  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.2567\n",
      "Counts of : original binary labels Counter({0: 95450, 1: 44470}) predicted binary labels Counter({0: 86107, 1: 53813})\n",
      "Counts of  original  labels: {0: 95450, 1: 44239, 2: 30, 3: 20, 4: 61, 5: 32, 6: 36, 7: 52}\n",
      "Counts of misclassified original labels: {0: 9389, 1: 39, 3: 1, 4: 2, 6: 4}\n",
      "Test : Accuracy: 0.9326 Recall : 0.9990 FDR: 0.1745  F1-score: 0.9040  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.7055\n",
      "Counts of : original binary labels Counter({0: 95450, 1: 44470}) predicted binary labels Counter({0: 131329, 1: 8591})\n",
      "Counts of  original  labels: {0: 95450, 1: 44239, 2: 30, 3: 20, 4: 61, 5: 32, 6: 36, 7: 52}\n",
      "Counts of misclassified original labels: {0: 8335, 1: 44041, 2: 29, 3: 16, 4: 44, 5: 4, 6: 28, 7: 52}\n",
      "Test : Accuracy: 0.6244 Recall : 0.0058 FDR: 0.9702  F1-score: 0.0096  \n",
      "********** AdversarialAutoencoder **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0056 std: 0.0996\n",
      "Val: Accuracy: 0.9444  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.1051\n",
      "Counts of : original binary labels Counter({0: 95450, 1: 44470}) predicted binary labels Counter({0: 85514, 1: 54406})\n",
      "Counts of  original  labels: {0: 95450, 1: 44239, 2: 30, 3: 20, 4: 61, 5: 32, 6: 36, 7: 52}\n",
      "Counts of misclassified original labels: {0: 9977, 1: 36, 3: 1, 6: 4}\n",
      "Test : Accuracy: 0.9284 Recall : 0.9991 FDR: 0.1834  F1-score: 0.8987  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.3043\n",
      "Counts of : original binary labels Counter({0: 95450, 1: 44470}) predicted binary labels Counter({0: 86806, 1: 53114})\n",
      "Counts of  original  labels: {0: 95450, 1: 44239, 2: 30, 3: 20, 4: 61, 5: 32, 6: 36, 7: 52}\n",
      "Counts of misclassified original labels: {0: 8706, 1: 38, 3: 1, 4: 2, 5: 17, 6: 4}\n",
      "Test : Accuracy: 0.9373 Recall : 0.9986 FDR: 0.1639  F1-score: 0.9101  \n",
      "./ModbusDataset/attack/compromised-scada/ied1a/ied1a-network-captures/ready/veth3614724-1-labeled.csv\n",
      "********** AE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0049 std: 0.1301\n",
      "Val: Accuracy: 0.9906  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.1349\n",
      "Counts of : original binary labels Counter({0: 128425, 1: 21856}) predicted binary labels Counter({0: 109069, 1: 41212})\n",
      "Counts of  original  labels: {0: 128425, 1: 21507, 2: 71, 3: 66, 4: 32, 5: 80, 6: 40, 7: 60}\n",
      "Counts of misclassified original labels: {0: 19411, 1: 47, 3: 5, 6: 2, 7: 1}\n",
      "Test : Accuracy: 0.8705 Recall : 0.9975 FDR: 0.4710  F1-score: 0.6913  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.3951\n",
      "Counts of : original binary labels Counter({0: 128425, 1: 21856}) predicted binary labels Counter({0: 126510, 1: 23771})\n",
      "Counts of  original  labels: {0: 128425, 1: 21507, 2: 71, 3: 66, 4: 32, 5: 80, 6: 40, 7: 60}\n",
      "Counts of misclassified original labels: {0: 18133, 1: 16133, 2: 44, 3: 19, 4: 4, 6: 15, 7: 3}\n",
      "Test : Accuracy: 0.7714 Recall : 0.2580 FDR: 0.7628  F1-score: 0.2471  \n",
      "********** VAE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0323 std: 0.2246\n",
      "Val: Accuracy: 0.8426  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.2569\n",
      "Counts of : original binary labels Counter({0: 128425, 1: 21856}) predicted binary labels Counter({0: 107348, 1: 42933})\n",
      "Counts of  original  labels: {0: 128425, 1: 21507, 2: 71, 3: 66, 4: 32, 5: 80, 6: 40, 7: 60}\n",
      "Counts of misclassified original labels: {0: 21131, 1: 46, 3: 5, 6: 2, 7: 1}\n",
      "Test : Accuracy: 0.8590 Recall : 0.9975 FDR: 0.4922  F1-score: 0.6730  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.7062\n",
      "Counts of : original binary labels Counter({0: 128425, 1: 21856}) predicted binary labels Counter({0: 131001, 1: 19280})\n",
      "Counts of  original  labels: {0: 128425, 1: 21507, 2: 71, 3: 66, 4: 32, 5: 80, 6: 40, 7: 60}\n",
      "Counts of misclassified original labels: {0: 17690, 1: 20029, 2: 60, 3: 50, 4: 22, 5: 20, 6: 27, 7: 58}\n",
      "Test : Accuracy: 0.7474 Recall : 0.0727 FDR: 0.9175  F1-score: 0.0773  \n",
      "********** AdversarialAutoencoder **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0056 std: 0.0996\n",
      "Val: Accuracy: 0.9444  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.1051\n",
      "Counts of : original binary labels Counter({0: 128425, 1: 21856}) predicted binary labels Counter({0: 108461, 1: 41820})\n",
      "Counts of  original  labels: {0: 128425, 1: 21507, 2: 71, 3: 66, 4: 32, 5: 80, 6: 40, 7: 60}\n",
      "Counts of misclassified original labels: {0: 20019, 1: 47, 3: 5, 6: 2, 7: 1}\n",
      "Test : Accuracy: 0.8664 Recall : 0.9975 FDR: 0.4787  F1-score: 0.6847  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.3043\n",
      "Counts of : original binary labels Counter({0: 128425, 1: 21856}) predicted binary labels Counter({0: 109555, 1: 40726})\n",
      "Counts of  original  labels: {0: 128425, 1: 21507, 2: 71, 3: 66, 4: 32, 5: 80, 6: 40, 7: 60}\n",
      "Counts of misclassified original labels: {0: 18950, 1: 47, 3: 5, 5: 25, 6: 2, 7: 1}\n",
      "Test : Accuracy: 0.8734 Recall : 0.9963 FDR: 0.4653  F1-score: 0.6959  \n",
      "./ModbusDataset/attack/compromised-scada/ied1a/ied1a-network-captures/ready/veth3614724-2-labeled.csv\n",
      "********** AE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0049 std: 0.1301\n",
      "Val: Accuracy: 0.9906  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.1349\n",
      "Counts of : original binary labels Counter({0: 153304, 1: 12788}) predicted binary labels Counter({0: 147078, 1: 19014})\n",
      "Counts of  original  labels: {0: 153304, 1: 12725, 2: 15, 3: 8, 4: 12, 5: 12, 6: 12, 7: 4}\n",
      "Counts of misclassified original labels: {0: 6323, 1: 96, 6: 1}\n",
      "Test : Accuracy: 0.9613 Recall : 0.9924 FDR: 0.3325  F1-score: 0.7981  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.3951\n",
      "Counts of : original binary labels Counter({0: 153304, 1: 12788}) predicted binary labels Counter({0: 158827, 1: 7265})\n",
      "Counts of  original  labels: {0: 153304, 1: 12725, 2: 15, 3: 8, 4: 12, 5: 12, 6: 12, 7: 4}\n",
      "Counts of misclassified original labels: {0: 5427, 1: 10933, 2: 5, 3: 2, 4: 2, 5: 4, 6: 4}\n",
      "Test : Accuracy: 0.9014 Recall : 0.1437 FDR: 0.7470  F1-score: 0.1833  \n",
      "********** VAE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0323 std: 0.2252\n",
      "Val: Accuracy: 0.8428  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.2575\n",
      "Counts of : original binary labels Counter({0: 153304, 1: 12788}) predicted binary labels Counter({0: 146453, 1: 19639})\n",
      "Counts of  original  labels: {0: 153304, 1: 12725, 2: 15, 3: 8, 4: 12, 5: 12, 6: 12, 7: 4}\n",
      "Counts of misclassified original labels: {0: 6952, 1: 96, 5: 4, 6: 1}\n",
      "Test : Accuracy: 0.9575 Recall : 0.9921 FDR: 0.3540  F1-score: 0.7825  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.7079\n",
      "Counts of : original binary labels Counter({0: 153304, 1: 12788}) predicted binary labels Counter({0: 161280, 1: 4812})\n",
      "Counts of  original  labels: {0: 153304, 1: 12725, 2: 15, 3: 8, 4: 12, 5: 12, 6: 12, 7: 4}\n",
      "Counts of misclassified original labels: {0: 4752, 1: 12678, 2: 15, 3: 7, 4: 10, 5: 4, 6: 10, 7: 4}\n",
      "Test : Accuracy: 0.8948 Recall : 0.0047 FDR: 0.9875  F1-score: 0.0068  \n",
      "********** AdversarialAutoencoder **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0056 std: 0.0996\n",
      "Val: Accuracy: 0.9444  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.1051\n",
      "Counts of : original binary labels Counter({0: 153304, 1: 12788}) predicted binary labels Counter({0: 146467, 1: 19625})\n",
      "Counts of  original  labels: {0: 153304, 1: 12725, 2: 15, 3: 8, 4: 12, 5: 12, 6: 12, 7: 4}\n",
      "Counts of misclassified original labels: {0: 6934, 1: 96, 6: 1}\n",
      "Test : Accuracy: 0.9577 Recall : 0.9924 FDR: 0.3533  F1-score: 0.7831  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.3043\n",
      "Counts of : original binary labels Counter({0: 153304, 1: 12788}) predicted binary labels Counter({0: 147594, 1: 18498})\n",
      "Counts of  original  labels: {0: 153304, 1: 12725, 2: 15, 3: 8, 4: 12, 5: 12, 6: 12, 7: 4}\n",
      "Counts of misclassified original labels: {0: 5816, 1: 96, 5: 9, 6: 1}\n",
      "Test : Accuracy: 0.9643 Recall : 0.9917 FDR: 0.3144  F1-score: 0.8107  \n",
      "./ModbusDataset/attack/compromised-scada/ied1a/ied1a-network-captures/ready/veth3614724-5-labeled.csv\n",
      "********** AE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0049 std: 0.1301\n",
      "Val: Accuracy: 0.9906  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.1349\n",
      "Counts of : original binary labels Counter({0: 71401}) predicted binary labels Counter({0: 70620, 1: 781})\n",
      "Counts of  original  labels: {0: 71401}\n",
      "Counts of misclassified original labels: {0: 781}\n",
      "Test : Accuracy: 0.9891 Recall : 0.0000 FDR: 1.0000  F1-score: 0.0000  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.3951\n",
      "Counts of : original binary labels Counter({0: 71401}) predicted binary labels Counter({0: 70674, 1: 727})\n",
      "Counts of  original  labels: {0: 71401}\n",
      "Counts of misclassified original labels: {0: 727}\n",
      "Test : Accuracy: 0.9898 Recall : 0.0000 FDR: 1.0000  F1-score: 0.0000  \n",
      "********** VAE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0325 std: 0.2283\n",
      "Val: Accuracy: 0.8430  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.2608\n",
      "Counts of : original binary labels Counter({0: 71401}) predicted binary labels Counter({0: 69634, 1: 1767})\n",
      "Counts of  original  labels: {0: 71401}\n",
      "Counts of misclassified original labels: {0: 1767}\n",
      "Test : Accuracy: 0.9753 Recall : 0.0000 FDR: 1.0000  F1-score: 0.0000  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.7173\n",
      "Counts of : original binary labels Counter({0: 71401}) predicted binary labels Counter({0: 70391, 1: 1010})\n",
      "Counts of  original  labels: {0: 71401}\n",
      "Counts of misclassified original labels: {0: 1010}\n",
      "Test : Accuracy: 0.9859 Recall : 0.0000 FDR: 1.0000  F1-score: 0.0000  \n",
      "********** AdversarialAutoencoder **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0056 std: 0.0996\n",
      "Val: Accuracy: 0.9444  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.1051\n",
      "Counts of : original binary labels Counter({0: 71401}) predicted binary labels Counter({0: 70291, 1: 1110})\n",
      "Counts of  original  labels: {0: 71401}\n",
      "Counts of misclassified original labels: {0: 1110}\n",
      "Test : Accuracy: 0.9845 Recall : 0.0000 FDR: 1.0000  F1-score: 0.0000  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.3043\n",
      "Counts of : original binary labels Counter({0: 71401}) predicted binary labels Counter({0: 70628, 1: 773})\n",
      "Counts of  original  labels: {0: 71401}\n",
      "Counts of misclassified original labels: {0: 773}\n",
      "Test : Accuracy: 0.9892 Recall : 0.0000 FDR: 1.0000  F1-score: 0.0000  \n",
      "external\n",
      "exclude 6 ['./ModbusDataset/attack/external/network-wide/ready/network-wide-normal-1-labeled.csv', './ModbusDataset/attack/external/network-wide/ready/network-wide-normal-0-labeled.csv', './ModbusDataset/attack/external/ied4c/ied4c-network-capture/ready/veth8bc3408-0-labeled.csv', './ModbusDataset/attack/external/ied1b/ied1b-network-capture/ready/vethd9e14c0-0-labeled.csv', './ModbusDataset/attack/external/scada-hmi/scada-hmi-network-capture/ready/veth5bbeaa2-0-labeled.csv', './ModbusDataset/attack/external/central-agent/central-agent-network-capture/ready/veth460b141-0-labeled.csv']\n",
      "filtered test files without ied1b 2 ['./ModbusDataset/attack/external/external-attacker/external-attacker-network-capture/ready/veth665f3cf-0-labeled.csv', './ModbusDataset/attack/external/ied1a/ied1a-network-capture/ready/veth4edc015-0-labeled.csv']\n",
      "./ModbusDataset/attack/external/external-attacker/external-attacker-network-capture/ready/veth665f3cf-0-labeled.csv\n",
      "********** AE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0049 std: 0.1301\n",
      "Val: Accuracy: 0.9906  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.1349\n",
      "Counts of : original binary labels Counter({1: 65594, 0: 32}) predicted binary labels Counter({1: 65441, 0: 185})\n",
      "Counts of  original  labels: {0: 32, 1: 65556, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 12, 1: 165}\n",
      "Test : Accuracy: 0.9973 Recall : 0.9975 FDR: 0.0002  F1-score: 0.9986  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.3951\n",
      "Counts of : original binary labels Counter({1: 65594, 0: 32}) predicted binary labels Counter({1: 35905, 0: 29721})\n",
      "Counts of  original  labels: {0: 32, 1: 65556, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2, 1: 29691}\n",
      "Test : Accuracy: 0.5475 Recall : 0.5474 FDR: 0.0001  F1-score: 0.7075  \n",
      "********** VAE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0323 std: 0.2256\n",
      "Val: Accuracy: 0.8424  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.2578\n",
      "Counts of : original binary labels Counter({1: 65594, 0: 32}) predicted binary labels Counter({1: 65473, 0: 153})\n",
      "Counts of  original  labels: {0: 32, 1: 65556, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 32, 1: 153}\n",
      "Test : Accuracy: 0.9972 Recall : 0.9977 FDR: 0.0005  F1-score: 0.9986  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.709\n",
      "Counts of : original binary labels Counter({1: 65594, 0: 32}) predicted binary labels Counter({0: 39492, 1: 26134})\n",
      "Counts of  original  labels: {0: 32, 1: 65556, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 32, 1: 39484, 6: 8}\n",
      "Test : Accuracy: 0.3977 Recall : 0.3979 FDR: 0.0012  F1-score: 0.5691  \n",
      "********** AdversarialAutoencoder **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0056 std: 0.0996\n",
      "Val: Accuracy: 0.9444  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.1051\n",
      "Counts of : original binary labels Counter({1: 65594, 0: 32}) predicted binary labels Counter({1: 65458, 0: 168})\n",
      "Counts of  original  labels: {0: 32, 1: 65556, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 12, 1: 148}\n",
      "Test : Accuracy: 0.9976 Recall : 0.9977 FDR: 0.0002  F1-score: 0.9988  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.3043\n",
      "Counts of : original binary labels Counter({1: 65594, 0: 32}) predicted binary labels Counter({1: 65428, 0: 198})\n",
      "Counts of  original  labels: {0: 32, 1: 65556, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2, 1: 168}\n",
      "Test : Accuracy: 0.9974 Recall : 0.9974 FDR: 0.0000  F1-score: 0.9987  \n",
      "./ModbusDataset/attack/external/ied1a/ied1a-network-capture/ready/veth4edc015-0-labeled.csv\n",
      "********** AE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0049 std: 0.1301\n",
      "Val: Accuracy: 0.9906  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.1349\n",
      "Counts of : original binary labels Counter({1: 65594, 0: 59838}) predicted binary labels Counter({1: 65518, 0: 59914})\n",
      "Counts of  original  labels: {0: 59838, 1: 65556, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 89, 1: 165}\n",
      "Test : Accuracy: 0.9980 Recall : 0.9975 FDR: 0.0014  F1-score: 0.9981  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.3951\n",
      "Counts of : original binary labels Counter({1: 65594, 0: 59838}) predicted binary labels Counter({0: 89325, 1: 36107})\n",
      "Counts of  original  labels: {0: 59838, 1: 65556, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 55, 1: 29542}\n",
      "Test : Accuracy: 0.7640 Recall : 0.5496 FDR: 0.0015  F1-score: 0.7090  \n",
      "********** VAE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0322 std: 0.2248\n",
      "Val: Accuracy: 0.8423  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.257\n",
      "Counts of : original binary labels Counter({1: 65594, 0: 59838}) predicted binary labels Counter({1: 66065, 0: 59367})\n",
      "Counts of  original  labels: {0: 59838, 1: 65556, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 625, 1: 154}\n",
      "Test : Accuracy: 0.9938 Recall : 0.9977 FDR: 0.0095  F1-score: 0.9941  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.7066\n",
      "Counts of : original binary labels Counter({1: 65594, 0: 59838}) predicted binary labels Counter({0: 99017, 1: 26415})\n",
      "Counts of  original  labels: {0: 59838, 1: 65556, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 311, 1: 39482, 6: 8}\n",
      "Test : Accuracy: 0.6827 Recall : 0.3980 FDR: 0.0118  F1-score: 0.5674  \n",
      "********** AdversarialAutoencoder **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0056 std: 0.0996\n",
      "Val: Accuracy: 0.9444  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.1051\n",
      "Counts of : original binary labels Counter({1: 65594, 0: 59838}) predicted binary labels Counter({1: 65618, 0: 59814})\n",
      "Counts of  original  labels: {0: 59838, 1: 65556, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 165, 1: 141}\n",
      "Test : Accuracy: 0.9976 Recall : 0.9979 FDR: 0.0025  F1-score: 0.9977  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.3043\n",
      "Counts of : original binary labels Counter({1: 65594, 0: 59838}) predicted binary labels Counter({1: 65498, 0: 59934})\n",
      "Counts of  original  labels: {0: 59838, 1: 65556, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 69, 1: 165}\n",
      "Test : Accuracy: 0.9981 Recall : 0.9975 FDR: 0.0011  F1-score: 0.9982  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "## TEST RESULTS WITHOUT IED1B TRAFFIC\n",
    "modbus = ModbusDataset(dataset_directory,\"ready\")\n",
    "\n",
    "for scenario in {\"external\",\"compromised-scada\"}:\n",
    "\n",
    "    print(scenario)\n",
    "    test_files=modbus.dataset[\"attack_dataset_dir\"][scenario]\n",
    "    nodes_to_exclude = [\n",
    "    \"ied1b\",\n",
    "    \"network-wide\",\n",
    "    \"substation-wide-capture\",\n",
    "    \"scada-hmi-network-capture\",\n",
    "    \"trust-scada-hmi\",\n",
    "    \"central-agent\",\n",
    "    \"ied4c\"\n",
    "    ]\n",
    "    exclude = [col for col in test_files if any(node in col for node in nodes_to_exclude)]\n",
    "    [test_files.remove(c) for c in exclude if c in test_files]\n",
    "    print(\"exclude\",len(exclude),exclude)\n",
    "    print(\"filtered test files without ied1b\",len(test_files),test_files)\n",
    "    for test_file in test_files: \n",
    "        print(test_file)\n",
    "        val_dataloader=DataLoader(ModbusFlowStream(\n",
    "                    shuffle=False,\n",
    "                    chunk_size=1,\n",
    "                    batch_size=64,\n",
    "                    csv_files=val_files,\n",
    "                    scalers=loaded_scalers['network-wide']['min_max_scalers'],\n",
    "                ),batch_size=1,shuffle=False)\n",
    "        test_dataloader=DataLoader(ModbusFlowStream(\n",
    "                    shuffle=False,\n",
    "                    chunk_size=1,\n",
    "                    batch_size=64,\n",
    "                    csv_files=[test_file],\n",
    "                    scalers=loaded_scalers['network-wide']['min_max_scalers'],\n",
    "                ),batch_size=1,shuffle=False)\n",
    "        for trained_model in {Trained_AE_model,Trained_VAE_model,Trained_AAE_model}:\n",
    "            print(\"*\"*10,trained_model._get_name(),10*\"*\")\n",
    "            train_eval(trained_model,None,val_dataloader,test_dataloader,shuffle_files=False,num_epochs=1,eval_epoch=1,criterion_method=\"mse\",train_model=False,learning_rates=[0],weight_decays=[0])\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e10197",
   "metadata": {},
   "source": [
    "### Part b: Federated learning \n",
    "####  non iid distribution of dataset (ip\\node based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f948763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 1. SETUP: INSTALL LIBRARIES AND IMPORT DEPENDENCIES\n",
    "# ==============================================================================\n",
    "# In a Kaggle notebook, run this cell first to install the necessary libraries.\n",
    "# !pip install -q flwr[simulation] torch torchvision pandas scikit-learn matplotlib seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc049d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from collections import OrderedDict\n",
    "from typing import Dict, List, Tuple, Optional , Union\n",
    "import os \n",
    "import flwr as fl\n",
    "import ray\n",
    "from flwr.common import FitRes, Scalar,Context, ndarrays_to_parameters, parameters_to_ndarrays\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "\n",
    "import random\n",
    "\n",
    "# Suppress warning messages for a cleaner output\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "# Set a seed for reproducibility\n",
    "SEED = 20\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "#global device\n",
    "dataset_directory = \"./ModbusDataset/\" \n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on {DEVICE}\")\n",
    "modbus = ModbusDataset(dataset_directory,\"ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e80a446",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================================================================\n",
    "#  FEDERATED LEARNING CLIENT: FlowerClient\n",
    "# ==============================================================================\n",
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    \"\"\"Flower client for training.\"\"\"\n",
    "    def __init__(self, cid, model, trainloader,valloader):\n",
    "        self.cid = cid\n",
    "        self.model = model\n",
    "        self.train_dataloader = trainloader\n",
    "        self.val_dataloader = valloader\n",
    "    def get_parameters(self, config):\n",
    "        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n",
    "\n",
    "    def set_parameters(self, parameters):\n",
    "        params_dict = zip(self.model.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "        self.model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        model =self.model\n",
    "        lr = cfg.LEARNING_RATE\n",
    "        wd= cfg.WEIGHT_DECAY\n",
    "        \n",
    "        criterion = nn.MSELoss(reduction='sum').to(DEVICE)\n",
    "        if model._get_name()==\"AdversarialAutoencoder\":\n",
    "            adversarial_criterion= nn.BCELoss(reduction=\"sum\")\n",
    "            optimizer_D = optim.Adam(model.discriminator.parameters(), lr=lr, weight_decay=wd)\n",
    "            optimizer_G =  optim.Adam(list(model.encoder.parameters()) + list(model.decoder.parameters()), lr=lr, weight_decay=wd)\n",
    "        else:\n",
    "            AE_optimizer = optim.Adam(model.parameters(), lr=lr,weight_decay=wd)\n",
    "\n",
    "        if cfg.STRATEGY == \"FED_PROX\":\n",
    "            global_params_dict = {\n",
    "                k: torch.tensor(v, device=DEVICE) \n",
    "                for k, v in zip(self.model.state_dict().keys(), parameters)\n",
    "            }\n",
    "\n",
    "        for epoch in range(cfg.LOCAL_EPOCHS):\n",
    "            time_1 = time.time()\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            ## for AAE\n",
    "            Discriminator_loss = 0\n",
    "            for sequences, _ in self.train_dataloader:\n",
    "                sequences=sequences.squeeze().to(DEVICE)\n",
    "                if model._get_name()==\"AdversarialAutoencoder\":\n",
    "                    target_ones= torch.ones(sequences.size(0), 1,device=DEVICE,dtype=torch.float)\n",
    "                    target_zeros= torch.zeros(sequences.size(0), 1,device=DEVICE,dtype=torch.float)\n",
    "                    random_latent = torch.randn(sequences.size(0), 2, device=DEVICE)\n",
    "                    optimizer_G.zero_grad()\n",
    "                    fake_z,decoded_seq = model(sequences)\n",
    "                    G_loss = 0.001*adversarial_criterion(model.discriminator(fake_z),target_ones ) + 0.999*criterion(decoded_seq, sequences)\n",
    "                    if cfg.STRATEGY == \"FED_PROX\":\n",
    "                        proximal_term_G = 0.0\n",
    "                        # Proximal term for ENCODER\n",
    "                        for name, local_param in model.encoder.named_parameters():\n",
    "                            global_param = global_params_dict['encoder.' + name]\n",
    "                            proximal_term_G += torch.pow((local_param - global_param).norm(2), 2)\n",
    "                        # Proximal term for DECODER\n",
    "                        for name, local_param in model.decoder.named_parameters():\n",
    "                            global_param = global_params_dict['decoder.' + name]\n",
    "                            proximal_term_G += torch.pow((local_param - global_param).norm(2), 2)\n",
    "                        \n",
    "                        G_loss += (cfg.PROXIMAL_MU / 2) * proximal_term_G\n",
    "                    G_loss.backward()\n",
    "                    optimizer_G.step()\n",
    "                    # 2) discriminator loss\n",
    "                    optimizer_D.zero_grad()\n",
    "                    real_loss = adversarial_criterion(model.discriminator(random_latent), target_ones)\n",
    "                    fake_loss = adversarial_criterion(model.discriminator(fake_z.detach()),  target_zeros)\n",
    "                    D_loss =  0.5*(real_loss + fake_loss)\n",
    "                    if cfg.STRATEGY == \"FED_PROX\":\n",
    "                        proximal_term_D = 0.0\n",
    "                        # Proximal term for DISCRIMINATOR\n",
    "                        for name, local_param in model.discriminator.named_parameters():\n",
    "                            global_param = global_params_dict['discriminator.' + name]\n",
    "                            proximal_term_D += torch.pow((local_param - global_param).norm(2), 2)\n",
    "                        D_loss += (cfg.PROXIMAL_MU / 2) * proximal_term_D\n",
    "            \n",
    "                    D_loss.backward()\n",
    "                    optimizer_D.step()\n",
    "                    train_loss+=G_loss.item()\n",
    "                    Discriminator_loss+=D_loss.item()   \n",
    "                else:\n",
    "                    AE_optimizer.zero_grad()\n",
    "                    if model._get_name()==\"AE\":\n",
    "                        recon = model(sequences)\n",
    "                        loss = criterion(recon, sequences) / sequences.size(0)\n",
    "                    elif model._get_name()==\"VAE\" :\n",
    "                        recon, mu, logvar = model(sequences)\n",
    "                        loss = vae_loss_function(recon, sequences, mu, logvar) /sequences.size(0)\n",
    "                    \n",
    "                    if cfg.STRATEGY == \"FED_PROX\":\n",
    "                        proximal_term = 0.0\n",
    "                        for name, local_param in model.encoder.named_parameters():\n",
    "                            global_param = global_params_dict['encoder.' + name]\n",
    "                            proximal_term += torch.pow((local_param - global_param).norm(2), 2)\n",
    "                        # Proximal term for DECODER\n",
    "                        for name, local_param in model.decoder.named_parameters():\n",
    "                            global_param = global_params_dict['decoder.' + name]\n",
    "                            proximal_term += torch.pow((local_param - global_param).norm(2), 2)\n",
    "                        loss+= (cfg.PROXIMAL_MU / 2) *proximal_term\n",
    "                    loss.backward()\n",
    "                    AE_optimizer.step()\n",
    "                    train_loss += loss.item()\n",
    "            print(f\"Train : time {(time.time()-time_1):.2f} s\",\n",
    "            f\"Epoch {epoch+1}\")\n",
    "            num_samples=len(self.train_dataloader)\n",
    "            if model._get_name()==\"AdversarialAutoencoder\":\n",
    "                print(f\"Generator Loss: {train_loss / num_samples:.4f}\",\n",
    "                    f\"Discriminator Loss: {Discriminator_loss / num_samples:.4f}\")\n",
    "            else:\n",
    "                print(f\"Train Loss: {train_loss / num_samples:.4f}\")\n",
    "        local_threshold,len_val_samples=self._calculate_threshold()\n",
    "        metrics = {\"threshold\": local_threshold,\"len\": len_val_samples}\n",
    "        return self.get_parameters(config={}), num_samples, metrics\n",
    "\n",
    "    def _calculate_threshold(self):\n",
    "        model = self.model\n",
    "        model.to(DEVICE)\n",
    "        model.eval()\n",
    "        eval_criterion = nn.MSELoss(reduction='none').to(DEVICE)\n",
    "\n",
    "        # Evaluate part\n",
    "        all_val_losses = []\n",
    "        all_val_labels = []\n",
    "        with torch.no_grad():\n",
    "            for sequences, labels in self.val_dataloader:\n",
    "                sequences = sequences.squeeze().to(DEVICE) \n",
    "                if model._get_name()==\"AE\":\n",
    "                    recon = model(sequences)\n",
    "                elif model._get_name()==\"VAE\" :\n",
    "                    recon, _, _ = model(sequences)\n",
    "                elif model._get_name()==\"AdversarialAutoencoder\":\n",
    "                    _,recon= model(sequences)\n",
    "                val_loss = eval_criterion(recon, sequences)\n",
    "                if val_loss.dim() > 1:\n",
    "                    val_loss = val_loss\n",
    "                else:\n",
    "                    val_loss = val_loss.unsqueeze(dim=0)\n",
    "                    labels = labels.unsqueeze(dim=0)\n",
    "                val_loss = val_loss.sum(dim=1)\n",
    "                all_val_losses.extend(val_loss.cpu().numpy())\n",
    "                all_val_labels.extend(labels.flatten().cpu().numpy())     \n",
    "        threshold_1,std_mse = compute_threshold(all_val_losses,k=1)\n",
    "        all_val_losses = np.array(all_val_losses).squeeze()  \n",
    "        all_val_labels = np.array(all_val_labels).squeeze()  \n",
    "        # If intrusion score > threshold, predict 1 (intrusion), else 0 (benign)\n",
    "        # For FDR, get True Positives (TP) and False Positives (FP)\n",
    "        \n",
    "        predictions = (all_val_losses > threshold_1).astype(int)\n",
    "        accuracy = accuracy_score(all_val_labels, predictions)\n",
    "        print(f\"Val: Accuracy: {accuracy:.4f}  \")\n",
    "        return threshold_1,len(all_val_losses)\n",
    "    def evaluate(self, parameters, config):\n",
    "        #focuses on server-side evaluation, so we can keep this simple\n",
    "        return 0.0, 0, {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "147c51d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedAnomalyStrategy(fl.server.strategy.FedAvg):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.aggregated_threshold: Optional[float] = None\n",
    "\n",
    "    def aggregate_fit(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, FitRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
    "    ) -> Tuple[Optional[fl.common.Parameters], Dict[str, Scalar]]:\n",
    "        \n",
    "        aggregated_parameters, _ = super().aggregate_fit(server_round, results, failures)\n",
    "        candidates = [\n",
    "            (res.metrics[\"threshold\"],res.metrics[\"len\"]) for _, res in results if \"threshold\" in res.metrics\n",
    "        ]\n",
    "        if candidates:\n",
    "            threholds=np.array([pair[0] for pair in candidates],dtype=float)\n",
    "            weights=np.array([pair[1] for pair in candidates],dtype=int)\n",
    "\n",
    "            self.aggregated_threshold = np.average(threholds,weights=weights)\n",
    "            print(f\"Round {server_round}: Aggregated threshold = {self.aggregated_threshold:.4f}\")\n",
    "        else:\n",
    "            print(\"Warning: No thresholds received from clients.\")\n",
    "        return aggregated_parameters, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "34efffc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================================================================\n",
    "#  SERVER-SIDE LOGIC AND SIMULATION START\n",
    "# ==============================================================================\n",
    "\n",
    "def client_function(context:Context ) -> FlowerClient:\n",
    "    client_id = int(context.node_config[\"partition-id\"])\n",
    "    trainloader = load_data_from_id(client_id,\"client\",chunk_size=1)\n",
    "    valloader = load_data_from_id(client_id,\"server\",chunk_size=1)\n",
    "    model = get_model().to(DEVICE)\n",
    "    return FlowerClient(client_id, model, trainloader,valloader).to_client()\n",
    "\n",
    "def make_client_fn_with_cache(chunk_size=10000):\n",
    "    print(\"...\")\n",
    "    dataloader_cache: Dict[str, DataLoader] = {}\n",
    "    def client_fn(context:Context ) -> FlowerClient:\n",
    "        client_id = int(context.node_config[\"partition-id\"])\n",
    "        if client_id not in dataloader_cache:\n",
    "            # If not, create it once and store it in the cache\n",
    "            print(f\"Round 1: Loading and caching data for client {client_id}...\")\n",
    "            dataloader_cache[client_id] = load_data_from_id(client_id,\"client\",chunk_size=chunk_size)\n",
    "        else:\n",
    "            print(f\"Reusing cached dataloader for client {client_id}...\")\n",
    "        trainloader = dataloader_cache[client_id]\n",
    "        model = get_model().to(DEVICE)\n",
    "        return FlowerClient(client_id, model, trainloader).to_client()\n",
    "    return client_fn\n",
    "\n",
    "\n",
    "def get_evaluate_fn(model, test_dataloader, strategy: FedAnomalyStrategy):\n",
    "    \"\"\"Return an evaluation function for server-side evaluation with caching \"\"\"\n",
    "    eval_criterion = nn.MSELoss(reduction='none').to(DEVICE)\n",
    "    best_f1=0\n",
    "    best_recall=0\n",
    "    def evaluate(\n",
    "        server_round: int,\n",
    "        parameters: fl.common.NDArrays,\n",
    "        config: Dict[str, fl.common.Scalar],\n",
    "        train_model=True\n",
    "    ) -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:\n",
    "        nonlocal best_f1,best_recall\n",
    "        params_dict = zip(model.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "        model.load_state_dict(state_dict, strict=True)\n",
    "        model.to(DEVICE)\n",
    "        model.eval()\n",
    "        all_test_losses = []\n",
    "        all_test_labels = []\n",
    "        temp_best_recall =best_recall\n",
    "        temp_best_f1 =best_f1\n",
    "        with torch.no_grad():\n",
    "            for sequences, labels in test_dataloader:\n",
    "                sequences = sequences.squeeze().to(DEVICE)\n",
    "                labels = labels.squeeze().to(DEVICE)\n",
    "                if model._get_name()==\"AE\":\n",
    "                    recon = model(sequences)\n",
    "                elif model._get_name()==\"VAE\" :\n",
    "                    recon, mu, logvar = model(sequences)\n",
    "                elif model._get_name()==\"AdversarialAutoencoder\":\n",
    "                    _,recon= model(sequences)\n",
    "\n",
    "                intrusion_scores = eval_criterion(recon, sequences)\n",
    "                if intrusion_scores.dim() > 1:\n",
    "                    intrusion_scores = intrusion_scores\n",
    "                else:\n",
    "                    intrusion_scores = intrusion_scores.unsqueeze(dim=0)\n",
    "                    labels = labels.unsqueeze(dim=0)\n",
    "                if intrusion_scores.dim()==3:\n",
    "                    ##GRU : mean of window\n",
    "                    intrusion_scores = intrusion_scores.mean(dim=1)\n",
    "                intrusion_scores = intrusion_scores.sum(dim=1)\n",
    "                all_test_losses.extend(intrusion_scores.cpu().numpy())\n",
    "                all_test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        all_test_losses = np.array(all_test_losses)\n",
    "        all_test_labels = np.array(all_test_labels)\n",
    "        if strategy.aggregated_threshold is None:\n",
    "            # Threshold not available yet (e.g., round 0)\n",
    "            threshold=0\n",
    "        else:\n",
    "            threshold = strategy.aggregated_threshold\n",
    "        test_result = {}\n",
    "\n",
    "        predictions = (all_test_losses > threshold).astype(int)\n",
    "        binary_test_labels = (all_test_labels != 0).astype(int)\n",
    "\n",
    "        # Find the indices where the prediction was incorrect\n",
    "        misclassified_indices = np.where(binary_test_labels != predictions)[0]\n",
    "\n",
    "        # Get the original labels for those misclassified instances\n",
    "        misclassified_original_labels = all_test_labels[misclassified_indices]\n",
    "\n",
    "        # To get a summary count of which labels were misclassified\n",
    "        print(\"Counts of : original binary labels\",Counter(binary_test_labels),\"predicted binary labels\",Counter(predictions))\n",
    "        print(f\"Counts of  original  labels: {dict(sorted(Counter(all_test_labels).items()))}\")\n",
    "        print(f\"Counts of misclassified original labels: {dict(sorted(Counter(misclassified_original_labels).items()))}\")\n",
    "        accuracy = accuracy_score(binary_test_labels, predictions)\n",
    "        f1 = f1_score(binary_test_labels, predictions, zero_division=0)\n",
    "        recall = recall_score(binary_test_labels, predictions,zero_division=0)\n",
    "        _, fp, _, tp = confusion_matrix(binary_test_labels, predictions, labels=[0, 1]).ravel()\n",
    "        # FDR = FP / (FP + TP) \n",
    "        if (fp + tp) == 0:\n",
    "            fdr = 0.0 \n",
    "        else:\n",
    "            fdr = fp / (fp + tp)\n",
    "        test_result[0] = f\"threshold={threshold:.4f} ,Test : Accuracy: {accuracy:.4f} Recall : {recall:.4f} FDR: {fdr:.4f}  F1-score: {f1:.4f} \"\n",
    "        print(test_result)\n",
    "        !mkdir fed_best_models -p\n",
    "        if f1>best_f1 :\n",
    "            best_f1=f1\n",
    "        if recall>best_recall:\n",
    "            best_recall=recall\n",
    "        if ((best_recall>temp_best_recall or best_f1 > temp_best_f1) and not(strategy.aggregated_threshold is None)):\n",
    "            if train_model:\n",
    "                save_path =\"fed_best_models/\"+cfg.STRATEGY+\"_\"+model._get_name()+\"_f1_\"+f\"{best_f1:.2f}\" +\"_recall_\"+f\"{best_recall:.2f}\" +\"_.pth\"\n",
    "                torch.save(model.state_dict(),save_path)\n",
    "                print(\"model\",model._get_name(),\"is saved in\" ,save_path )\n",
    "        return np.sum(all_test_losses)/len(all_test_losses),test_result\n",
    "\n",
    "    return evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d0340aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_initial_parameters(model_name: str):\n",
    "    \"\"\"\n",
    "    Initializes the model weights using Xavier uniform distribution\n",
    "    and returns them as a Flower Parameters object.\n",
    "    \"\"\"\n",
    "    \n",
    "    temp_model = get_model()\n",
    "    for param in temp_model.parameters():\n",
    "        if param.dim() > 1:\n",
    "            nn.init.xavier_uniform_(param)\n",
    "            \n",
    "    ndarrays = [val.cpu().numpy() for _, val in temp_model.state_dict().items()]\n",
    "    return ndarrays_to_parameters(ndarrays)\n",
    "\n",
    "\n",
    "def load_data_from_id(id: int, node = \"client\" ,chunk_size=10000):\n",
    "    \"\"\"Loads the data for a specific training client.\"\"\"\n",
    "    if node == \"client\":\n",
    "        file_list = TRAIN_CLIENT_DATA_MAPPING[id]\n",
    "        shuffle=cfg.SHUFFLE_FILES\n",
    "    else: # server\n",
    "        file_list = SERVER_EVALUATION_DATA_MAPPING[id]\n",
    "        shuffle = False\n",
    "    ## means load all chunks of data in memory at once \n",
    "    if chunk_size==10000:\n",
    "        train_loader=DataLoader(ModbusFlowStream(\n",
    "                shuffle=False,\n",
    "                chunk_size=chunk_size,\n",
    "                batch_size=1 ,\n",
    "                csv_files=file_list,\n",
    "                scalers=loaded_scalers['network-wide']['min_max_scalers'],\n",
    "            ),batch_size=64,shuffle=shuffle)\n",
    "    else :\n",
    "        train_loader=DataLoader(ModbusFlowStream(\n",
    "                shuffle=shuffle,\n",
    "                chunk_size=chunk_size,\n",
    "                batch_size=cfg.BATCH_SIZE ,\n",
    "                csv_files=file_list,\n",
    "                scalers=loaded_scalers['network-wide']['min_max_scalers'],\n",
    "            ),batch_size=1,shuffle=False)\n",
    "    return train_loader\n",
    "\n",
    "def get_model():\n",
    "    \"\"\"Returns the model specified in the config.\"\"\"\n",
    "    if cfg.MODEL_NAME == \"VAE\":\n",
    "        return VAE(input_dim=cfg.INPUT_DIM)\n",
    "    elif cfg.MODEL_NAME == \"AE\":\n",
    "        return AE(input_dim=cfg.INPUT_DIM)\n",
    "    elif cfg.MODEL_NAME ==\"AAE\":\n",
    "        return AdversarialAutoencoder()#76\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model name: {cfg.MODEL_NAME}. Choose 'AE' or 'VAE' or 'AAE'.\")\n",
    "\n",
    "def set_server_strategy():\n",
    "    if cfg.STRATEGY == \"FED_PROX\":\n",
    "        print(f\"Using FedProx strategy with {cfg.MODEL_NAME} model.\")\n",
    "    else:\n",
    "        print(f\"Using FedAvg strategy with {cfg.MODEL_NAME} model.\")\n",
    "    strategy = FedAnomalyStrategy(\n",
    "        fraction_fit=1.0,\n",
    "        fraction_evaluate=0.0,\n",
    "        min_fit_clients=cfg.NUM_TRAIN_CLIENTS,\n",
    "        min_available_clients=cfg.NUM_TRAIN_CLIENTS,\n",
    "        min_evaluate_clients=0,\n",
    "        initial_parameters=get_initial_parameters(cfg.MODEL_NAME)\n",
    "    )\n",
    "    model = get_model().to(DEVICE)\n",
    "    testloader = load_data_from_id(-1,\"server\",chunk_size=1)\n",
    "    evaluate_function = get_evaluate_fn(model, testloader, strategy)\n",
    "    strategy.evaluate_fn=evaluate_function\n",
    "    return strategy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bc0e13",
   "metadata": {},
   "source": [
    "#### test on compromised scada attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3219b1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_ 1 train: 4 ['./ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-27-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-29-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-20-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-19-labeled.csv']\n",
      "node_ 1 val: 1 ['./ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-15-labeled.csv']\n",
      "node_ 2 train: 4 ['./ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-14-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-28-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-31-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-16-labeled.csv']\n",
      "node_ 2 val: 1 ['./ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-30-labeled.csv']\n",
      "node_ 3 train: 4 ['./ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-32-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-24-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-25-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-26-labeled.csv']\n",
      "node_ 3 val: 1 ['./ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-23-labeled.csv']\n",
      "node_ 4 train: 3 ['./ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-21-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-17-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-22-labeled.csv']\n",
      "node_ 4 val: 1 ['./ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-18-labeled.csv']\n",
      "test 2 ['./ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-7-labeled.csv', './ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-3-labeled.csv']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # ==============================================================================\n",
    "# #  DATA Distribution\n",
    "# # ==============================================================================\n",
    "\n",
    "\n",
    "SEED=20\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "network_train_files=[col for col in modbus.dataset[\"benign_dataset_dir\"] if col.find(\"network-wide\")!=-1][:]\n",
    "test_files= [col for col in modbus.dataset[\"attack_dataset_dir\"][\"compromised-scada\"] if col.find(\"ied1b\")!=-1]\n",
    "### missed attack logs files for the day 21 for ied1b which can reduce the accuracy.\n",
    "test_files.remove(dataset_directory+\"attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-6-labeled.csv\")\n",
    "\n",
    "random.shuffle(network_train_files)\n",
    "random.shuffle(test_files)\n",
    "\n",
    "num_splits = 4\n",
    "train_files = list(np.array_split(network_train_files, num_splits))\n",
    "\n",
    "SERVER_EVALUATION_DATA_MAPPING = [list(traffic_file[-1:]) for traffic_file in train_files ]\n",
    "SERVER_EVALUATION_DATA_MAPPING.extend([test_files[:2]])\n",
    "TRAIN_CLIENT_DATA_MAPPING = [list(traffic_file[:-1]) for traffic_file in train_files ]\n",
    "\n",
    "for i in range(num_splits):\n",
    "    print(\"node_\",i+1,\"train:\",len(TRAIN_CLIENT_DATA_MAPPING[i]),TRAIN_CLIENT_DATA_MAPPING[i])\n",
    "    print(\"node_\",i+1,\"val:\",len(SERVER_EVALUATION_DATA_MAPPING[i]),SERVER_EVALUATION_DATA_MAPPING[i])\n",
    "\n",
    "print(\"test\",len(SERVER_EVALUATION_DATA_MAPPING[-1]),SERVER_EVALUATION_DATA_MAPPING[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "69c2c487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded scalers for 'network-wide'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==============================================================================\n",
    "#  CONFIGURATION: TWEAK  FEDERATED LEARNING EXPERIMENT\n",
    "# ==============================================================================\n",
    "class Config:\n",
    "    \"\"\"Global configuration class for the federated learning experiment.\"\"\"\n",
    "    # --- FL Parameters ---\n",
    "    NUM_TRAIN_CLIENTS = num_splits\n",
    "    NUM_ROUNDS = 10\n",
    "    LOCAL_EPOCHS = 2\n",
    "    BATCH_SIZE = 64\n",
    "    LEARNING_RATE = 1e-3\n",
    "    WEIGHT_DECAY = 1e-5\n",
    "    \n",
    "    # --- Strategy Selection ---\n",
    "    # Choose from \"FED_AVG\", \"FED_PROX\"\n",
    "    STRATEGY = \"FED_AVG\" \n",
    "    PROXIMAL_MU = 1e-2 # Proximal term for FedProx\n",
    "    # --- Model Selection ---\n",
    "    # Choose from \"AE\" (Autoencoder) or \"VAE\" (Variational Autoencoder) or \"AdverserialAutoencoder\"\n",
    "    MODEL_NAME = \"AE\"\n",
    "    INPUT_DIM = 76\n",
    "    # --- Anomaly Detection ---\n",
    "    SHUFFLE_FILES=  True\n",
    "# Instantiate the configuration\n",
    "cfg = Config()\n",
    "\n",
    "loaded_scalers = load_scalers(\"fitted_scalers\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dde2ad73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## cache all client data in memory\n",
    "# client_fn=make_client_fn_with_cache()\n",
    "\n",
    "# for i in range(3):\n",
    "#     context= Context(0,i,{},0,0)\n",
    "#     context.node_config[\"partition-id\"]=i\n",
    "#     client_fn(context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "df19ac4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using FedAvg strategy with AE model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n",
      "\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n",
      "\n",
      "\t\t$ flwr new  # Create a new Flower app from a template\n",
      "\n",
      "\t\t$ flwr run  # Run the Flower app in Simulation Mode\n",
      "\n",
      "\tUsing `start_simulation()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=10, no round_timeout\n",
      "2025-07-28 00:06:10,283\tINFO worker.py:1771 -- Started a local Ray instance.\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'accelerator_type:G': 1.0, 'node:__internal_head__': 1.0, 'CPU': 2.0, 'memory': 2785542144.0, 'object_store_memory': 1392771072.0, 'GPU': 1.0, 'node:172.24.78.91': 1.0}\n",
      "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 1}\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 1 actors\n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of : original binary labels Counter({0: 97486, 1: 41564}) predicted binary labels Counter({1: 139050})\n",
      "Counts of  original  labels: {0: 97486, 1: 41306, 2: 59, 3: 40, 4: 55, 5: 40, 6: 36, 7: 28}\n",
      "Counts of misclassified original labels: {0: 97486}\n",
      "{0: 'threshold=0.0000 ,Test : Accuracy: 0.2989 Recall : 1.0000 FDR: 0.7011  F1-score: 0.4603 '}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 17.23868932038835, {0: 'threshold=0.0000 ,Test : Accuracy: 0.2989 Recall : 1.0000 FDR: 0.7011  F1-score: 0.4603 '}\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=313681)\u001b[0m Train : time 42.54 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=313681)\u001b[0m Train Loss: 0.7803\n",
      "\u001b[36m(ClientAppActor pid=313681)\u001b[0m Train : time 30.56 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=313681)\u001b[0m Train Loss: 0.1295\n",
      "\u001b[36m(ClientAppActor pid=313681)\u001b[0m -----------mse_loss mean :  0.0417 std: 0.4311\n",
      "\u001b[36m(ClientAppActor pid=313681)\u001b[0m Val: Accuracy: 0.9926  \n",
      "\u001b[36m(ClientAppActor pid=313681)\u001b[0m Train : time 46.75 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=313681)\u001b[0m Train Loss: 0.6489\n",
      "\u001b[36m(ClientAppActor pid=313681)\u001b[0m Train : time 46.29 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=313681)\u001b[0m Train Loss: 0.0286\n",
      "\u001b[36m(ClientAppActor pid=313681)\u001b[0m -----------mse_loss mean :  0.0161 std: 0.2168\n",
      "\u001b[36m(ClientAppActor pid=313681)\u001b[0m Val: Accuracy: 0.9944  \n",
      "\u001b[36m(ClientAppActor pid=313681)\u001b[0m Train : time 49.80 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=313681)\u001b[0m Train Loss: 0.2919\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*DEPRECATED FEATURE: flwr.simulation.start_simulation.*\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "strategy=set_server_strategy()\n",
    "\n",
    "\n",
    "history = fl.simulation.start_simulation(\n",
    "    client_fn=client_function,\n",
    "    num_clients=cfg.NUM_TRAIN_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=cfg.NUM_ROUNDS),\n",
    "    strategy=strategy,\n",
    "    client_resources={\"num_cpus\": 1, \"num_gpus\": 1} if DEVICE.type == \"cuda\" else {\"num_cpus\": 1},\n",
    ")\n",
    "print(\"Federated learning simulation finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5f6d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n",
      "\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n",
      "\n",
      "\t\t$ flwr new  # Create a new Flower app from a template\n",
      "\n",
      "\t\t$ flwr run  # Run the Flower app in Simulation Mode\n",
      "\n",
      "\tUsing `start_simulation()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=5, no round_timeout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using FedProx strategy with AE model.\n",
      "Starting federated learning simulation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-26 23:34:59,298\tINFO worker.py:1771 -- Started a local Ray instance.\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'accelerator_type:G': 1.0, 'node:__internal_head__': 1.0, 'CPU': 2.0, 'object_store_memory': 1709929267.0, 'memory': 3419858535.0, 'GPU': 1.0, 'node:172.24.78.91': 1.0}\n",
      "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 1}\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 1 actors\n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of : original binary labels Counter({0: 156058, 1: 65271}) predicted binary labels Counter({1: 221329})\n",
      "Counts of  original  labels: {0: 156058, 1: 65233, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 156058}\n",
      "{0: 'threshold=0.0000 ,Test : Accuracy: 0.2949 Recall : 1.0000 FDR: 0.7051  F1-score: 0.4555 '}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 16.93721112009723, {0: 'threshold=0.0000 ,Test : Accuracy: 0.2949 Recall : 1.0000 FDR: 0.7051  F1-score: 0.4555 '}\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 73.86 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.4775\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 75.82 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.1543\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 72.74 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.1531\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m -----------mse_loss mean :  0.0408 std: 0.3339\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Val: Accuracy: 0.9929  \n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 77.81 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.4767\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 72.74 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.1574\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 74.83 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.1562\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m -----------mse_loss mean :  0.0415 std: 0.3669\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Val: Accuracy: 0.9944  \n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 63.06 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.5102\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 63.88 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.1526\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 63.46 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.1513\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m -----------mse_loss mean :  0.0345 std: 0.3107\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Val: Accuracy: 0.9954  \n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 55.42 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.4401\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 55.17 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.1440\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 55.07 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.1410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m -----------mse_loss mean :  0.0344 std: 0.3227\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Val: Accuracy: 0.9932  \n",
      "Round 1: Aggregated threshold = 0.3713\n",
      "Counts of : original binary labels Counter({0: 156058, 1: 65271}) predicted binary labels Counter({0: 134173, 1: 87156})\n",
      "Counts of  original  labels: {0: 156058, 1: 65233, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 22038, 1: 153}\n",
      "{0: 'threshold=0.3713 ,Test : Accuracy: 0.8997 Recall : 0.9977 FDR: 0.2529  F1-score: 0.8544 '}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (1, 0.6500179032119605, {0: 'threshold=0.3713 ,Test : Accuracy: 0.8997 Recall : 0.9977 FDR: 0.2529  F1-score: 0.8544 '}, 906.6179958290004)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model AE is saved in fed_best_models/FED_PROX_AE_f1_0.85_recall_1.00_.pth\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 73.12 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0327\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 74.16 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0315\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 70.83 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0314\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m -----------mse_loss mean :  0.0246 std: 0.2598\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Val: Accuracy: 0.9928  \n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 54.80 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0331\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 56.85 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0314\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 54.40 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0314\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m -----------mse_loss mean :  0.0237 std: 0.2312\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Val: Accuracy: 0.9931  \n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 71.74 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0317\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 71.58 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0305\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 74.56 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0303\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m -----------mse_loss mean :  0.0225 std: 0.2504\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Val: Accuracy: 0.9944  \n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 60.96 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0322\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 63.52 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0309\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 62.17 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 2: Aggregated threshold = 0.2641\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m -----------mse_loss mean :  0.0204 std: 0.2236\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Val: Accuracy: 0.9953  \n",
      "Counts of : original binary labels Counter({0: 156058, 1: 65271}) predicted binary labels Counter({0: 155269, 1: 66060})\n",
      "Counts of  original  labels: {0: 156058, 1: 65233, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 954, 1: 165}\n",
      "{0: 'threshold=0.2641 ,Test : Accuracy: 0.9949 Recall : 0.9975 FDR: 0.0144  F1-score: 0.9915 '}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (2, 0.4974349201302134, {0: 'threshold=0.2641 ,Test : Accuracy: 0.9949 Recall : 0.9975 FDR: 0.0144  F1-score: 0.9915 '}, 1794.9931981460004)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model AE is saved in fed_best_models/FED_PROX_AE_f1_0.99_recall_1.00_.pth\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 72.01 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0205\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 75.21 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0202\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 77.52 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0201\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m -----------mse_loss mean :  0.0175 std: 0.1873\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Val: Accuracy: 0.9928  \n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 58.85 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0201\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 58.96 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0196\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 58.11 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0195\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m -----------mse_loss mean :  0.0183 std: 0.1841\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Val: Accuracy: 0.9931  \n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 75.17 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0194\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 74.70 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0190\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 73.20 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0189\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m -----------mse_loss mean :  0.0155 std: 0.1723\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Val: Accuracy: 0.9944  \n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 63.67 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0197\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 63.17 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0192\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 61.31 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 3: Aggregated threshold = 0.1922\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m -----------mse_loss mean :  0.0152 std: 0.1587\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Val: Accuracy: 0.9953  \n",
      "Counts of : original binary labels Counter({0: 156058, 1: 65271}) predicted binary labels Counter({0: 155264, 1: 66065})\n",
      "Counts of  original  labels: {0: 156058, 1: 65233, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 955, 1: 161}\n",
      "{0: 'threshold=0.1922 ,Test : Accuracy: 0.9950 Recall : 0.9975 FDR: 0.0145  F1-score: 0.9915 '}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (3, 0.6186465482381432, {0: 'threshold=0.1922 ,Test : Accuracy: 0.9950 Recall : 0.9975 FDR: 0.0145  F1-score: 0.9915 '}, 2707.8700235740007)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model AE is saved in fed_best_models/FED_PROX_AE_f1_0.99_recall_1.00_.pth\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 63.02 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0146\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 64.00 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0144\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 64.27 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0144\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m -----------mse_loss mean :  0.0106 std: 0.1358\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Val: Accuracy: 0.9953  \n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 75.33 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0155\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 73.97 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0154\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 71.95 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0154\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m -----------mse_loss mean :  0.0145 std: 0.1516\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Val: Accuracy: 0.9928  \n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 54.37 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0147\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 55.01 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0146\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 54.83 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0145\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m -----------mse_loss mean :  0.0136 std: 0.1615\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Val: Accuracy: 0.9931  \n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 74.65 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0142\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 71.27 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0140\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 74.31 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m -----------mse_loss mean :  0.0105 std: 0.1204\n",
      "Round 4: Aggregated threshold = 0.1547\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Val: Accuracy: 0.9944  \n",
      "Counts of : original binary labels Counter({0: 156058, 1: 65271}) predicted binary labels Counter({0: 155257, 1: 66072})\n",
      "Counts of  original  labels: {0: 156058, 1: 65233, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 955, 1: 154}\n",
      "{0: 'threshold=0.1547 ,Test : Accuracy: 0.9950 Recall : 0.9976 FDR: 0.0145  F1-score: 0.9916 '}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (4, 0.7948349798264123, {0: 'threshold=0.1547 ,Test : Accuracy: 0.9950 Recall : 0.9976 FDR: 0.0145  F1-score: 0.9916 '}, 3601.7165690419997)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model AE is saved in fed_best_models/FED_PROX_AE_f1_0.99_recall_1.00_.pth\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 71.13 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0120\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 74.82 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0120\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 74.42 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0119\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m -----------mse_loss mean :  0.0094 std: 0.1092\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Val: Accuracy: 0.9944  \n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 62.52 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0124\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 61.94 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0122\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 61.64 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0123\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m -----------mse_loss mean :  0.0134 std: 0.1076\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Val: Accuracy: 0.9953  \n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 53.17 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0123\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 56.59 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0124\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 53.99 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0124\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m -----------mse_loss mean :  0.0122 std: 0.1548\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Val: Accuracy: 0.9931  \n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 71.50 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0135\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 74.52 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0134\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train : time 71.58 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Train Loss: 0.0133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m -----------mse_loss mean :  0.0132 std: 0.1290\n",
      "Round 5: Aggregated threshold = 0.1373\n",
      "\u001b[36m(ClientAppActor pid=21780)\u001b[0m Val: Accuracy: 0.9928  \n",
      "Counts of : original binary labels Counter({0: 156058, 1: 65271}) predicted binary labels Counter({0: 155254, 1: 66075})\n",
      "Counts of  original  labels: {0: 156058, 1: 65233, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 957, 1: 153}\n",
      "{0: 'threshold=0.1373 ,Test : Accuracy: 0.9950 Recall : 0.9977 FDR: 0.0145  F1-score: 0.9915 '}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (5, 0.7993914743436242, {0: 'threshold=0.1373 ,Test : Accuracy: 0.9950 Recall : 0.9977 FDR: 0.0145  F1-score: 0.9915 '}, 4487.011939446001)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 5 round(s) in 4487.01s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, centralized):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 0: 16.93721112009723\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.6500179032119605\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.4974349201302134\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.6186465482381432\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 4: 0.7948349798264123\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 5: 0.7993914743436242\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, centralized):\n",
      "\u001b[92mINFO \u001b[0m:      \t{0: [(0,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'threshold=0.0000 ,Test : Accuracy: 0.2949 Recall : 1.0000 FDR: 0.7051  '\n",
      "\u001b[92mINFO \u001b[0m:      \t      'F1-score: 0.4555 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (1,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'threshold=0.3713 ,Test : Accuracy: 0.8997 Recall : 0.9977 FDR: 0.2529  '\n",
      "\u001b[92mINFO \u001b[0m:      \t      'F1-score: 0.8544 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (2,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'threshold=0.2641 ,Test : Accuracy: 0.9949 Recall : 0.9975 FDR: 0.0144  '\n",
      "\u001b[92mINFO \u001b[0m:      \t      'F1-score: 0.9915 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (3,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'threshold=0.1922 ,Test : Accuracy: 0.9950 Recall : 0.9975 FDR: 0.0145  '\n",
      "\u001b[92mINFO \u001b[0m:      \t      'F1-score: 0.9915 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (4,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'threshold=0.1547 ,Test : Accuracy: 0.9950 Recall : 0.9976 FDR: 0.0145  '\n",
      "\u001b[92mINFO \u001b[0m:      \t      'F1-score: 0.9916 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (5,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'threshold=0.1373 ,Test : Accuracy: 0.9950 Recall : 0.9977 FDR: 0.0145  '\n",
      "\u001b[92mINFO \u001b[0m:      \t      'F1-score: 0.9915 ')]}\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Federated learning simulation finished.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Instantiate the configuration\n",
    "cfg.STRATEGY=\"FED_PROX\"\n",
    "strategy=set_server_strategy()\n",
    "\n",
    "# --- Start the Simulation ---\n",
    "print(\"Starting federated learning simulation...\")\n",
    "history = fl.simulation.start_simulation(\n",
    "    client_fn=client_function,\n",
    "    num_clients=cfg.NUM_TRAIN_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=cfg.NUM_ROUNDS),\n",
    "    strategy=strategy,\n",
    "    client_resources={\"num_cpus\": 1, \"num_gpus\": 1} if DEVICE.type == \"cuda\" else {\"num_cpus\": 1},\n",
    ")\n",
    "print(\"Federated learning simulation finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8515c34",
   "metadata": {},
   "source": [
    "### VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cb200f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n",
      "\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n",
      "\n",
      "\t\t$ flwr new  # Create a new Flower app from a template\n",
      "\n",
      "\t\t$ flwr run  # Run the Flower app in Simulation Mode\n",
      "\n",
      "\tUsing `start_simulation()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=5, no round_timeout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using FedAvg strategy with VAE model.\n",
      "Starting federated learning simulation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-27 00:44:18,687\tINFO worker.py:1771 -- Started a local Ray instance.\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'accelerator_type:G': 1.0, 'node:__internal_head__': 1.0, 'CPU': 2.0, 'memory': 3333827790.0, 'object_store_memory': 1666913894.0, 'GPU': 1.0, 'node:172.24.78.91': 1.0}\n",
      "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 1}\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 1 actors\n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of : original binary labels Counter({0: 156058, 1: 65271}) predicted binary labels Counter({1: 221329})\n",
      "Counts of  original  labels: {0: 156058, 1: 65233, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 156058}\n",
      "{0: 'threshold=0.0000 ,Test : Accuracy: 0.2949 Recall : 1.0000 FDR: 0.7051  F1-score: 0.4555 '}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 18.036986793416137, {0: 'threshold=0.0000 ,Test : Accuracy: 0.2949 Recall : 1.0000 FDR: 0.7051  F1-score: 0.4555 '}\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 30.11 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.5352\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 30.65 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1550\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 29.61 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1380\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m -----------mse_loss mean :  0.0381 std: 0.1958\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Val: Accuracy: 0.9852  \n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 42.29 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.4714\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 39.58 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1689\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 40.69 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1602\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m -----------mse_loss mean :  0.0618 std: 0.5117\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Val: Accuracy: 0.9927  \n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 40.21 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.4537\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 41.01 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1656\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 42.08 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1570\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m -----------mse_loss mean :  0.0514 std: 0.2479\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Val: Accuracy: 0.9802  \n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 34.28 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.5044\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 35.97 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1655\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 33.97 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1: Aggregated threshold = 0.4155\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m -----------mse_loss mean :  0.0613 std: 0.4961\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Val: Accuracy: 0.9938  \n",
      "Counts of : original binary labels Counter({0: 156058, 1: 65271}) predicted binary labels Counter({0: 122723, 1: 98606})\n",
      "Counts of  original  labels: {0: 156058, 1: 65233, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 33487, 1: 152}\n",
      "{0: 'threshold=0.4155 ,Test : Accuracy: 0.8480 Recall : 0.9977 FDR: 0.3396  F1-score: 0.7947 '}\n",
      "model"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (1, 0.9953139613426166, {0: 'threshold=0.4155 ,Test : Accuracy: 0.8480 Recall : 0.9977 FDR: 0.3396  F1-score: 0.7947 '}, 510.31632201999855)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " VAE is saved in fed_best_models/FED_AVG_VAE_f1_0.79_recall_1.00_.pth\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 30.22 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1704\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 27.88 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1619\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 30.37 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1602\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m -----------mse_loss mean :  0.0614 std: 0.5008\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Val: Accuracy: 0.9920  \n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 41.43 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1663\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 41.82 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1585\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 39.01 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1566\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m -----------mse_loss mean :  0.0626 std: 0.5311\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Val: Accuracy: 0.9925  \n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 33.95 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1662\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 35.64 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1568\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 33.74 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1554\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m -----------mse_loss mean :  0.0459 std: 0.4516\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Val: Accuracy: 0.9951  \n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 42.10 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1672\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 40.18 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1599\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 39.10 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 2: Aggregated threshold = 0.5662\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m -----------mse_loss mean :  0.0677 std: 0.5438\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Val: Accuracy: 0.9914  \n",
      "Counts of : original binary labels Counter({0: 156058, 1: 65271}) predicted binary labels Counter({0: 193792, 1: 27537})\n",
      "Counts of  original  labels: {0: 156058, 1: 65233, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 1307, 1: 39033, 6: 8}\n",
      "{0: 'threshold=0.5662 ,Test : Accuracy: 0.8177 Recall : 0.4019 FDR: 0.0475  F1-score: 0.5653 '}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (2, 0.5350337478369306, {0: 'threshold=0.5662 ,Test : Accuracy: 0.8177 Recall : 0.4019 FDR: 0.0475  F1-score: 0.5653 '}, 1013.6585695119993)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 29.76 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1594\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 31.12 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1585\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 29.52 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1584\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m -----------mse_loss mean :  0.0600 std: 0.4995\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Val: Accuracy: 0.9920  \n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 39.68 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1575\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 41.54 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1568\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 40.99 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1563\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m -----------mse_loss mean :  0.0639 std: 0.5285\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Val: Accuracy: 0.9917  \n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 35.83 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1551\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 35.04 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1539\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 35.88 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1531\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m -----------mse_loss mean :  0.0553 std: 0.4726\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Val: Accuracy: 0.9912  \n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 39.16 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1560\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 43.29 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1553\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 41.53 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m -----------mse_loss mean :  0.0586 std: 0.5236\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Val: Accuracy: 0.9931  \n",
      "Round 3: Aggregated threshold = 0.5655\n",
      "Counts of : original binary labels Counter({0: 156058, 1: 65271}) predicted binary labels Counter({0: 193900, 1: 27429})\n",
      "Counts of  original  labels: {0: 156058, 1: 65233, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 1110, 1: 38944, 6: 8}\n",
      "{0: 'threshold=0.5655 ,Test : Accuracy: 0.8190 Recall : 0.4032 FDR: 0.0405  F1-score: 0.5678 '}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (3, 0.5416102837856765, {0: 'threshold=0.5655 ,Test : Accuracy: 0.8190 Recall : 0.4032 FDR: 0.0405  F1-score: 0.5678 '}, 1522.1402817749986)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 41.64 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1559\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 39.62 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1550\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 41.58 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1544\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m -----------mse_loss mean :  0.0597 std: 0.5216\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Val: Accuracy: 0.9922  \n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 35.92 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1528\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 34.67 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1517\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 32.97 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1510\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m -----------mse_loss mean :  0.0475 std: 0.4424\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Val: Accuracy: 0.9944  \n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 40.49 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1543\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 41.68 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1537\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 38.31 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1533\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m -----------mse_loss mean :  0.0527 std: 0.5006\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Val: Accuracy: 0.9938  \n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 31.02 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1575\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 29.85 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1569\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 30.97 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 4: Aggregated threshold = 0.5436\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m -----------mse_loss mean :  0.0632 std: 0.4867\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Val: Accuracy: 0.9911  \n",
      "Counts of : original binary labels Counter({0: 156058, 1: 65271}) predicted binary labels Counter({0: 193943, 1: 27386})\n",
      "Counts of  original  labels: {0: 156058, 1: 65233, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 1105, 1: 38982, 6: 8}\n",
      "{0: 'threshold=0.5436 ,Test : Accuracy: 0.8188 Recall : 0.4026 FDR: 0.0403  F1-score: 0.5673 '}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (4, 0.5357206494630166, {0: 'threshold=0.5436 ,Test : Accuracy: 0.8188 Recall : 0.4026 FDR: 0.0403  F1-score: 0.5673 '}, 2026.6842474159985)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 31.99 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1511\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 36.03 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1507\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 33.83 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1500\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m -----------mse_loss mean :  0.0475 std: 0.3565\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Val: Accuracy: 0.9910  \n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 31.52 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1558\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 29.75 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1556\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 30.41 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1537\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m -----------mse_loss mean :  0.0458 std: 0.3124\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Val: Accuracy: 0.9906  \n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 38.41 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1527\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 41.96 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1526\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 40.76 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1518\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m -----------mse_loss mean :  0.0510 std: 0.4427\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Val: Accuracy: 0.9935  \n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 42.42 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1541\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 41.57 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1538\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train : time 39.07 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Train Loss: 0.1507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 5: Aggregated threshold = 0.4054\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m -----------mse_loss mean :  0.0498 std: 0.3166\n",
      "\u001b[36m(ClientAppActor pid=36318)\u001b[0m Val: Accuracy: 0.9892  \n",
      "Counts of : original binary labels Counter({0: 156058, 1: 65271}) predicted binary labels Counter({0: 167338, 1: 53991})\n",
      "Counts of  original  labels: {0: 156058, 1: 65233, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 1235, 1: 12507, 6: 8}\n",
      "{0: 'threshold=0.4054 ,Test : Accuracy: 0.9379 Recall : 0.8083 FDR: 0.0229  F1-score: 0.8847 '}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (5, 0.5403309383316239, {0: 'threshold=0.4054 ,Test : Accuracy: 0.9379 Recall : 0.8083 FDR: 0.0229  F1-score: 0.8847 '}, 2531.6515583889995)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 5 round(s) in 2531.65s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, centralized):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 0: 18.036986793416137\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.9953139613426166\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.5350337478369306\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.5416102837856765\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 4: 0.5357206494630166\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 5: 0.5403309383316239\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, centralized):\n",
      "\u001b[92mINFO \u001b[0m:      \t{0: [(0,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'threshold=0.0000 ,Test : Accuracy: 0.2949 Recall : 1.0000 FDR: 0.7051  '\n",
      "\u001b[92mINFO \u001b[0m:      \t      'F1-score: 0.4555 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (1,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'threshold=0.4155 ,Test : Accuracy: 0.8480 Recall : 0.9977 FDR: 0.3396  '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model VAE is saved in fed_best_models/FED_AVG_VAE_f1_0.88_recall_1.00_.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      \t      'F1-score: 0.7947 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (2,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'threshold=0.5662 ,Test : Accuracy: 0.8177 Recall : 0.4019 FDR: 0.0475  '\n",
      "\u001b[92mINFO \u001b[0m:      \t      'F1-score: 0.5653 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (3,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'threshold=0.5655 ,Test : Accuracy: 0.8190 Recall : 0.4032 FDR: 0.0405  '\n",
      "\u001b[92mINFO \u001b[0m:      \t      'F1-score: 0.5678 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (4,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'threshold=0.5436 ,Test : Accuracy: 0.8188 Recall : 0.4026 FDR: 0.0403  '\n",
      "\u001b[92mINFO \u001b[0m:      \t      'F1-score: 0.5673 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (5,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'threshold=0.4054 ,Test : Accuracy: 0.9379 Recall : 0.8083 FDR: 0.0229  '\n",
      "\u001b[92mINFO \u001b[0m:      \t      'F1-score: 0.8847 ')]}\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Federated learning simulation finished.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the configuration\n",
    "cfg.STRATEGY=\"FED_AVG\"\n",
    "cfg.MODEL_NAME=\"VAE\"\n",
    "cfg.LEARNING_RATE=1e-4\n",
    "cfg.WEIGHT_DECAY=1e-4\n",
    "strategy=set_server_strategy()\n",
    "\n",
    "# --- Start the Simulation ---\n",
    "print(\"Starting federated learning simulation...\")\n",
    "history = fl.simulation.start_simulation(\n",
    "    client_fn=client_function,\n",
    "    num_clients=cfg.NUM_TRAIN_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=cfg.NUM_ROUNDS),\n",
    "    strategy=strategy,\n",
    "    client_resources={\"num_cpus\": 1, \"num_gpus\": 1} if DEVICE.type == \"cuda\" else {\"num_cpus\": 4},\n",
    ")\n",
    "print(\"Federated learning simulation finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b129e9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n",
      "\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n",
      "\n",
      "\t\t$ flwr new  # Create a new Flower app from a template\n",
      "\n",
      "\t\t$ flwr run  # Run the Flower app in Simulation Mode\n",
      "\n",
      "\tUsing `start_simulation()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=5, no round_timeout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using FedProx strategy with VAE model.\n",
      "Starting federated learning simulation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-27 01:23:28,377\tINFO worker.py:1771 -- Started a local Ray instance.\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'accelerator_type:G': 1.0, 'node:__internal_head__': 1.0, 'CPU': 2.0, 'memory': 3277833831.0, 'object_store_memory': 1638916915.0, 'GPU': 1.0, 'node:172.24.78.91': 1.0}\n",
      "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 1}\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 1 actors\n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of : original binary labels Counter({0: 156058, 1: 65271}) predicted binary labels Counter({1: 221329})\n",
      "Counts of  original  labels: {0: 156058, 1: 65233, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 156058}\n",
      "{0: 'threshold=0.0000 ,Test : Accuracy: 0.2949 Recall : 1.0000 FDR: 0.7051  F1-score: 0.4555 '}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 17.708340298831153, {0: 'threshold=0.0000 ,Test : Accuracy: 0.2949 Recall : 1.0000 FDR: 0.7051  F1-score: 0.4555 '}\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 49.82 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.8157\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 45.44 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.4286\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 48.59 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.4183\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m -----------mse_loss mean :  0.1000 std: 0.4407\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Val: Accuracy: 0.9910  \n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 63.35 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.7061\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 62.99 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.4222\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 63.36 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.4165\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m -----------mse_loss mean :  0.1087 std: 0.4783\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Val: Accuracy: 0.9898  \n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 53.28 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.7429\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 52.10 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.4242\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 55.55 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.4162\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m -----------mse_loss mean :  0.0958 std: 0.4281\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Val: Accuracy: 0.9906  \n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 63.34 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.7125\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 63.36 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.4230\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 62.83 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.4149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m -----------mse_loss mean :  0.1003 std: 0.4691\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Val: Accuracy: 0.9908  \n",
      "Round 1: Aggregated threshold = 0.5552\n",
      "Counts of : original binary labels Counter({0: 156058, 1: 65271}) predicted binary labels Counter({0: 187327, 1: 34002})\n",
      "Counts of  original  labels: {0: 156058, 1: 65233, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2843, 1: 34104, 6: 8}\n",
      "{0: 'threshold=0.5552 ,Test : Accuracy: 0.8330 Recall : 0.4774 FDR: 0.0836  F1-score: 0.6277 '}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (1, 0.5551878863027438, {0: 'threshold=0.5552 ,Test : Accuracy: 0.8330 Recall : 0.4774 FDR: 0.0836  F1-score: 0.6277 '}, 770.0015450480005)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model VAE is saved in fed_best_models/FED_PROX_VAE_f1_0.63_recall_1.00_.pth\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 46.03 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.2092\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 47.20 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.2073\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 46.75 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.2073\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m -----------mse_loss mean :  0.0838 std: 0.4483\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Val: Accuracy: 0.9897  \n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 63.03 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.2078\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 62.69 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.2060\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 60.83 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.2060\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m -----------mse_loss mean :  0.0781 std: 0.4648\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Val: Accuracy: 0.9922  \n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 53.40 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.2069\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 52.41 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.2051\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 53.14 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.2050\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m -----------mse_loss mean :  0.0787 std: 0.4250\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Val: Accuracy: 0.9905  \n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 62.63 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.2081\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 62.53 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.2067\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 62.42 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.2063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m -----------mse_loss mean :  0.0886 std: 0.4716\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Val: Accuracy: 0.9885  \n",
      "Round 2: Aggregated threshold = 0.5347\n",
      "Counts of : original binary labels Counter({0: 156058, 1: 65271}) predicted binary labels Counter({0: 192435, 1: 28894})\n",
      "Counts of  original  labels: {0: 156058, 1: 65233, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 1411, 1: 37781, 6: 7}\n",
      "{0: 'threshold=0.5347 ,Test : Accuracy: 0.8229 Recall : 0.4211 FDR: 0.0488  F1-score: 0.5837 '}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (2, 0.5316846611831256, {0: 'threshold=0.5347 ,Test : Accuracy: 0.8229 Recall : 0.4211 FDR: 0.0488  F1-score: 0.5837 '}, 1529.7249870169999)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 63.29 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.1901\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 62.81 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.1899\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 61.80 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.1901\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m -----------mse_loss mean :  0.0751 std: 0.4421\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Val: Accuracy: 0.9908  \n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 62.91 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.1912\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 60.14 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.1908\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 62.99 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.1906\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m -----------mse_loss mean :  0.0799 std: 0.4583\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Val: Accuracy: 0.9902  \n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 52.66 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.1897\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 54.60 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.1894\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 52.96 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.1892\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m -----------mse_loss mean :  0.0681 std: 0.3915\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Val: Accuracy: 0.9905  \n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 45.82 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.1916\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 47.61 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.1914\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 45.48 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.1911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 3: Aggregated threshold = 0.5038\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m -----------mse_loss mean :  0.0726 std: 0.4277\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Val: Accuracy: 0.9913  \n",
      "Counts of : original binary labels Counter({0: 156058, 1: 65271}) predicted binary labels Counter({0: 175875, 1: 45454})\n",
      "Counts of  original  labels: {0: 156058, 1: 65233, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 1320, 1: 21129, 6: 8}\n",
      "{0: 'threshold=0.5038 ,Test : Accuracy: 0.8985 Recall : 0.6762 FDR: 0.0290  F1-score: 0.7972 '}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (3, 0.5308336585467788, {0: 'threshold=0.5038 ,Test : Accuracy: 0.8985 Recall : 0.6762 FDR: 0.0290  F1-score: 0.7972 '}, 2290.9276955780006)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model VAE is saved in fed_best_models/FED_PROX_VAE_f1_0.80_recall_1.00_.pth\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 55.95 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.1841\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 53.35 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.1838\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 52.09 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.1838\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m -----------mse_loss mean :  0.0655 std: 0.3656\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Val: Accuracy: 0.9915  \n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 45.71 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.1856\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 48.90 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.1853\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 44.99 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.1853\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m -----------mse_loss mean :  0.0760 std: 0.4143\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Val: Accuracy: 0.9890  \n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 62.57 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.1844\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 62.67 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.1842\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 63.29 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.1844\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m -----------mse_loss mean :  0.0706 std: 0.4253\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Val: Accuracy: 0.9920  \n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 61.37 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.1852\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 63.28 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.1852\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 69.14 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.1850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m -----------mse_loss mean :  0.0796 std: 0.4404\n",
      "Round 4: Aggregated threshold = 0.4844\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Val: Accuracy: 0.9884  \n",
      "Counts of : original binary labels Counter({0: 156058, 1: 65271}) predicted binary labels Counter({0: 171689, 1: 49640})\n",
      "Counts of  original  labels: {0: 156058, 1: 65233, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 1532, 1: 17155, 6: 8}\n",
      "{0: 'threshold=0.4844 ,Test : Accuracy: 0.9155 Recall : 0.7371 FDR: 0.0309  F1-score: 0.8373 '}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (4, 0.532405449014815, {0: 'threshold=0.4844 ,Test : Accuracy: 0.9155 Recall : 0.7371 FDR: 0.0309  F1-score: 0.8373 '}, 3062.090114531)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model VAE is saved in fed_best_models/FED_PROX_VAE_f1_0.84_recall_1.00_.pth\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 60.82 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.1813\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 62.18 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.1813\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 62.12 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.1814\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m -----------mse_loss mean :  0.0702 std: 0.4032\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Val: Accuracy: 0.9898  \n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 46.89 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.1817\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 45.80 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.1821\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 45.74 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.1817\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m -----------mse_loss mean :  0.0670 std: 0.3864\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Val: Accuracy: 0.9908  \n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 53.92 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.1806\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 52.95 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.1803\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 53.41 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.1804\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m -----------mse_loss mean :  0.0665 std: 0.3722\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Val: Accuracy: 0.9891  \n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 63.28 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.1806\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 63.12 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.1805\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train : time 59.05 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Train Loss: 0.1807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 5: Aggregated threshold = 0.4608\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m -----------mse_loss mean :  0.0694 std: 0.4085\n",
      "\u001b[36m(ClientAppActor pid=44427)\u001b[0m Val: Accuracy: 0.9902  \n",
      "Counts of : original binary labels Counter({0: 156058, 1: 65271}) predicted binary labels Counter({0: 169831, 1: 51498})\n",
      "Counts of  original  labels: {0: 156058, 1: 65233, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 1457, 1: 15222, 6: 8}\n",
      "{0: 'threshold=0.4608 ,Test : Accuracy: 0.9246 Recall : 0.7667 FDR: 0.0283  F1-score: 0.8571 '}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (5, 0.5313830386551243, {0: 'threshold=0.4608 ,Test : Accuracy: 0.9246 Recall : 0.7667 FDR: 0.0283  F1-score: 0.8571 '}, 3821.811365921001)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 5 round(s) in 3821.81s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, centralized):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 0: 17.708340298831153\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.5551878863027438\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.5316846611831256\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.5308336585467788\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 4: 0.532405449014815\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 5: 0.5313830386551243\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, centralized):\n",
      "\u001b[92mINFO \u001b[0m:      \t{0: [(0,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'threshold=0.0000 ,Test : Accuracy: 0.2949 Recall : 1.0000 FDR: 0.7051  '\n",
      "\u001b[92mINFO \u001b[0m:      \t      'F1-score: 0.4555 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (1,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'threshold=0.5552 ,Test : Accuracy: 0.8330 Recall : 0.4774 FDR: 0.0836  '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model VAE is saved in fed_best_models/FED_PROX_VAE_f1_0.86_recall_1.00_.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      \t      'F1-score: 0.6277 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (2,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'threshold=0.5347 ,Test : Accuracy: 0.8229 Recall : 0.4211 FDR: 0.0488  '\n",
      "\u001b[92mINFO \u001b[0m:      \t      'F1-score: 0.5837 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (3,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'threshold=0.5038 ,Test : Accuracy: 0.8985 Recall : 0.6762 FDR: 0.0290  '\n",
      "\u001b[92mINFO \u001b[0m:      \t      'F1-score: 0.7972 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (4,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'threshold=0.4844 ,Test : Accuracy: 0.9155 Recall : 0.7371 FDR: 0.0309  '\n",
      "\u001b[92mINFO \u001b[0m:      \t      'F1-score: 0.8373 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (5,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'threshold=0.4608 ,Test : Accuracy: 0.9246 Recall : 0.7667 FDR: 0.0283  '\n",
      "\u001b[92mINFO \u001b[0m:      \t      'F1-score: 0.8571 ')]}\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Federated learning simulation finished.\n"
     ]
    }
   ],
   "source": [
    "cfg.STRATEGY=\"FED_PROX\"\n",
    "strategy=set_server_strategy()\n",
    "\n",
    "print(\"Starting federated learning simulation...\")\n",
    "history = fl.simulation.start_simulation(\n",
    "    client_fn=client_function,\n",
    "    num_clients=cfg.NUM_TRAIN_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=cfg.NUM_ROUNDS),\n",
    "    strategy=strategy,\n",
    "    client_resources={\"num_cpus\": 1, \"num_gpus\": 1} if DEVICE.type == \"cuda\" else {\"num_cpus\": 1},\n",
    ")\n",
    "print(\"Federated learning simulation finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fad8408",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n",
      "\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n",
      "\n",
      "\t\t$ flwr new  # Create a new Flower app from a template\n",
      "\n",
      "\t\t$ flwr run  # Run the Flower app in Simulation Mode\n",
      "\n",
      "\tUsing `start_simulation()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=5, no round_timeout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using FedAvg strategy with AAE model.\n",
      "Starting federated learning simulation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-27 02:22:29,737\tINFO worker.py:1771 -- Started a local Ray instance.\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'accelerator_type:G': 1.0, 'node:__internal_head__': 1.0, 'CPU': 2.0, 'memory': 3242832692.0, 'object_store_memory': 1621416345.0, 'GPU': 1.0, 'node:172.24.78.91': 1.0}\n",
      "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 1}\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 1 actors\n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of : original binary labels Counter({0: 156058, 1: 65271}) predicted binary labels Counter({1: 221329})\n",
      "Counts of  original  labels: {0: 156058, 1: 65233, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 156058}\n",
      "{0: 'threshold=0.0000 ,Test : Accuracy: 0.2949 Recall : 1.0000 FDR: 0.7051  F1-score: 0.4555 '}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 17.18490911719657, {0: 'threshold=0.0000 ,Test : Accuracy: 0.2949 Recall : 1.0000 FDR: 0.7051  F1-score: 0.4555 '}\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 67.21 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 120.6971 Discriminator Loss: 8.2306\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 67.25 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 12.8002 Discriminator Loss: 7.7419\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 67.29 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 3.6445 Discriminator Loss: 7.5593\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m -----------mse_loss mean :  0.0356 std: 0.3169\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Val: Accuracy: 0.9944  \n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 63.79 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 120.6778 Discriminator Loss: 8.1995\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 64.44 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 13.0397 Discriminator Loss: 7.7359\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 65.80 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 3.7659 Discriminator Loss: 7.3760\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m -----------mse_loss mean :  0.0414 std: 0.3497\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Val: Accuracy: 0.9929  \n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 56.02 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 130.6215 Discriminator Loss: 8.7442\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 55.97 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 13.5650 Discriminator Loss: 5.7166\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 55.07 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 3.7869 Discriminator Loss: 3.3810\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m -----------mse_loss mean :  0.0329 std: 0.2560\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Val: Accuracy: 0.9954  \n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 46.41 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 149.7142 Discriminator Loss: 9.2216\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 50.84 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 23.8664 Discriminator Loss: 6.5619\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 48.14 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 6.2077 Discriminator Loss: 7.3374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1: Aggregated threshold = 0.3635\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m -----------mse_loss mean :  0.0515 std: 0.3694\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Val: Accuracy: 0.9934  \n",
      "Counts of : original binary labels Counter({0: 156058, 1: 65271}) predicted binary labels Counter({0: 154199, 1: 67130})\n",
      "Counts of  original  labels: {0: 156058, 1: 65233, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2027, 1: 168}\n",
      "{0: 'threshold=0.3635 ,Test : Accuracy: 0.9901 Recall : 0.9974 FDR: 0.0302  F1-score: 0.9834 '}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (1, 0.5044641193088117, {0: 'threshold=0.3635 ,Test : Accuracy: 0.9901 Recall : 0.9974 FDR: 0.0302  F1-score: 0.9834 '}, 800.0963934020001)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model AdversarialAutoencoder is saved in fed_best_models/FED_AVG_AdversarialAutoencoder_f1_0.98_recall_1.00_.pth\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 55.52 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 2.8521 Discriminator Loss: 8.3604\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 54.61 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 2.1463 Discriminator Loss: 11.5994\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 56.09 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 1.8089 Discriminator Loss: 16.6232\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m -----------mse_loss mean :  0.0185 std: 0.2092\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Val: Accuracy: 0.9953  \n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 47.78 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 3.0424 Discriminator Loss: 7.9623\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 51.28 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 2.3742 Discriminator Loss: 10.9102\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 47.48 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 1.9936 Discriminator Loss: 15.8880\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m -----------mse_loss mean :  0.0264 std: 0.2672\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Val: Accuracy: 0.9932  \n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 67.21 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 2.8342 Discriminator Loss: 8.5792\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 64.05 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 2.0669 Discriminator Loss: 13.5190\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 66.22 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 1.6739 Discriminator Loss: 18.5246\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m -----------mse_loss mean :  0.0204 std: 0.2242\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Val: Accuracy: 0.9944  \n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 65.22 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 2.9387 Discriminator Loss: 8.5273\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 65.39 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 2.1973 Discriminator Loss: 13.3330\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 65.56 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 1.8975 Discriminator Loss: 20.0439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m -----------mse_loss mean :  0.0280 std: 0.2932\n",
      "Round 2: Aggregated threshold = 0.2718\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Val: Accuracy: 0.9929  \n",
      "Counts of : original binary labels Counter({0: 156058, 1: 65271}) predicted binary labels Counter({0: 155408, 1: 65921})\n",
      "Counts of  original  labels: {0: 156058, 1: 65233, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 952, 1: 302}\n",
      "{0: 'threshold=0.2718 ,Test : Accuracy: 0.9943 Recall : 0.9954 FDR: 0.0144  F1-score: 0.9904 '}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (2, 0.5094359669315814, {0: 'threshold=0.2718 ,Test : Accuracy: 0.9943 Recall : 0.9954 FDR: 0.0144  F1-score: 0.9904 '}, 1595.0653152330015)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model AdversarialAutoencoder is saved in fed_best_models/FED_AVG_AdversarialAutoencoder_f1_0.99_recall_1.00_.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 65.73 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 1.6625 Discriminator Loss: 20.0987\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 65.29 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 1.4741 Discriminator Loss: 20.3186\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 66.08 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 1.3783 Discriminator Loss: 19.4683\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m -----------mse_loss mean :  0.0198 std: 0.2162\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Val: Accuracy: 0.9928  \n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 50.30 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 1.6881 Discriminator Loss: 20.1837\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 48.57 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 1.5112 Discriminator Loss: 20.4733\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 48.07 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 1.4070 Discriminator Loss: 20.9100\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m -----------mse_loss mean :  0.0202 std: 0.2287\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Val: Accuracy: 0.9931  \n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 65.94 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 1.5542 Discriminator Loss: 20.7752\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 65.68 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 1.3589 Discriminator Loss: 21.1565\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 67.06 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 1.2595 Discriminator Loss: 20.7646\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m -----------mse_loss mean :  0.0167 std: 0.2014\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Val: Accuracy: 0.9944  \n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 58.56 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 1.5763 Discriminator Loss: 20.9083\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 56.91 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 1.4483 Discriminator Loss: 20.8229\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 56.19 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 1.3524 Discriminator Loss: 20.2984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m -----------mse_loss mean :  0.0153 std: 0.1953\n",
      "Round 3: Aggregated threshold = 0.2284\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Val: Accuracy: 0.9953  \n",
      "Counts of : original binary labels Counter({0: 156058, 1: 65271}) predicted binary labels Counter({0: 155265, 1: 66064})\n",
      "Counts of  original  labels: {0: 156058, 1: 65233, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 958, 1: 165}\n",
      "{0: 'threshold=0.2284 ,Test : Accuracy: 0.9949 Recall : 0.9975 FDR: 0.0145  F1-score: 0.9914 '}\n",
      "model AdversarialAutoencoder is saved in fed_best_models/FED_AVG_AdversarialAutoencoder_f1_0.99_recall_1.00_.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (3, 1.402052346280876, {0: 'threshold=0.2284 ,Test : Accuracy: 0.9949 Recall : 0.9975 FDR: 0.0145  F1-score: 0.9914 '}, 2393.3482871779997)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 51.26 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 1.3156 Discriminator Loss: 18.8691\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 47.56 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 1.2424 Discriminator Loss: 16.6868\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 48.07 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 1.1202 Discriminator Loss: 14.9636\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m -----------mse_loss mean :  0.0161 std: 0.2090\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Val: Accuracy: 0.9947  \n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 55.63 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 1.2754 Discriminator Loss: 18.8376\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 57.20 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 1.2100 Discriminator Loss: 19.1915\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 55.54 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 1.1116 Discriminator Loss: 15.7565\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m -----------mse_loss mean :  0.0138 std: 0.1889\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Val: Accuracy: 0.9958  \n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 66.59 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 1.2306 Discriminator Loss: 18.5420\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 66.56 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 1.1066 Discriminator Loss: 15.8879\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 73.95 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 1.0585 Discriminator Loss: 13.0131\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m -----------mse_loss mean :  0.0138 std: 0.1927\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Val: Accuracy: 0.9962  \n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 72.53 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 1.3321 Discriminator Loss: 18.3986\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 69.82 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 1.2315 Discriminator Loss: 15.6188\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 66.19 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 1.1141 Discriminator Loss: 14.0823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 4: Aggregated threshold = 0.2115\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m -----------mse_loss mean :  0.0143 std: 0.1974\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Val: Accuracy: 0.9957  \n",
      "Counts of : original binary labels Counter({0: 156058, 1: 65271}) predicted binary labels Counter({0: 155306, 1: 66023})\n",
      "Counts of  original  labels: {0: 156058, 1: 65233, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 917, 1: 165}\n",
      "{0: 'threshold=0.2115 ,Test : Accuracy: 0.9951 Recall : 0.9975 FDR: 0.0139  F1-score: 0.9918 '}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (4, 1.2725523993692647, {0: 'threshold=0.2115 ,Test : Accuracy: 0.9951 Recall : 0.9975 FDR: 0.0139  F1-score: 0.9918 '}, 3210.563227941002)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model AdversarialAutoencoder is saved in fed_best_models/FED_AVG_AdversarialAutoencoder_f1_0.99_recall_1.00_.pth\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 65.79 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 1.1213 Discriminator Loss: 13.2397\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 69.05 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 1.0951 Discriminator Loss: 15.4672\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 65.02 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 1.1059 Discriminator Loss: 13.5196\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m -----------mse_loss mean :  0.0138 std: 0.2017\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Val: Accuracy: 0.9954  \n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 49.37 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 1.0964 Discriminator Loss: 13.4367\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 51.22 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 1.0596 Discriminator Loss: 15.9394\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 48.89 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 1.0517 Discriminator Loss: 13.7844\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m -----------mse_loss mean :  0.0149 std: 0.2087\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Val: Accuracy: 0.9948  \n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 56.05 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 1.0696 Discriminator Loss: 14.3082\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 54.84 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 1.0615 Discriminator Loss: 12.7208\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 55.86 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 1.0360 Discriminator Loss: 18.9074\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m -----------mse_loss mean :  0.0131 std: 0.1913\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Val: Accuracy: 0.9958  \n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 65.64 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 1.0332 Discriminator Loss: 12.6039\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 65.94 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 0.9971 Discriminator Loss: 20.7147\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Train : time 66.83 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Generator Loss: 0.9978 Discriminator Loss: 20.0136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 5: Aggregated threshold = 0.2121\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m -----------mse_loss mean :  0.0130 std: 0.1916\n",
      "\u001b[36m(ClientAppActor pid=56481)\u001b[0m Val: Accuracy: 0.9962  \n",
      "Counts of : original binary labels Counter({0: 156058, 1: 65271}) predicted binary labels Counter({0: 155294, 1: 66035})\n",
      "Counts of  original  labels: {0: 156058, 1: 65233, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 929, 1: 165}\n",
      "{0: 'threshold=0.2121 ,Test : Accuracy: 0.9951 Recall : 0.9975 FDR: 0.0141  F1-score: 0.9917 '}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (5, 1.2696438333883042, {0: 'threshold=0.2121 ,Test : Accuracy: 0.9951 Recall : 0.9975 FDR: 0.0141  F1-score: 0.9917 '}, 4013.688750272002)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 5 round(s) in 4013.69s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, centralized):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 0: 17.18490911719657\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.5044641193088117\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.5094359669315814\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 1.402052346280876\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 4: 1.2725523993692647\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 5: 1.2696438333883042\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, centralized):\n",
      "\u001b[92mINFO \u001b[0m:      \t{0: [(0,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'threshold=0.0000 ,Test : Accuracy: 0.2949 Recall : 1.0000 FDR: 0.7051  '\n",
      "\u001b[92mINFO \u001b[0m:      \t      'F1-score: 0.4555 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (1,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'threshold=0.3635 ,Test : Accuracy: 0.9901 Recall : 0.9974 FDR: 0.0302  '\n",
      "\u001b[92mINFO \u001b[0m:      \t      'F1-score: 0.9834 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (2,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'threshold=0.2718 ,Test : Accuracy: 0.9943 Recall : 0.9954 FDR: 0.0144  '\n",
      "\u001b[92mINFO \u001b[0m:      \t      'F1-score: 0.9904 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (3,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'threshold=0.2284 ,Test : Accuracy: 0.9949 Recall : 0.9975 FDR: 0.0145  '\n",
      "\u001b[92mINFO \u001b[0m:      \t      'F1-score: 0.9914 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (4,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'threshold=0.2115 ,Test : Accuracy: 0.9951 Recall : 0.9975 FDR: 0.0139  '\n",
      "\u001b[92mINFO \u001b[0m:      \t      'F1-score: 0.9918 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (5,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'threshold=0.2121 ,Test : Accuracy: 0.9951 Recall : 0.9975 FDR: 0.0141  '\n",
      "\u001b[92mINFO \u001b[0m:      \t      'F1-score: 0.9917 ')]}\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Federated learning simulation finished.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the configuration\n",
    "cfg.STRATEGY=\"FED_AVG\"\n",
    "cfg.MODEL_NAME=\"AAE\"\n",
    "cfg.LEARNING_RATE=1e-2\n",
    "cfg.WEIGHT_DECAY=1e-5\n",
    "strategy=set_server_strategy()\n",
    "\n",
    "# --- Start the Simulation ---\n",
    "print(\"Starting federated learning simulation...\")\n",
    "history = fl.simulation.start_simulation(\n",
    "    client_fn=client_function,\n",
    "    num_clients=cfg.NUM_TRAIN_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=cfg.NUM_ROUNDS),\n",
    "    strategy=strategy,\n",
    "    client_resources={\"num_cpus\": 1, \"num_gpus\": 1} if DEVICE.type == \"cuda\" else {\"num_cpus\": 1},\n",
    ")\n",
    "print(\"Federated learning simulation finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055eb90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n",
      "\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n",
      "\n",
      "\t\t$ flwr new  # Create a new Flower app from a template\n",
      "\n",
      "\t\t$ flwr run  # Run the Flower app in Simulation Mode\n",
      "\n",
      "\tUsing `start_simulation()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=5, no round_timeout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using FedProx strategy with AAE model.\n",
      "Starting federated learning simulation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-27 09:25:23,522\tINFO worker.py:1771 -- Started a local Ray instance.\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'accelerator_type:G': 1.0, 'node:__internal_head__': 1.0, 'CPU': 2.0, 'memory': 3270986958.0, 'object_store_memory': 1635493478.0, 'GPU': 1.0, 'node:172.24.78.91': 1.0}\n",
      "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 1}\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 1 actors\n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of : original binary labels Counter({0: 156058, 1: 65271}) predicted binary labels Counter({1: 221329})\n",
      "Counts of  original  labels: {0: 156058, 1: 65233, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 156058}\n",
      "{0: 'threshold=0.0000 ,Test : Accuracy: 0.2949 Recall : 1.0000 FDR: 0.7051  F1-score: 0.4555 '}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 17.891992237799837, {0: 'threshold=0.0000 ,Test : Accuracy: 0.2949 Recall : 1.0000 FDR: 0.7051  F1-score: 0.4555 '}\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Train : time 90.41 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Generator Loss: 140.9080 Discriminator Loss: 7.8880\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Train : time 90.33 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Generator Loss: 8.0050 Discriminator Loss: 0.3683\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Train : time 92.05 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Generator Loss: 6.0133 Discriminator Loss: 0.7436\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m -----------mse_loss mean :  0.0345 std: 0.2231\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Val: Accuracy: 0.9953  \n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Train : time 112.40 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Generator Loss: 123.7736 Discriminator Loss: 6.5872\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Train : time 106.42 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Generator Loss: 7.3452 Discriminator Loss: 0.5118\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Train : time 109.92 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Generator Loss: 5.2085 Discriminator Loss: 0.8802\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m -----------mse_loss mean :  0.0355 std: 0.2416\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Val: Accuracy: 0.9929  \n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Train : time 106.56 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Generator Loss: 123.4404 Discriminator Loss: 6.5806\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Train : time 108.12 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Generator Loss: 7.2391 Discriminator Loss: 0.5761\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Train : time 112.31 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Generator Loss: 5.2433 Discriminator Loss: 0.9489\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m -----------mse_loss mean :  0.0302 std: 0.2089\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Val: Accuracy: 0.9944  \n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Train : time 82.76 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Generator Loss: 161.7499 Discriminator Loss: 8.7229\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Train : time 82.72 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Generator Loss: 8.7939 Discriminator Loss: 0.4894\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Train : time 79.87 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Generator Loss: 6.2270 Discriminator Loss: 0.7967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m -----------mse_loss mean :  0.0471 std: 0.2836\n",
      "Round 1: Aggregated threshold = 0.2762\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Val: Accuracy: 0.9932  \n",
      "Counts of : original binary labels Counter({0: 156058, 1: 65271}) predicted binary labels Counter({0: 155275, 1: 66054})\n",
      "Counts of  original  labels: {0: 156058, 1: 65233, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 951, 1: 168}\n",
      "{0: 'threshold=0.2762 ,Test : Accuracy: 0.9949 Recall : 0.9974 FDR: 0.0144  F1-score: 0.9915 '}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (1, 0.48734678493328937, {0: 'threshold=0.2762 ,Test : Accuracy: 0.9949 Recall : 0.9974 FDR: 0.0144  F1-score: 0.9915 '}, 1304.0023682550018)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model AdversarialAutoencoder is saved in fed_best_models/FED_PROX_AdversarialAutoencoder_f1_0.99_recall_1.00_.pth\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Train : time 84.67 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Generator Loss: 4.1141 Discriminator Loss: 0.9664\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Train : time 88.04 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Generator Loss: 4.0689 Discriminator Loss: 1.5014\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Train : time 95.11 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Generator Loss: 3.5488 Discriminator Loss: 2.5702\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m -----------mse_loss mean :  0.0196 std: 0.1664\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Val: Accuracy: 0.9931  \n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Train : time 119.94 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Generator Loss: 4.1929 Discriminator Loss: 1.0361\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Train : time 119.88 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Generator Loss: 4.1083 Discriminator Loss: 2.3250\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/flwr/server/server.py:353\u001b[0m, in \u001b[0;36mfit_clients\u001b[0;34m(client_instructions, max_workers, timeout, group_id)\u001b[0m\n\u001b[1;32m    349\u001b[0m     submitted_fs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    350\u001b[0m         executor\u001b[38;5;241m.\u001b[39msubmit(fit_client, client_proxy, ins, timeout, group_id)\n\u001b[1;32m    351\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m client_proxy, ins \u001b[38;5;129;01min\u001b[39;00m client_instructions\n\u001b[1;32m    352\u001b[0m     }\n\u001b[0;32m--> 353\u001b[0m     finished_fs, _ \u001b[38;5;241m=\u001b[39m \u001b[43mconcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubmitted_fs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Handled in the respective communication stack\u001b[39;49;00m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;66;03m# Gather results\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:307\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(fs, timeout, return_when)\u001b[0m\n\u001b[1;32m    305\u001b[0m     waiter \u001b[38;5;241m=\u001b[39m _create_and_install_waiters(fs, return_when)\n\u001b[0;32m--> 307\u001b[0m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fs:\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# --- Start the Simulation ---\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting federated learning simulation...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mfl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_simulation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_clients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNUM_TRAIN_CLIENTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mServerConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNUM_ROUNDS\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_resources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_cpus\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_gpus\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_cpus\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFederated learning simulation finished.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/flwr/simulation/legacy_app.py:361\u001b[0m, in \u001b[0;36mstart_simulation\u001b[0;34m(client_fn, num_clients, clients_ids, client_resources, server, config, strategy, client_manager, ray_init_args, keep_initialised, actor_type, actor_kwargs, actor_scheduling)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[0;32m--> 361\u001b[0m     hist \u001b[38;5;241m=\u001b[39m \u001b[43mrun_fl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitialized_server\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitialized_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m    366\u001b[0m     log(ERROR, ex)\n",
      "File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/flwr/server/server.py:492\u001b[0m, in \u001b[0;36mrun_fl\u001b[0;34m(server, config)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_fl\u001b[39m(\n\u001b[1;32m    488\u001b[0m     server: Server,\n\u001b[1;32m    489\u001b[0m     config: ServerConfig,\n\u001b[1;32m    490\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m History:\n\u001b[1;32m    491\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train a model on the given server and return the History object.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 492\u001b[0m     hist, elapsed_time \u001b[38;5;241m=\u001b[39m \u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mround_timeout\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    496\u001b[0m     log(INFO, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    497\u001b[0m     log(INFO, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[SUMMARY]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/flwr/server/server.py:115\u001b[0m, in \u001b[0;36mServer.fit\u001b[0;34m(self, num_rounds, timeout)\u001b[0m\n\u001b[1;32m    113\u001b[0m log(INFO, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[ROUND \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m, current_round)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# Train model and replace previous global model\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m res_fit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_round\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurrent_round\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res_fit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     parameters_prime, fit_metrics, _ \u001b[38;5;241m=\u001b[39m res_fit  \u001b[38;5;66;03m# fit_metrics_aggregated\u001b[39;00m\n",
      "File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/flwr/server/server.py:234\u001b[0m, in \u001b[0;36mServer.fit_round\u001b[0;34m(self, server_round, timeout)\u001b[0m\n\u001b[1;32m    226\u001b[0m log(\n\u001b[1;32m    227\u001b[0m     INFO,\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigure_fit: strategy sampled \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m clients (out of \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28mlen\u001b[39m(client_instructions),\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_manager\u001b[38;5;241m.\u001b[39mnum_available(),\n\u001b[1;32m    231\u001b[0m )\n\u001b[1;32m    233\u001b[0m \u001b[38;5;66;03m# Collect `fit` results from all clients participating in this round\u001b[39;00m\n\u001b[0;32m--> 234\u001b[0m results, failures \u001b[38;5;241m=\u001b[39m \u001b[43mfit_clients\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_instructions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_instructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_round\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m log(\n\u001b[1;32m    241\u001b[0m     INFO,\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggregate_fit: received \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m results and \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m failures\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28mlen\u001b[39m(results),\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28mlen\u001b[39m(failures),\n\u001b[1;32m    245\u001b[0m )\n\u001b[1;32m    247\u001b[0m \u001b[38;5;66;03m# Aggregate training results\u001b[39;00m\n",
      "File \u001b[0;32m~/labeling/Project1404/FLBased-ICS-NIDS/vnv/lib/python3.10/site-packages/flwr/server/server.py:348\u001b[0m, in \u001b[0;36mfit_clients\u001b[0;34m(client_instructions, max_workers, timeout, group_id)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit_clients\u001b[39m(\n\u001b[1;32m    342\u001b[0m     client_instructions: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[ClientProxy, FitIns]],\n\u001b[1;32m    343\u001b[0m     max_workers: Optional[\u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m    344\u001b[0m     timeout: Optional[\u001b[38;5;28mfloat\u001b[39m],\n\u001b[1;32m    345\u001b[0m     group_id: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m    346\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FitResultsAndFailures:\n\u001b[1;32m    347\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Refine parameters concurrently on all selected clients.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 348\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mThreadPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39mmax_workers) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m    349\u001b[0m         submitted_fs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    350\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(fit_client, client_proxy, ins, timeout, group_id)\n\u001b[1;32m    351\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m client_proxy, ins \u001b[38;5;129;01min\u001b[39;00m client_instructions\n\u001b[1;32m    352\u001b[0m         }\n\u001b[1;32m    353\u001b[0m         finished_fs, _ \u001b[38;5;241m=\u001b[39m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mwait(\n\u001b[1;32m    354\u001b[0m             fs\u001b[38;5;241m=\u001b[39msubmitted_fs,\n\u001b[1;32m    355\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# Handled in the respective communication stack\u001b[39;00m\n\u001b[1;32m    356\u001b[0m         )\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:649\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 649\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/thread.py:235\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads:\n\u001b[0;32m--> 235\u001b[0m         \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:1096\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1096\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:1116\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1117\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1118\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Train : time 119.33 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Generator Loss: 3.0342 Discriminator Loss: 2.9670\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m -----------mse_loss mean :  0.0159 std: 0.1333\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Val: Accuracy: 0.9944  \n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Train : time 119.72 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Generator Loss: 4.1789 Discriminator Loss: 1.0082\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Train : time 108.03 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Generator Loss: 4.0193 Discriminator Loss: 2.0101\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Train : time 113.99 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Generator Loss: 2.9522 Discriminator Loss: 2.7669\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m -----------mse_loss mean :  0.0166 std: 0.1413\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Val: Accuracy: 0.9928  \n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Train : time 106.53 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Generator Loss: 4.3807 Discriminator Loss: 0.9481\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Train : time 99.86 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Generator Loss: 4.3755 Discriminator Loss: 2.2909\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Train : time 112.95 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Generator Loss: 3.4315 Discriminator Loss: 2.8457\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m -----------mse_loss mean :  0.0164 std: 0.1441\n",
      "\u001b[36m(ClientAppActor pid=139326)\u001b[0m Val: Accuracy: 0.9953  \n"
     ]
    }
   ],
   "source": [
    "# Instantiate the configuration\n",
    "cfg.STRATEGY=\"FED_PROX\"\n",
    "cfg.MODEL_NAME=\"AAE\"\n",
    "strategy=set_server_strategy()\n",
    "\n",
    "# --- Start the Simulation ---\n",
    "print(\"Starting federated learning simulation...\")\n",
    "history = fl.simulation.start_simulation(\n",
    "    client_fn=client_function,\n",
    "    num_clients=cfg.NUM_TRAIN_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=cfg.NUM_ROUNDS),\n",
    "    strategy=strategy,\n",
    "    client_resources={\"num_cpus\": 1, \"num_gpus\": 1} if DEVICE.type == \"cuda\" else {\"num_cpus\": 1},\n",
    ")\n",
    "print(\"Federated learning simulation finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9462e083",
   "metadata": {},
   "source": [
    "#### FedAVG evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9919de72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-24-labeled.csv',\n",
       " './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-28-labeled.csv',\n",
       " './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-30-labeled.csv',\n",
       " './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-22-labeled.csv']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[col for sublist in SERVER_EVALUATION_DATA_MAPPING[:-1] for col in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d71893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The CIC Modbus Dataset contains network (pcap) captures and attack logs from a simulated substation network.\n",
      "                The dataset is categorized into two groups: an attack dataset and a benign dataset\n",
      "                The attack dataset includes network traffic captures that simulate various types of Modbus protocol attacks in a substation environment.\n",
      "                The attacks are reconnaissance, query flooding, loading payloads, delay response, modify length parameters, false data injection, stacking Modbus frames, brute force write and baseline replay.\n",
      "                These attacks are based of some techniques in the MITRE ICS ATT&CK framework.\n",
      "                On the other hand, the benign dataset consists of normal network traffic captures representing legitimate Modbus communication within the substation network.\n",
      "                The purpose of this dataset is to facilitate research, analysis, and development of intrusion detection systems, anomaly detection algorithms and other security mechanisms for substation networks using the Modbus protocol.\n",
      "                https://www.unb.ca/cic/datasets/modbus-2023.html\n",
      "                In my custom PyTorch Dataset class,\n",
      "                I utilize the Enhanced CICflowMeter and the Attack logs correlation to extract and label sequential data flows,\n",
      "                preparing them for batch processing with the DataLoader, which is crucial for AI model training.\n",
      "                https://github.com/hamid-rd/FLBased-ICS-NIDS/tree/main\n",
      "\n",
      "                \n",
      "csv files  in the dataset directory founded with the filter:  ready\n",
      "{\n",
      "    \"total_dataset_num\": 170,\n",
      "    \"benign_dataset_num\": 62,\n",
      "    \"attack_dataset_num\": {\n",
      "        \"total_num\": 108,\n",
      "        \"external_num\": 8,\n",
      "        \"compromised-ied_num\": 43,\n",
      "        \"compromised-scada_num\": 57\n",
      "    },\n",
      "    \"attack_logs_num\": {\n",
      "        \"total_num\": 34,\n",
      "        \"external_num\": [\n",
      "            \"./ModbusDataset/attack/external/external-attacker/attacker logs/02-01-2023/02-01-2023-1.csv\",\n",
      "            \"./ModbusDataset/attack/external/external-attacker/attacker logs/12-29-2022/12-29-2022-1.csv\",\n",
      "            \"./ModbusDataset/attack/external/external-attacker/attacker logs/01-17-2023/01-17-2023-1.csv\",\n",
      "            \"./ModbusDataset/attack/external/external-attacker/attacker logs/01-02-2023/01-02-2023-1.csv\",\n",
      "            \"./ModbusDataset/attack/external/external-attacker/attacker logs/12-30-2022/12-30-2022-1.csv\",\n",
      "            \"./ModbusDataset/attack/external/external-attacker/attacker logs/01-01-2023/01-01-2023-1.csv\"\n",
      "        ],\n",
      "        \"compromised-ied_num\": 7,\n",
      "        \"compromised-scada_num\": 21\n",
      "    }\n",
      "}\n",
      "scenario : compromised-scada\n",
      "----------- benign valid files: 4 ['./ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-24-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-28-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-30-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-22-labeled.csv']\n",
      "----------compromised-scada attack  test files :  7 ['./ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-3-labeled.csv', './ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-4-labeled.csv', './ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-1-labeled.csv', './ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-7-labeled.csv', './ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-0-labeled.csv', './ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-5-labeled.csv', './ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-2-labeled.csv']\n",
      "********** AdversarialAutoencoder **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0167 std: 0.1959\n",
      "Val: Accuracy: 0.9935  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.2125\n",
      "Counts of : original binary labels Counter({0: 529457, 1: 220322}) predicted binary labels Counter({0: 561806, 1: 187973})\n",
      "Counts of  original  labels: {0: 529457, 1: 218884, 2: 317, 3: 236, 4: 243, 5: 240, 6: 170, 7: 232}\n",
      "Counts of misclassified original labels: {0: 7942, 1: 40034, 2: 58, 3: 96, 4: 32, 5: 2, 6: 68, 7: 1}\n",
      "Test : Accuracy: 0.9357 Recall : 0.8171 FDR: 0.0423  F1-score: 0.8819  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.6043\n",
      "Counts of : original binary labels Counter({0: 529457, 1: 220322}) predicted binary labels Counter({0: 601749, 1: 148030})\n",
      "Counts of  original  labels: {0: 529457, 1: 218884, 2: 317, 3: 236, 4: 243, 5: 240, 6: 170, 7: 232}\n",
      "Counts of misclassified original labels: {0: 6908, 1: 78527, 2: 100, 3: 183, 4: 42, 5: 2, 6: 114, 7: 232}\n",
      "Test : Accuracy: 0.8852 Recall : 0.6405 FDR: 0.0467  F1-score: 0.7662  \n",
      "********** VAE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0467 std: 0.3384\n",
      "Val: Accuracy: 0.8697  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.3851\n",
      "Counts of : original binary labels Counter({0: 529457, 1: 220322}) predicted binary labels Counter({0: 562532, 1: 187247})\n",
      "Counts of  original  labels: {0: 529457, 1: 218884, 2: 317, 3: 236, 4: 243, 5: 240, 6: 170, 7: 232}\n",
      "Counts of misclassified original labels: {0: 9353, 1: 41962, 2: 59, 3: 99, 4: 41, 5: 2, 6: 69, 7: 196}\n",
      "Test : Accuracy: 0.9309 Recall : 0.8074 FDR: 0.0500  F1-score: 0.8730  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.062\n",
      "Counts of : original binary labels Counter({0: 529457, 1: 220322}) predicted binary labels Counter({0: 564536, 1: 185243})\n",
      "Counts of  original  labels: {0: 529457, 1: 218884, 2: 317, 3: 236, 4: 243, 5: 240, 6: 170, 7: 232}\n",
      "Counts of misclassified original labels: {0: 8000, 1: 42568, 2: 59, 3: 99, 4: 41, 5: 10, 6: 70, 7: 232}\n",
      "Test : Accuracy: 0.9319 Recall : 0.8045 FDR: 0.0432  F1-score: 0.8741  \n",
      "********** AE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0230 std: 0.2549\n",
      "Val: Accuracy: 0.9503  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.2779\n",
      "Counts of : original binary labels Counter({0: 529457, 1: 220322}) predicted binary labels Counter({0: 561816, 1: 187963})\n",
      "Counts of  original  labels: {0: 529457, 1: 218884, 2: 317, 3: 236, 4: 243, 5: 240, 6: 170, 7: 232}\n",
      "Counts of misclassified original labels: {0: 7942, 1: 40034, 2: 58, 3: 96, 4: 42, 5: 2, 6: 68, 7: 1}\n",
      "Test : Accuracy: 0.9357 Recall : 0.8171 FDR: 0.0423  F1-score: 0.8818  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.7876\n",
      "Counts of : original binary labels Counter({0: 529457, 1: 220322}) predicted binary labels Counter({0: 564676, 1: 185103})\n",
      "Counts of  original  labels: {0: 529457, 1: 218884, 2: 317, 3: 236, 4: 243, 5: 240, 6: 170, 7: 232}\n",
      "Counts of misclassified original labels: {0: 7883, 1: 42590, 2: 59, 3: 99, 4: 42, 5: 10, 6: 70, 7: 232}\n",
      "Test : Accuracy: 0.9320 Recall : 0.8044 FDR: 0.0426  F1-score: 0.8742  \n",
      "scenario : external\n",
      "----------- benign valid files: 4 ['./ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-24-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-28-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-30-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-22-labeled.csv']\n",
      "----------external attack  test files :  2 ['./ModbusDataset/attack/external/network-wide/ready/network-wide-normal-1-labeled.csv', './ModbusDataset/attack/external/network-wide/ready/network-wide-normal-0-labeled.csv']\n",
      "********** AdversarialAutoencoder **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0167 std: 0.1959\n",
      "Val: Accuracy: 0.9935  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.2125\n",
      "Counts of : original binary labels Counter({0: 156058, 1: 65271}) predicted binary labels Counter({0: 155306, 1: 66023})\n",
      "Counts of  original  labels: {0: 156058, 1: 65233, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 917, 1: 165}\n",
      "Test : Accuracy: 0.9951 Recall : 0.9975 FDR: 0.0139  F1-score: 0.9918  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.6043\n",
      "Counts of : original binary labels Counter({0: 156058, 1: 65271}) predicted binary labels Counter({0: 194475, 1: 26854})\n",
      "Counts of  original  labels: {0: 156058, 1: 65233, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 889, 1: 39298, 6: 8}\n",
      "Test : Accuracy: 0.8184 Recall : 0.3978 FDR: 0.0331  F1-score: 0.5637  \n",
      "********** VAE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0468 std: 0.3387\n",
      "Val: Accuracy: 0.8707  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.3855\n",
      "Counts of : original binary labels Counter({0: 156058, 1: 65271}) predicted binary labels Counter({0: 164741, 1: 56588})\n",
      "Counts of  original  labels: {0: 156058, 1: 65233, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 1268, 1: 9945, 6: 6}\n",
      "Test : Accuracy: 0.9493 Recall : 0.8475 FDR: 0.0224  F1-score: 0.9079  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.063\n",
      "Counts of : original binary labels Counter({0: 156058, 1: 65271}) predicted binary labels Counter({0: 194372, 1: 26957})\n",
      "Counts of  original  labels: {0: 156058, 1: 65233, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 982, 1: 39287, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8180 Recall : 0.3980 FDR: 0.0364  F1-score: 0.5633  \n",
      "********** AE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0230 std: 0.2549\n",
      "Val: Accuracy: 0.9503  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.2779\n",
      "Counts of : original binary labels Counter({0: 156058, 1: 65271}) predicted binary labels Counter({0: 155274, 1: 66055})\n",
      "Counts of  original  labels: {0: 156058, 1: 65233, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 949, 1: 165}\n",
      "Test : Accuracy: 0.9950 Recall : 0.9975 FDR: 0.0144  F1-score: 0.9915  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.7876\n",
      "Counts of : original binary labels Counter({0: 156058, 1: 65271}) predicted binary labels Counter({0: 194422, 1: 26907})\n",
      "Counts of  original  labels: {0: 156058, 1: 65233, 2: 1, 3: 1, 4: 1, 5: 2, 6: 32, 7: 1}\n",
      "Counts of misclassified original labels: {0: 943, 1: 39299, 6: 8}\n",
      "Test : Accuracy: 0.8181 Recall : 0.3978 FDR: 0.0350  F1-score: 0.5633  \n",
      "scenario : compromised-ied\n",
      "----------- benign valid files: 4 ['./ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-24-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-28-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-30-labeled.csv', './ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-22-labeled.csv']\n",
      "----------compromised-ied attack  test files :  20 ['./ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-2-labeled.csv', './ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-10-labeled.csv', './ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-19-labeled.csv', './ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-17-labeled.csv', './ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-0-labeled.csv', './ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-9-labeled.csv', './ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-15-labeled.csv', './ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-3-labeled.csv', './ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-7-labeled.csv', './ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-14-labeled.csv', './ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-12-labeled.csv', './ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-18-labeled.csv', './ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-6-labeled.csv', './ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-16-labeled.csv', './ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-8-labeled.csv', './ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-1-labeled.csv', './ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-13-labeled.csv', './ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-4-labeled.csv', './ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-5-labeled.csv', './ModbusDataset/attack/compromised-ied/trust-scada-hmi/trust-scada-network-captures/ready/veth3efd353-11-labeled.csv']\n",
      "********** AdversarialAutoencoder **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0167 std: 0.1959\n",
      "Val: Accuracy: 0.9935  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.2125\n",
      "Counts of : original binary labels Counter({0: 2552713, 1: 356}) predicted binary labels Counter({0: 2533884, 1: 19185})\n",
      "Counts of  original  labels: {0: 2552713, 2: 64, 3: 78, 4: 51, 5: 61, 7: 59, 8: 43}\n",
      "Counts of misclassified original labels: {0: 19086, 2: 64, 3: 78, 4: 36, 7: 59, 8: 20}\n",
      "Test : Accuracy: 0.9924 Recall : 0.2781 FDR: 0.9948  F1-score: 0.0101  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.6043\n",
      "Counts of : original binary labels Counter({0: 2552713, 1: 356}) predicted binary labels Counter({0: 2534447, 1: 18622})\n",
      "Counts of  original  labels: {0: 2552713, 2: 64, 3: 78, 4: 51, 5: 61, 7: 59, 8: 43}\n",
      "Counts of misclassified original labels: {0: 18540, 2: 64, 3: 78, 4: 48, 5: 1, 7: 59, 8: 24}\n",
      "Test : Accuracy: 0.9926 Recall : 0.2303 FDR: 0.9956  F1-score: 0.0086  \n",
      "********** VAE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0468 std: 0.3393\n",
      "Val: Accuracy: 0.8698  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.3861\n",
      "Counts of : original binary labels Counter({0: 2552713, 1: 356}) predicted binary labels Counter({0: 2521802, 1: 31267})\n",
      "Counts of  original  labels: {0: 2552713, 2: 64, 3: 78, 4: 51, 5: 61, 7: 59, 8: 43}\n",
      "Counts of misclassified original labels: {0: 31183, 2: 64, 3: 78, 4: 44, 7: 59, 8: 27}\n",
      "Test : Accuracy: 0.9877 Recall : 0.2360 FDR: 0.9973  F1-score: 0.0053  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.065\n",
      "Counts of : original binary labels Counter({0: 2552713, 1: 356}) predicted binary labels Counter({0: 2528302, 1: 24767})\n",
      "Counts of  original  labels: {0: 2552713, 2: 64, 3: 78, 4: 51, 5: 61, 7: 59, 8: 43}\n",
      "Counts of misclassified original labels: {0: 24700, 2: 64, 3: 78, 4: 51, 7: 59, 8: 37}\n",
      "Test : Accuracy: 0.9902 Recall : 0.1882 FDR: 0.9973  F1-score: 0.0053  \n",
      "********** AE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0230 std: 0.2549\n",
      "Val: Accuracy: 0.9503  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.2779\n",
      "Counts of : original binary labels Counter({0: 2552713, 1: 356}) predicted binary labels Counter({0: 2525303, 1: 27766})\n",
      "Counts of  original  labels: {0: 2552713, 2: 64, 3: 78, 4: 51, 5: 61, 7: 59, 8: 43}\n",
      "Counts of misclassified original labels: {0: 27683, 2: 64, 3: 78, 4: 48, 7: 59, 8: 24}\n",
      "Test : Accuracy: 0.9891 Recall : 0.2331 FDR: 0.9970  F1-score: 0.0059  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.7876\n",
      "Counts of : original binary labels Counter({0: 2552713, 1: 356}) predicted binary labels Counter({0: 2529570, 1: 23499})\n",
      "Counts of  original  labels: {0: 2552713, 2: 64, 3: 78, 4: 51, 5: 61, 7: 59, 8: 43}\n",
      "Counts of misclassified original labels: {0: 23429, 2: 64, 3: 78, 4: 51, 7: 59, 8: 34}\n",
      "Test : Accuracy: 0.9907 Recall : 0.1966 FDR: 0.9970  F1-score: 0.0059  \n"
     ]
    }
   ],
   "source": [
    "dataset_directory = \"./ModbusDataset/\" \n",
    "\n",
    "modbus = ModbusDataset(dataset_directory,\"ready\")\n",
    "modbus.summary_print()\n",
    "\n",
    "Trained_AE_model=AE(input_dim=76)\n",
    "Trained_AE_model.load_state_dict(torch.load(\"./fed_best_models/FED_AVG_AE_f1_0.99_recall_1.00_.pth\"))\n",
    "Trained_VAE_model=VAE(input_dim=76)\n",
    "Trained_VAE_model.load_state_dict(torch.load(\"./fed_best_models/FED_AVG_VAE_f1_0.88_recall_1.00_.pth\"))\n",
    "Trained_AAE_model=AdversarialAutoencoder()\n",
    "Trained_AAE_model.load_state_dict(torch.load(\"./fed_best_models/FED_AVG_AdversarialAutoencoder_f1_0.99_recall_1.00_.pth\"))\n",
    "val_files=[col for sublist in SERVER_EVALUATION_DATA_MAPPING[:-1] for col in sublist]\n",
    "\n",
    "\n",
    "for scenario in {\"compromised-ied\",\"external\",\"compromised-scada\"}:\n",
    "    if scenario==\"compromised-scada\":\n",
    "        print(\"scenario :\",scenario)\n",
    "        dataset_directory = \"./ModbusDataset\" \n",
    "        test_files= [col for col in modbus.dataset[\"attack_dataset_dir\"][scenario] if col.find(\"ied1b\")!=-1]\n",
    "        ### missed attack logs for the day 21 for ied1b which can reduce the accuracy.\n",
    "        test_files.remove(dataset_directory+\"attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-6-labeled.csv\")    \n",
    "\n",
    "    elif scenario==\"compromised-ied\":\n",
    "        print(\"scenario :\",scenario)\n",
    "        test_files= [col for col in modbus.dataset[\"attack_dataset_dir\"][scenario] if col.find(\"trust-scada-hmi\")!=-1]\n",
    "    else:\n",
    "        print(\"scenario :\",scenario)\n",
    "        test_files= [col for col in modbus.dataset[\"attack_dataset_dir\"][scenario] if col.find(\"network-wide\")!=-1]        \n",
    "\n",
    "    print(\"----------- benign valid files:\",len(val_files),val_files)\n",
    "    print(f\"----------{scenario} attack  test files : \",len(test_files),test_files)\n",
    "    val_dataloader=DataLoader(ModbusFlowStream(\n",
    "                shuffle=False,\n",
    "                chunk_size=1,\n",
    "                batch_size=64,\n",
    "                csv_files=val_files,\n",
    "                scalers=loaded_scalers['network-wide']['min_max_scalers'],\n",
    "            ),batch_size=1,shuffle=False)\n",
    "    test_dataloader=DataLoader(ModbusFlowStream(\n",
    "                shuffle=False,\n",
    "                chunk_size=1,\n",
    "                batch_size=64,\n",
    "                csv_files=test_files,\n",
    "                scalers=loaded_scalers['network-wide']['min_max_scalers'],\n",
    "            ),batch_size=1,shuffle=False)\n",
    "    for trained_model in {Trained_AE_model,Trained_VAE_model,Trained_AAE_model}:\n",
    "        print(\"*\"*10,trained_model._get_name(),10*\"*\")\n",
    "        train_eval(trained_model,None,val_dataloader,test_dataloader,shuffle_files=False,num_epochs=1,eval_epoch=1,criterion_method=\"mse\",train_model=False,learning_rates=[0],weight_decays=[0])\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7758849,
     "sourceId": 12309500,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 250292947,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "vnv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
