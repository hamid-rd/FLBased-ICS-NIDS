{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d32826f1-1369-4eb5-a21b-0e6e548cded3",
   "metadata": {},
   "source": [
    "### Download and make the dataset ready in Kaggle \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26c2ad5c-f43a-4b40-a647-ecc58c71ff16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T16:17:38.693282Z",
     "iopub.status.busy": "2025-07-13T16:17:38.692671Z",
     "iopub.status.idle": "2025-07-13T16:20:31.990912Z",
     "shell.execute_reply": "2025-07-13T16:20:31.990108Z",
     "shell.execute_reply.started": "2025-07-13T16:17:38.693248Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# ## uncomment if The zip file of the dataset isn't downloaded,extraced \n",
    "# !pip install gdown\n",
    "# Copy the link. The file ID is the long string of characters between d/ and /view.\n",
    "#For example, in the URL https://drive.google.com/file/d/1aBcDeFgHiJkLmNoPqRsTuVwXyZ/view?usp=sharing, \n",
    "#the file ID is 1aBcDeFgHiJkLmNoPqRsTuVwXyZ\n",
    "# !mkdir /kaggle/tmp\n",
    "# !gdown  1pzXpA5Cz0DJmjRsLxlqRNnJq-kOUvojb -O /kaggle/tmp/Labeled_CICMODBUS2023.zip\n",
    "# !unzip /kaggle/tmp/Labeled_CICMODBUS2023.zip -d /kaggle/working/\n",
    "\n",
    "# # ## uncomment if the python modules (modbus.py,utils.py ,...) not cloned  and added to the path \n",
    "\n",
    "# !git clone https://github.com/hamid-rd/FLBased-ICS-NIDS.git\n",
    "# import sys\n",
    "# # Add the repository folder to the Python path\n",
    "# repo_path = '/kaggle/working/FLBased-ICS-NIDS'\n",
    "# repo_input_path = '/kaggle/input/training/FLBased-ICS-NIDS'\n",
    "# dataset_path = '/kaggle/input/training/'\n",
    "\n",
    "# for path in {repo_path,repo_input_path,dataset_path}:\n",
    "#     if path not in sys.path:\n",
    "#         sys.path.append(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "601bb537-782e-4266-b619-48cdad4fe6a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T16:25:34.078617Z",
     "iopub.status.busy": "2025-07-13T16:25:34.077721Z",
     "iopub.status.idle": "2025-07-13T16:25:34.430103Z",
     "shell.execute_reply": "2025-07-13T16:25:34.429493Z",
     "shell.execute_reply.started": "2025-07-13T16:25:34.078584Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The CIC Modbus Dataset contains network (pcap) captures and attack logs from a simulated substation network.\n",
      "                The dataset is categorized into two groups: an attack dataset and a benign dataset\n",
      "                The attack dataset includes network traffic captures that simulate various types of Modbus protocol attacks in a substation environment.\n",
      "                The attacks are reconnaissance, query flooding, loading payloads, delay response, modify length parameters, false data injection, stacking Modbus frames, brute force write and baseline replay.\n",
      "                These attacks are based of some techniques in the MITRE ICS ATT&CK framework.\n",
      "                On the other hand, the benign dataset consists of normal network traffic captures representing legitimate Modbus communication within the substation network.\n",
      "                The purpose of this dataset is to facilitate research, analysis, and development of intrusion detection systems, anomaly detection algorithms and other security mechanisms for substation networks using the Modbus protocol.\n",
      "                https://www.unb.ca/cic/datasets/modbus-2023.html\n",
      "                In my custom PyTorch Dataset class,\n",
      "                I utilize the Enhanced CICflowMeter and the Attack logs correlation to extract and label sequential data flows,\n",
      "                preparing them for batch processing with the DataLoader, which is crucial for AI model training.\n",
      "                https://github.com/hamid-rd/FLBased-ICS-NIDS/tree/main\n",
      "\n",
      "                \n",
      "csv files  in the dataset directory founded with the filter:  ready\n",
      "{\n",
      "    \"total_dataset_num\": 170,\n",
      "    \"benign_dataset_num\": 62,\n",
      "    \"attack_dataset_num\": {\n",
      "        \"total_num\": 108,\n",
      "        \"external_num\": 8,\n",
      "        \"compromised-ied_num\": 43,\n",
      "        \"compromised-scada_num\": 57\n",
      "    },\n",
      "    \"attack_logs_num\": {\n",
      "        \"total_num\": 0,\n",
      "        \"external_num\": [],\n",
      "        \"compromised-ied_num\": 0,\n",
      "        \"compromised-scada_num\": 0\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# To test if every thing is okay (modbus.py class and correct number of founded csv files )\n",
    "from modbus import ModbusDataset,ModbusFlowStream\n",
    "\n",
    "# dataset_directory = \"/kaggle/working/ModbusDataset\" \n",
    "# dataset_directory = \"/kaggle/input/training/ModbusDataset\" \n",
    "dataset_directory = \"dataset\" \n",
    "\n",
    "modbus = ModbusDataset(dataset_directory,\"ready\")\n",
    "modbus.summary_print()\n",
    "\n",
    "# Don't forget to save version in kaggle (to save outputs written on the disk (/kaggle/working/))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d238262",
   "metadata": {},
   "source": [
    "### Unsupervised Autoencoder training  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2c01e06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T16:25:38.158958Z",
     "iopub.status.busy": "2025-07-13T16:25:38.158509Z",
     "iopub.status.idle": "2025-07-13T16:25:38.167563Z",
     "shell.execute_reply": "2025-07-13T16:25:38.166807Z",
     "shell.execute_reply.started": "2025-07-13T16:25:38.158938Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np # For standard deviation calculation\n",
    "from modbus import ModbusDataset,ModbusFlowStream\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix,recall_score\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "from utils import load_scalers\n",
    "import random\n",
    "from random import SystemRandom\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import torch.nn.init as init\n",
    "import flwr as fl\n",
    "import ray\n",
    "from collections import Counter\n",
    "from flwr.common import ndarrays_to_parameters\n",
    "\n",
    "def compute_threshold(mse_values,k=1):\n",
    "\n",
    "    \"\"\"\n",
    "    K-SIGMA\n",
    "    Computes the anomaly detection threshold (for marking sample as Intrusion if the IS was greater )\n",
    "    based on the mean and standard deviation of Mean Squared Error (MSE) values.\n",
    "    Formula: thr = mean(MSE) + std(MSE)\n",
    "    Args:\n",
    "    mse_values (torch.Tensor or list/np.array): A tensor or list of MSE values\n",
    "\n",
    "                            obtained from the validation set.\n",
    "    Returns:\n",
    "    float: The calculated threshold.\n",
    "    float: The calculated std.\n",
    "\n",
    "    \"\"\"\n",
    "    if not isinstance(mse_values, torch.Tensor):\n",
    "        mse_values = torch.tensor(mse_values, dtype=torch.float32)\n",
    "    if mse_values.numel() == 0:\n",
    "        return 0.0\n",
    "    mean_mse = torch.mean(mse_values)\n",
    "    std_mse = torch.std(mse_values)\n",
    "    print(\"-----------mse_loss mean : \",f\"{mean_mse.item():.4f}\",\"std:\",f\"{std_mse.item():.4f}\")\n",
    "    threshold = mean_mse + k*std_mse\n",
    "    return threshold.item(),std_mse.item()\n",
    "\n",
    "def vae_loss_function(recon_x, x, mu, logvar,beta =1):\n",
    "    \"\"\"\n",
    "    VAE loss function.\n",
    "    \"\"\"\n",
    "    BCE = nn.functional.mse_loss(recon_x, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return (BCE + beta*KLD)\n",
    "\n",
    "def _init_weights( module):\n",
    "    ## for one layer apply Xavier Initialization\n",
    "    if isinstance(module, nn.Linear):\n",
    "        init.xavier_normal_(module.weight)\n",
    "        if module.bias is not None:\n",
    "            init.zeros_(module.bias)\n",
    "    return module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9478520",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T16:25:42.807302Z",
     "iopub.status.busy": "2025-07-13T16:25:42.807033Z",
     "iopub.status.idle": "2025-07-13T16:25:42.941019Z",
     "shell.execute_reply": "2025-07-13T16:25:42.940221Z",
     "shell.execute_reply.started": "2025-07-13T16:25:42.807283Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The CIC Modbus Dataset contains network (pcap) captures and attack logs from a simulated substation network.\n",
      "                The dataset is categorized into two groups: an attack dataset and a benign dataset\n",
      "                The attack dataset includes network traffic captures that simulate various types of Modbus protocol attacks in a substation environment.\n",
      "                The attacks are reconnaissance, query flooding, loading payloads, delay response, modify length parameters, false data injection, stacking Modbus frames, brute force write and baseline replay.\n",
      "                These attacks are based of some techniques in the MITRE ICS ATT&CK framework.\n",
      "                On the other hand, the benign dataset consists of normal network traffic captures representing legitimate Modbus communication within the substation network.\n",
      "                The purpose of this dataset is to facilitate research, analysis, and development of intrusion detection systems, anomaly detection algorithms and other security mechanisms for substation networks using the Modbus protocol.\n",
      "                https://www.unb.ca/cic/datasets/modbus-2023.html\n",
      "                In my custom PyTorch Dataset class,\n",
      "                I utilize the Enhanced CICflowMeter and the Attack logs correlation to extract and label sequential data flows,\n",
      "                preparing them for batch processing with the DataLoader, which is crucial for AI model training.\n",
      "                https://github.com/hamid-rd/FLBased-ICS-NIDS/tree/main\n",
      "\n",
      "                \n",
      "csv files  in the dataset directory founded with the filter:  ready\n",
      "{\n",
      "    \"total_dataset_num\": 170,\n",
      "    \"benign_dataset_num\": 62,\n",
      "    \"attack_dataset_num\": {\n",
      "        \"total_num\": 108,\n",
      "        \"external_num\": 8,\n",
      "        \"compromised-ied_num\": 43,\n",
      "        \"compromised-scada_num\": 57\n",
      "    },\n",
      "    \"attack_logs_num\": {\n",
      "        \"total_num\": 0,\n",
      "        \"external_num\": [],\n",
      "        \"compromised-ied_num\": 0,\n",
      "        \"compromised-scada_num\": 0\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# dataset_directory = \"/kaggle/input/training/ModbusDataset\" # change this to the folder contain benign and attack subdirs\n",
    "dataset_directory = \"dataset\" \n",
    "modbus = ModbusDataset(dataset_directory,\"ready\")\n",
    "modbus.summary_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0dede4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# AutoEncoder (AE)\n",
    "class AE(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder: (89-64-32)\n",
    "    Decoder: (32-64-89)\n",
    "    \"\"\"\n",
    "    def __init__(self,input_dim=89):\n",
    "        super(AE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        x_recon = self.decoder(z)\n",
    "        return x_recon\n",
    "\n",
    "\n",
    "# Variational AutoEncoder (VAE)\n",
    "class VAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder: (89-64-64-32 for mu and log_var)\n",
    "    Decoder: (32-64-64-89)\n",
    "    return x_recon, mu, logvar\n",
    "    \"\"\"\n",
    "    def __init__(self,input_dim=89):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(64, 32)\n",
    "        self.fc_logvar = nn.Linear(64, 32)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, input_dim),\n",
    "            nn.Sigmoid()\n",
    "                    )\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu = self.fc_mu(h)\n",
    "        logvar = self.fc_logvar(h)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_recon = self.decoder(z)\n",
    "        return x_recon, mu, logvar\n",
    "\n",
    "    \n",
    "class AAE_Encoder(nn.Module):\n",
    "    def __init__(self,input_dim=76):\n",
    "        \"\"\"\n",
    "        Encoder(Generator):(89-16-4-2)\n",
    "        \"\"\"\n",
    "        super(AAE_Encoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 16),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(16, 4),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(4, 2))\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "class AAE_Decoder(nn.Module):\n",
    "    def __init__(self,input_dim=76):\n",
    "        super(AAE_Decoder, self).__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2, 4),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(4, 16),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(16, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.decoder(x)\n",
    "class AAE_Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AAE_Discriminator, self).__init__()\n",
    "        # corrected to 2-16-4-1\n",
    "        self.discriminator = nn.Sequential(\n",
    "            nn.Linear(2, 16),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(16, 4),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(4, 1), \n",
    "            nn.Sigmoid()\n",
    "        )    \n",
    "    def forward(self, x):\n",
    "        return self.discriminator(x)\n",
    " \n",
    "class AdversarialAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AdversarialAutoencoder, self).__init__()\n",
    "        self.encoder = AAE_Encoder()\n",
    "        self.decoder = AAE_Decoder()\n",
    "        self.discriminator = AAE_Discriminator()\n",
    "    def forward(self, x):\n",
    "        fake_z = self.encoder(x)\n",
    "        x_recon = self.decoder(fake_z)\n",
    "        return fake_z,x_recon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436b79f1",
   "metadata": {},
   "source": [
    "### Centralized part \n",
    "\n",
    "##### You can go from here right to the FL part\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2d2e0ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T08:02:58.408647Z",
     "iopub.status.busy": "2025-07-13T08:02:58.407931Z",
     "iopub.status.idle": "2025-07-13T08:02:58.430831Z",
     "shell.execute_reply": "2025-07-13T08:02:58.430062Z",
     "shell.execute_reply.started": "2025-07-13T08:02:58.408625Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_eval(model,train_dataloader,val_dataloader,test_dataloader,learning_rates= [5e-6,1e-7,5e-5,1e-5,1e-6],\n",
    "               weight_decays=[1e-5,1e-4,1e-7],shuffle_files=True,num_epochs=20,eval_epoch=4,criterion_method=\"mse\", k_range=[1,3],train_model=True):\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model=model.to(device)\n",
    "    if criterion_method==\"bce\":\n",
    "        criterion = nn.BCELoss(reduction='sum').to(device)\n",
    "        eval_criterion = nn.BCELoss(reduction='none').to(device)\n",
    "    else: #mse\n",
    "        criterion = nn.MSELoss(reduction='sum').to(device)\n",
    "        eval_criterion = nn.MSELoss(reduction='none').to(device)\n",
    "    best_f1=0 #to save best version of the model during test\n",
    "    best_recall=0 #to save best version of the model during test\n",
    "\n",
    "    for lr, wd in itertools.product(learning_rates, weight_decays):\n",
    "        if model._get_name()==\"AdversarialAutoencoder\":\n",
    "            adversarial_criterion= nn.BCELoss(reduction=\"sum\")\n",
    "            optimizer_D = optim.SGD(model.discriminator.parameters(), lr=lr, weight_decay=wd)\n",
    "            optimizer_G =  optim.SGD(list(model.encoder.parameters()) + list(model.decoder.parameters()), lr=lr, weight_decay=wd)\n",
    "        else:\n",
    "            AE_optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "            ### new code\n",
    "            # AE_optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "        print(f\"\\n==================  lr={lr}, wd={wd} ==================\")\n",
    "        if train_model==True:\n",
    "            model.apply(_init_weights)\n",
    "        for epoch in range(num_epochs):\n",
    "            if train_model==True:\n",
    "                time_1 = time.time()\n",
    "                model.train()\n",
    "                train_loss = 0\n",
    "                ## for AAE\n",
    "                Discriminator_loss = 0\n",
    "                if shuffle_files:\n",
    "                    sys_rand = SystemRandom()\n",
    "                    sys_rand.shuffle(train_dataloader.dataset.csv_files)\n",
    "                for sequences, labels in train_dataloader:\n",
    "                    sequences=sequences.squeeze().to(device)\n",
    "                    if labels.sum()!=0:\n",
    "                        continue\n",
    "                    if model._get_name()==\"AdversarialAutoencoder\":\n",
    "                        target_ones= torch.ones(sequences.size(0), 1,device=device,dtype=torch.float)\n",
    "                        target_zeros= torch.zeros(sequences.size(0), 1,device=device,dtype=torch.float)\n",
    "                        random_latent = torch.randn(sequences.size(0), 2, device=device)\n",
    "                        optimizer_G.zero_grad()\n",
    "                        fake_z,decoded_seq = model(sequences)\n",
    "                        G_loss = 0.001*adversarial_criterion(model.discriminator(fake_z),target_ones ) + 0.999*criterion(decoded_seq, sequences)\n",
    "                        G_loss.backward()\n",
    "                        optimizer_G.step()\n",
    "                        # 2) discriminator loss\n",
    "                        optimizer_D.zero_grad()\n",
    "                        real_loss = adversarial_criterion(model.discriminator(random_latent), target_ones)\n",
    "                        fake_loss = adversarial_criterion(model.discriminator(fake_z.detach()),  target_zeros)\n",
    "                        D_loss = 0.5*(real_loss + fake_loss)\n",
    "                        D_loss.backward()\n",
    "                        optimizer_D.step()\n",
    "                        train_loss+=G_loss.item()\n",
    "                        Discriminator_loss+=D_loss.item()   \n",
    "                    else:\n",
    "                        AE_optimizer.zero_grad()\n",
    "                        if model._get_name()==\"AE\":\n",
    "                            recon = model(sequences)\n",
    "                            loss = criterion(recon, sequences) / sequences.size(0)\n",
    "                        elif model._get_name()==\"VAE\" or model._get_name()==\"GRUVAE\":\n",
    "                            recon, mu, logvar = model(sequences)\n",
    "                            loss = vae_loss_function(recon, sequences, mu, logvar) /sequences.size(0)\n",
    "                        loss.backward()\n",
    "                        AE_optimizer.step()\n",
    "                        train_loss += loss.item()\n",
    "                print(f\"Train : time {(time.time()-time_1):.2f} s\",\n",
    "                f\"Epoch {epoch+1}\")\n",
    "                if model._get_name()==\"AdversarialAutoencoder\":\n",
    "                    print(f\"Generator Loss: {train_loss / len(train_dataloader):.4f}\",\n",
    "                        f\"Discriminator Loss: {Discriminator_loss / len(train_dataloader):.4f}\")\n",
    "                else:\n",
    "                    print(f\"Train Loss: {train_loss / len(train_dataloader):.4f}\")\n",
    "            # Evaluate part\n",
    "            if (epoch + 1) % eval_epoch == 0:\n",
    "                model.eval() \n",
    "                all_val_losses = []\n",
    "                all_val_labels = []\n",
    "                print(f\"--- Running Evaluation for Epoch {epoch+1} lr ={lr} wd {wd} ---\")\n",
    "                with torch.no_grad():\n",
    "                    for sequences, labels in val_dataloader:\n",
    "                        sequences = sequences.squeeze().to(device) \n",
    "                        if labels.sum()!=0:\n",
    "                            continue\n",
    "                        if criterion_method==\"bce\":\n",
    "                            ## may test features be greater than 1 after scaling \n",
    "                            sequences=torch.clamp(sequences, min=0.0, max=1.0)      \n",
    "                        if model._get_name()==\"AE\":\n",
    "                            recon = model(sequences)\n",
    "                        elif model._get_name()==\"VAE\" or model._get_name()==\"GRUVAE\" :\n",
    "                            recon, _, _ = model(sequences)\n",
    "                        elif model._get_name()==\"AdversarialAutoencoder\":\n",
    "                            _,recon= model(sequences)\n",
    "                        val_loss = eval_criterion(recon, sequences)\n",
    "                        if val_loss.dim() > 1:\n",
    "                            val_loss = val_loss\n",
    "                        else:\n",
    "                            val_loss = val_loss.unsqueeze(dim=0)\n",
    "                            labels = labels.unsqueeze(dim=0)\n",
    "                        if val_loss.dim()==3:\n",
    "                            ##GRU : mean of window\n",
    "                            val_loss = val_loss.mean(dim=1)\n",
    "                        val_loss = val_loss.sum(dim=1)\n",
    "                        all_val_losses.extend(val_loss.cpu().numpy())\n",
    "                        all_val_labels.extend(labels.flatten().cpu().numpy())     \n",
    "                threshold_1,std_mse = compute_threshold(all_val_losses,k=0)\n",
    "\n",
    "                all_val_losses = np.array(all_val_losses).squeeze()  \n",
    "                all_val_labels = np.array(all_val_labels).squeeze()  \n",
    "                # If intrusion score > threshold, predict 1 (intrusion), else 0 (benign)\n",
    "                # For FDR, get True Positives (TP) and False Positives (FP)\n",
    "                \n",
    "                predictions = (all_val_losses > threshold_1).astype(int)\n",
    "\n",
    "                accuracy = accuracy_score(all_val_labels, predictions)\n",
    "                print(f\"Val: Accuracy: {accuracy:.4f}  \")\n",
    "                model.eval() \n",
    "                all_test_losses = []\n",
    "                all_test_labels = []\n",
    "                with torch.no_grad():\n",
    "                    for sequences, labels in test_dataloader:\n",
    "                        sequences = sequences.squeeze().to(device)\n",
    "                        labels = labels.squeeze().to(device)\n",
    "                        if criterion_method==\"bce\":\n",
    "                            ## may test features be greater than 1 after scaling \n",
    "                            sequences=torch.clamp(sequences, min=0.0, max=1.0)\n",
    "                        if model._get_name()==\"AE\":\n",
    "                            recon = model(sequences)\n",
    "                        elif model._get_name()==\"VAE\"  or model._get_name()==\"GRUVAE\":\n",
    "                            recon, mu, logvar = model(sequences)\n",
    "                        elif model._get_name()==\"AdversarialAutoencoder\":\n",
    "                            _,recon= model(sequences)\n",
    "\n",
    "                        intrusion_scores = eval_criterion(recon, sequences)\n",
    "                        if intrusion_scores.dim() > 1:\n",
    "                            intrusion_scores = intrusion_scores\n",
    "                        else:\n",
    "                            intrusion_scores = intrusion_scores.unsqueeze(dim=0)\n",
    "                            labels = labels.unsqueeze(dim=0)\n",
    "                        if intrusion_scores.dim()==3:\n",
    "                            ##GRU : mean of window\n",
    "                            intrusion_scores = intrusion_scores.mean(dim=1)\n",
    "                        intrusion_scores = intrusion_scores.sum(dim=1)\n",
    "                        all_test_losses.extend(intrusion_scores.cpu().numpy())\n",
    "                        all_test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "                all_test_losses = np.array(all_test_losses)\n",
    "                all_test_labels = np.array(all_test_labels)\n",
    "                temp_best_recall =best_recall\n",
    "                temp_best_f1 =best_f1\n",
    "\n",
    "                for k in k_range:\n",
    "                    threshold=threshold_1+k*std_mse\n",
    "                    print(f\" K: {k} K-SIGMA Threshold : ---thr {threshold:.4}\")\n",
    "                    predictions = (all_test_losses > threshold).astype(int)\n",
    "                    binary_test_labels = (all_test_labels != 0).astype(int)\n",
    "\n",
    "                    # Find the indices where the prediction was incorrect\n",
    "                    misclassified_indices = np.where(binary_test_labels != predictions)[0]\n",
    "\n",
    "                    # Get the original labels for those misclassified instances\n",
    "                    misclassified_original_labels = all_test_labels[misclassified_indices]\n",
    "\n",
    "                    # To get a summary count of which labels were misclassified\n",
    "                    print(\"Counts of : original binary labels\",Counter(binary_test_labels),\"predicted binary labels\",Counter(predictions))\n",
    "                    print(f\"Counts of  original  labels: {dict(sorted(Counter(all_test_labels).items()))}\")\n",
    "                    print(f\"Counts of misclassified original labels: {dict(sorted(Counter(misclassified_original_labels).items()))}\")\n",
    "                    accuracy = accuracy_score(binary_test_labels, predictions)\n",
    "                    f1 = f1_score(binary_test_labels, predictions, zero_division=0)\n",
    "                    recall = recall_score(binary_test_labels, predictions,zero_division=0)\n",
    "                    _, fp, _, tp = confusion_matrix(binary_test_labels, predictions, labels=[0, 1]).ravel()\n",
    "                    # FDR = FP / (FP + TP) \n",
    "                    if (fp + tp) == 0:\n",
    "                        fdr = 0.0 \n",
    "                    else:\n",
    "                        fdr = fp / (fp + tp)\n",
    "                    print(f\"Test : Accuracy: {accuracy:.4f} Recall : {recall:.4f} FDR: {fdr:.4f}  F1-score: {f1:.4f}  \")\n",
    "                    !mkdir best_models -p\n",
    "                    if f1>best_f1 :\n",
    "                        best_f1=f1\n",
    "                    if recall>best_recall:\n",
    "                        best_recall=recall\n",
    "                if (best_recall>temp_best_recall or best_f1 > temp_best_f1):\n",
    "                    if train_model==True:\n",
    "                        save_path =\"best_models/\"+model._get_name()+\"_f1_\"+f\"{best_f1:.2f}\" +\"_recall_\"+f\"{best_recall:.2f}\" +\"_.pth\"\n",
    "                        torch.save(model.state_dict(),save_path)\n",
    "                        print(\"model\",model._get_name(),\"is saved in\" ,save_path )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfeeeaf",
   "metadata": {},
   "source": [
    "#### Centralized : external scenario -> ied1a node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db440aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ied1b comp ied attack ->\n",
      " test:  1 ['dataset/ModbusDataset/attack/external/ied1a/ied1a-network-capture/ready/veth4edc015-0-labeled.csv']\n",
      "----------- Network-wide number of csv files -> \n",
      " ----------- train : 16 ['dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-16-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-31-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-18-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-23-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-19-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-27-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-20-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-24-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-29-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-14-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-21-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-30-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-32-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-26-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-15-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-28-labeled.csv'] \n",
      " -------- valid: 3 ['dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-22-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-25-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-17-labeled.csv']\n"
     ]
    }
   ],
   "source": [
    "# train_files=[col for col in modbus.dataset[\"benign_dataset_dir\"] if col.find(\"network-wide\")!=-1]\n",
    "train_files=[col for col in modbus.dataset[\"benign_dataset_dir\"] if col.find(\"network-wide\")!=-1][:]\n",
    "test_files=[col for col in modbus.dataset[\"attack_dataset_dir\"][\"external\"] if col.find(\"ied1a\")!=-1]\n",
    "random.seed(42)\n",
    "random.shuffle(train_files)\n",
    "random.shuffle(test_files)\n",
    "val_files = train_files[-3:]\n",
    "train_files = train_files[:-3]\n",
    "print(\"ied1b comp ied attack ->\\n test: \",len(test_files),test_files)\n",
    "print(\"----------- Network-wide number of csv files -> \\n ----------- train :\",len(train_files),train_files,\"\\n -------- valid:\",len(val_files),val_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb2505cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded scalers for 'network-wide'\n"
     ]
    }
   ],
   "source": [
    "### Try The Copy-on-Write (CoW) technique, share the same single copy of the dataset in memory with multiple forked workers from the main process\n",
    "# Ensure to have enough memory for saving large tensors in the ram \n",
    "###### else use chunk_size =1 and read the files iteratively\n",
    "\n",
    "use_cow=True\n",
    "window_size=1\n",
    "loaded_scalers=load_scalers('fitted_scalers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eac4698b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T08:12:06.828444Z",
     "iopub.status.busy": "2025-07-13T08:12:06.827779Z",
     "iopub.status.idle": "2025-07-13T08:12:07.034947Z",
     "shell.execute_reply": "2025-07-13T08:12:07.034115Z",
     "shell.execute_reply.started": "2025-07-13T08:12:06.828415Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cow Processing datasets...\n",
      "  - Creating 'train' dataset...\n",
      "  - Finished 'train' dataset.\n",
      "  - Creating 'val' dataset...\n",
      "  - Finished 'val' dataset.\n",
      "  - Creating 'test' dataset...\n",
      "  - Finished 'test' dataset.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# This cell Initializes and returns train, validation, and test dataloaders.\n",
    "\n",
    "# This function supports two strategies for data loading:\n",
    "# 1. Copy-on-Write (use_cow=True): Loads the entire dataset into RAM. This is fast\n",
    "#     but memory-intensive. It allows multiple worker processes to share the same\n",
    "#     dataset copy in memory, which is efficient for multiprocessing.\n",
    "# 2. Iterative (use_cow=False): Reads data from files in small chunks. This is\n",
    "#     slower but uses significantly less memory, suitable for very large datasets\n",
    "#     that don't fit in RAM.\n",
    "\n",
    "#     train_files (list): List of file paths for the training dataset.\n",
    "#     val_files (list): List of file paths for the validation dataset.\n",
    "#     test_files (list): List of file paths for the test dataset.\n",
    "#     window_size (int): The size of the sliding window for sequence data.\n",
    "#     use_cow (bool, optional): If True, uses the Copy-on-Write strategy. \n",
    "#                                 Defaults to True.\n",
    "\n",
    "#      return        (train_dataloader, val_dataloader, test_dataloader)\n",
    "\n",
    "if use_cow==True:\n",
    "    large_chunk_size = modbus.dataset[\"metadata\"][\"founded_files_num\"][\"total_dataset_num\"]\n",
    "\n",
    "    dataset_configs = {\n",
    "        \"train\": {\"files\": train_files},\n",
    "        \"val\": {\"files\": val_files},\n",
    "        \"test\": {\"files\": test_files},\n",
    "    }\n",
    "    datasets = {}\n",
    "    ae_datasets = {}\n",
    "\n",
    "    print(\"Cow Processing datasets...\")\n",
    "\n",
    "    for name, config in dataset_configs.items():\n",
    "        print(f\"  - Creating '{name}' dataset...\")\n",
    "        \n",
    "        # 1. Create the primary ModbusFlowStream dataset\n",
    "        datasets[name] = ModbusFlowStream(\n",
    "            shuffle=False,\n",
    "            chunk_size=large_chunk_size,\n",
    "            batch_size=1,\n",
    "            csv_files=config[\"files\"],\n",
    "            scalers=loaded_scalers['network-wide']['min_max_scalers'],\n",
    "            window_size=window_size\n",
    "        )\n",
    "        \n",
    "        # 2. Call __getitem__(0) once to load the entire dataset chunk into memory\n",
    "        datasets[name].__getitem__(0)\n",
    "        \n",
    "        # used for specific AE training/evaluation without re-reading files.\n",
    "        ae_datasets[name] = ModbusFlowStream(\n",
    "            shuffle=False,  # AE data is typically processed in order\n",
    "            chunk_size=large_chunk_size,\n",
    "            batch_size=1,\n",
    "            csv_files=[],  # No CSV files needed as we copy the data directly\n",
    "            scalers=None,   # Data is already scaled from the original dataset\n",
    "            window_size=window_size\n",
    "        )\n",
    "        \n",
    "        # 4. Manually copy the loaded data and properties to the AE dataset\n",
    "\n",
    "        ae_datasets[name].current_chunk_data =  datasets[name].current_chunk_data\n",
    "        ae_datasets[name].current_len_chunk_data =  datasets[name].current_len_chunk_data\n",
    "        ae_datasets[name].current_chunk_labels =  datasets[name].current_chunk_labels\n",
    "        ae_datasets[name].total_batches =  datasets[name].total_batches\n",
    "        \n",
    "        print(f\"  - Finished '{name}' dataset.\")\n",
    "    train_dataloader=DataLoader(ae_datasets['train'],batch_size=64,shuffle=True,num_workers=4,persistent_workers=True,prefetch_factor=2,pin_memory=True)\n",
    "    val_dataloader=DataLoader(ae_datasets['val'],batch_size=64,shuffle=False,num_workers=4,persistent_workers=True,prefetch_factor=2,pin_memory=True)\n",
    "    test_dataloader=DataLoader(ae_datasets['test'],batch_size=64,shuffle=False,num_workers=4,persistent_workers=True,prefetch_factor=2,pin_memory=True)\n",
    "\n",
    "else :\n",
    "    train_dataloader=DataLoader(ModbusFlowStream( \n",
    "        shuffle=True,chunk_size=1,batch_size=64,csv_files=train_files,scalers=loaded_scalers['network-wide']['min_max_scalers'],window_size=window_size\n",
    "    ),  batch_size=1,shuffle=False)\n",
    "    val_dataloader=DataLoader(ModbusFlowStream( \n",
    "        shuffle=False,chunk_size=1,batch_size=64,csv_files=val_files,scalers=loaded_scalers['network-wide']['min_max_scalers'],window_size=window_size\n",
    "    ),batch_size=1,shuffle=False)\n",
    "    test_dataloader=DataLoader(ModbusFlowStream(shuffle=False,chunk_size=1,batch_size=64,csv_files=test_files,scalers=loaded_scalers['network-wide']['min_max_scalers'],window_size=window_size),\n",
    "                               batch_size=1,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69406aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36907 7195 1960\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataloader),len(val_dataloader),len(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e82123e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================  lr=5e-05, wd=0.0001 ==================\n",
      "Train : time 146.63 s Epoch 1\n",
      "Train Loss: 0.2344\n",
      "--- Running Evaluation for Epoch 1 lr =5e-05 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0034 std: 0.0535\n",
      "Val: Accuracy: 0.9253  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.05691\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65735, 0: 59697})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29816, 1: 96}\n",
      "Test : Accuracy: 0.7615 Recall : 0.9973 FDR: 0.4536  F1-score: 0.7060  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.164\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65589, 0: 59843})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29739, 1: 165}\n",
      "Test : Accuracy: 0.7616 Recall : 0.9954 FDR: 0.4534  F1-score: 0.7057  \n",
      "model AE is saved in best_models/AE_f1_0.71_recall_1.00_.pth\n",
      "Train : time 142.75 s Epoch 2\n",
      "Train Loss: 0.0025\n",
      "--- Running Evaluation for Epoch 2 lr =5e-05 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0029 std: 0.0475\n",
      "Val: Accuracy: 0.9012  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.05044\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65763, 0: 59669})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29817, 1: 69}\n",
      "Test : Accuracy: 0.7617 Recall : 0.9981 FDR: 0.4534  F1-score: 0.7064  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.1454\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65578, 0: 59854})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29728, 1: 165}\n",
      "Test : Accuracy: 0.7617 Recall : 0.9954 FDR: 0.4533  F1-score: 0.7058  \n",
      "model AE is saved in best_models/AE_f1_0.71_recall_1.00_.pth\n",
      "Train : time 143.07 s Epoch 3\n",
      "Train Loss: 0.0023\n",
      "--- Running Evaluation for Epoch 3 lr =5e-05 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0028 std: 0.0467\n",
      "Val: Accuracy: 0.8911  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.04951\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65757, 0: 59675})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29810, 1: 68}\n",
      "Test : Accuracy: 0.7618 Recall : 0.9981 FDR: 0.4533  F1-score: 0.7064  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.143\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65583, 0: 59849})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29733, 1: 165}\n",
      "Test : Accuracy: 0.7616 Recall : 0.9954 FDR: 0.4534  F1-score: 0.7057  \n",
      "model AE is saved in best_models/AE_f1_0.71_recall_1.00_.pth\n",
      "Train : time 141.63 s Epoch 4\n",
      "Train Loss: 0.0022\n",
      "--- Running Evaluation for Epoch 4 lr =5e-05 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0027 std: 0.0455\n",
      "Val: Accuracy: 0.8849  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.04819\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65760, 0: 59672})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29812, 1: 67}\n",
      "Test : Accuracy: 0.7618 Recall : 0.9981 FDR: 0.4533  F1-score: 0.7064  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.1391\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65575, 0: 59857})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29725, 1: 165}\n",
      "Test : Accuracy: 0.7617 Recall : 0.9954 FDR: 0.4533  F1-score: 0.7058  \n",
      "model AE is saved in best_models/AE_f1_0.71_recall_1.00_.pth\n",
      "Train : time 144.34 s Epoch 5\n",
      "Train Loss: 0.0022\n",
      "--- Running Evaluation for Epoch 5 lr =5e-05 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0026 std: 0.0449\n",
      "Val: Accuracy: 0.8799  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.04749\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65762, 0: 59670})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29814, 1: 67}\n",
      "Test : Accuracy: 0.7618 Recall : 0.9981 FDR: 0.4534  F1-score: 0.7064  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.1372\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65571, 0: 59861})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29721, 1: 165}\n",
      "Test : Accuracy: 0.7617 Recall : 0.9954 FDR: 0.4533  F1-score: 0.7058  \n",
      "Train : time 144.64 s Epoch 6\n",
      "Train Loss: 0.0021\n",
      "--- Running Evaluation for Epoch 6 lr =5e-05 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0025 std: 0.0432\n",
      "Val: Accuracy: 0.8718  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.04572\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65756, 0: 59676})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29807, 1: 66}\n",
      "Test : Accuracy: 0.7618 Recall : 0.9982 FDR: 0.4533  F1-score: 0.7065  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.1321\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65552, 0: 59880})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29702, 1: 165}\n",
      "Test : Accuracy: 0.7619 Recall : 0.9954 FDR: 0.4531  F1-score: 0.7059  \n",
      "model AE is saved in best_models/AE_f1_0.71_recall_1.00_.pth\n",
      "\n",
      "==================  lr=0.0001, wd=0.0001 ==================\n",
      "Train : time 145.33 s Epoch 1\n",
      "Train Loss: 0.1134\n",
      "--- Running Evaluation for Epoch 1 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0031 std: 0.0516\n",
      "Val: Accuracy: 0.9092  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.0547\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65739, 0: 59693})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29823, 1: 99}\n",
      "Test : Accuracy: 0.7614 Recall : 0.9973 FDR: 0.4537  F1-score: 0.7059  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.1579\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65585, 0: 59847})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29735, 1: 165}\n",
      "Test : Accuracy: 0.7616 Recall : 0.9954 FDR: 0.4534  F1-score: 0.7057  \n",
      "Train : time 144.60 s Epoch 2\n",
      "Train Loss: 0.0024\n",
      "--- Running Evaluation for Epoch 2 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0029 std: 0.0490\n",
      "Val: Accuracy: 0.8961  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.05192\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65762, 0: 59670})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29823, 1: 76}\n",
      "Test : Accuracy: 0.7616 Recall : 0.9979 FDR: 0.4535  F1-score: 0.7062  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.15\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65580, 0: 59852})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29730, 1: 165}\n",
      "Test : Accuracy: 0.7617 Recall : 0.9954 FDR: 0.4533  F1-score: 0.7057  \n",
      "Train : time 146.62 s Epoch 3\n",
      "Train Loss: 0.0023\n",
      "--- Running Evaluation for Epoch 3 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0028 std: 0.0489\n",
      "Val: Accuracy: 0.8930  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.05172\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65773, 0: 59659})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29825, 1: 67}\n",
      "Test : Accuracy: 0.7617 Recall : 0.9981 FDR: 0.4535  F1-score: 0.7063  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.1495\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65583, 0: 59849})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29733, 1: 165}\n",
      "Test : Accuracy: 0.7616 Recall : 0.9954 FDR: 0.4534  F1-score: 0.7057  \n",
      "Train : time 143.51 s Epoch 4\n",
      "Train Loss: 0.0022\n",
      "--- Running Evaluation for Epoch 4 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0028 std: 0.0468\n",
      "Val: Accuracy: 0.8855  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.04957\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65777, 0: 59655})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29828, 1: 66}\n",
      "Test : Accuracy: 0.7617 Recall : 0.9982 FDR: 0.4535  F1-score: 0.7063  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.1432\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65579, 0: 59853})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29729, 1: 165}\n",
      "Test : Accuracy: 0.7617 Recall : 0.9954 FDR: 0.4533  F1-score: 0.7058  \n",
      "Train : time 144.70 s Epoch 5\n",
      "Train Loss: 0.0022\n",
      "--- Running Evaluation for Epoch 5 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0026 std: 0.0427\n",
      "Val: Accuracy: 0.8763  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.04534\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65794, 0: 59638})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29837, 1: 58}\n",
      "Test : Accuracy: 0.7617 Recall : 0.9984 FDR: 0.4535  F1-score: 0.7064  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.1308\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65592, 0: 59840})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29739, 1: 162}\n",
      "Test : Accuracy: 0.7616 Recall : 0.9955 FDR: 0.4534  F1-score: 0.7057  \n",
      "model AE is saved in best_models/AE_f1_0.71_recall_1.00_.pth\n",
      "Train : time 141.73 s Epoch 6\n",
      "Train Loss: 0.0021\n",
      "--- Running Evaluation for Epoch 6 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0024 std: 0.0341\n",
      "Val: Accuracy: 0.8562  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.03648\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65829, 0: 59603})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29849, 1: 35}\n",
      "Test : Accuracy: 0.7618 Recall : 0.9990 FDR: 0.4534  F1-score: 0.7066  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.1047\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65612, 0: 59820})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29751, 1: 154}\n",
      "Test : Accuracy: 0.7616 Recall : 0.9957 FDR: 0.4534  F1-score: 0.7057  \n",
      "model AE is saved in best_models/AE_f1_0.71_recall_1.00_.pth\n",
      "\n",
      "==================  lr=1e-05, wd=0.0001 ==================\n",
      "Train : time 142.50 s Epoch 1\n",
      "Train Loss: 1.1822\n",
      "--- Running Evaluation for Epoch 1 lr =1e-05 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0089 std: 0.0942\n",
      "Val: Accuracy: 0.9451  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.1031\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65745, 0: 59687})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29884, 1: 154}\n",
      "Test : Accuracy: 0.7605 Recall : 0.9957 FDR: 0.4545  F1-score: 0.7048  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.2915\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65591, 0: 59841})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29742, 1: 166}\n",
      "Test : Accuracy: 0.7616 Recall : 0.9954 FDR: 0.4534  F1-score: 0.7056  \n",
      "Train : time 148.04 s Epoch 2\n",
      "Train Loss: 0.0051\n",
      "--- Running Evaluation for Epoch 2 lr =1e-05 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0046 std: 0.0753\n",
      "Val: Accuracy: 0.9530  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.07989\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65673, 0: 59759})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29811, 1: 153}\n",
      "Test : Accuracy: 0.7611 Recall : 0.9958 FDR: 0.4539  F1-score: 0.7053  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.2305\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65564, 0: 59868})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29714, 1: 165}\n",
      "Test : Accuracy: 0.7618 Recall : 0.9954 FDR: 0.4532  F1-score: 0.7059  \n",
      "Train : time 137.49 s Epoch 3\n",
      "Train Loss: 0.0036\n",
      "--- Running Evaluation for Epoch 3 lr =1e-05 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0040 std: 0.0656\n",
      "Val: Accuracy: 0.9513  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.06961\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65680, 0: 59752})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29808, 1: 143}\n",
      "Test : Accuracy: 0.7612 Recall : 0.9960 FDR: 0.4538  F1-score: 0.7055  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.2008\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65576, 0: 59856})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29726, 1: 165}\n",
      "Test : Accuracy: 0.7617 Recall : 0.9954 FDR: 0.4533  F1-score: 0.7058  \n",
      "Train : time 126.94 s Epoch 4\n",
      "Train Loss: 0.0032\n",
      "--- Running Evaluation for Epoch 4 lr =1e-05 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0036 std: 0.0589\n",
      "Val: Accuracy: 0.9401  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.06257\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65703, 0: 59729})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29813, 1: 125}\n",
      "Test : Accuracy: 0.7613 Recall : 0.9965 FDR: 0.4538  F1-score: 0.7057  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.1804\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65580, 0: 59852})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29730, 1: 165}\n",
      "Test : Accuracy: 0.7617 Recall : 0.9954 FDR: 0.4533  F1-score: 0.7057  \n",
      "Train : time 126.66 s Epoch 5\n",
      "Train Loss: 0.0029\n",
      "--- Running Evaluation for Epoch 5 lr =1e-05 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0034 std: 0.0540\n",
      "Val: Accuracy: 0.9259  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.05733\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65728, 0: 59704})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29818, 1: 105}\n",
      "Test : Accuracy: 0.7614 Recall : 0.9971 FDR: 0.4537  F1-score: 0.7059  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.1652\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65583, 0: 59849})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29733, 1: 165}\n",
      "Test : Accuracy: 0.7616 Recall : 0.9954 FDR: 0.4534  F1-score: 0.7057  \n",
      "Train : time 135.75 s Epoch 6\n",
      "Train Loss: 0.0027\n",
      "--- Running Evaluation for Epoch 6 lr =1e-05 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0032 std: 0.0525\n",
      "Val: Accuracy: 0.9140  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.05571\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65729, 0: 59703})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29814, 1: 100}\n",
      "Test : Accuracy: 0.7615 Recall : 0.9972 FDR: 0.4536  F1-score: 0.7060  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.1607\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65583, 0: 59849})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29733, 1: 165}\n",
      "Test : Accuracy: 0.7616 Recall : 0.9954 FDR: 0.4534  F1-score: 0.7057  \n",
      "\n",
      "==================  lr=1e-06, wd=0.0001 ==================\n",
      "Train : time 130.60 s Epoch 1\n",
      "Train Loss: 10.9083\n",
      "--- Running Evaluation for Epoch 1 lr =1e-06 wd 0.0001 ---\n",
      "-----------mse_loss mean :  3.8178 std: 1.5310\n",
      "Val: Accuracy: 0.6168  \n",
      " K: 1 K-SIGMA Threshold : ---thr 5.349\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 117090, 1: 8342})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5454, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.6924 Recall : 0.0802 FDR: 0.6538  F1-score: 0.1302  \n",
      " K: 3 K-SIGMA Threshold : ---thr 8.411\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 121385, 1: 4047})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 1159, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.7267 Recall : 0.0802 FDR: 0.2864  F1-score: 0.1442  \n",
      "Train : time 132.05 s Epoch 2\n",
      "Train Loss: 1.4384\n",
      "--- Running Evaluation for Epoch 2 lr =1e-06 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.4225 std: 0.8288\n",
      "Val: Accuracy: 0.8593  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.251\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 92831, 1: 32601})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6609, 1: 10014, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8674 Recall : 0.7217 FDR: 0.2027  F1-score: 0.7576  \n",
      " K: 3 K-SIGMA Threshold : ---thr 2.909\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 120175, 1: 5257})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2369, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.7170 Recall : 0.0802 FDR: 0.4506  F1-score: 0.1399  \n",
      "model AE is saved in best_models/AE_f1_0.76_recall_1.00_.pth\n",
      "Train : time 137.07 s Epoch 3\n",
      "Train Loss: 0.1863\n",
      "--- Running Evaluation for Epoch 3 lr =1e-06 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0893 std: 0.4225\n",
      "Val: Accuracy: 0.8069  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.5118\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 98844, 1: 26588})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 595, 1: 10014, 6: 8}\n",
      "Test : Accuracy: 0.9154 Recall : 0.7217 FDR: 0.0224  F1-score: 0.8304  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.357\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99101, 1: 26331})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 339, 1: 10014, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.9174 Recall : 0.7217 FDR: 0.0129  F1-score: 0.8338  \n",
      "model AE is saved in best_models/AE_f1_0.83_recall_1.00_.pth\n",
      "Train : time 128.78 s Epoch 4\n",
      "Train Loss: 0.0714\n",
      "--- Running Evaluation for Epoch 4 lr =1e-06 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0572 std: 0.3491\n",
      "Val: Accuracy: 0.8886  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.4063\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 97867, 1: 27565})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 353, 1: 8795, 6: 8}\n",
      "Test : Accuracy: 0.9270 Recall : 0.7556 FDR: 0.0128  F1-score: 0.8560  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.105\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99090, 1: 26342})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 350, 1: 10014, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.9173 Recall : 0.7217 FDR: 0.0133  F1-score: 0.8337  \n",
      "model AE is saved in best_models/AE_f1_0.86_recall_1.00_.pth\n",
      "Train : time 130.61 s Epoch 5\n",
      "Train Loss: 0.0476\n",
      "--- Running Evaluation for Epoch 5 lr =1e-06 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0380 std: 0.2520\n",
      "Val: Accuracy: 0.9206  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.29\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65734, 0: 59698})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29884, 1: 165}\n",
      "Test : Accuracy: 0.7604 Recall : 0.9954 FDR: 0.4546  F1-score: 0.7047  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.7939\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99090, 1: 26342})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 350, 1: 10014, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.9173 Recall : 0.7217 FDR: 0.0133  F1-score: 0.8337  \n",
      "Train : time 132.13 s Epoch 6\n",
      "Train Loss: 0.0306\n",
      "--- Running Evaluation for Epoch 6 lr =1e-06 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0236 std: 0.1793\n",
      "Val: Accuracy: 0.9412  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.2029\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65745, 0: 59687})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29884, 1: 154}\n",
      "Test : Accuracy: 0.7605 Recall : 0.9957 FDR: 0.4545  F1-score: 0.7048  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.5615\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99088, 1: 26344})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 351, 1: 10014, 6: 8}\n",
      "Test : Accuracy: 0.9173 Recall : 0.7217 FDR: 0.0133  F1-score: 0.8337  \n"
     ]
    }
   ],
   "source": [
    "# train_eval(AE_model,AE_train_dataloader,AE_val_dataloader,AE_test_dataloader,shuffle_files=True,num_epochs=20,eval_epoch=1,criterion_method=\"bce\",learning_rates=[5e-4],weight_decays=[0])\n",
    "AE_model = AE(input_dim=76)\n",
    "train_eval(AE_model,train_dataloader,val_dataloader,test_dataloader,shuffle_files=False,num_epochs=6,eval_epoch=1,criterion_method=\"mse\",learning_rates=[5e-5,1e-4,1e-5,1e-6],weight_decays=[1e-4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea756ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================  lr=0.01, wd=1e-05 ==================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : time 172.20 s Epoch 1\n",
      "Train Loss: 1.3981\n",
      "--- Running Evaluation for Epoch 1 lr =0.01 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.4596 std: 1.4261\n",
      "Val: Accuracy: 0.8703  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.886\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 94568, 1: 30864})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 4486, 1: 9628, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8874 Recall : 0.7324 FDR: 0.1453  F1-score: 0.7888  \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.738\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 118842, 1: 6590})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2580, 1: 31971, 2: 1, 3: 1, 4: 1, 5: 2, 6: 28, 7: 1}\n",
      "Test : Accuracy: 0.7243 Recall : 0.1113 FDR: 0.3915  F1-score: 0.1882  \n",
      "model VAE is saved in best_models/VAE_f1_0.79_recall_0.73_.pth\n",
      "Train : time 160.39 s Epoch 2\n",
      "Train Loss: 1.3734\n",
      "--- Running Evaluation for Epoch 2 lr =0.01 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.4440 std: 1.2936\n",
      "Val: Accuracy: 0.8453  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.738\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 93806, 1: 31626})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5220, 1: 9600, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8818 Recall : 0.7332 FDR: 0.1651  F1-score: 0.7808  \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.325\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 118701, 1: 6731})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2662, 1: 31912, 2: 1, 3: 1, 4: 1, 5: 2, 6: 28, 7: 1}\n",
      "Test : Accuracy: 0.7241 Recall : 0.1130 FDR: 0.3955  F1-score: 0.1904  \n",
      "model VAE is saved in best_models/VAE_f1_0.79_recall_0.73_.pth\n",
      "Train : time 170.35 s Epoch 3\n",
      "Train Loss: 1.3690\n",
      "--- Running Evaluation for Epoch 3 lr =0.01 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.3673 std: 1.1786\n",
      "Val: Accuracy: 0.8492  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.546\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 94952, 1: 30480})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 4315, 1: 9841, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8871 Recall : 0.7265 FDR: 0.1416  F1-score: 0.7870  \n",
      " K: 3 K-SIGMA Threshold : ---thr 3.903\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 120321, 1: 5111})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 1737, 1: 32606, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.7259 Recall : 0.0937 FDR: 0.3399  F1-score: 0.1641  \n",
      "Train : time 170.38 s Epoch 4\n",
      "Train Loss: 1.3672\n",
      "--- Running Evaluation for Epoch 4 lr =0.01 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.4180 std: 1.3006\n",
      "Val: Accuracy: 0.8525  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.719\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 94932, 1: 30500})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 4267, 1: 9773, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8880 Recall : 0.7284 FDR: 0.1399  F1-score: 0.7888  \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.32\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 119899, 1: 5533})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2065, 1: 32512, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.7241 Recall : 0.0963 FDR: 0.3732  F1-score: 0.1669  \n",
      "Train : time 170.86 s Epoch 5\n",
      "Train Loss: 1.3666\n",
      "--- Running Evaluation for Epoch 5 lr =0.01 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.3316 std: 1.1037\n",
      "Val: Accuracy: 0.8503  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.435\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 95515, 1: 29917})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 3868, 1: 9957, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8897 Recall : 0.7233 FDR: 0.1293  F1-score: 0.7902  \n",
      " K: 3 K-SIGMA Threshold : ---thr 3.643\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 121249, 1: 4183})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 1167, 1: 32964, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.7276 Recall : 0.0837 FDR: 0.2790  F1-score: 0.1501  \n",
      "model VAE is saved in best_models/VAE_f1_0.79_recall_0.73_.pth\n",
      "Train : time 171.69 s Epoch 6\n",
      "Train Loss: 1.3676\n",
      "--- Running Evaluation for Epoch 6 lr =0.01 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.3823 std: 1.2034\n",
      "Val: Accuracy: 0.8466  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.586\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 94985, 1: 30447})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 4404, 1: 9963, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8854 Recall : 0.7231 FDR: 0.1446  F1-score: 0.7837  \n",
      " K: 3 K-SIGMA Threshold : ---thr 3.993\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 120437, 1: 4995})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 1602, 1: 32587, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.7272 Recall : 0.0942 FDR: 0.3207  F1-score: 0.1655  \n",
      "\n",
      "==================  lr=0.001, wd=1e-05 ==================\n",
      "Train : time 170.15 s Epoch 1\n",
      "Train Loss: 1.3943\n",
      "--- Running Evaluation for Epoch 1 lr =0.001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.3444 std: 1.1186\n",
      "Val: Accuracy: 0.8567  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.463\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 94329, 1: 31103})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 4750, 1: 9653, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8851 Recall : 0.7317 FDR: 0.1527  F1-score: 0.7853  \n",
      " K: 3 K-SIGMA Threshold : ---thr 3.7\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 117582, 1: 7850})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2190, 1: 30320, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.7405 Recall : 0.1572 FDR: 0.2790  F1-score: 0.2581  \n",
      "Train : time 172.15 s Epoch 2\n",
      "Train Loss: 1.3376\n",
      "--- Running Evaluation for Epoch 2 lr =0.001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.3917 std: 1.2378\n",
      "Val: Accuracy: 0.8512  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.63\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 94219, 1: 31213})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 4877, 1: 9670, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8840 Recall : 0.7313 FDR: 0.1562  F1-score: 0.7835  \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.105\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 116525, 1: 8907})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2336, 1: 29413, 2: 1, 3: 1, 4: 1, 5: 2, 6: 25, 7: 1}\n",
      "Test : Accuracy: 0.7466 Recall : 0.1825 FDR: 0.2623  F1-score: 0.2926  \n",
      "Train : time 173.37 s Epoch 3\n",
      "Train Loss: 1.3329\n",
      "--- Running Evaluation for Epoch 3 lr =0.001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.4234 std: 1.2786\n",
      "Val: Accuracy: 0.8418  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.702\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 93708, 1: 31724})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5348, 1: 9630, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8805 Recall : 0.7324 FDR: 0.1686  F1-score: 0.7788  \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.259\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 117701, 1: 7731})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2483, 1: 30734, 2: 1, 4: 1, 5: 2, 6: 28, 7: 1}\n",
      "Test : Accuracy: 0.7349 Recall : 0.1457 FDR: 0.3212  F1-score: 0.2399  \n",
      "Train : time 167.97 s Epoch 4\n",
      "Train Loss: 1.3318\n",
      "--- Running Evaluation for Epoch 4 lr =0.001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.3556 std: 1.1125\n",
      "Val: Accuracy: 0.8551  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.468\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 93972, 1: 31460})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5079, 1: 9625, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8827 Recall : 0.7325 FDR: 0.1614  F1-score: 0.7819  \n",
      " K: 3 K-SIGMA Threshold : ---thr 3.693\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 116792, 1: 8640})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2417, 1: 29761, 2: 1, 3: 1, 4: 1, 5: 2, 6: 25, 7: 1}\n",
      "Test : Accuracy: 0.7432 Recall : 0.1728 FDR: 0.2797  F1-score: 0.2787  \n",
      "Train : time 177.67 s Epoch 5\n",
      "Train Loss: 1.3302\n",
      "--- Running Evaluation for Epoch 5 lr =0.001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.3762 std: 1.2052\n",
      "Val: Accuracy: 0.8536  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.581\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 94301, 1: 31131})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 4784, 1: 9659, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8848 Recall : 0.7316 FDR: 0.1537  F1-score: 0.7848  \n",
      " K: 3 K-SIGMA Threshold : ---thr 3.992\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 117781, 1: 7651})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2383, 1: 30714, 2: 1, 3: 1, 4: 1, 5: 2, 6: 27, 7: 1}\n",
      "Test : Accuracy: 0.7359 Recall : 0.1463 FDR: 0.3115  F1-score: 0.2413  \n",
      "Train : time 167.47 s Epoch 6\n",
      "Train Loss: 1.3305\n",
      "--- Running Evaluation for Epoch 6 lr =0.001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.3631 std: 1.1598\n",
      "Val: Accuracy: 0.8468  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.523\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 94004, 1: 31428})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5104, 1: 9682, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8820 Recall : 0.7309 FDR: 0.1624  F1-score: 0.7806  \n",
      " K: 3 K-SIGMA Threshold : ---thr 3.842\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 118384, 1: 7048})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2178, 1: 31114, 2: 1, 3: 1, 4: 1, 5: 2, 6: 25, 7: 1}\n",
      "Test : Accuracy: 0.7343 Recall : 0.1352 FDR: 0.3090  F1-score: 0.2262  \n",
      "\n",
      "==================  lr=0.0001, wd=1e-05 ==================\n",
      "Train : time 170.14 s Epoch 1\n",
      "Train Loss: 1.6603\n",
      "--- Running Evaluation for Epoch 1 lr =0.0001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.3987 std: 1.1653\n",
      "Val: Accuracy: 0.8263  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.564\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 92256, 1: 33176})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6341, 1: 9171, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8763 Recall : 0.7451 FDR: 0.1911  F1-score: 0.7757  \n",
      " K: 3 K-SIGMA Threshold : ---thr 3.894\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 110564, 1: 14868})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 3244, 1: 24366, 4: 1, 5: 2, 6: 22}\n",
      "Test : Accuracy: 0.7797 Recall : 0.3228 FDR: 0.2182  F1-score: 0.4569  \n",
      "model VAE is saved in best_models/VAE_f1_0.79_recall_0.75_.pth\n",
      "Train : time 161.29 s Epoch 2\n",
      "Train Loss: 1.3500\n",
      "--- Running Evaluation for Epoch 2 lr =0.0001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.3881 std: 1.1983\n",
      "Val: Accuracy: 0.8448  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.586\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 93165, 1: 32267})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5602, 1: 9341, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8808 Recall : 0.7404 FDR: 0.1736  F1-score: 0.7810  \n",
      " K: 3 K-SIGMA Threshold : ---thr 3.983\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 114450, 1: 10982})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2820, 1: 27821, 2: 1, 3: 1, 4: 1, 5: 2, 6: 26, 7: 1}\n",
      "Test : Accuracy: 0.7555 Recall : 0.2266 FDR: 0.2568  F1-score: 0.3473  \n",
      "Train : time 163.88 s Epoch 3\n",
      "Train Loss: 1.3347\n",
      "--- Running Evaluation for Epoch 3 lr =0.0001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.3831 std: 1.2016\n",
      "Val: Accuracy: 0.8476  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.585\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 93390, 1: 32042})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5474, 1: 9438, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8810 Recall : 0.7377 FDR: 0.1708  F1-score: 0.7808  \n",
      " K: 3 K-SIGMA Threshold : ---thr 3.988\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 116990, 1: 8442})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2668, 1: 30207, 2: 1, 3: 1, 4: 1, 5: 2, 6: 28, 7: 1}\n",
      "Test : Accuracy: 0.7376 Recall : 0.1603 FDR: 0.3160  F1-score: 0.2598  \n",
      "Train : time 163.23 s Epoch 4\n",
      "Train Loss: 1.3321\n",
      "--- Running Evaluation for Epoch 4 lr =0.0001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.4149 std: 1.3007\n",
      "Val: Accuracy: 0.8546  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.716\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 93269, 1: 32163})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5569, 1: 9412, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8805 Recall : 0.7384 FDR: 0.1731  F1-score: 0.7801  \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.317\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 116962, 1: 8470})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2980, 1: 30490, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.7329 Recall : 0.1524 FDR: 0.3518  F1-score: 0.2468  \n",
      "Train : time 161.77 s Epoch 5\n",
      "Train Loss: 1.3300\n",
      "--- Running Evaluation for Epoch 5 lr =0.0001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.4016 std: 1.2130\n",
      "Val: Accuracy: 0.8459  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.615\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 92674, 1: 32758})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6082, 1: 9330, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.8771 Recall : 0.7407 FDR: 0.1857  F1-score: 0.7758  \n",
      " K: 3 K-SIGMA Threshold : ---thr 4.04\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 116907, 1: 8525})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2981, 1: 30437, 2: 1, 3: 1, 4: 1, 5: 2, 6: 28, 7: 1}\n",
      "Test : Accuracy: 0.7333 Recall : 0.1539 FDR: 0.3497  F1-score: 0.2489  \n",
      "Train : time 162.48 s Epoch 6\n",
      "Train Loss: 1.3294\n",
      "--- Running Evaluation for Epoch 6 lr =0.0001 wd 1e-05 ---\n",
      "-----------mse_loss mean :  0.3712 std: 1.1718\n",
      "Val: Accuracy: 0.8489  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.543\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 93139, 1: 32293})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5728, 1: 9442, 5: 1, 6: 7}\n",
      "Test : Accuracy: 0.8790 Recall : 0.7376 FDR: 0.1774  F1-score: 0.7778  \n",
      " K: 3 K-SIGMA Threshold : ---thr 3.887\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 116659, 1: 8773})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2758, 1: 29970, 3: 1, 4: 1, 5: 2, 6: 25, 7: 1}\n",
      "Test : Accuracy: 0.7388 Recall : 0.1670 FDR: 0.3144  F1-score: 0.2686  \n"
     ]
    }
   ],
   "source": [
    "VAE_model = VAE(input_dim=76)\n",
    "train_eval(VAE_model,train_dataloader,val_dataloader,test_dataloader,shuffle_files=False,num_epochs=6,eval_epoch=1,criterion_method=\"mse\",learning_rates=[1e-2,1e-3,1e-4],weight_decays=[1e-5],k_range=[1,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54635226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================  lr=0.01, wd=0.0001 ==================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : time 228.85 s Epoch 1\n",
      "Generator Loss: 176.8262 Discriminator Loss: 5.3518\n",
      "--- Running Evaluation for Epoch 1 lr =0.01 wd 0.0001 ---\n",
      "-----------mse_loss mean :  3.5951 std: 3.4918\n",
      "Val: Accuracy: 0.6065  \n",
      " K: 1 K-SIGMA Threshold : ---thr 7.087\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 117049, 1: 8383})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5495, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.6921 Recall : 0.0802 FDR: 0.6555  F1-score: 0.1301  \n",
      " K: 3 K-SIGMA Threshold : ---thr 14.07\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 125309, 1: 123})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6, 1: 35861, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Test : Accuracy: 0.7138 Recall : 0.0032 FDR: 0.0488  F1-score: 0.0065  \n",
      "model AdversarialAutoencoder is saved in best_models/AdversarialAutoencoder_f1_0.13_recall_0.08_.pth\n",
      "Train : time 232.27 s Epoch 2\n",
      "Generator Loss: 236.1101 Discriminator Loss: 0.0166\n",
      "--- Running Evaluation for Epoch 2 lr =0.01 wd 0.0001 ---\n",
      "-----------mse_loss mean :  3.5951 std: 3.4917\n",
      "Val: Accuracy: 0.6065  \n",
      " K: 1 K-SIGMA Threshold : ---thr 7.087\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 117049, 1: 8383})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5495, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.6921 Recall : 0.0802 FDR: 0.6555  F1-score: 0.1301  \n",
      " K: 3 K-SIGMA Threshold : ---thr 14.07\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 125309, 1: 123})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6, 1: 35861, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Test : Accuracy: 0.7138 Recall : 0.0032 FDR: 0.0488  F1-score: 0.0065  \n",
      "Train : time 229.78 s Epoch 3\n",
      "Generator Loss: 233.6358 Discriminator Loss: 0.0430\n",
      "--- Running Evaluation for Epoch 3 lr =0.01 wd 0.0001 ---\n",
      "-----------mse_loss mean :  3.5011 std: 3.3216\n",
      "Val: Accuracy: 0.6067  \n",
      " K: 1 K-SIGMA Threshold : ---thr 6.823\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 103012, 1: 22420})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 19604, 1: 33164, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.5790 Recall : 0.0782 FDR: 0.8744  F1-score: 0.0964  \n",
      " K: 3 K-SIGMA Threshold : ---thr 13.47\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 125310, 1: 122})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 5, 1: 35861, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Test : Accuracy: 0.7138 Recall : 0.0032 FDR: 0.0410  F1-score: 0.0065  \n",
      "Train : time 234.54 s Epoch 4\n",
      "Generator Loss: 306.7760 Discriminator Loss: 0.0391\n",
      "--- Running Evaluation for Epoch 4 lr =0.01 wd 0.0001 ---\n",
      "-----------mse_loss mean :  4.7396 std: 2.4142\n",
      "Val: Accuracy: 0.6105  \n",
      " K: 1 K-SIGMA Threshold : ---thr 7.154\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 121304, 1: 4128})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 3522, 1: 35374, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.6896 Recall : 0.0168 FDR: 0.8532  F1-score: 0.0302  \n",
      " K: 3 K-SIGMA Threshold : ---thr 11.98\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 125167, 1: 265})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 148, 1: 35861, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Test : Accuracy: 0.7126 Recall : 0.0032 FDR: 0.5585  F1-score: 0.0064  \n",
      "Train : time 233.78 s Epoch 5\n",
      "Generator Loss: 309.0570 Discriminator Loss: 0.0009\n",
      "--- Running Evaluation for Epoch 5 lr =0.01 wd 0.0001 ---\n",
      "-----------mse_loss mean :  4.7396 std: 2.4142\n",
      "Val: Accuracy: 0.6105  \n",
      " K: 1 K-SIGMA Threshold : ---thr 7.154\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 121304, 1: 4128})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 3522, 1: 35374, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.6896 Recall : 0.0168 FDR: 0.8532  F1-score: 0.0302  \n",
      " K: 3 K-SIGMA Threshold : ---thr 11.98\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 125167, 1: 265})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 148, 1: 35861, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Test : Accuracy: 0.7126 Recall : 0.0032 FDR: 0.5585  F1-score: 0.0064  \n",
      "Train : time 233.17 s Epoch 6\n",
      "Generator Loss: 308.6756 Discriminator Loss: 0.0006\n",
      "--- Running Evaluation for Epoch 6 lr =0.01 wd 0.0001 ---\n",
      "-----------mse_loss mean :  4.7396 std: 2.4142\n",
      "Val: Accuracy: 0.6105  \n",
      " K: 1 K-SIGMA Threshold : ---thr 7.154\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 121304, 1: 4128})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 3522, 1: 35374, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "Test : Accuracy: 0.6896 Recall : 0.0168 FDR: 0.8532  F1-score: 0.0302  \n",
      " K: 3 K-SIGMA Threshold : ---thr 11.98\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 125167, 1: 265})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 148, 1: 35861, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Test : Accuracy: 0.7126 Recall : 0.0032 FDR: 0.5585  F1-score: 0.0064  \n",
      "\n",
      "==================  lr=0.001, wd=0.0001 ==================\n",
      "Train : time 239.11 s Epoch 1\n",
      "Generator Loss: 4.1309 Discriminator Loss: 7.7194\n",
      "--- Running Evaluation for Epoch 1 lr =0.001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0184 std: 0.2063\n",
      "Val: Accuracy: 0.9813  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.2247\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65734, 0: 59698})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29884, 1: 165}\n",
      "Test : Accuracy: 0.7604 Recall : 0.9954 FDR: 0.4546  F1-score: 0.7047  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.6373\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99108, 1: 26324})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 331, 1: 10014, 6: 8}\n",
      "Test : Accuracy: 0.9175 Recall : 0.7217 FDR: 0.0126  F1-score: 0.8339  \n",
      "model AdversarialAutoencoder is saved in best_models/AdversarialAutoencoder_f1_0.83_recall_1.00_.pth\n",
      "Train : time 237.31 s Epoch 2\n",
      "Generator Loss: 1.6544 Discriminator Loss: 11.2261\n",
      "--- Running Evaluation for Epoch 2 lr =0.001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0301 std: 0.1836\n",
      "Val: Accuracy: 0.9382  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.2136\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65734, 0: 59698})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29884, 1: 165}\n",
      "Test : Accuracy: 0.7604 Recall : 0.9954 FDR: 0.4546  F1-score: 0.7047  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.5808\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99088, 1: 26344})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 351, 1: 10014, 6: 8}\n",
      "Test : Accuracy: 0.9173 Recall : 0.7217 FDR: 0.0133  F1-score: 0.8337  \n",
      "Train : time 235.84 s Epoch 3\n",
      "Generator Loss: 1.8781 Discriminator Loss: 15.6813\n",
      "--- Running Evaluation for Epoch 3 lr =0.001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0233 std: 0.1841\n",
      "Val: Accuracy: 0.9811  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.2074\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65734, 0: 59698})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29884, 1: 165}\n",
      "Test : Accuracy: 0.7604 Recall : 0.9954 FDR: 0.4546  F1-score: 0.7047  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.5756\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99036, 1: 26396})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 351, 1: 9962, 6: 8}\n",
      "Test : Accuracy: 0.9177 Recall : 0.7232 FDR: 0.0133  F1-score: 0.8346  \n",
      "model AdversarialAutoencoder is saved in best_models/AdversarialAutoencoder_f1_0.83_recall_1.00_.pth\n",
      "Train : time 236.47 s Epoch 4\n",
      "Generator Loss: 1.5950 Discriminator Loss: 16.2237\n",
      "--- Running Evaluation for Epoch 4 lr =0.001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0227 std: 0.1802\n",
      "Val: Accuracy: 0.9811  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.2029\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65734, 0: 59698})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29884, 1: 165}\n",
      "Test : Accuracy: 0.7604 Recall : 0.9954 FDR: 0.4546  F1-score: 0.7047  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.5634\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99088, 1: 26344})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 351, 1: 10014, 6: 8}\n",
      "Test : Accuracy: 0.9173 Recall : 0.7217 FDR: 0.0133  F1-score: 0.8337  \n",
      "Train : time 236.74 s Epoch 5\n",
      "Generator Loss: 1.5011 Discriminator Loss: 18.0652\n",
      "--- Running Evaluation for Epoch 5 lr =0.001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0215 std: 0.1836\n",
      "Val: Accuracy: 0.9897  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.2051\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65735, 0: 59697})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29884, 1: 164}\n",
      "Test : Accuracy: 0.7604 Recall : 0.9954 FDR: 0.4546  F1-score: 0.7047  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.5724\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99108, 1: 26324})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 331, 1: 10014, 6: 8}\n",
      "Test : Accuracy: 0.9175 Recall : 0.7217 FDR: 0.0126  F1-score: 0.8339  \n",
      "model AdversarialAutoencoder is saved in best_models/AdversarialAutoencoder_f1_0.83_recall_1.00_.pth\n",
      "Train : time 243.17 s Epoch 6\n",
      "Generator Loss: 1.2232 Discriminator Loss: 22.6538\n",
      "--- Running Evaluation for Epoch 6 lr =0.001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0167 std: 0.1769\n",
      "Val: Accuracy: 0.9844  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.1936\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({1: 65734, 0: 59698})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 29884, 1: 165}\n",
      "Test : Accuracy: 0.7604 Recall : 0.9954 FDR: 0.4546  F1-score: 0.7047  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.5475\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 97255, 1: 28177})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 353, 1: 8183, 6: 8}\n",
      "Test : Accuracy: 0.9319 Recall : 0.7726 FDR: 0.0125  F1-score: 0.8669  \n",
      "model AdversarialAutoencoder is saved in best_models/AdversarialAutoencoder_f1_0.87_recall_1.00_.pth\n",
      "\n",
      "==================  lr=0.0001, wd=0.0001 ==================\n",
      "Train : time 232.10 s Epoch 1\n",
      "Generator Loss: 40.9228 Discriminator Loss: 4.7518\n",
      "--- Running Evaluation for Epoch 1 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0643 std: 0.5388\n",
      "Val: Accuracy: 0.9551  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.6031\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99089, 1: 26343})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 350, 1: 10014, 6: 8}\n",
      "Test : Accuracy: 0.9173 Recall : 0.7217 FDR: 0.0133  F1-score: 0.8337  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.681\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99092, 1: 26340})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 348, 1: 10014, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.9173 Recall : 0.7217 FDR: 0.0132  F1-score: 0.8337  \n",
      "Train : time 231.28 s Epoch 2\n",
      "Generator Loss: 3.6065 Discriminator Loss: 4.8913\n",
      "--- Running Evaluation for Epoch 2 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0446 std: 0.4188\n",
      "Val: Accuracy: 0.9826  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.4634\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99088, 1: 26344})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 351, 1: 10014, 6: 8}\n",
      "Test : Accuracy: 0.9173 Recall : 0.7217 FDR: 0.0133  F1-score: 0.8337  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.301\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99090, 1: 26342})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 350, 1: 10014, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.9173 Recall : 0.7217 FDR: 0.0133  F1-score: 0.8337  \n",
      "Train : time 236.68 s Epoch 3\n",
      "Generator Loss: 3.0012 Discriminator Loss: 3.5079\n",
      "--- Running Evaluation for Epoch 3 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0395 std: 0.3916\n",
      "Val: Accuracy: 0.9828  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.4311\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99087, 1: 26345})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 352, 1: 10014, 6: 8}\n",
      "Test : Accuracy: 0.9173 Recall : 0.7217 FDR: 0.0134  F1-score: 0.8336  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.214\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99090, 1: 26342})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 350, 1: 10014, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.9173 Recall : 0.7217 FDR: 0.0133  F1-score: 0.8337  \n",
      "Train : time 241.90 s Epoch 4\n",
      "Generator Loss: 2.7489 Discriminator Loss: 2.6974\n",
      "--- Running Evaluation for Epoch 4 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0353 std: 0.3443\n",
      "Val: Accuracy: 0.9830  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.3796\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 97859, 1: 27573})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 356, 1: 8790, 6: 8}\n",
      "Test : Accuracy: 0.9270 Recall : 0.7557 FDR: 0.0129  F1-score: 0.8560  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.068\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99090, 1: 26342})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 350, 1: 10014, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.9173 Recall : 0.7217 FDR: 0.0133  F1-score: 0.8337  \n",
      "Train : time 233.90 s Epoch 5\n",
      "Generator Loss: 2.5526 Discriminator Loss: 2.2999\n",
      "--- Running Evaluation for Epoch 5 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0324 std: 0.3124\n",
      "Val: Accuracy: 0.9797  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.3449\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 88780, 1: 36652})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2175, 1: 1538}\n",
      "Test : Accuracy: 0.9704 Recall : 0.9573 FDR: 0.0593  F1-score: 0.9489  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.9697\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99089, 1: 26343})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 350, 1: 10014, 6: 8}\n",
      "Test : Accuracy: 0.9173 Recall : 0.7217 FDR: 0.0133  F1-score: 0.8337  \n",
      "model AdversarialAutoencoder is saved in best_models/AdversarialAutoencoder_f1_0.95_recall_1.00_.pth\n",
      "Train : time 254.28 s Epoch 6\n",
      "Generator Loss: 2.3765 Discriminator Loss: 2.8582\n",
      "--- Running Evaluation for Epoch 6 lr =0.0001 wd 0.0001 ---\n",
      "-----------mse_loss mean :  0.0304 std: 0.2940\n",
      "Val: Accuracy: 0.9831  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.3244\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 87437, 1: 37995})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2177, 1: 197}\n",
      "Test : Accuracy: 0.9811 Recall : 0.9945 FDR: 0.0573  F1-score: 0.9679  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.9123\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 98371, 1: 27061})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 350, 1: 9296, 6: 8}\n",
      "Test : Accuracy: 0.9230 Recall : 0.7417 FDR: 0.0129  F1-score: 0.8469  \n",
      "model AdversarialAutoencoder is saved in best_models/AdversarialAutoencoder_f1_0.97_recall_1.00_.pth\n"
     ]
    }
   ],
   "source": [
    "AAE_model = AdversarialAutoencoder()\n",
    "train_eval(AAE_model,train_dataloader,val_dataloader,test_dataloader,shuffle_files=False,num_epochs=6,eval_epoch=1,criterion_method=\"mse\",learning_rates=[1e-2,1e-3,1e-4],weight_decays=[1e-4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b21a73a",
   "metadata": {},
   "source": [
    "#### Evaluate pre-trained autoencoders  on the compromised-ied and compromised scada scenarios \n",
    "\n",
    "No exact labeling for the comp ied scenario results in low performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19349642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Trained_AE_model=AE(input_dim=76)\n",
    "Trained_AE_model.load_state_dict(torch.load(\"./best_models/AE_f1_0.86_recall_1.00_.pth\"))\n",
    "Trained_VAE_model=VAE(input_dim=76)\n",
    "Trained_VAE_model.load_state_dict(torch.load(\"./best_models/VAE_f1_0.79_recall_0.75_.pth\"))\n",
    "Trained_AAE_model=AdversarialAutoencoder()\n",
    "Trained_AAE_model.load_state_dict(torch.load(\"./best_models/AdversarialAutoencoder_f1_0.97_recall_1.00_.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3d7e62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scenario : compromised-scada node ied1b\n",
      "----------- benign valid files: 3 ['dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-22-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-25-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-17-labeled.csv']\n",
      "----------compromised-scada attack  test files :  8 ['dataset/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-6-labeled.csv', 'dataset/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-3-labeled.csv', 'dataset/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-4-labeled.csv', 'dataset/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-1-labeled.csv', 'dataset/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-7-labeled.csv', 'dataset/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-0-labeled.csv', 'dataset/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-5-labeled.csv', 'dataset/ModbusDataset/attack/compromised-scada/ied1b/ied1b-network-captures/ready/vethc76bd3f-2-labeled.csv']\n",
      "********** AdversarialAutoencoder **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0305 std: 0.2940\n",
      "Val: Accuracy: 0.9831  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.3245\n",
      "Counts of : original binary labels Counter({0: 701716, 1: 171557}) predicted binary labels Counter({0: 649808, 1: 223465})\n",
      "Counts of  original  labels: {0: 701716, 1: 170342, 2: 263, 3: 182, 4: 208, 5: 197, 6: 158, 7: 207}\n",
      "Counts of misclassified original labels: {0: 82595, 1: 30474, 2: 47, 3: 69, 4: 33, 5: 2, 6: 61, 7: 1}\n",
      "Test : Accuracy: 0.8703 Recall : 0.8211 FDR: 0.3696  F1-score: 0.7132  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.9125\n",
      "Counts of : original binary labels Counter({0: 701716, 1: 171557}) predicted binary labels Counter({0: 653077, 1: 220196})\n",
      "Counts of  original  labels: {0: 701716, 1: 170342, 2: 263, 3: 182, 4: 208, 5: 197, 6: 158, 7: 207}\n",
      "Counts of misclassified original labels: {0: 81328, 1: 32259, 2: 47, 3: 72, 4: 33, 5: 8, 6: 63, 7: 207}\n",
      "Test : Accuracy: 0.8694 Recall : 0.8095 FDR: 0.3693  F1-score: 0.7090  \n",
      "********** AE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0572 std: 0.3491\n",
      "Val: Accuracy: 0.8886  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.4063\n",
      "Counts of : original binary labels Counter({0: 701716, 1: 171557}) predicted binary labels Counter({0: 652911, 1: 220362})\n",
      "Counts of  original  labels: {0: 701716, 1: 170342, 2: 263, 3: 182, 4: 208, 5: 197, 6: 158, 7: 207}\n",
      "Counts of misclassified original labels: {0: 81469, 1: 32240, 2: 47, 3: 72, 4: 33, 5: 2, 6: 63, 7: 207}\n",
      "Test : Accuracy: 0.8693 Recall : 0.8096 FDR: 0.3697  F1-score: 0.7088  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.104\n",
      "Counts of : original binary labels Counter({0: 701716, 1: 171557}) predicted binary labels Counter({0: 653078, 1: 220195})\n",
      "Counts of  original  labels: {0: 701716, 1: 170342, 2: 263, 3: 182, 4: 208, 5: 197, 6: 158, 7: 207}\n",
      "Counts of misclassified original labels: {0: 81327, 1: 32259, 2: 47, 3: 72, 4: 33, 5: 8, 6: 63, 7: 207}\n",
      "Test : Accuracy: 0.8694 Recall : 0.8095 FDR: 0.3693  F1-score: 0.7090  \n",
      "********** VAE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.4013 std: 1.1737\n",
      "Val: Accuracy: 0.8273  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.575\n",
      "Counts of : original binary labels Counter({0: 701716, 1: 171557}) predicted binary labels Counter({0: 628033, 1: 245240})\n",
      "Counts of  original  labels: {0: 701716, 1: 170342, 2: 263, 3: 182, 4: 208, 5: 197, 6: 158, 7: 207}\n",
      "Counts of misclassified original labels: {0: 104995, 1: 30903, 2: 42, 3: 69, 4: 32, 5: 7, 6: 62, 7: 197}\n",
      "Test : Accuracy: 0.8439 Recall : 0.8175 FDR: 0.4281  F1-score: 0.6730  \n",
      " K: 3 K-SIGMA Threshold : ---thr 3.922\n",
      "Counts of : original binary labels Counter({0: 701716, 1: 171557}) predicted binary labels Counter({0: 827813, 1: 45460})\n",
      "Counts of  original  labels: {0: 701716, 1: 170342, 2: 263, 3: 182, 4: 208, 5: 197, 6: 158, 7: 207}\n",
      "Counts of misclassified original labels: {0: 26034, 1: 151031, 2: 233, 3: 163, 4: 191, 5: 168, 6: 144, 7: 201}\n",
      "Test : Accuracy: 0.7960 Recall : 0.1132 FDR: 0.5727  F1-score: 0.1790  \n",
      "scenario : compromised-ied node ied1b\n",
      "----------- benign valid files: 3 ['dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-22-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-25-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-17-labeled.csv']\n",
      "----------compromised-ied attack  test files :  6 ['dataset/ModbusDataset/attack/compromised-ied/ied1b/ied1b-network-captures/ready/vethc76bd3f-3-labeled.csv', 'dataset/ModbusDataset/attack/compromised-ied/ied1b/ied1b-network-captures/ready/vethc76bd3f-4-labeled.csv', 'dataset/ModbusDataset/attack/compromised-ied/ied1b/ied1b-network-captures/ready/vethc76bd3f-1-labeled.csv', 'dataset/ModbusDataset/attack/compromised-ied/ied1b/ied1b-network-captures/ready/vethc76bd3f-0-labeled.csv', 'dataset/ModbusDataset/attack/compromised-ied/ied1b/ied1b-network-captures/ready/vethc76bd3f-5-labeled.csv', 'dataset/ModbusDataset/attack/compromised-ied/ied1b/ied1b-network-captures/ready/vethc76bd3f-2-labeled.csv']\n",
      "********** AdversarialAutoencoder **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0305 std: 0.2940\n",
      "Val: Accuracy: 0.9831  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.3245\n",
      "Counts of : original binary labels Counter({0: 658934, 1: 362}) predicted binary labels Counter({0: 657143, 1: 2153})\n",
      "Counts of  original  labels: {0: 658934, 2: 66, 3: 78, 4: 52, 5: 62, 7: 60, 8: 44}\n",
      "Counts of misclassified original labels: {0: 2142, 2: 66, 3: 78, 4: 52, 5: 51, 7: 60, 8: 44}\n",
      "Test : Accuracy: 0.9962 Recall : 0.0304 FDR: 0.9949  F1-score: 0.0087  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.9125\n",
      "Counts of : original binary labels Counter({0: 658934, 1: 362}) predicted binary labels Counter({0: 657171, 1: 2125})\n",
      "Counts of  original  labels: {0: 658934, 2: 66, 3: 78, 4: 52, 5: 62, 7: 60, 8: 44}\n",
      "Counts of misclassified original labels: {0: 2114, 2: 66, 3: 78, 4: 52, 5: 51, 7: 60, 8: 44}\n",
      "Test : Accuracy: 0.9963 Recall : 0.0304 FDR: 0.9948  F1-score: 0.0088  \n",
      "********** AE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0572 std: 0.3491\n",
      "Val: Accuracy: 0.8886  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.4063\n",
      "Counts of : original binary labels Counter({0: 658934, 1: 362}) predicted binary labels Counter({0: 657266, 1: 2030})\n",
      "Counts of  original  labels: {0: 658934, 2: 66, 3: 78, 4: 52, 5: 62, 7: 60, 8: 44}\n",
      "Counts of misclassified original labels: {0: 2019, 2: 66, 3: 78, 4: 52, 5: 51, 7: 60, 8: 44}\n",
      "Test : Accuracy: 0.9964 Recall : 0.0304 FDR: 0.9946  F1-score: 0.0092  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.104\n",
      "Counts of : original binary labels Counter({0: 658934, 1: 362}) predicted binary labels Counter({0: 658151, 1: 1145})\n",
      "Counts of  original  labels: {0: 658934, 2: 66, 3: 78, 4: 52, 5: 62, 7: 60, 8: 44}\n",
      "Counts of misclassified original labels: {0: 1134, 2: 66, 3: 78, 4: 52, 5: 51, 7: 60, 8: 44}\n",
      "Test : Accuracy: 0.9977 Recall : 0.0304 FDR: 0.9904  F1-score: 0.0146  \n",
      "********** VAE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.4011 std: 1.1726\n",
      "Val: Accuracy: 0.8271  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.574\n",
      "Counts of : original binary labels Counter({0: 658934, 1: 362}) predicted binary labels Counter({0: 583984, 1: 75312})\n",
      "Counts of  original  labels: {0: 658934, 2: 66, 3: 78, 4: 52, 5: 62, 7: 60, 8: 44}\n",
      "Counts of misclassified original labels: {0: 75257, 2: 58, 3: 73, 4: 47, 5: 45, 7: 52, 8: 32}\n",
      "Test : Accuracy: 0.8854 Recall : 0.1519 FDR: 0.9993  F1-score: 0.0015  \n",
      " K: 3 K-SIGMA Threshold : ---thr 3.919\n",
      "Counts of : original binary labels Counter({0: 658934, 1: 362}) predicted binary labels Counter({0: 644857, 1: 14439})\n",
      "Counts of  original  labels: {0: 658934, 2: 66, 3: 78, 4: 52, 5: 62, 7: 60, 8: 44}\n",
      "Counts of misclassified original labels: {0: 14424, 2: 64, 3: 76, 4: 51, 5: 55, 7: 60, 8: 41}\n",
      "Test : Accuracy: 0.9776 Recall : 0.0414 FDR: 0.9990  F1-score: 0.0020  \n",
      "scenario : external node ied1a\n",
      "----------- benign valid files: 3 ['dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-22-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-25-labeled.csv', 'dataset/ModbusDataset/benign/network-wide-pcap-capture/network-wide/ready/network-wide-normal-17-labeled.csv']\n",
      "----------external attack  test files :  1 ['dataset/ModbusDataset/attack/external/ied1a/ied1a-network-capture/ready/veth4edc015-0-labeled.csv']\n",
      "********** AdversarialAutoencoder **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0305 std: 0.2940\n",
      "Val: Accuracy: 0.9831  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.3245\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 87437, 1: 37995})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2177, 1: 197}\n",
      "Test : Accuracy: 0.9811 Recall : 0.9945 FDR: 0.0573  F1-score: 0.9679  \n",
      " K: 3 K-SIGMA Threshold : ---thr 0.9125\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 98371, 1: 27061})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 350, 1: 9296, 6: 8}\n",
      "Test : Accuracy: 0.9230 Recall : 0.7417 FDR: 0.0129  F1-score: 0.8469  \n",
      "********** AE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.0572 std: 0.3491\n",
      "Val: Accuracy: 0.8886  \n",
      " K: 1 K-SIGMA Threshold : ---thr 0.4063\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 97867, 1: 27565})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 353, 1: 8795, 6: 8}\n",
      "Test : Accuracy: 0.9270 Recall : 0.7556 FDR: 0.0128  F1-score: 0.8560  \n",
      " K: 3 K-SIGMA Threshold : ---thr 1.104\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99090, 1: 26342})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 350, 1: 10014, 5: 1, 6: 8}\n",
      "Test : Accuracy: 0.9173 Recall : 0.7217 FDR: 0.0133  F1-score: 0.8337  \n",
      "********** VAE **********\n",
      "\n",
      "==================  lr=0, wd=0 ==================\n",
      "--- Running Evaluation for Epoch 1 lr =0 wd 0 ---\n",
      "-----------mse_loss mean :  0.4040 std: 1.1783\n",
      "Val: Accuracy: 0.8268  \n",
      " K: 1 K-SIGMA Threshold : ---thr 1.582\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 92178, 1: 33254})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6402, 1: 9155, 5: 1, 6: 7}\n",
      "Test : Accuracy: 0.8759 Recall : 0.7456 FDR: 0.1925  F1-score: 0.7753  \n",
      " K: 3 K-SIGMA Threshold : ---thr 3.939\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 110661, 1: 14771})\n",
      "Counts of  original  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 3212, 1: 24424, 2: 1, 3: 1, 5: 2, 6: 27, 7: 1}\n",
      "Test : Accuracy: 0.7794 Recall : 0.3209 FDR: 0.2175  F1-score: 0.4552  \n"
     ]
    }
   ],
   "source": [
    "for scenario in {\"external\",\"compromised-scada\",\"compromised-ied\"}:\n",
    "    if scenario!=\"external\":\n",
    "        print(\"scenario :\",scenario,\"node ied1b\")\n",
    "        test_files= [col for col in modbus.dataset[\"attack_dataset_dir\"][scenario] if col.find(\"ied1b\")!=-1]\n",
    "    else:\n",
    "        print(\"scenario :\",scenario,\"node ied1a\")\n",
    "        test_files= [col for col in modbus.dataset[\"attack_dataset_dir\"][scenario] if col.find(\"ied1a\")!=-1]        \n",
    "\n",
    "    print(\"----------- benign valid files:\",len(val_files),val_files)\n",
    "    print(f\"----------{scenario} attack  test files : \",len(test_files),test_files)\n",
    "    val_dataloader=DataLoader(ModbusFlowStream(\n",
    "                shuffle=False,\n",
    "                chunk_size=100,\n",
    "                batch_size=64,\n",
    "                csv_files=val_files,\n",
    "                scalers=loaded_scalers['network-wide']['min_max_scalers'],\n",
    "            ),batch_size=1,shuffle=False)\n",
    "    test_dataloader=DataLoader(ModbusFlowStream(\n",
    "                shuffle=False,\n",
    "                chunk_size=100,\n",
    "                batch_size=64,\n",
    "                csv_files=test_files,\n",
    "                scalers=loaded_scalers['network-wide']['min_max_scalers'],\n",
    "            ),batch_size=1,shuffle=False)\n",
    "    for trained_model in {Trained_AE_model,Trained_VAE_model,Trained_AAE_model}:\n",
    "        print(\"*\"*10,trained_model._get_name(),10*\"*\")\n",
    "        train_eval(trained_model,None,val_dataloader,test_dataloader,shuffle_files=False,num_epochs=1,eval_epoch=1,criterion_method=\"mse\",train_model=False,learning_rates=[0],weight_decays=[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e10197",
   "metadata": {},
   "source": [
    "### FedAvg - non iid distribution (ip based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f948763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 1. SETUP: INSTALL LIBRARIES AND IMPORT DEPENDENCIES\n",
    "# ==============================================================================\n",
    "# In a Kaggle notebook, run this cell first to install the necessary libraries.\n",
    "# !pip install -q flwr[simulation] torch torchvision pandas scikit-learn matplotlib seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc049d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import flwr as fl\n",
    "from collections import OrderedDict\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import seaborn as sns\n",
    "import os \n",
    "from flwr.common import Context # Make sure this import is added\n",
    "import random\n",
    "# Suppress warning messages for a cleaner output\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "# Set a seed for reproducibility\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "#global device\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on {DEVICE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e80a446",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================================================================\n",
    "#  FEDERATED LEARNING CLIENT: FlowerClient\n",
    "# ==============================================================================\n",
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    \"\"\"Flower client for training.\"\"\"\n",
    "    def __init__(self, cid, model, trainloader):\n",
    "        self.cid = cid\n",
    "        self.model = model\n",
    "        self.train_dataloader = trainloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n",
    "\n",
    "    def set_parameters(self, parameters):\n",
    "        params_dict = zip(self.model.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "        self.model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        model =self.model\n",
    "        lr = cfg.LEARNING_RATE\n",
    "        wd= cfg.WEIGHT_DECAY\n",
    "        \n",
    "        criterion = nn.MSELoss(reduction='sum').to(DEVICE)\n",
    "        if model._get_name()==\"AdversarialAutoencoder\":\n",
    "            adversarial_criterion= nn.BCELoss(reduction=\"sum\")\n",
    "            optimizer_D = optim.Adam(model.discriminator.parameters(), lr=lr, weight_decay=wd)\n",
    "            optimizer_G =  optim.Adam(list(model.encoder.parameters()) + list(model.decoder.parameters()), lr=lr, weight_decay=wd)\n",
    "        else:\n",
    "            AE_optimizer = optim.Adam(model.parameters(), lr=lr,weight_decay=wd)\n",
    "\n",
    "        if cfg.STRATEGY == \"FED_PROX\":\n",
    "            global_params = [torch.tensor(p, device=DEVICE) for p in parameters]\n",
    "\n",
    "        for epoch in range(cfg.LOCAL_EPOCHS):\n",
    "                time_1 = time.time()\n",
    "                model.train()\n",
    "                train_loss = 0\n",
    "                ## for AAE\n",
    "                Discriminator_loss = 0\n",
    "                if cfg.SHUFFLE_FILES:\n",
    "                    sys_rand = SystemRandom()\n",
    "                    sys_rand.shuffle(self.train_dataloader.dataset.csv_files)\n",
    "                for sequences, _ in self.train_dataloader:\n",
    "                    sequences=sequences.squeeze().to(DEVICE)\n",
    "                    if model._get_name()==\"AdversarialAutoencoder\":\n",
    "                        target_ones= torch.ones(sequences.size(0), 1,device=DEVICE,dtype=torch.float)\n",
    "                        target_zeros= torch.zeros(sequences.size(0), 1,device=DEVICE,dtype=torch.float)\n",
    "                        random_latent = torch.randn(sequences.size(0), 2, device=DEVICE)\n",
    "                        optimizer_G.zero_grad()\n",
    "                        fake_z,decoded_seq = model(sequences)\n",
    "                        G_loss = 0.001*adversarial_criterion(model.discriminator(fake_z),target_ones ) + 0.999*criterion(decoded_seq, sequences)\n",
    "                        G_loss.backward()\n",
    "                        optimizer_G.step()\n",
    "                        # 2) discriminator loss\n",
    "                        optimizer_D.zero_grad()\n",
    "                        real_loss = adversarial_criterion(model.discriminator(random_latent), target_ones)\n",
    "                        fake_loss = adversarial_criterion(model.discriminator(fake_z.detach()),  target_zeros)\n",
    "                        D_loss =  0.001*0.5*(real_loss + fake_loss)\n",
    "                        D_loss.backward()\n",
    "                        optimizer_D.step()\n",
    "                        train_loss+=G_loss.item()\n",
    "                        Discriminator_loss+=D_loss.item()   \n",
    "                    else:\n",
    "                        AE_optimizer.zero_grad()\n",
    "                        if model._get_name()==\"AE\":\n",
    "                            recon = model(sequences)\n",
    "                            loss = criterion(recon, sequences) / sequences.size(0)\n",
    "                        elif model._get_name()==\"VAE\" or model._get_name()==\"GRUVAE\":\n",
    "                            recon, mu, logvar = model(sequences)\n",
    "                            loss = vae_loss_function(recon, sequences, mu, logvar) /sequences.size(0)\n",
    "                            if cfg.STRATEGY == \"FED_PROX\":\n",
    "                                proximal_term = 0.0\n",
    "                                for local_w, global_w in zip(model.parameters(), global_params):\n",
    "                                    proximal_term += (local_w - global_w).norm(2)\n",
    "                                loss += (cfg.PROXIMAL_MU / 2) * proximal_term\n",
    "                        loss.backward()\n",
    "                        AE_optimizer.step()\n",
    "                        train_loss += loss.item()\n",
    "                print(f\"Train : time {(time.time()-time_1):.2f} s\",\n",
    "                f\"Epoch {epoch+1}\")\n",
    "                if model._get_name()==\"AdversarialAutoencoder\":\n",
    "                    print(f\"Generator Loss: {train_loss / len(self.train_dataloader):.4f}\",\n",
    "                        f\"Discriminator Loss: {Discriminator_loss / len(self.train_dataloader):.4f}\")\n",
    "                else:\n",
    "                    print(f\"Train Loss: {train_loss / len(self.train_dataloader):.4f}\")\n",
    "        return self.get_parameters(config={}), len(self.train_dataloader.dataset), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        return 0.0, 0, {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "34efffc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================================================================\n",
    "# 6. SERVER-SIDE LOGIC AND SIMULATION START\n",
    "# ==============================================================================\n",
    "def client_fn(context: Context) -> FlowerClient:\n",
    "    \"\"\"Create a Flower client instance for a given client ID.\"\"\"\n",
    "    # The client's ID is retrieved from the context.\n",
    "    client_id = int(context.node_config[\"partition-id\"])\n",
    "    model = get_model().to(DEVICE)\n",
    "    trainloader = load_data_from_id(client_id,\"client\")\n",
    "    return FlowerClient(client_id, model, trainloader).to_client()\n",
    "\n",
    "def get_evaluate_fn():\n",
    "    \"\"\"Return an evaluation function for server-side evaluation.\"\"\"\n",
    "    # val_dataloader = load_data_from_id(0,\"server\")\n",
    "    # test_dataloader = load_data_from_id(1,\"server\")\n",
    "    val_dataloader = load_data_from_id(0,\"server\")\n",
    "    test_dataloader = load_data_from_id(1,\"server\")\n",
    "    eval_criterion = nn.MSELoss(reduction='none').to(DEVICE)\n",
    "\n",
    "    def evaluate(\n",
    "        server_round: int,\n",
    "        parameters: fl.common.NDArrays,\n",
    "        config: Dict[str, fl.common.Scalar],\n",
    "    ) -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:\n",
    "        model = get_model() # Use the get_model function\n",
    "        params_dict = zip(model.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "        model.load_state_dict(state_dict, strict=True)\n",
    "        model.to(DEVICE)\n",
    "        model.eval()\n",
    "        # Evaluate part\n",
    "        all_val_losses = []\n",
    "        all_val_labels = []\n",
    "        print(f\"--- Running Evaluation for Server round {server_round} ---\")\n",
    "        with torch.no_grad():\n",
    "            for sequences, labels in val_dataloader:\n",
    "                sequences = sequences.squeeze().to(DEVICE) \n",
    "                if labels.sum()!=0:\n",
    "                    continue\n",
    "                if model._get_name()==\"AE\":\n",
    "                    recon = model(sequences)\n",
    "                elif model._get_name()==\"VAE\" or model._get_name()==\"GRUVAE\" :\n",
    "                    recon, _, _ = model(sequences)\n",
    "                elif model._get_name()==\"AdversarialAutoencoder\":\n",
    "                    _,recon= model(sequences)\n",
    "                val_loss = eval_criterion(recon, sequences)\n",
    "                if val_loss.dim() > 1:\n",
    "                    val_loss = val_loss\n",
    "                else:\n",
    "                    val_loss = val_loss.unsqueeze(dim=0)\n",
    "                    labels = labels.unsqueeze(dim=0)\n",
    "                if val_loss.dim()==3:\n",
    "                    ##GRU : mean of window\n",
    "                    val_loss = val_loss.mean(dim=1)\n",
    "                val_loss = val_loss.sum(dim=1)\n",
    "                all_val_losses.extend(val_loss.cpu().numpy())\n",
    "                all_val_labels.extend(labels.flatten().cpu().numpy())     \n",
    "        threshold_1,std_mse = compute_threshold(all_val_losses,k=0)\n",
    "\n",
    "        all_val_losses = np.array(all_val_losses).squeeze()  \n",
    "        all_val_labels = np.array(all_val_labels).squeeze()  \n",
    "        # If intrusion score > threshold, predict 1 (intrusion), else 0 (benign)\n",
    "        # For FDR, get True Positives (TP) and False Positives (FP)\n",
    "        \n",
    "        predictions = (all_val_losses > threshold_1).astype(int)\n",
    "\n",
    "        accuracy = accuracy_score(all_val_labels, predictions)\n",
    "        print(f\"Val: Accuracy: {accuracy:.4f}  \")\n",
    "        model.eval() \n",
    "\n",
    "        all_test_losses = []\n",
    "        all_test_labels = []\n",
    "        with torch.no_grad():\n",
    "            for sequences, labels in test_dataloader:\n",
    "                sequences = sequences.squeeze().to(DEVICE)\n",
    "                labels = labels.squeeze().to(DEVICE)\n",
    "                if model._get_name()==\"AE\":\n",
    "                    recon = model(sequences)\n",
    "                elif model._get_name()==\"VAE\"  or model._get_name()==\"GRUVAE\":\n",
    "                    recon, mu, logvar = model(sequences)\n",
    "                elif model._get_name()==\"AdversarialAutoencoder\":\n",
    "                    _,recon= model(sequences)\n",
    "\n",
    "                intrusion_scores = eval_criterion(recon, sequences)\n",
    "                if intrusion_scores.dim() > 1:\n",
    "                    intrusion_scores = intrusion_scores\n",
    "                else:\n",
    "                    intrusion_scores = intrusion_scores.unsqueeze(dim=0)\n",
    "                    labels = labels.unsqueeze(dim=0)\n",
    "                if intrusion_scores.dim()==3:\n",
    "                    ##GRU : mean of window\n",
    "                    intrusion_scores = intrusion_scores.mean(dim=1)\n",
    "                intrusion_scores = intrusion_scores.sum(dim=1)\n",
    "                all_test_losses.extend(intrusion_scores.cpu().numpy())\n",
    "                all_test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        all_test_losses = np.array(all_test_losses)\n",
    "        all_test_labels = np.array(all_test_labels)\n",
    "        test_result = {}\n",
    "        for k in {1,3}:\n",
    "            threshold=threshold_1+k*std_mse\n",
    "            print(f\" K: {k} K-SIGMA Threshold : ---thr {threshold:.4}\")\n",
    "            predictions = (all_test_losses > threshold).astype(int)\n",
    "            binary_test_labels = (all_test_labels != 0).astype(int)\n",
    "\n",
    "            # Find the indices where the prediction was incorrect\n",
    "            misclassified_indices = np.where(binary_test_labels != predictions)[0]\n",
    "\n",
    "            # Get the original labels for those misclassified instances\n",
    "            misclassified_original_labels = all_test_labels[misclassified_indices]\n",
    "\n",
    "            # To get a summary count of which labels were misclassified\n",
    "            print(\"Counts of : original binary labels\",Counter(binary_test_labels),\"predicted binary labels\",Counter(predictions))\n",
    "            print(f\"Counts of  original  labels: {dict(sorted(Counter(all_test_labels).items()))}\")\n",
    "            print(f\"Counts of misclassified original labels: {dict(sorted(Counter(misclassified_original_labels).items()))}\")\n",
    "            accuracy = accuracy_score(binary_test_labels, predictions)\n",
    "            f1 = f1_score(binary_test_labels, predictions, zero_division=0)\n",
    "            recall = recall_score(binary_test_labels, predictions,zero_division=0)\n",
    "            _, fp, _, tp = confusion_matrix(binary_test_labels, predictions, labels=[0, 1]).ravel()\n",
    "            # FDR = FP / (FP + TP) \n",
    "            if (fp + tp) == 0:\n",
    "                fdr = 0.0 \n",
    "            else:\n",
    "                fdr = fp / (fp + tp)\n",
    "            test_result[k] = f\"k= {k} ,Test : Accuracy: {accuracy:.4f} Recall : {recall:.4f} FDR: {fdr:.4f}  F1-score: {f1:.4f} \"\n",
    "            print(test_result[k])\n",
    "        return np.sum(all_test_losses)/len(all_test_losses),test_result\n",
    "    return evaluate\n",
    "\n",
    "def get_initial_parameters(model_name: str):\n",
    "    \"\"\"\n",
    "    Initializes the model weights using Xavier uniform distribution\n",
    "    and returns them as a Flower Parameters object.\n",
    "    \"\"\"\n",
    "    \n",
    "    temp_model = get_model()\n",
    "    for param in temp_model.parameters():\n",
    "        if param.dim() > 1:\n",
    "            nn.init.xavier_uniform_(param)\n",
    "            \n",
    "    ndarrays = [val.cpu().numpy() for _, val in temp_model.state_dict().items()]\n",
    "    return ndarrays_to_parameters(ndarrays)\n",
    "\n",
    "\n",
    "def load_data_from_id(id: int, node = \"client\" ):\n",
    "    \"\"\"Loads the data for a specific training client.\"\"\"\n",
    "    if node == \"client\":\n",
    "        file_list = TRAIN_CLIENT_DATA_MAPPING[id]\n",
    "        shuffle=cfg.SHUFFLE_FILES\n",
    "    else: # server\n",
    "        file_list = SERVER_EVALUATION_DATA_MAPPING[id]\n",
    "        shuffle = False\n",
    "\n",
    "    train_loader=DataLoader(ModbusFlowStream(\n",
    "            shuffle=shuffle,\n",
    "            chunk_size=1,\n",
    "            batch_size=cfg.BATCH_SIZE ,\n",
    "            csv_files=file_list,\n",
    "            scalers=loaded_scalers['network-wide']['min_max_scalers'],\n",
    "        ),batch_size=1,shuffle=False)\n",
    "    return train_loader\n",
    "def get_model():\n",
    "    \"\"\"Returns the model specified in the config.\"\"\"\n",
    "    if cfg.MODEL_NAME == \"VAE\":\n",
    "        print(f\"Using Variational Autoencoder (VAE) \")\n",
    "        return VAE(input_dim=cfg.INPUT_DIM)\n",
    "    elif cfg.MODEL_NAME == \"AE\":\n",
    "        print(f\"Using Autoencoder (AE) \")\n",
    "        return AE(input_dim=cfg.INPUT_DIM)\n",
    "    elif cfg.MODEL_NAME ==\"AdverserialAutoencoder\":\n",
    "        print(f\"Using Adverserial Autoencoder (AAE) \")\n",
    "        return AdverserialAutoencoder(input_dim=76)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model name: {cfg.MODEL_NAME}. Choose 'AE' or 'VAE' or 'AdverserialAutoencoder'.\")\n",
    "def set_server_strategy():\n",
    "    ### Call this function after initiate Config \n",
    "    if cfg.STRATEGY == \"FED_PROX\":\n",
    "        strategy = fl.server.strategy.FedProx(\n",
    "            fraction_fit=1.0, fraction_evaluate=0.0,\n",
    "            min_fit_clients=cfg.NUM_TRAIN_CLIENTS,\n",
    "            min_available_clients=cfg.NUM_TRAIN_CLIENTS,\n",
    "            evaluate_fn=evaluate_function,\n",
    "            proximal_mu=cfg.PROXIMAL_MU,\n",
    "            initial_parameters=get_initial_parameters(cfg.MODEL_NAME)\n",
    "        )\n",
    "        print(\"Using FedProx strategy.\")\n",
    "    else:\n",
    "        strategy = fl.server.strategy.FedAvg(\n",
    "            fraction_fit=1.0, fraction_evaluate=0.0,\n",
    "            min_fit_clients=cfg.NUM_TRAIN_CLIENTS,\n",
    "            min_available_clients=cfg.NUM_TRAIN_CLIENTS,\n",
    "            evaluate_fn=evaluate_function,\n",
    "            initial_parameters=get_initial_parameters(cfg.MODEL_NAME)\n",
    "\n",
    "        )\n",
    "        print(f\"Using FedAvg strategy with {cfg.MODEL_NAME} model.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bc0e13",
   "metadata": {},
   "source": [
    "#### External Attack-FedAVG-AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3219b1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================================================================\n",
    "#  DATA Distribution\n",
    "# ==============================================================================\n",
    "\n",
    "ied1b_train_files=[col for col in modbus.dataset[\"benign_dataset_dir\"] if col.find(\"ied1b\")!=-1][:]\n",
    "ied1a_train_files=[col for col in modbus.dataset[\"benign_dataset_dir\"] if col.find(\"ied1a\")!=-1][:]\n",
    "ied4c_train_files=[col for col in modbus.dataset[\"benign_dataset_dir\"] if col.find(\"ied4c\")!=-1][:]\n",
    "cent_agent_train_files=[col for col in modbus.dataset[\"benign_dataset_dir\"] if col.find(\"central-agent\")!=-1][:]\n",
    "test_files=[col for col in modbus.dataset[\"attack_dataset_dir\"][\"external\"] if col.find(\"ied1a\")!=-1][:]\n",
    "random.seed(42)\n",
    "val_files = []\n",
    "\n",
    "for list_files in [ied1b_train_files,ied1a_train_files,ied4c_train_files]: \n",
    "    random.shuffle(list_files)\n",
    "    val_files += list_files[-2:]\n",
    "TRAIN_CLIENT_DATA_MAPPING = {\n",
    "    0: ied1b_train_files[-3:-2],\n",
    "    1: ied1a_train_files[-3:-2],\n",
    "    2: ied4c_train_files[-3:-2],\n",
    "    3: cent_agent_train_files,\n",
    "}\n",
    "\n",
    "SERVER_EVALUATION_DATA_MAPPING = {\n",
    "    0: val_files,\n",
    "    1: test_files \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8580f738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 1, 6, 1, 6)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ied1b_train_files),len(TRAIN_CLIENT_DATA_MAPPING[0]),len(val_files),len(test_files),len(val_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "69c2c487",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================================================================\n",
    "#  CONFIGURATION: TWEAK  FEDERATED LEARNING EXPERIMENT\n",
    "# ==============================================================================\n",
    "class Config:\n",
    "    \"\"\"Global configuration class for the federated learning experiment.\"\"\"\n",
    "    # --- FL Parameters ---\n",
    "    NUM_TRAIN_CLIENTS = 4\n",
    "    NUM_ROUNDS = 5\n",
    "    LOCAL_EPOCHS = 5\n",
    "    BATCH_SIZE = 64\n",
    "    LEARNING_RATE = 5e-6\n",
    "    WEIGHT_DECAY = 1e-4\n",
    "    # --- Strategy Selection ---\n",
    "    # Choose from \"FED_AVG\", \"FED_PROX\"\n",
    "    STRATEGY = \"FED_AVG\" \n",
    "    PROXIMAL_MU = 0.1 # Proximal term for FedProx\n",
    "    # --- Model Selection ---\n",
    "    # Choose from \"AE\" (Autoencoder) or \"VAE\" (Variational Autoencoder) or \"AdverserialAutoencoder\"\n",
    "    MODEL_NAME = \"AE\"\n",
    "    INPUT_DIM = 76\n",
    "    # --- Anomaly Detection ---\n",
    "    SHUFFLE_FILES=  True\n",
    "# Instantiate the configuration\n",
    "cfg = Config()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635dab53",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_scalers = load_scalers(\"fitted_scalers\")\n",
    "# --- Select the Federation Strategy ---\n",
    "evaluate_function = get_evaluate_fn()\n",
    "# --- Start the Simulation ---\n",
    "strategy=set_server_strategy()\n",
    "print(\"Starting federated learning simulation...\")\n",
    "history = fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=cfg.NUM_TRAIN_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=cfg.NUM_ROUNDS),\n",
    "    strategy=strategy,\n",
    "    client_resources={\"num_cpus\": 4, \"num_gpus\": 1/cfg.NUM_TRAIN_CLIENTS} if DEVICE.type == \"cuda\" else {\"num_cpus\": 4},\n",
    ")\n",
    "print(\"Federated learning simulation finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5f6d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n",
      "\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n",
      "\n",
      "\t\t$ flwr new  # Create a new Flower app from a template\n",
      "\n",
      "\t\t$ flwr run  # Run the Flower app in Simulation Mode\n",
      "\n",
      "\tUsing `start_simulation()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=10, no round_timeout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting federated learning simulation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-17 22:07:51,327\tINFO worker.py:1771 -- Started a local Ray instance.\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'accelerator_type:G': 1.0, 'node:__internal_head__': 1.0, 'node:172.27.10.149': 1.0, 'CPU': 4.0, 'memory': 5926934939.0, 'object_store_memory': 2963467468.0, 'GPU': 1.0}\n",
      "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 4, 'num_gpus': 0.25}\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 1 actors\n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m /home/hamid_rd3/labeling/FLBased-ICS-NIDS-main/modbus.py:4: DeprecationWarning: \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m (to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m but was not found to be installed on your system.\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m If this would cause problems for you,\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m   import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Using Autoencoder (AE) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 0 ---\n",
      "-----------mse_loss mean :  16.9683 std: 1.2855\n",
      "Val: Accuracy: 0.2209  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 17.535465431468843, {1: 'k= 1 ,Test : Accuracy: 0.7763 Recall : 0.2722 FDR: 0.1585  F1-score: 0.4113 ', 3: 'k= 3 ,Test : Accuracy: 0.7358 Recall : 0.0802 FDR: 0.0028  F1-score: 0.1484 '}\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 18.25\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 113783, 1: 11649})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 1846, 1: 26195, 2: 1, 5: 1, 6: 14, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.7763 Recall : 0.2722 FDR: 0.1585  F1-score: 0.4113 \n",
      " K: 3 K-SIGMA Threshold : ---thr 20.82\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 122536, 1: 2896})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 8, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7358 Recall : 0.0802 FDR: 0.0028  F1-score: 0.1484 \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 56.97 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 6.2542\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.93 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.3154\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 56.42 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0473\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 56.39 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0207\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 56.65 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0110\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 32.84 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 9.6167\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 32.53 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0929\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 32.16 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0069\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 32.62 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0065\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 32.28 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0064\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.76 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 14.1356\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.80 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 14.0416\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.75 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 13.9340\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.76 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 13.8033\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.79 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 13.6392\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.66 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 6.3077\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 54.32 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.3433\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 56.09 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0490\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 54.43 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 1 ---\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.84 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0105\n",
      "-----------mse_loss mean :  1.5301 std: 2.0137\n",
      "Val: Accuracy: 0.5086  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (1, 1.5064251696138147, {1: 'k= 1 ,Test : Accuracy: 0.6875 Recall : 0.0802 FDR: 0.6774  F1-score: 0.1284 ', 3: 'k= 3 ,Test : Accuracy: 0.7192 Recall : 0.0802 FDR: 0.4202  F1-score: 0.1409 '}, 762.9639702620007)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 3.544\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 116479, 1: 8953})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6065, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.6875 Recall : 0.0802 FDR: 0.6774  F1-score: 0.1284 \n",
      " K: 3 K-SIGMA Threshold : ---thr 7.571\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 120451, 1: 4981})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2093, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7192 Recall : 0.0802 FDR: 0.4202  F1-score: 0.1409 \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 32.33 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0073\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 32.91 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0047\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 33.27 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0020\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 32.68 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0011\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 31.50 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0008\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 54.13 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0703\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 56.16 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0091\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.61 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0072\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.78 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0062\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.15 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0054\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.76 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 2.3295\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.79 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 1.9033\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.77 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 1.6050\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.79 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 1.3841\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.83 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 1.2179\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.47 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0723\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 56.50 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0099\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.47 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0079\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.09 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 2 ---\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.92 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0057\n",
      "-----------mse_loss mean :  0.8185 std: 1.5219\n",
      "Val: Accuracy: 0.8430  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (2, 1.1977533145449326, {1: 'k= 1 ,Test : Accuracy: 0.8665 Recall : 0.7041 FDR: 0.1937  F1-score: 0.7517 ', 3: 'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4217  F1-score: 0.1408 '}, 1521.4633154900002)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 2.34\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 93979, 1: 31453})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6094, 1: 10635, 3: 1, 4: 1, 5: 2, 6: 16, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.8665 Recall : 0.7041 FDR: 0.1937  F1-score: 0.7517 \n",
      " K: 3 K-SIGMA Threshold : ---thr 5.384\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 120438, 1: 4994})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2106, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4217  F1-score: 0.1408 \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 32.67 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0035\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 33.65 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0016\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 32.27 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0005\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 31.11 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0005\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 32.17 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0005\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.76 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 1.6140\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.85 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 1.0890\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.76 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.7739\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.81 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.6288\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.83 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.5646\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 56.00 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0269\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 54.73 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0055\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.92 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0048\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.87 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0044\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.27 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0042\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 56.35 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0274\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 56.21 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0051\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 56.35 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0044\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 56.09 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 3 ---\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.90 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0038\n",
      "-----------mse_loss mean :  0.8607 std: 1.7108\n",
      "Val: Accuracy: 0.8436  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (3, 1.2058659024411633, {1: 'k= 1 ,Test : Accuracy: 0.7802 Recall : 0.4046 FDR: 0.2958  F1-score: 0.5139 ', 3: 'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: 0.1408 '}, 2282.236114285999)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 2.571\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 104740, 1: 20692})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6121, 1: 21409, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.7802 Recall : 0.4046 FDR: 0.2958  F1-score: 0.5139 \n",
      " K: 3 K-SIGMA Threshold : ---thr 5.993\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 120433, 1: 4999})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2111, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: 0.1408 \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 32.14 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0025\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 33.22 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0005\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 32.98 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 32.64 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 32.80 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.41 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0275\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 56.41 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0040\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.89 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0037\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.98 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0035\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 56.02 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0034\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.76 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 1.8061\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.77 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 1.1809\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.78 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.7533\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.85 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.5533\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.79 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.4781\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.32 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0280\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 56.07 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0044\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 56.40 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0041\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.09 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 4 ---\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 57.25 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0037\n",
      "-----------mse_loss mean :  0.8291 std: 1.7234\n",
      "Val: Accuracy: 0.8435  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (4, 1.1877138858106384, {1: 'k= 1 ,Test : Accuracy: 0.8237 Recall : 0.5561 FDR: 0.2341  F1-score: 0.6443 ', 3: 'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: 0.1408 '}, 3046.5301939010023)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 2.553\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 99283, 1: 26149})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6122, 1: 15953, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.8237 Recall : 0.5561 FDR: 0.2341  F1-score: 0.6443 \n",
      " K: 3 K-SIGMA Threshold : ---thr 5.999\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 120433, 1: 4999})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2111, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: 0.1408 \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 32.35 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0018\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 32.51 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 31.81 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 33.23 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 31.99 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.19 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0265\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.44 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0037\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 54.28 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0034\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 56.00 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0032\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 54.96 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0031\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.73 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 1.7420\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.77 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 1.1203\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.78 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.6976\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.78 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.5092\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.97 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.4406\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.51 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0268\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.83 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0040\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.86 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0036\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 56.07 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 5 ---\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 57.98 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0033\n",
      "-----------mse_loss mean :  0.8433 std: 1.7945\n",
      "Val: Accuracy: 0.8436  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (5, 1.1997575130349512, {1: 'k= 1 ,Test : Accuracy: 0.6874 Recall : 0.0806 FDR: 0.6773  F1-score: 0.1290 ', 3: 'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: 0.1408 '}, 3805.712017156002)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 6]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 2.638\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 116434, 1: 8998})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6094, 1: 33076, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.6874 Recall : 0.0806 FDR: 0.6773  F1-score: 0.1290 \n",
      " K: 3 K-SIGMA Threshold : ---thr 6.227\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 120433, 1: 4999})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2111, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: 0.1408 \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.82 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 1.7494\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.77 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 1.1207\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.80 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.6846\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.76 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.4922\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.75 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.4234\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 32.19 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0017\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 32.54 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 33.18 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 32.54 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 31.91 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.31 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0276\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.78 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0034\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.97 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0032\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.35 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0030\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.93 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0029\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.32 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0275\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 56.22 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0037\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 56.38 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0034\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.38 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 56.14 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0031\n",
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 6 ---\n",
      "-----------mse_loss mean :  0.8511 std: 1.7888\n",
      "Val: Accuracy: 0.8436  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (6, 1.2176109366030996, {1: 'k= 1 ,Test : Accuracy: 0.8176 Recall : 0.5340 FDR: 0.2409  F1-score: 0.6270 ', 3: 'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: 0.1408 '}, 4565.8889677020015)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 7]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 2.64\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 100096, 1: 25336})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6103, 1: 16747, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.8176 Recall : 0.5340 FDR: 0.2409  F1-score: 0.6270 \n",
      " K: 3 K-SIGMA Threshold : ---thr 6.217\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 120433, 1: 4999})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2111, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: 0.1408 \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 32.82 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0015\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 32.49 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 32.09 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 31.97 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 32.76 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.83 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0266\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.67 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0035\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.42 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0032\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 56.59 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0031\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.76 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0030\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.65 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0276\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.30 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0033\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.75 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0030\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.51 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0029\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.28 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0028\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.78 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 1.7197\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.77 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 1.0881\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.80 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.6577\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.82 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.4712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 7 ---\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.92 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.4068\n",
      "-----------mse_loss mean :  0.8807 std: 1.8261\n",
      "Val: Accuracy: 0.8437  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (7, 1.2306566007876778, {1: 'k= 1 ,Test : Accuracy: 0.6875 Recall : 0.0806 FDR: 0.6769  F1-score: 0.1290 ', 3: 'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4222  F1-score: 0.1408 '}, 5325.162471431002)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 8]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 2.707\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 116449, 1: 8983})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6081, 1: 33078, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.6875 Recall : 0.0806 FDR: 0.6769  F1-score: 0.1290 \n",
      " K: 3 K-SIGMA Threshold : ---thr 6.359\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 120434, 1: 4998})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2110, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4222  F1-score: 0.1408 \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 56.34 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0275\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.74 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0034\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.34 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0031\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 56.55 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0030\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 56.14 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0029\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.87 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0275\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.22 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0031\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.72 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0029\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.54 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0028\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.97 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0027\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.78 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 1.7256\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.79 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 1.0847\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.78 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.6477\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.79 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.4607\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.85 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.3977\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 32.10 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0015\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 32.98 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 32.46 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 32.69 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 8 ---\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 32.82 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0004\n",
      "-----------mse_loss mean :  0.8679 std: 1.7948\n",
      "Val: Accuracy: 0.8437  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (8, 1.2216748915747178, {1: 'k= 1 ,Test : Accuracy: 0.6877 Recall : 0.0810 FDR: 0.6757  F1-score: 0.1297 ', 3: 'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: 0.1408 '}, 6086.628914834004)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 9]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 2.663\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 116432, 1: 9000})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6081, 1: 33061, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.6877 Recall : 0.0810 FDR: 0.6757  F1-score: 0.1297 \n",
      " K: 3 K-SIGMA Threshold : ---thr 6.252\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 120433, 1: 4999})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2111, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: 0.1408 \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 56.90 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0271\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 56.28 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0031\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 56.24 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0028\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 56.48 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0027\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 54.98 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0027\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 57.15 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0287\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.87 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0033\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.12 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0030\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.02 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0029\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 56.81 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0029\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 31.42 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0013\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 32.09 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 32.17 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 33.17 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 32.51 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.76 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 1.6805\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.73 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 1.0446\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.79 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.6222\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.77 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.4462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 9 ---\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.75 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.3886\n",
      "-----------mse_loss mean :  0.8716 std: 1.7943\n",
      "Val: Accuracy: 0.8437  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (9, 1.2197261265067925, {1: 'k= 1 ,Test : Accuracy: 0.6876 Recall : 0.0806 FDR: 0.6768  F1-score: 0.1290 ', 3: 'k= 3 ,Test : Accuracy: 0.7190 Recall : 0.0802 FDR: 0.4229  F1-score: 0.1408 '}, 6848.9499657669985)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 10]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 2.666\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 116453, 1: 8979})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6077, 1: 33078, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.6876 Recall : 0.0806 FDR: 0.6768  F1-score: 0.1290 \n",
      " K: 3 K-SIGMA Threshold : ---thr 6.255\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 120428, 1: 5004})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2116, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7190 Recall : 0.0802 FDR: 0.4229  F1-score: 0.1408 \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.91 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 1.6528\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.76 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 1.0236\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.78 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.6097\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.80 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.4378\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 0.76 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.3833\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 54.54 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0262\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 56.67 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0032\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.18 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0030\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 57.26 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0029\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 56.25 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0028\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 32.21 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0012\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 32.99 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 32.40 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 32.71 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 32.36 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 54.91 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0268\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 56.59 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0030\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.11 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0028\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.18 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 10 ---\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train : time 55.74 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=64208)\u001b[0m Train Loss: 0.0027\n",
      "-----------mse_loss mean :  0.8876 std: 1.8063\n",
      "Val: Accuracy: 0.8437  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (10, 1.2283682592958736, {1: 'k= 1 ,Test : Accuracy: 0.6876 Recall : 0.0806 FDR: 0.6767  F1-score: 0.1290 ', 3: 'k= 3 ,Test : Accuracy: 0.7190 Recall : 0.0802 FDR: 0.4229  F1-score: 0.1408 '}, 7609.805287936)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 10 round(s) in 7609.81s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, centralized):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 0: 17.535465431468843\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 1.5064251696138147\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 1.1977533145449326\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 1.2058659024411633\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 4: 1.1877138858106384\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 5: 1.1997575130349512\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 6: 1.2176109366030996\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 7: 1.2306566007876778\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 8: 1.2216748915747178\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 9: 1.2197261265067925\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 10: 1.2283682592958736\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, centralized):\n",
      "\u001b[92mINFO \u001b[0m:      \t{1: [(0,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.7763 Recall : 0.2722 FDR: 0.1585  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.4113 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (1,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.6875 Recall : 0.0802 FDR: 0.6774  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1284 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (2,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.8665 Recall : 0.7041 FDR: 0.1937  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.7517 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (3,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.7802 Recall : 0.4046 FDR: 0.2958  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.5139 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (4,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.8237 Recall : 0.5561 FDR: 0.2341  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.6443 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (5,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.6874 Recall : 0.0806 FDR: 0.6773  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1290 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (6,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.8176 Recall : 0.5340 FDR: 0.2409  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.6270 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (7,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.6875 Recall : 0.0806 FDR: 0.6769  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1290 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (8,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.6877 Recall : 0.0810 FDR: 0.6757  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1297 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (9,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.6876 Recall : 0.0806 FDR: 0.6768  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1290 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (10,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.6876 Recall : 0.0806 FDR: 0.6767  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1290 ')],\n",
      "\u001b[92mINFO \u001b[0m:      \t 3: [(0,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7358 Recall : 0.0802 FDR: 0.0028  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1484 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (1,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7192 Recall : 0.0802 FDR: 0.4202  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1409 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (2,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4217  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1408 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (3,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1408 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (4,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1408 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (5,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1408 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (6,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1408 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (7,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4222  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1408 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (8,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1408 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (9,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7190 Recall : 0.0802 FDR: 0.4229  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1408 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (10,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7190 Recall : 0.0802 FDR: 0.4229  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1408 ')]}\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 2.694\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 116457, 1: 8975})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6073, 1: 33078, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.6876 Recall : 0.0806 FDR: 0.6767  F1-score: 0.1290 \n",
      " K: 3 K-SIGMA Threshold : ---thr 6.306\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 120428, 1: 5004})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2116, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7190 Recall : 0.0802 FDR: 0.4229  F1-score: 0.1408 \n",
      "Federated learning simulation finished.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Instantiate the configuration\n",
    "cfg.STRATEGY=\"FED_PROX\"\n",
    "\n",
    "# --- Start the Simulation ---\n",
    "print(\"Starting federated learning simulation...\")\n",
    "history = fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=cfg.NUM_TRAIN_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=cfg.NUM_ROUNDS),\n",
    "    strategy=strategy,\n",
    "    client_resources={\"num_cpus\": 4, \"num_gpus\": 1/cfg.NUM_TRAIN_CLIENTS} if DEVICE.type == \"cuda\" else {\"num_cpus\": 4},\n",
    ")\n",
    "print(\"Federated learning simulation finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8cb200f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n",
      "\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n",
      "\n",
      "\t\t$ flwr new  # Create a new Flower app from a template\n",
      "\n",
      "\t\t$ flwr run  # Run the Flower app in Simulation Mode\n",
      "\n",
      "\tUsing `start_simulation()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=10, no round_timeout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting federated learning simulation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-18 00:15:27,488\tINFO worker.py:1771 -- Started a local Ray instance.\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'accelerator_type:G': 1.0, 'node:__internal_head__': 1.0, 'node:172.27.10.149': 1.0, 'CPU': 4.0, 'object_store_memory': 2930664652.0, 'memory': 5861329307.0, 'GPU': 1.0}\n",
      "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 4, 'num_gpus': 0.25}\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 1 actors\n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m /home/hamid_rd3/labeling/FLBased-ICS-NIDS-main/modbus.py:4: DeprecationWarning: \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m (to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m but was not found to be installed on your system.\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m If this would cause problems for you,\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m   import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Using Autoencoder (AE) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 0 ---\n",
      "-----------mse_loss mean :  16.7312 std: 1.2323\n",
      "Val: Accuracy: 0.2209  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 17.26719856177052, {1: 'k= 1 ,Test : Accuracy: 0.7723 Recall : 0.2649 FDR: 0.1793  F1-score: 0.4005 ', 3: 'k= 3 ,Test : Accuracy: 0.7358 Recall : 0.0802 FDR: 0.0028  F1-score: 0.1484 '}\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 17.96\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 113808, 1: 11624})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2084, 1: 26453, 2: 1, 5: 1, 6: 19, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.7723 Recall : 0.2649 FDR: 0.1793  F1-score: 0.4005 \n",
      " K: 3 K-SIGMA Threshold : ---thr 20.43\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 122536, 1: 2896})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 8, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7358 Recall : 0.0802 FDR: 0.0028  F1-score: 0.1484 \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 34.05 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 8.9621\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 33.61 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0623\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 33.29 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0067\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 32.52 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0064\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 33.31 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0063\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 56.64 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 5.7753\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 56.69 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.3341\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.43 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0520\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 55.69 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0234\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 56.46 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0107\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 56.14 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 5.7065\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.82 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.3087\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 56.30 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0529\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 56.86 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0263\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 56.84 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0134\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.77 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 14.0920\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.78 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 13.9774\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.77 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 13.8471\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.76 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 13.6871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 1 ---\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.88 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 13.4743\n",
      "-----------mse_loss mean :  1.5564 std: 1.7957\n",
      "Val: Accuracy: 0.4759  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (1, 1.5249920026388801, {1: 'k= 1 ,Test : Accuracy: 0.6875 Recall : 0.0802 FDR: 0.6775  F1-score: 0.1284 ', 3: 'k= 3 ,Test : Accuracy: 0.7234 Recall : 0.0802 FDR: 0.3525  F1-score: 0.1427 '}, 775.1704724950032)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 3.352\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 116476, 1: 8956})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6068, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.6875 Recall : 0.0802 FDR: 0.6775  F1-score: 0.1284 \n",
      " K: 3 K-SIGMA Threshold : ---thr 6.943\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 120972, 1: 4460})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 1572, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7234 Recall : 0.0802 FDR: 0.3525  F1-score: 0.1427 \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 32.63 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0078\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 33.82 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0049\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 32.60 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0034\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 32.56 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0012\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 32.21 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0007\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.79 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 2.4238\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.78 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 1.9871\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.76 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 1.6843\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.79 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 1.4619\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.77 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 1.2973\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.92 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0725\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 56.77 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0101\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 60.73 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0088\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 58.54 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0078\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.30 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0067\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.06 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0704\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 56.38 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0091\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 56.53 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0077\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.67 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 2 ---\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 56.48 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0062\n",
      "-----------mse_loss mean :  0.9159 std: 1.4928\n",
      "Val: Accuracy: 0.8429  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (2, 1.233013081789336, {1: 'k= 1 ,Test : Accuracy: 0.8665 Recall : 0.7040 FDR: 0.1936  F1-score: 0.7517 ', 3: 'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4217  F1-score: 0.1408 '}, 1555.0968734790004)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 2.409\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 93992, 1: 31440})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6086, 1: 10640, 3: 1, 4: 1, 5: 2, 6: 16, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.8665 Recall : 0.7040 FDR: 0.1936  F1-score: 0.7517 \n",
      " K: 3 K-SIGMA Threshold : ---thr 5.394\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 120438, 1: 4994})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2106, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4217  F1-score: 0.1408 \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.76 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0300\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.17 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0056\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 56.67 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0049\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.00 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0046\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.44 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0044\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 32.96 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0037\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 32.71 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0027\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 33.40 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0008\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 32.72 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0005\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 32.95 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0005\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 56.44 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0309\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.54 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0064\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 56.31 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0056\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 58.81 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0050\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 58.38 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0047\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.78 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 1.5209\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.77 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 1.0375\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.79 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.7695\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.77 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.6483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 3 ---\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.78 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.5929\n",
      "-----------mse_loss mean :  0.9114 std: 1.5497\n",
      "Val: Accuracy: 0.8437  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (3, 1.2357067723946042, {1: 'k= 1 ,Test : Accuracy: 0.8662 Recall : 0.7037 FDR: 0.1942  F1-score: 0.7513 ', 3: 'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4217  F1-score: 0.1408 '}, 2334.6962904570028)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 2.461\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 93981, 1: 31451})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6109, 1: 10652, 3: 1, 4: 1, 5: 2, 6: 16, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.8662 Recall : 0.7037 FDR: 0.1942  F1-score: 0.7513 \n",
      " K: 3 K-SIGMA Threshold : ---thr 5.561\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 120438, 1: 4994})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2106, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4217  F1-score: 0.1408 \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 32.68 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0031\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 33.39 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0016\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 33.72 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0005\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 32.57 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 33.24 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.83 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 1.6422\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.78 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 1.0565\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.85 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.6937\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.83 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.5363\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.79 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.4777\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 56.41 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0282\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 56.81 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0046\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 55.93 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0041\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.05 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0039\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 55.77 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0037\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.41 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0276\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.25 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0050\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.33 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0046\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.75 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 4 ---\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.47 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0040\n",
      "-----------mse_loss mean :  0.8573 std: 1.5879\n",
      "Val: Accuracy: 0.8436  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (4, 1.2048294843022513, {1: 'k= 1 ,Test : Accuracy: 0.8663 Recall : 0.7041 FDR: 0.1943  F1-score: 0.7515 ', 3: 'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4217  F1-score: 0.1408 '}, 3111.3250643560023)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 2.445\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 93959, 1: 31473})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6114, 1: 10635, 3: 1, 4: 1, 5: 2, 6: 16, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.8663 Recall : 0.7041 FDR: 0.1943  F1-score: 0.7515 \n",
      " K: 3 K-SIGMA Threshold : ---thr 5.621\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 120438, 1: 4994})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2106, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4217  F1-score: 0.1408 \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 33.94 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0030\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 33.84 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0006\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 33.61 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 33.70 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 32.55 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.42 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0266\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.52 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0043\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 56.51 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0040\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 56.92 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0038\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.61 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0036\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.79 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 1.6211\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.77 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 1.0253\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.76 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.6599\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.79 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.5057\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.80 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.4493\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 56.92 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0261\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.52 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0039\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 55.98 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0036\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 56.92 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 5 ---\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 56.04 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0034\n",
      "-----------mse_loss mean :  0.8364 std: 1.6314\n",
      "Val: Accuracy: 0.8436  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (5, 1.193427389940366, {1: 'k= 1 ,Test : Accuracy: 0.8663 Recall : 0.7041 FDR: 0.1944  F1-score: 0.7514 ', 3: 'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: 0.1408 '}, 3888.7427700229964)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 6]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 2.468\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 93955, 1: 31477})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6119, 1: 10636, 3: 1, 4: 1, 5: 2, 6: 16, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.8663 Recall : 0.7041 FDR: 0.1944  F1-score: 0.7514 \n",
      " K: 3 K-SIGMA Threshold : ---thr 5.731\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 120433, 1: 4999})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2111, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: 0.1408 \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 59.03 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0261\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.85 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0040\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.41 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0036\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 58.38 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0034\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.03 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0033\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 32.64 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0025\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 33.24 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 33.46 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 32.43 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 32.53 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.78 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 1.6352\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.78 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 1.0191\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.78 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.6414\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.78 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.4883\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.76 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.4330\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.30 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0260\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 56.56 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0036\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.84 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0034\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.40 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 6 ---\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.64 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0031\n",
      "-----------mse_loss mean :  0.8108 std: 1.6494\n",
      "Val: Accuracy: 0.8436  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (6, 1.1852837842416608, {1: 'k= 1 ,Test : Accuracy: 0.8662 Recall : 0.7041 FDR: 0.1945  F1-score: 0.7514 ', 3: 'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: 0.1408 '}, 4670.254546949996)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 7]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 2.46\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 93951, 1: 31481})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6122, 1: 10635, 3: 1, 4: 1, 5: 2, 6: 16, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.8662 Recall : 0.7041 FDR: 0.1945  F1-score: 0.7514 \n",
      " K: 3 K-SIGMA Threshold : ---thr 5.759\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 120433, 1: 4999})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2111, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: 0.1408 \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 33.53 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0020\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 34.08 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 32.25 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 33.97 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 33.74 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.19 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0257\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 56.79 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0037\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.43 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0034\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 56.71 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0032\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 56.72 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0031\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.76 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 1.6235\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.81 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.9938\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.76 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.6172\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.76 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.4692\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.79 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.4179\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 58.24 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0256\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 56.62 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0034\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 56.88 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0031\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.97 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.06 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0029\n",
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 7 ---\n",
      "-----------mse_loss mean :  0.8035 std: 1.6527\n",
      "Val: Accuracy: 0.8436  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (7, 1.1765548265195485, {1: 'k= 1 ,Test : Accuracy: 0.8661 Recall : 0.7038 FDR: 0.1946  F1-score: 0.7512 ', 3: 'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: 0.1408 '}, 5449.42424488)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 8]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 2.456\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 93960, 1: 31472})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6124, 1: 10646, 3: 1, 4: 1, 5: 2, 6: 16, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.8661 Recall : 0.7038 FDR: 0.1946  F1-score: 0.7512 \n",
      " K: 3 K-SIGMA Threshold : ---thr 5.762\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 120433, 1: 4999})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2111, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: 0.1408 \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 33.55 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0014\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 33.36 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 32.83 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 33.15 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 34.59 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.14 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0249\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.44 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0034\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 58.17 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0032\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.11 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0031\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.05 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0030\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.61 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0242\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 56.72 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0032\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.88 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0030\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.61 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0029\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.11 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0028\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.80 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 1.6159\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.76 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.9765\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.77 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.5993\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.77 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.4559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 8 ---\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.80 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.4069\n",
      "-----------mse_loss mean :  0.8121 std: 1.6656\n",
      "Val: Accuracy: 0.8436  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (8, 1.1878161573601633, {1: 'k= 1 ,Test : Accuracy: 0.8661 Recall : 0.7034 FDR: 0.1945  F1-score: 0.7510 ', 3: 'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: 0.1408 '}, 6231.007664300996)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 9]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 2.478\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 93983, 1: 31449})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6117, 1: 10662, 3: 1, 4: 1, 5: 2, 6: 16, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.8661 Recall : 0.7034 FDR: 0.1945  F1-score: 0.7510 \n",
      " K: 3 K-SIGMA Threshold : ---thr 5.809\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 120433, 1: 4999})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2111, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: 0.1408 \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.37 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0246\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 56.85 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0034\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 58.10 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0031\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.15 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0030\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.83 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0030\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 33.12 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0013\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 32.92 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 33.77 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 33.01 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 32.82 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 56.08 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0248\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.02 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0031\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 56.15 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0029\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 56.45 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0028\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 58.05 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0028\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.77 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 1.6036\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.80 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.9644\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.78 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.5867\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.78 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.4437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 9 ---\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.80 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.3962\n",
      "-----------mse_loss mean :  0.8224 std: 1.6737\n",
      "Val: Accuracy: 0.8437  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (9, 1.193619226951655, {1: 'k= 1 ,Test : Accuracy: 0.8650 Recall : 0.6995 FDR: 0.1950  F1-score: 0.7485 ', 3: 'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: 0.1408 '}, 7008.780781731999)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 10]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 2.496\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 94137, 1: 31295})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6104, 1: 10795, 2: 1, 3: 1, 4: 1, 5: 2, 6: 23, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.8650 Recall : 0.6995 FDR: 0.1950  F1-score: 0.7485 \n",
      " K: 3 K-SIGMA Threshold : ---thr 5.844\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 120433, 1: 4999})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2111, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: 0.1408 \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 33.20 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0011\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 33.36 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 33.44 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 32.89 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 32.08 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.78 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 1.5743\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.78 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.9403\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.80 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.5705\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.88 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.4332\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 0.79 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.3880\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 56.80 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0255\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 56.94 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0032\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 58.05 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0030\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.32 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0029\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.36 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0029\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 57.64 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0252\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 56.63 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0030\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 56.73 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0028\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 56.70 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 10 ---\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train : time 56.83 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=88009)\u001b[0m Train Loss: 0.0027\n",
      "-----------mse_loss mean :  0.8177 std: 1.6865\n",
      "Val: Accuracy: 0.8437  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (10, 1.1907898801741184, {1: 'k= 1 ,Test : Accuracy: 0.8626 Recall : 0.6910 FDR: 0.1969  F1-score: 0.7428 ', 3: 'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: 0.1408 '}, 7785.678264584996)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 10 round(s) in 7785.68s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, centralized):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 0: 17.26719856177052\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 1.5249920026388801\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 1.233013081789336\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 1.2357067723946042\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 4: 1.2048294843022513\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 5: 1.193427389940366\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 6: 1.1852837842416608\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 7: 1.1765548265195485\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 8: 1.1878161573601633\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 9: 1.193619226951655\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 10: 1.1907898801741184\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, centralized):\n",
      "\u001b[92mINFO \u001b[0m:      \t{1: [(0,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.7723 Recall : 0.2649 FDR: 0.1793  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.4005 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (1,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.6875 Recall : 0.0802 FDR: 0.6775  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1284 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (2,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.8665 Recall : 0.7040 FDR: 0.1936  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.7517 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (3,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.8662 Recall : 0.7037 FDR: 0.1942  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.7513 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (4,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.8663 Recall : 0.7041 FDR: 0.1943  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.7515 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (5,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.8663 Recall : 0.7041 FDR: 0.1944  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.7514 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (6,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.8662 Recall : 0.7041 FDR: 0.1945  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.7514 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (7,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.8661 Recall : 0.7038 FDR: 0.1946  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.7512 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (8,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.8661 Recall : 0.7034 FDR: 0.1945  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.7510 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (9,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.8650 Recall : 0.6995 FDR: 0.1950  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.7485 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (10,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.8626 Recall : 0.6910 FDR: 0.1969  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.7428 ')],\n",
      "\u001b[92mINFO \u001b[0m:      \t 3: [(0,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7358 Recall : 0.0802 FDR: 0.0028  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1484 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (1,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7234 Recall : 0.0802 FDR: 0.3525  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1427 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (2,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4217  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1408 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (3,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4217  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1408 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (4,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4217  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1408 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (5,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1408 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (6,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1408 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (7,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1408 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (8,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1408 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (9,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1408 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (10,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1408 ')]}\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 2.504\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 94443, 1: 30989})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6103, 1: 11100, 2: 1, 3: 1, 4: 1, 5: 2, 6: 23, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.8626 Recall : 0.6910 FDR: 0.1969  F1-score: 0.7428 \n",
      " K: 3 K-SIGMA Threshold : ---thr 5.877\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 120433, 1: 4999})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2111, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: 0.1408 \n",
      "Federated learning simulation finished.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==============================================================================\n",
    "#  DATA Distribution\n",
    "# ==============================================================================\n",
    "\n",
    "val_files = [col for col in modbus.dataset[\"benign_dataset_dir\"] if col.find(\"ied1b\")!=-1][:]\n",
    "test_files=[col for col in modbus.dataset[\"attack_dataset_dir\"][\"compromised-scada\"] if col.find(\"ied1b\")!=-1][:]\n",
    "\n",
    "SERVER_EVALUATION_DATA_MAPPING = {\n",
    "    0: val_files,\n",
    "    1: test_files \n",
    "}\n",
    "\n",
    "\n",
    "# --- Start the Simulation ---\n",
    "print(\"Starting federated learning simulation...\")\n",
    "history = fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=cfg.NUM_TRAIN_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=cfg.NUM_ROUNDS),\n",
    "    strategy=strategy,\n",
    "    client_resources={\"num_cpus\": 4, \"num_gpus\": 1/cfg.NUM_TRAIN_CLIENTS} if DEVICE.type == \"cuda\" else {\"num_cpus\": 4},\n",
    ")\n",
    "print(\"Federated learning simulation finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fad8408",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n",
      "\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n",
      "\n",
      "\t\t$ flwr new  # Create a new Flower app from a template\n",
      "\n",
      "\t\t$ flwr run  # Run the Flower app in Simulation Mode\n",
      "\n",
      "\tUsing `start_simulation()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=10, no round_timeout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded scalers for 'network-wide'\n",
      "Using Autoencoder (AE) \n",
      "Using FedAvg strategy with AE model.\n",
      "Starting federated learning simulation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-17 19:54:16,712\tINFO worker.py:1771 -- Started a local Ray instance.\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'accelerator_type:G': 1.0, 'node:__internal_head__': 1.0, 'node:172.27.10.149': 1.0, 'CPU': 4.0, 'memory': 5934887732.0, 'object_store_memory': 2967443865.0, 'GPU': 1.0}\n",
      "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 4, 'num_gpus': 0.25}\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 1 actors\n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 0 ---\n",
      "-----------mse_loss mean :  16.7737 std: 1.2341\n",
      "Val: Accuracy: 0.2198  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 17.40935726130493, {1: 'k= 1 ,Test : Accuracy: 0.7804 Recall : 0.2909 FDR: 0.1610  F1-score: 0.4320 ', 3: 'k= 3 ,Test : Accuracy: 0.7358 Recall : 0.0802 FDR: 0.0028  F1-score: 0.1484 '}\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 18.01\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 112945, 1: 12487})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2011, 1: 25524, 2: 1, 5: 1, 6: 13}\n",
      "k= 1 ,Test : Accuracy: 0.7804 Recall : 0.2909 FDR: 0.1610  F1-score: 0.4320 \n",
      " K: 3 K-SIGMA Threshold : ---thr 20.48\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 122536, 1: 2896})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 8, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7358 Recall : 0.0802 FDR: 0.0028  F1-score: 0.1484 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m /home/hamid_rd3/labeling/FLBased-ICS-NIDS-main/modbus.py:4: DeprecationWarning: \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m (to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m but was not found to be installed on your system.\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m If this would cause problems for you,\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m   import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 62.39 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 4.9510\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 64.90 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0899\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 65.37 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0248\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 64.64 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0102\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 62.92 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0072\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 61.80 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 4.9149\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 66.66 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0884\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 65.32 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0246\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 65.64 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0107\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 69.12 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0079\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.91 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 13.9217\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 1.04 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 13.7421\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.86 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 13.5123\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.89 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 13.2375\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.96 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 12.9291\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 36.04 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 9.0079\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 37.39 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.1132\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 38.32 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0069\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 38.39 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 36.43 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0059\n",
      "--- Running Evaluation for Server round 1 ---\n",
      "-----------mse_loss mean :  1.2197 std: 1.8407\n",
      "Val: Accuracy: 0.6983  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (1, 1.354145822039033, {1: 'k= 1 ,Test : Accuracy: 0.6877 Recall : 0.0806 FDR: 0.6764  F1-score: 0.1290 ', 3: 'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4216  F1-score: 0.1409 '}, 884.4892666769993)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 3.06\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 116465, 1: 8967})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6065, 1: 33078, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.6877 Recall : 0.0806 FDR: 0.6764  F1-score: 0.1290 \n",
      " K: 3 K-SIGMA Threshold : ---thr 6.742\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 120439, 1: 4993})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2105, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4216  F1-score: 0.1409 \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 63.31 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0562\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 66.35 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0074\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 58.53 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0062\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 60.72 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0054\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 60.19 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0046\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 39.78 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0070\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 35.10 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0026\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 36.36 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0012\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 35.71 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0008\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 37.16 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0006\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 61.31 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0560\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 60.99 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0068\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 61.99 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0055\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 60.28 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0048\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 63.72 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0043\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.85 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 1.9550\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.83 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 1.5817\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.81 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 1.3258\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.86 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 1.1459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 2 ---\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.81 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 1.0141\n",
      "-----------mse_loss mean :  0.8932 std: 1.5807\n",
      "Val: Accuracy: 0.8434  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (2, 1.2003784919318834, {1: 'k= 1 ,Test : Accuracy: 0.8363 Recall : 0.5985 FDR: 0.2200  F1-score: 0.6773 ', 3: 'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4217  F1-score: 0.1408 '}, 1729.8654816380003)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 2.474\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 97796, 1: 27636})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6080, 1: 14430, 2: 1, 3: 1, 4: 1, 5: 2, 6: 23, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.8363 Recall : 0.5985 FDR: 0.2200  F1-score: 0.6773 \n",
      " K: 3 K-SIGMA Threshold : ---thr 5.635\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 120438, 1: 4994})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2106, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4217  F1-score: 0.1408 \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 37.73 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0033\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 34.43 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0011\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 35.89 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0005\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 36.22 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0005\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 38.17 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0005\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 61.82 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0298\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 65.05 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0043\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 64.63 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0038\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 62.63 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0034\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 63.11 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0031\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.95 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 1.4605\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.87 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.9643\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 1.05 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.6818\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.99 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.5532\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.93 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.4984\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 64.28 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0305\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 68.29 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0048\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 61.16 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0040\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 56.61 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 3 ---\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 55.86 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0034\n",
      "-----------mse_loss mean :  0.8931 std: 1.7286\n",
      "Val: Accuracy: 0.8437  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (3, 1.2018531455290515, {1: 'k= 1 ,Test : Accuracy: 0.6876 Recall : 0.0806 FDR: 0.6766  F1-score: 0.1290 ', 3: 'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: 0.1408 '}, 2577.6864192520006)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 2.622\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 116458, 1: 8974})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6072, 1: 33078, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.6876 Recall : 0.0806 FDR: 0.6766  F1-score: 0.1290 \n",
      " K: 3 K-SIGMA Threshold : ---thr 6.079\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 120433, 1: 4999})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2111, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: 0.1408 \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 32.27 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0022\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 31.65 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0005\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 32.84 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 32.30 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 31.25 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.76 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 1.6610\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.78 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 1.0556\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.76 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.6646\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.75 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.4913\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.76 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.4293\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 56.22 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0298\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 55.07 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0035\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 55.09 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0031\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 56.37 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0029\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 55.05 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0028\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 56.34 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0300\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 56.07 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0037\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 56.64 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0033\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 57.16 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 4 ---\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 57.21 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0030\n",
      "-----------mse_loss mean :  0.8773 std: 1.7122\n",
      "Val: Accuracy: 0.8437  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (4, 1.1951348639103259, {1: 'k= 1 ,Test : Accuracy: 0.6873 Recall : 0.0806 FDR: 0.6779  F1-score: 0.1290 ', 3: 'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: 0.1408 '}, 3339.788373608997)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 2.589\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 116416, 1: 9016})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6112, 1: 33076, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.6873 Recall : 0.0806 FDR: 0.6779  F1-score: 0.1290 \n",
      " K: 3 K-SIGMA Threshold : ---thr 6.014\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 120433, 1: 4999})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2111, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: 0.1408 \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 33.55 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0017\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 32.77 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 32.13 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 32.67 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 32.67 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.78 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 1.6833\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.77 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 1.0478\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.76 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.6378\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.77 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.4647\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.77 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.4054\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 56.42 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0283\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 56.80 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0033\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 55.86 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0030\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 55.79 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0030\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 56.66 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0029\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 56.38 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0279\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 55.76 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0031\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 55.54 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0029\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 56.89 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 5 ---\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 55.37 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0027\n",
      "-----------mse_loss mean :  0.8570 std: 1.7237\n",
      "Val: Accuracy: 0.8437  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (5, 1.186398930296894, {1: 'k= 1 ,Test : Accuracy: 0.6872 Recall : 0.0807 FDR: 0.6784  F1-score: 0.1290 ', 3: 'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: 0.1408 '}, 4104.881800297)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 6]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 2.581\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 116396, 1: 9036})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6130, 1: 33074, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.6872 Recall : 0.0807 FDR: 0.6784  F1-score: 0.1290 \n",
      " K: 3 K-SIGMA Threshold : ---thr 6.028\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 120433, 1: 4999})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2111, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: 0.1408 \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 57.06 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0275\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 57.32 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0032\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 55.55 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0030\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 57.57 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0028\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 56.07 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0028\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.79 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 1.7288\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.78 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 1.0748\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.77 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.6456\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.79 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.4626\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.80 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.4000\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 56.73 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0276\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 57.30 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0030\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 55.86 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0028\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 56.68 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0027\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 55.33 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0026\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 32.50 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0015\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 33.30 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 32.48 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 31.54 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 6 ---\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 32.58 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0004\n",
      "-----------mse_loss mean :  0.8213 std: 1.6719\n",
      "Val: Accuracy: 0.8436  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (6, 1.1665915097423305, {1: 'k= 1 ,Test : Accuracy: 0.8304 Recall : 0.5803 FDR: 0.2276  F1-score: 0.6627 ', 3: 'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: 0.1408 '}, 4872.6566810179975)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 7]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 2.493\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 98376, 1: 27056})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6157, 1: 15081, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.8304 Recall : 0.5803 FDR: 0.2276  F1-score: 0.6627 \n",
      " K: 3 K-SIGMA Threshold : ---thr 5.837\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 120433, 1: 4999})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2111, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: 0.1408 \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 56.78 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0254\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 56.49 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0031\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 57.31 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0029\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 57.41 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0028\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 57.59 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0027\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 56.24 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0254\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 56.44 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0029\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 56.20 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0027\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 56.73 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0026\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 56.72 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0025\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.81 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 1.7258\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.82 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 1.0665\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.88 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.6391\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.93 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.4575\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.79 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.3936\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 32.53 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0015\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 33.32 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 32.99 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 32.81 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 7 ---\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 33.05 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0004\n",
      "-----------mse_loss mean :  0.8129 std: 1.6474\n",
      "Val: Accuracy: 0.8436  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (7, 1.1618739386679635, {1: 'k= 1 ,Test : Accuracy: 0.8568 Recall : 0.6724 FDR: 0.2028  F1-score: 0.7295 ', 3: 'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: 0.1408 '}, 5645.621542910998)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 8]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 2.46\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 95054, 1: 30378})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6160, 1: 11768, 2: 1, 3: 1, 4: 1, 5: 2, 6: 23, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.8568 Recall : 0.6724 FDR: 0.2028  F1-score: 0.7295 \n",
      " K: 3 K-SIGMA Threshold : ---thr 5.755\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 120433, 1: 4999})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2111, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: 0.1408 \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.78 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 1.7180\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.78 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 1.0646\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.79 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.6377\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.79 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.4555\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.81 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.3912\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 57.55 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0256\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 57.88 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0030\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 56.51 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0028\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 57.57 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0028\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 56.18 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0027\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 33.01 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0014\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 33.25 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 33.85 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 32.31 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 32.99 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 58.12 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0248\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 56.07 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0029\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 56.14 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0027\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 56.22 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 8 ---\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 55.96 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0025\n",
      "-----------mse_loss mean :  0.7961 std: 1.6208\n",
      "Val: Accuracy: 0.8350  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (8, 1.1531951824494546, {1: 'k= 1 ,Test : Accuracy: 0.8651 Recall : 0.7012 FDR: 0.1962  F1-score: 0.7490 ', 3: 'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: 0.1408 '}, 6419.847642654)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 9]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 2.417\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 94014, 1: 31418})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6164, 1: 10732, 2: 1, 3: 1, 4: 1, 5: 2, 6: 23, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.8651 Recall : 0.7012 FDR: 0.1962  F1-score: 0.7490 \n",
      " K: 3 K-SIGMA Threshold : ---thr 5.659\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 120433, 1: 4999})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2111, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: 0.1408 \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 33.36 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0012\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 32.79 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 32.73 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 32.92 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 34.11 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 54.79 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0258\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 56.14 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0028\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 56.39 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0026\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 57.06 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0025\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 56.68 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0025\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 57.18 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0249\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 57.21 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0030\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 57.48 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0028\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 56.27 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0027\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 57.45 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0027\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.82 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 1.6890\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.93 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 1.0426\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.85 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.6265\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.77 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.4497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.80 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.3875\n",
      "\n",
      "--- Running Evaluation for Server round 9 ---\n",
      "-----------mse_loss mean :  0.7928 std: 1.6180\n",
      "Val: Accuracy: 0.8424  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (9, 1.1514254237355699, {1: 'k= 1 ,Test : Accuracy: 0.8651 Recall : 0.7012 FDR: 0.1960  F1-score: 0.7491 ', 3: 'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: 0.1408 '}, 7192.826253883999)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 10]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 2.411\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 94024, 1: 31408})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6156, 1: 10734, 2: 1, 3: 1, 4: 1, 5: 2, 6: 23, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.8651 Recall : 0.7012 FDR: 0.1960  F1-score: 0.7491 \n",
      " K: 3 K-SIGMA Threshold : ---thr 5.647\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 120433, 1: 4999})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2111, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: 0.1408 \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.79 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 1.6613\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.80 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 1.0259\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.81 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.6170\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.84 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.4420\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 0.79 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.3813\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 56.93 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0260\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 57.87 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0029\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 57.78 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0027\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 59.89 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0027\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 56.23 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0026\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 56.24 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0252\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 57.61 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0027\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 56.27 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0026\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 56.92 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0025\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 54.97 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0025\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Using Autoencoder (AE) \n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 32.21 s Epoch 1\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0012\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 34.00 s Epoch 2\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 33.28 s Epoch 3\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0004\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 32.86 s Epoch 4\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Autoencoder (AE) \n",
      "--- Running Evaluation for Server round 10 ---\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train : time 33.18 s Epoch 5\n",
      "\u001b[36m(ClientAppActor pid=27250)\u001b[0m Train Loss: 0.0004\n",
      "-----------mse_loss mean :  0.8076 std: 1.6320\n",
      "Val: Accuracy: 0.8436  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (10, 1.1615170470852734, {1: 'k= 1 ,Test : Accuracy: 0.8614 Recall : 0.6885 FDR: 0.1990  F1-score: 0.7405 ', 3: 'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: 0.1408 '}, 7970.309693292998)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 10 round(s) in 7970.31s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, centralized):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 0: 17.40935726130493\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 1.354145822039033\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 1.2003784919318834\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 1.2018531455290515\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 4: 1.1951348639103259\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 5: 1.186398930296894\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 6: 1.1665915097423305\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 7: 1.1618739386679635\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 8: 1.1531951824494546\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 9: 1.1514254237355699\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 10: 1.1615170470852734\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, centralized):\n",
      "\u001b[92mINFO \u001b[0m:      \t{1: [(0,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.7804 Recall : 0.2909 FDR: 0.1610  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.4320 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (1,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.6877 Recall : 0.0806 FDR: 0.6764  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1290 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (2,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.8363 Recall : 0.5985 FDR: 0.2200  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.6773 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (3,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.6876 Recall : 0.0806 FDR: 0.6766  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1290 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (4,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.6873 Recall : 0.0806 FDR: 0.6779  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1290 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (5,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.6872 Recall : 0.0807 FDR: 0.6784  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1290 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (6,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.8304 Recall : 0.5803 FDR: 0.2276  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.6627 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (7,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.8568 Recall : 0.6724 FDR: 0.2028  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.7295 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (8,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.8651 Recall : 0.7012 FDR: 0.1962  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.7490 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (9,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.8651 Recall : 0.7012 FDR: 0.1960  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.7491 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (10,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 1 ,Test : Accuracy: 0.8614 Recall : 0.6885 FDR: 0.1990  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.7405 ')],\n",
      "\u001b[92mINFO \u001b[0m:      \t 3: [(0,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7358 Recall : 0.0802 FDR: 0.0028  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1484 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (1,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4216  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1409 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (2,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4217  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1408 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (3,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1408 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (4,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1408 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (5,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1408 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (6,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1408 '),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K: 1 K-SIGMA Threshold : ---thr 2.44\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 94474, 1: 30958})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 6162, 1: 11190, 2: 1, 3: 1, 4: 1, 5: 2, 6: 23, 7: 1}\n",
      "k= 1 ,Test : Accuracy: 0.8614 Recall : 0.6885 FDR: 0.1990  F1-score: 0.7405 \n",
      " K: 3 K-SIGMA Threshold : ---thr 5.704\n",
      "Counts of : original binary labels Counter({0: 89417, 1: 36015}) predicted binary labels Counter({0: 120433, 1: 4999})\n",
      "Counts of  predicted  labels: {0: 89417, 1: 35978, 2: 1, 3: 1, 4: 1, 5: 2, 6: 31, 7: 1}\n",
      "Counts of misclassified original labels: {0: 2111, 1: 33092, 2: 1, 3: 1, 4: 1, 5: 2, 6: 29, 7: 1}\n",
      "k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: 0.1408 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      \t     (7,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1408 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (8,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1408 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (9,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1408 '),\n",
      "\u001b[92mINFO \u001b[0m:      \t     (10,\n",
      "\u001b[92mINFO \u001b[0m:      \t      'k= 3 ,Test : Accuracy: 0.7191 Recall : 0.0802 FDR: 0.4223  F1-score: '\n",
      "\u001b[92mINFO \u001b[0m:      \t      '0.1408 ')]}\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Federated learning simulation finished.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# --- Start the Simulation ---\n",
    "print(\"Starting federated learning simulation...\")\n",
    "history = fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=cfg.NUM_TRAIN_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=cfg.NUM_ROUNDS),\n",
    "    strategy=strategy,\n",
    "    client_resources={\"num_cpus\": 4, \"num_gpus\": 1/cfg.NUM_TRAIN_CLIENTS} if DEVICE.type == \"cuda\" else {\"num_cpus\": 4},\n",
    ")\n",
    "print(\"Federated learning simulation finished.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7758849,
     "sourceId": 12309500,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 250292947,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "vnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
